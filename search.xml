<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>LeetCode《剑指Offer》题目情况整理（持续更新）</title>
    <url>/2022/02/03/b62f2c89d90c/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="0192ce36e4ee7d24b04030ddcc8d89f06e46601e641e4d34bff10701b72d421f">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>题集整理</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode 算法解题Tricks（持续更新）</title>
    <url>/2022/02/02/e7e76d98fb52/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="55a6b16c4e4a5ac6ecb2f5240d5e72ce8de1846c3af99dac2e58d45fad206649">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>题集整理</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记19——EMA指数滑动平均原理</title>
    <url>/2022/03/27/6de89f1d1ae9/</url>
    <content><![CDATA[<p>​ 在训练神经网络时，通常会使用一个叫 Exponential Moving Average (EMA) 的方法，中文名叫指数滑动平均。它的意义在于利用滑动平均的参数来<strong>提高模型在测试数据上的健壮性</strong>。</p>
<h4 id="一什么是滑动平均">一、什么是滑动平均？</h4>
<p>​ 滑动平均(exponential moving average)，或者叫做指数加权平均(exponentially weighted moving average)，可以用来估计变量的局部均值，使得变量的更新与一段时间内的历史取值有关。</p>
<p>​ 首先我们假设一个训练参数a，它在不同的epoch结束后的值分别为： <span class="math display">\[
a_1,a_2,a_3,……,a_t
\]</span> ​ <span class="math inline">\(a_1\)</span>代表第1轮epoch迭代结束后，可训练参数a的值，以此类推。</p>
<p>​ 然后，我们假设不同的epoch结束后，滑动平均的值分别为： <span class="math display">\[
 mv_1,mv_2,mv_3,……,mv_t
\]</span> ​ <span class="math inline">\(mv_1\)</span>代表第1轮epoch迭代结束后，滑动平均mv的值，以此类推。</p>
<p>​ 滑动平均计算的递推式如下： <span class="math display">\[
mv_t = decay * mv_{t-1} + (1-decay)*a_t
\]</span> ​ 其中，decay为衰减率，用于控制模型更新的速度。递推式中其实就是利用加权的思想，把新的a和先前的平均，做了一个相加。我们可以发现，再很多轮之后，有些离<span class="math inline">\(a_t\)</span>很远的a,它已经乘了很多遍decay，相当于权重为0，也就是不影响最新的<span class="math inline">\(mv_t\)</span>的值了。</p>
<p>​ 从直观意义上来看，我们可以把<span class="math inline">\(a_1,a_2,a_3,……,a_t\)</span> 看作是t个位置，然后想象有一个长度为k的窗口，从最前面开始向后滑动。为了方便说明，我们先假设k=3。最开始的时候，窗口把<span class="math inline">\(a_1\)</span>涵括在内，然后一个epoch过后窗口右移，现在窗口内有<span class="math inline">\(a_1,a_2\)</span>，再一个epoch过后窗口再右移，现在窗口内有<span class="math inline">\(a_1,a_2,a_3\)</span>，再一个epoch过后窗口再右移，此时由于窗口长度为3，所以<span class="math inline">\(a_1\)</span>就不在窗口内了，窗口内的元素为<span class="math inline">\(a_2,a_3,a_4\)</span>，从公式上来讲就是在此时，由于<span class="math inline">\(a_1\)</span>已经乘了较多遍数的decay衰减系数了，所以其的系数接近于0了，不会再影响窗口内计算的值了。</p>
<p>​ 故此称为滑动平均。</p>
<h4 id="二更为公式化的解读">二、更为公式化的解读：</h4>
<p>EMA 在实现时如下所述：</p>
<p>​ Exponential Moving Average 对每一个变量（ <span class="math inline">\(variable\)</span> ）会维护一个影子变量（ <span class="math inline">\(shadow\_variable\)</span> ），这个影子变量的初始值就是相应变量的初始值，而每次运行变量更新时，影子变量的值会更新为： <span class="math display">\[
shadow\_variable = decay * shadow\_variable + (1-decay) * variable
\]</span> ​ 其中：<span class="math inline">\(variable\)</span>为每一轮结束时，训练参数的值；<span class="math inline">\(shadow\_variable\)</span>为影子变量；<span class="math inline">\(decay\)</span>为衰减速率。</p>
<p>​ decay 决定了影子变量的更新速度，decay 越大影子变量越趋于稳定。在实际运用中，decay一般会设成非常接近 1 的数（比如0.999或0.9999）。</p>
<p>​ 为了使得影子变量在训练前期可以更新更快，Exponential Moving Average 还提供了 num_updates 参数动态设置 decay 的大小。如果在初始化 Exponential Moving Average 时提供了 num_updates 参数，那么每次使用的衰减率将是： <span class="math display">\[
decay = min\{decay,\frac{1+num\_updates}{10+num\_updates}\}
\]</span></p>
<h4 id="三什么时候用到ema">三、什么时候用到EMA？</h4>
<p>请注意：</p>
<p>​ <strong>EMA不参与实际的训练过程，是用在测试过程的</strong>！</p>
<p>​ <strong>EMA不参与实际的训练过程，是用在测试过程的</strong>！</p>
<p>​ <strong>EMA不参与实际的训练过程，是用在测试过程的</strong>！</p>
<p>​ 在训练过程中，EMA只是以一个记录者的身份，在进行记录。实际的实现中，如果你在正常训练的网络是network['C']，那么你可以再实例化一个新的网络，叫做network['C_EMA'],其最初和network['C']一模一样，但是network['C_EMA']并不参与实际记录，其里面的参数只是用来记录滑动平均！！！<strong>（这就是DG-Font代码中，network['C_EMA']的作用）</strong></p>
<p>​ EMA作用是<strong>使得模型在测试数据上更加健壮，有更好的鲁棒性。或者是最后save模型时存储ema的值，取最近n次的近似平均值，使模型具备更好的测试指标(accuracy)等，更强的泛化能力。</strong></p>
<p>参考：</p>
<p>https://zhuanlan.zhihu.com/p/51672655</p>
<p>https://zhuanlan.zhihu.com/p/343210667</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>EMA</tag>
      </tags>
  </entry>
  <entry>
    <title>SCI EI 核心期刊以及计算机领域CCF会议等级分类文件</title>
    <url>/2022/03/17/58ef9be2b7d9/</url>
    <content><![CDATA[<h4 id="一sci">一、SCI：</h4>
<p>​ 美国《科学引文索引》，SCI(科学引文索引 )、EI(工程索引 )、ISTP(科技会议录索引 ) 是世界著名的三大科技文献检索系统，是国际公认的进行科学统计与科学评价的主要检索工具，其中以SCI最为重要。</p>
<p>​ 一般SCI<strong>侧重科学前沿理论</strong>，审核标准严格，发稿周期也比较长。</p>
<h4 id="二ei">二、EI：</h4>
<p>​ 《工程索引》（The Engineering Index, 简称EI）是供查阅<strong>工程技术领域文献</strong>的综合性情报检索刊物。</p>
<p>​ EI的主要特点是摘录质量较高，文摘直接按字顺排列，索引简便实用</p>
<h4 id="三核心期刊">三、核心期刊</h4>
<p>​ 在国内简单地说，核心期刊是学术界通过一整套科学的方法，对于期刊质量进行跟踪评价，并以情报学理论为基础，将期刊进行分类定级，把最为重要的一级称之为核心期刊。</p>
<ul>
<li>（1）北京大学图书馆“中文核心期刊”，这个的认可度一般最高。</li>
<li>（2）南京大学“中文社会科学引文索引（CSSCI）来源期刊”。</li>
<li>（3）中国科学院文献情报中心“中国科学引文数据库（CSCD）来源期刊”。</li>
<li>（4）中国科学技术信息研究所“中国科技论文统计源期刊”（又称“中国科技核心期刊”）。</li>
<li>（5）中国社会科学院文献信息中心“中国人文社会科学核心期刊”。</li>
<li>（6）中国人文社会科学学报学会“中国人文社科学报核心期刊”。</li>
</ul>
<h4 id="四中国计算机学会ccf推荐中文科技期刊目录">四、中国计算机学会CCF推荐中文科技期刊目录</h4>
<p>​ <a href="https://my-blog-fantast.oss-cn-hangzhou.aliyuncs.com/%E4%B8%AD%E5%9B%BD%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E4%BC%9A%E6%8E%A8%E8%8D%90%E4%B8%AD%E6%96%87%E7%A7%91%E6%8A%80%E6%9C%9F%E5%88%8A%E7%9B%AE%E5%BD%95.pdf">点我下载 中国计算机学会推荐中文科技期刊目录PDF</a></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/1123qwdsa.jpg" /></p>
<p>![中国计算机学会推荐中文科技期刊目录(1)_页面_3](https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/中国计算机学会推荐中文科技期刊目录(1)_页面_3.jpg)</p>
<p>![中国计算机学会推荐中文科技期刊目录(1)_页面_4](https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/中国计算机学会推荐中文科技期刊目录(1)_页面_4.jpg)</p>
<p>![中国计算机学会推荐中文科技期刊目录(1)_页面_5](https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/中国计算机学会推荐中文科技期刊目录(1)_页面_5.jpg)</p>
<h4 id="五中国计算机学会ccf推荐国际学术会议和期刊目录">五、中国计算机学会CCF推荐国际学术会议和期刊目录</h4>
<p>​ <a href="https://my-blog-fantast.oss-cn-hangzhou.aliyuncs.com/%E4%B8%AD%E5%9B%BD%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%A6%E4%BC%9A%E6%8E%A8%E8%8D%90%E5%9B%BD%E9%99%85%E5%AD%A6%E6%9C%AF%E4%BC%9A%E8%AE%AE%E5%92%8C%E6%9C%9F%E5%88%8A%E7%9B%AE%E5%BD%95.pdf">点我下载 中国计算机学会推荐国际学术会议和期刊目录 PDF</a></p>
<p>参考：https://zhuanlan.zhihu.com/p/57932081</p>
]]></content>
      <categories>
        <category>⓻ 经验整理类笔记</category>
      </categories>
  </entry>
  <entry>
    <title>字体生成效果评价指标</title>
    <url>/2022/03/16/827639831232/</url>
    <content><![CDATA[<h4 id="一intersection-over-unioniou">一、Intersection-Over-Union（IOU）</h4>
<p>​ 计算两个矩形的交并比，通常在检测任务里面可以作为一个检测指标。往往可用于目标检测和语义分割。将预测框与ground truth框之间的交集比上两者的并集。</p>
<p>​ 应用到字体生成任务中，如下所示：img1和img2是参考字体图和生成字体图。由于生成的字体图像像素值很纯粹，所以我们认为 像素值&lt;127的为黑字部分，像素值&gt;=127的为白底部分</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_iou</span>(<span class="params">img1, img2</span>):</span></span><br><span class="line">    img1_change = np.where(img1 &lt; <span class="number">127</span>, <span class="number">0</span>, -<span class="number">1</span>)  <span class="comment"># 黑字部分保留，白底部分变为-1，黑字部分统一为0</span></span><br><span class="line">    img2_change = np.where(img2 &lt; <span class="number">127</span>, <span class="number">0</span>, -<span class="number">2</span>)  <span class="comment"># 黑字部分保留，白底部分变为-2，黑字部分统一为0</span></span><br><span class="line">    black_num1 = img1_change[img1_change==<span class="number">0</span>].shape[<span class="number">0</span>] <span class="comment"># 黑字部分的像素数</span></span><br><span class="line">    black_num2 = img2_change[img2_change==<span class="number">0</span>].shape[<span class="number">0</span>] <span class="comment"># 黑字部分的像素数</span></span><br><span class="line">    intersection_num = img1_change[img1_change == img2_change].shape[<span class="number">0</span>] <span class="comment"># img1 和 img2 黑字部分交叉的像素数</span></span><br><span class="line">    total_num = black_num1 + black_num2 - intersection_num <span class="comment"># 总像素数（img1 和 img2 黑字部分并集的像素数）</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;compute_iou:&#x27;</span>, total_num, intersection_num, black_num1, black_num2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> intersection_num / total_num</span><br></pre></td></tr></table></figure>
<h4 id="二rmse">二、RMSE</h4>
<p>​ 均方根误差亦称标准误差, 用 真实值-预测值 然后平方之后求和平均,最后再开根号。 <span class="math display">\[
\sqrt{\frac{1}{m} \sum_{i=1}^m(y_i - \hat y_i)^2  }
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_rmse</span>(<span class="params">img1, img2</span>):</span></span><br><span class="line">    img1 = img1 / <span class="number">255</span></span><br><span class="line">    img2 = img2 / <span class="number">255</span></span><br><span class="line">    mse = np.mean((img1 - img2) ** <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> np.sqrt(mse)</span><br></pre></td></tr></table></figure>
<h4 id="三l1-loss">三、L1 Loss</h4>
<p><span class="math display">\[
\frac{1}{m} \sum_{i=1}^mabs(y_i - \hat y_i)
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_l1_loss</span>(<span class="params">img1, img2</span>):</span></span><br><span class="line">    img1 = img1 / <span class="number">255</span></span><br><span class="line">    img2 = img2 / <span class="number">255</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(np.<span class="built_in">abs</span>(img1 - img2))</span><br></pre></td></tr></table></figure>
<h4 id="四structural-similarityssim">四、<strong>Structural Similarity</strong>（SSIM）</h4>
<p>​ 结构相似性，是一种衡量两幅图像相似度的指标。SSIM使用的两张图像中，一张为未经压缩的无失真图像，另一张为失真后的图像。</p>
<p>​ 给定两个图像x和y , 两张图像的结构相似性可按照以下方式求出：</p>
<p><img src="https://bkimg.cdn.bcebos.com/formula/cdebeba369b6159f2e3fa5364412f4ff.svg" /></p>
<p>​ 其中<span class="math inline">\(u_x\)</span>是<span class="math inline">\(x\)</span>的平均值，<span class="math inline">\(u_y\)</span>是<span class="math inline">\(y\)</span>的平均值，<span class="math inline">\(\sigma_x\)</span>是x的方差，<span class="math inline">\(\sigma_y\)</span>是y的方差，<span class="math inline">\(\sigma_{xy}\)</span>是x和y的协方差，</p>
<p><span class="math inline">\(c_1=(k_1L)^2\)</span> 和<span class="math inline">\(c_2=(k_2L)^2\)</span>是用来维持稳定的常数。<span class="math inline">\(L\)</span>是像素值的动态范围。<span class="math inline">\(k_1=0.01\)</span>,<span class="math inline">\(k_2=0.03\)</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage.metrics <span class="keyword">import</span> structural_similarity</span><br><span class="line"></span><br><span class="line">structural_similarity(output_img, target_img)</span><br></pre></td></tr></table></figure>
<h4 id="五peak-signal-noise-ratio-psnr">五、Peak Signal Noise Ratio( PSNR )</h4>
<p>​ 峰值信噪比，是一种评价图像的客观标准，它具有局限性，一般是用于最大值信号和背景噪音之间的一个工程项目。在图像处理中，要对图像进行客观的评价，常常需要计算<em>PSNR。PSNR</em>是衡量图像失真或是噪声水平的客观标准。2个图像之间的PSNR值越大，则越相似。普遍基准为30dB，30dB以下的图像劣化较为明显。</p>
<p>​ 定义： <span class="math display">\[
PSNR = 10log_{10}(\frac{MAX^2}{MSE})
\]</span> ​ MAX表示图像颜色的最大数值，8bit图像最大取值为255</p>
<p>​ MSE为均方差，定义为如下内容： <span class="math display">\[
MSE = \frac{1}{mn}\sum^{n}_{i=1}\sum^{m}_{j=1}||K(i,j)-I(i,j)||^2
\]</span> ​ 其中，<strong>I</strong>和<strong>K</strong>分辨是原始图像和处理后的图像，<strong><em>m*n</em></strong>为两图像的大小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> skimage.metrics <span class="keyword">import</span> peak_signal_noise_ratio</span><br><span class="line"></span><br><span class="line">peak_signal_noise_ratio(output_img, target_img)</span><br></pre></td></tr></table></figure>
<h4 id="六frechet-inception-distance-score-fid">六、Frechet Inception Distance Score( FID )</h4>
<p>​ Frechet Inception 距离得分（Frechet Inception Distance score，FID）是计算真实图像和生成图像的<strong>特征向量之间距离的一种度量</strong>。</p>
<p>​ FID 分数被用于评估由生成性对抗网络生成的图像的质量，较低的分数与较高质量的图像有很高的相关性。 <span class="math display">\[
FID = ||u_r - u_g||^2 + T_r(\sum_r + \sum_g = 2(\sum_r\sum_g)^{1/2})
\]</span> ​ <span class="math inline">\(u\)</span>为经验均值，<span class="math inline">\(\sum\)</span> 为经验协方差，<span class="math inline">\(T_r\)</span>为矩阵的迹，<span class="math inline">\(r\)</span>代表真实数据集，<span class="math inline">\(g\)</span>代表生成数据集。</p>
<p><strong>FID的计算过程为：</strong></p>
<ul>
<li><p>对目标数据集的N张图片使用InceptionV3生成N*2048的向量，取平均值，得到<span class="math inline">\(u_r\)</span> 。</p></li>
<li><p>对生成的M张图片使用InceptionV3生成M*2048的向量，取平均得到<span class="math inline">\(u_g\)</span>。</p></li>
<li><p>通过<span class="math inline">\(u_r\)</span> 和 <span class="math inline">\(u_g\)</span> 得到 <span class="math inline">\(\sum_r\)</span>和<span class="math inline">\(\sum_g\)</span>最后得到FID。</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> fid</span><br><span class="line"></span><br><span class="line">fid_value = fid.calculate_fid_given_paths([output_dir, target_dir], <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>FID优势：</p>
<blockquote>
<p>1、生成模型的训练集和 Inception V3 的训练集可以不同。 2、计算 FID 时同时用到了生成的数据和真实数据，比起 IS 来更灵活。可以理解成，IS 判断真实性与否，是把生成数据和 ImageNet 数据做比较，而 FID 是把生成数据和训练数据做比较，因此更 reasonable。 3、以优化 FID 为目标，不会产生对抗样本。因为优化的是 lantent space feature，不是最终的输出图片，不会导致最终的生成图片失真。</p>
</blockquote>
<p>FID 问题：</p>
<blockquote>
<p>1、FID 只是某一层的特征的分布，是否足以衡量真实数据分布与生成数据分布的距离？同时，提出 FID 公式计算的是多元正态分布的距离，显然神经网络提取的特征并不是多元正态分布。 2、针对同一个生成模型，不同框架下预训练的 Inception V3 算出的 FID 差别是否可以忽略？ F3、ID 无法反映生成模型过拟合的情况，如果某个生成模型只是简单拷贝训练数据，FID 会非常小，认为这是一个完美的生成模型，因此，使用 FID 时同时也要通过别的手段证明生成模型没有过拟合。</p>
</blockquote>
<h4 id="七四象限评估">七、四象限评估：</h4>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/%7B58D5EE05-1CD3-1E12-45C6-0A5D78F53358%7D.png" alt="四象限评估准则" /><figcaption aria-hidden="true">四象限评估准则</figcaption>
</figure>
<p>​ <strong>D1：</strong>已知内容、已知风格</p>
<p>​ <strong>D2：</strong>未知内容、已知风格</p>
<p>​ <strong>D3：</strong>已知内容、未知风格</p>
<p>​ <strong>D4：</strong>未知内容、未知风格</p>
<p>参考：https://zhuanlan.zhihu.com/p/99375611</p>
]]></content>
      <categories>
        <category>⓪ 深度学习笔记</category>
        <category>字体生成项目</category>
      </categories>
      <tags>
        <tag>Font Generation</tag>
        <tag>Evaluation</tag>
      </tags>
  </entry>
  <entry>
    <title>2.1 进程与线程的基本概念</title>
    <url>/2022/03/14/32aa5a2632ac/</url>
    <content><![CDATA[<p>笔记课程视频：https://www.bilibili.com/video/BV1YE411D7nH?p=12</p>
<h3 id="一进程的定义组成和组织方式">一、进程的定义、组成和组织方式</h3>
<h4 id="进程的由来">1、进程的由来：</h4>
<p>程序本身其实就是一个指令序列。</p>
<p>早期的计算机只支持单道程序，程序运行时，内存中会分配两块区域：</p>
<ul>
<li>程序段：程序的代码放在程序段内</li>
<li>数据段：程序运行过程处理的数据放在数据段内</li>
</ul>
<p>​ 引入多道程序技术后，内存中需要存放多道程序：</p>
<p>​ <strong>为方便操作系统管理，完成个程序并发执行</strong>，故而操作系统为每个运行的程序配置一个数据结构，被称为<strong>进程控制块（PCB）</strong>，用于描述进程的各种信息（比如该进程程序代码存放位置等）。</p>
<h4 id="进程的定义">2、进程的定义：</h4>
<p>​ <strong>PCB、程序段、数据段</strong>三部分构成了<strong>进程实体</strong>。<strong>所谓创建进程，实质上是创建进程实体中的PCB；</strong>而撤销进程，实质上是撤销进程实体中的PCB。</p>
<p>​ PCB是进程存在的唯一标志。</p>
<p>​ 引入进程实体的概念后，可把进程定义为：<strong>进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。</strong>注：严格来说，进程实体和进程并不一样，进程实体是静态的，进程则是动态的。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220314212804178.png" style="zoom:50%;" /></p>
<h4 id="进程组成">3、进程组成：</h4>
<h5 id="进程由以下三部分组成">1）进程由以下三部分组成：</h5>
<ul>
<li>PCB：进程的管理者所需的数据都在PCB中</li>
<li>程序段：存放要执行的代码</li>
<li>数据段：存放程序运行过程中处理的各种数据</li>
</ul>
<h5 id="pcb结构体中包含如下内容">2）PCB结构体中包含如下内容：</h5>
<ul>
<li>进程描述信息
<ul>
<li>进程标识符PID</li>
<li>用户标识符UID</li>
</ul></li>
<li>进程控制和管理信息
<ul>
<li>进程当前状态</li>
<li>进程优先级</li>
</ul></li>
<li>资源分配清单
<ul>
<li>程序段指针</li>
<li>数据段指针</li>
<li>键盘、鼠标</li>
</ul></li>
<li>处理机相关信息
<ul>
<li>各种寄存器的值</li>
</ul></li>
</ul>
<h4 id="进程的组织多个进程间">4、进程的组织：（多个进程间）</h4>
<h5 id="链接方式">1）链接方式</h5>
<p>按照进程状态将PCB分为多个队列，操作系统持有指向各个队列的指针</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220314221020998.png" alt="进程组织的链接方式" style="zoom: 50%;" /></p>
<h5 id="索引方式">2）索引方式</h5>
<p>​ 根据进程状态的不同，建立几张索引表，操作系统持有指向各个索引表的指针</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220314221055019.png" alt="进程组织的索引方式" style="zoom:50%;" /></p>
<h4 id="进程的特征">5、进程的特征：</h4>
<ul>
<li><strong>动态性（最基本特征）</strong>：进程是程序的一次执行过程，是动态地产生、变化和消亡的</li>
<li><strong>并发性：</strong>内存中有多个进程实体，各进程可并发执行</li>
<li><strong>独立性：</strong>进程是能独立运行、独立获得资源、独立接受调度的基本单位</li>
<li><strong>异步性：</strong>各进程按各自独立的、不可预知的速度向前推进，操作系统要提供“进程同步机制"来解决异步问题。异步性可能会导致并发程序执行结果的不确定性。</li>
<li><strong>结构性：</strong>每个进程都会配置一个PCB。结构上看，进程由程序段、数据段、PCB组成</li>
</ul>
<h3 id="二进程的状态和转换">二、进程的状态和转换</h3>
<h4 id="进程的三种基本状态">1、进程的三种基本状态：</h4>
<h5 id="运行态占用cpu并在cpu上运行">1）运行态：占用CPU，并在CPU上运行。</h5>
<p>​ 注意：单核处理机环境下，每一时刻最多见有一个进程处于运行态。（双核环境下可以同时有两个进程处于运</p>
<p>行态）。</p>
<h5 id="就绪态已经具备运行条件但由于没有空闲cpu而暂时不能运行">2）就绪态：已经具备运行条件，但由于没有空闲CPU，而暂时不能运行</h5>
<p>​ 进程已经拥有了除处理机之外所有需要的资源，一旦获得处理机，即可立即进入运行态开始运行。 即：万事俱备，只欠CPU即：万事俱备，只欠CPU</p>
<h5 id="阻塞态因等待某一事件而暂时不能运行">3）阻塞态：因等待某一事件而暂时不能运行</h5>
<p>​ 如：等待操作系统分配打印机、等待读磁盘操作的结果。CPU是计算机中最昂贵的部件，为了提高CPU的利用率，需要先将其他进程需要的资源分配到位，才能得到CPU的服务</p>
<h4 id="进程的另外两种状态">2、进程的另外两种状态：</h4>
<h5 id="创建态进程正在被创建操作系统为进程分配资源初始化pcb进程正在被创建操作系统为进程分配资源初始化pcb">1）创建态：进程正在被创建，操作系统为进程分配资源、初始化PCB进程正在被创建，操作系统为进程分配资源、初始化PCB</h5>
<p>​ 操作系统需要完成创建进程。操作系统为该进程分配所需的内存空间等系统资源，并为其创建、初始化PCB（如：为进程分配PID）</p>
<h5 id="终止态进程正在从系统中撤销操作系统会回收进程拥有的资源撤销pcb进程正在从系统中撤销操作系统会回收进程拥有的资源撤销pcb">2）终止态：进程正在从系统中撤销，操作系统会回收进程拥有的资源、撤销PCB进程正在从系统中撤销，操作系统会回收进程拥有的资源、撤销PCB</h5>
<p>​ 进程运行结束（或者由于bug导致进程无法继续执行下去，比如数组越界错误），需要撤销进程。操作系统需要完成撤销进程相关的工作。完成将分配给进程的资源回收，撤销进程PCB等工作</p>
<h4 id="进程状态的转换">2、进程状态的转换：</h4>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220314223023656.png" alt="进程状态转换图" /><figcaption aria-hidden="true">进程状态转换图</figcaption>
</figure>
<ul>
<li><p>运行态→阻塞态是一种进程自身做出的<strong>主动行为</strong></p></li>
<li><p>阻塞态→就绪态是不是进程自身能控制的，是一种<strong>被动行为</strong>。</p></li>
<li><p>注意：<strong>不能由阻塞态直接转换为运行态</strong>，<strong>也不能由就绪态直接转换为阻塞态</strong>（因为进入阻塞态是进程主动请求的，必然需要进程在运行时才能发出这种请求）</p></li>
</ul>
<h3 id="三进程控制">三、进程控制</h3>
<h4 id="什么是进程控制">1、什么是进程控制：</h4>
<p>​ 进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能。</p>
<h4 id="如何实现进程控制">2、如何实现进程控制：</h4>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220314223828760.png" style="zoom:50%;" /></p>
<ul>
<li>创建进程：需要初始化PCB、分配系统资源</li>
<li>创建态→就绪态：需修改PCB内容和相应队列</li>
<li>就绪态→运行态：需恢复进程运行环境、修改PCB内容和相应队列</li>
<li>运行态→阻塞态：需保存进程运行环境、修改PCB内容和相应队列</li>
<li>阻塞态→就绪态：需修改PCB内容和相应队列。如果等待的是资源，则还需为进程分配系统资源</li>
<li>运行态→就绪态：（进程切换）需保存进程运行环境、修改PCB内容和相应队列</li>
<li>运行态→终止态：需回收进程拥有的资源，撤销PCB的资源，撤销PCB</li>
</ul>
<p>​ 为了使得进程状态切换中，数据具有一致性（类似于事务的概念），用<strong>原语</strong>实现进程控制。原语的特点是执行期间不允许中断，只能一气呵成。</p>
<p><strong>这种不可被中断的操作即原子操作。</strong></p>
<p><strong>原语采用“关中断指令”和“开中断指令”实现，如下所示</strong>：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220314224013167.png" alt="" style="zoom: 67%;" /></p>
<p>​ 当在关中断指令执行后，如果系统收到外部中断信号，此时会将该信号转至开中断指令结束后再进行处理，即再开中断指令执行结束后，才会启动中断处理程序。如此，原语部分的代码就不会被打断执行。</p>
<p>​ 显然，<strong>关/开中断指令的权限非常大，必然是只允许在核心态下执行的特权指令</strong></p>
<p>​</p>
<h4 id="原语的具体操作">3、原语的具体操作：</h4>
<h5 id="进程控制会导致进程状态的转换无论哪个原语要做的无非三类事情">进程控制会导致进程状态的转换。无论哪个原语，要做的无非三类事情：</h5>
<ul>
<li>1.更新PCB中的信息（如修改进程状态标志、将运行环境保存到PCB、从PCB恢复运行环境）
<ul>
<li>a.所有的进程控制原语一定都会修改进程状态标志</li>
<li>b.剥夺当前运行进程的CPU使用权必然需要保存其运行环境</li>
<li>c.某进程开始运行前必然要恢复期运行环境</li>
</ul></li>
<li>2.将PCB插入合适的队列</li>
<li>3.分配/回收资源</li>
</ul>
<h5 id="创建原语无创建态就绪态">1）创建原语：（无→创建态→就绪态）</h5>
<p>申请空白PCB、为新进程分配所需资源、初始化PCB、将PCB插入就绪队列</p>
<h5 id="能够引起进程创建的事件如下">能够引起进程创建的事件如下：</h5>
<ul>
<li>用户登录：分时系统中，用户登录成功，系统会建立为其建立一个新的进程</li>
<li>作业调度：多道批处理系统中，有新的作业放入内存时，会为其建立一个新的进程引起进程创建的事件 l引起进程创建的事件</li>
<li>提供服务：用户向操作系统提出某些请求时，会新建一个进程处理该请求</li>
<li>应用请求：由用户进程主动请求创建一个子进程</li>
</ul>
<h5 id="撤销原语就绪态阻塞态运行态终止态无">2）撤销原语：（就绪态/阻塞态/运行态→终止态→无）</h5>
<p>​ 从PCB集合中找到终止进程的PCB，若进程正在运行，立即剥夺CPU，将CPU分配给其他进程。终止其所有子进程，将该进程拥有的所有资源归还给父进程或操作系统。删除PCB</p>
<h5 id="能够引起进程撤销的事件如下">能够引起进程撤销的事件如下：</h5>
<ul>
<li>正常结束</li>
<li>异常结束</li>
<li>外界干预</li>
</ul>
<h5 id="阻塞原语运行态阻塞态">3）阻塞原语：（运行态→阻塞态）</h5>
<p>​ 找到要阻塞的进程对应的PCB，保护进程运行现场，将PCB状态信息设置为“阻塞态”，暂时停止进程运行，将PCB插入相应事件的等待队列。</p>
<p><strong>能够引起进程阻塞的事件如下：</strong></p>
<ul>
<li>需要等待系统分配某种资源</li>
<li>需要等待相互合作的其他进程完成工作</li>
</ul>
<h5 id="唤醒原语阻塞态运行态">4）唤醒原语：（阻塞态→运行态）</h5>
<p>​ 在事件等待队列中找到PCB，将PCB从等待队列移除，设置进程为就绪态，将PCB插入就绪队列，等待被调度</p>
<p><strong>能够引起进程唤醒的事件如下：</strong></p>
<ul>
<li>正在等待的事件发生（因何事阻塞，就应当由何事唤醒，需与阻塞原语成对使用）</li>
</ul>
<h5 id="切换原语运行态阻塞态就绪态-或-就绪态运行态">5）切换原语：（运行态→阻塞态/就绪态 或 就绪态→运行态）</h5>
<p>​ 将运行环境信息存入PCB，PCB移入相应队列。选择另一个进程执行，并更新其PCB，根据PCB恢复新进程所需的运行环境</p>
<p><strong>能够引起进程切换的事件如下：</strong></p>
<ul>
<li>当前进程时间片到</li>
<li>有更高优先级的进程到达</li>
<li>当前进程主动阻塞</li>
<li>当前进程终止</li>
</ul>
<h3 id="四进程通信">四、进程通信：</h3>
<h4 id="什么是进程通信">1、什么是进程通信？</h4>
<p>​ 进程通信就是指进程之间的信息交换。进程是分配系统资源的单位（包括内存地址空间），因此<strong>各进程拥有的内存地址空间相互独立。</strong>进程1可以访问进程1的地址空间，但不能直接访问进程2的地址空间。</p>
<p>​ <strong>为了保证安全，一个进程不能直接访问另一个进程的地址空间，但是进程之间的信息交换是必须实现的，为了保证进程间的安全通信，操作系统提供了一些方法就是进程通信</strong></p>
<h4 id="进程通信共享存储-方法">2、进程通信——共享存储 方法</h4>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315171055164.png" alt="共享存储" style="zoom: 67%;" /></p>
<p>​ 两个进程对共享空间的访问必须是互斥的（互斥访问通过操作系统提供的工具实现）。</p>
<p>​ 操作系统只负责提供共享空间和同步互斥工具（如P、V操作）</p>
<p>​ <strong>其又有两种方式</strong>：</p>
<ul>
<li><p>基于数据结构的共享</p>
<p>​ 基于数据结构的共享：比如共享空间里只能放一个长度为10的数组。这种共享方式<strong>速度慢、限制多，是一种低级通信方式</strong></p></li>
<li><p>基于存储区的共享</p>
<p>​ 基于存储区的共享：在内存中画出一块共享存储区，<strong>数据的形式、存放位置都由进程控制，而不是操作系统。</strong>相比之下，这种共享方式<strong>速度更快，是一种高级通信方式。</strong></p></li>
</ul>
<h4 id="进程通信管道通信-方法">3、进程通信——管道通信 方法</h4>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315171447871.png" alt="管道通信" /><figcaption aria-hidden="true">管道通信</figcaption>
</figure>
<p>​ “管道”是指用于连接读写进程的一个共享文件，又名pipe程的一个共享文件，又名pipe 文件。其实就是<strong>在内存中开辟一个大小固定的缓冲区 </strong></p>
<ul>
<li>管道只能采用半双工通信，某一时间段内只能实现单向的传输。如果要实现双向同时通信，则需要设置两个管道。</li>
<li>各个进程需要互斥的访问管道</li>
<li>数据以字符流的形式写入管道，<strong>当管道写满时，写进程的write（）系统调用将被阻塞</strong>，等待读进程将数据取走。<strong>当读进程将数据全部取走后，管道变空，此时读进程的read（）系统调用将被阻塞。</strong></li>
<li><strong>如果没写满，就不允许读。如果没读空，就不允许写。</strong></li>
<li><strong>数据一旦被读出，就从管道中被抛弃，这就意味着读进程最多只能有一个，否则可能会有读错数据的情</strong></li>
</ul>
<h4 id="进程通信消息传递-方法">4、进程通信——消息传递 方法</h4>
<p>​ 进程间的数据交换<strong>以格式化的消息（Message）为单位</strong>。进程通过操作系统提供的<strong>“发送消息/接收消息”两个原语进行数据交换</strong>。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315180227145.png" /></p>
<p>​ 消息头包括：发送进程ID、接受进程ID、消息类型、消息长度等格式化的信息</p>
<p>​ 每个进程都会有一个消息缓冲队列：消息传递有以下两种方式：</p>
<ul>
<li>直接通信方式: 消息直接挂到接受进程的消息缓冲队列上
<ul>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315180138885.png" /></li>
</ul></li>
<li>间接通信方式：消息先发送到中间实体中
<ul>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315180217571.png" /></li>
</ul></li>
</ul>
<h3 id="五线程概念和多线程模型">五、线程概念和多线程模型：</h3>
<h4 id="什么是线程">1、什么是线程？</h4>
<p>​ 在传统的机制中，<strong>进程是程序执行流的最小单位。</strong></p>
<p>​ <strong>有的进程</strong>可能需要“同时”做很多事，而传统的进程只能串行地执行一系列程序。为此，引入了“线程”，来增加并发度。</p>
<p>​ 一个进程中，被分为多个线程。CPU轮流为不同的线程服务。故而，引入线程后，<strong>线程是程序执行流的最小单位。</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315180730244.png" style="zoom:67%;" /></p>
<p>​</p>
<p><strong>官方定义：线程是一个基本的CPU执行单元，也是程序执行流的最小单位。</strong></p>
<p>​ 引入线程之后，不仅是进程之间可以并发，进程内的各线程之间也可以并发，从而进一步提升了系统的并发度，使得一个进程内也可以并发处理各种任务</p>
<p>​ 引入线程后，<strong>进程只作为除CPU之外的系统资源的分配单元</strong>（如打印机、内存地址空间等都是分配给进程的），<strong>线程才是CPU的执行单元</strong>（而CPU是分配给不同的线程的）</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315181019487.png" alt="引入线程后的变化" /></p>
<h4 id="线程的属性">2、线程的属性：</h4>
<ul>
<li>线程是处理机调度的单位</li>
<li>多CPU计算机中，各个线程可占用不同的CPU</li>
<li>每个线程都有一个线程ID、线程控制块（TCB）</li>
<li>线程也有就绪、阻塞、运行三种基本状态</li>
<li>线程几乎不拥有系统资源</li>
<li><strong>同一进程的不同线程间共享进程的资源（例如打印机等）</strong></li>
<li>由于共享内存地址空间，同一进程中的线程间通信甚至无需系统干预</li>
<li>同一进程中的线程切换，不会引起进程切换</li>
<li>不同进程中的线程切换，会引起进程切换</li>
<li>切换同进程内的线程，系统开销很小</li>
<li>切换进程，系统开销较大</li>
</ul>
<h4 id="线程的实现方式">3、线程的实现方式：</h4>
<h5 id="用户级线程">1）用户级线程：</h5>
<p>​ 用户级线程由应用程序通过线程库实现。</p>
<p>​ 所有的线程管理工作都<strong>由应用程序负责（包括线程切换）</strong></p>
<p>​ 用户级线程中，线程切换可以在用户态下即可完成，无需操作系统干预。</p>
<p>​ <strong>在用户看来，是有多个线程。但是在操作系统内核看来，并意识不到线程的存在。</strong>（用户级线程对用户不透明，对操作系统透明）</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315181528334.png" alt="用户级线程" style="zoom: 67%;" /></p>
<h5 id="内核级线程">2）内核级线程：</h5>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315181555209.png" alt="内核级线程" style="zoom:67%;" /></p>
<p>​ 核级线程的管理工作由操作系统内核完成。</p>
<p>​ 线程调度、切换等工作都由内核负责，因此内核级线程的切换必然需要在核心态下才能完成。</p>
<h5 id="两者组合">3）两者组合：</h5>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315181640824.png" alt="" style="zoom:67%;" /></p>
<p>​ 在同时支持用户级线程和内核级线程的系统中，可采用二者组合的方式：将n个用户级线程映射到m 个内核级线程上（n&gt;=m）</p>
<p>​ 重点：<strong>操作系统只“看得见”内核级线程，因此只有内核级线程才是处理机分配的单位。</strong></p>
<p>​ 例如：左边这个模型中，该进程由两个内核级线程，三个用户级线程，在用户看来，这个进程中有三个线程。但即使该进程在一个4核处理机的计算机上运行，<strong>也最多只能被分配到两个核，最多只能有两个用户线程并行执行。</strong></p>
<h4 id="多线程模型">4、多线程模型：</h4>
<p>​ 在同时支持用户级线程和内核级线程的系统中，由几个用户级线程映射到几个内核级线程的问题引出了“多线程模型”问题。</p>
<h5 id="多对一模型">1）多对一模型：</h5>
<p>​ 多个用户及线程映射到一个内核级线程。每个用户进程只对应一个内核级线程。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315182055006.png" style="zoom:67%;" /></p>
<p>​ <strong>优点：</strong>用尸级线程的切换在用尸空间即可完成，不需要切换到核心态，线程管理的系统开销小，效率高</p>
<p>​ <strong>缺点：</strong>当一个用户级线程被阻塞后，整个进程都会被阻塞，并发度不高。多个线程不可在多核处理机上并行运行</p>
<h5 id="一对一模型">2）一对一模型：</h5>
<p>​ 一个用户及线程映射到一个内核级线程。每个用户进程有与用户级线程同数量的内核级线程。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315182003606.png" alt="一对一模型" style="zoom:67%;" /></p>
<p>​ <strong>优点</strong>：当一个线程被阻塞后，别的线程还可以继续执行，并发能力强。多线程可在多核处理机上并行执行。</p>
<p>​ <strong>缺点</strong>：一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要切换到核心态，因此线程管理的成本高，开销大。</p>
<h5 id="多对多模型">3）多对多模型：</h5>
<p>​ n用户及线程映射到m个内核级线程（n&gt;=m）。每个用户进程对应m个内核级线程。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220315182148042.png" style="zoom:67%;" /></p>
<p>​ 克服了多对一模型并发度不高的缺点，又克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点。</p>
]]></content>
      <categories>
        <category>⓻ 基础类笔记</category>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Operating System</tag>
      </tags>
  </entry>
  <entry>
    <title>__call__方法</title>
    <url>/2022/03/12/6c6b30d1f672/</url>
    <content><![CDATA[<p>​ Python的一个特殊的实例方法<code>__call__</code>，功能类似于在类中重载()运算符，使得类实例对象可以像调用普通函数那样进行使用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CLanguage</span>:</span></span><br><span class="line">    <span class="comment"># 定义__call__方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self,name,add</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;调用__call__()方法&quot;</span>,name,add)</span><br><span class="line">clangs = CLanguage()</span><br><span class="line">clangs(<span class="string">&quot;C test&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>通过在 CLanguage 类中实现<code>__call__</code>方法，使得 clangs 实例对象变为了可调用对象。</p>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>Python基础扩充笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch学习笔记11——torchvision图像数据预处理</title>
    <url>/2022/03/12/796f9da33963/</url>
    <content><![CDATA[<h3 id="一torchvision简介">一、TorchVision简介：</h3>
<p>torchvision 是Pytorch中专门用来处理图像的库。这个包中有四个大类。</p>
<ul>
<li><p>torchvision.datasets 包含了很多提前处理好的数据集：如COCO、ImageNet等</p></li>
<li><p>torchvision.models 包含了已经训练好的模型，可以加载后直接用：如AlexNet、VGG等</p></li>
<li><p>torchvision.transforms 包含一般的图像转换操作类 如归一化、展平</p></li>
<li><p>torchvision.utils</p></li>
</ul>
<h3 id="二transforms的一些函数">二、Transforms的一些函数：</h3>
<h4 id="transforms.normalizemeanstdinplacefalse">1、transforms.Normalize(mean,std,inplace=False)</h4>
<ul>
<li>mean:各通道的均值</li>
<li>std：各通道的标准差</li>
<li>inplace：是否原地操作</li>
</ul>
<p>一般可以如下传入mean和std:代表我要将数据归约化至如下的均值和方差的分布</p>
<p><code>mean = (0.5,0.5,0.5) std = (0.5,0.5,0.5)</code></p>
<p>该函数就是通过以下公式，对图像3个通道分别依据输入的mean和std进行归约化。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x = (x - mean) / std</span><br></pre></td></tr></table></figure>
<p>最终得到新的数据。整体过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line">mean = (<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>) </span><br><span class="line">std = (<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>)`</span><br><span class="line">new_data = transforms.Normalize(mean, std)(data)</span><br></pre></td></tr></table></figure>
<p>可以看到：其实 transforms.Normalize(mean, std) 只是指定了一个函数，所以还可以如下操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line">mean = (<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>) </span><br><span class="line">std = (<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>)`</span><br><span class="line">normalize = transforms.Normalize(mean=mean, std=std)</span><br><span class="line">new_data = normalize(data)</span><br></pre></td></tr></table></figure>
<h4 id="transforms.totensor">2、transforms.ToTensor()</h4>
<p>该函数有两个功能：</p>
<ol type="1">
<li>是将输入的数据改变Shpae，图像数据本身是三维的： W，H，C ，该函数会将其变成 C，W，H的维度</li>
<li>将所有数除以255，将像素数据归一化到<code>[0,1]</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(data.shape)   <span class="comment">#（5，5，3）</span></span><br><span class="line">data = transforms.ToTensor()(data)</span><br><span class="line"><span class="built_in">print</span>(data.shape)	<span class="comment">#（3，5，5）</span></span><br></pre></td></tr></table></figure>
<p>和Normalize函数一样：也可以按照如下方法使用：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">toTensor = transforms.ToTensor()</span><br><span class="line">data = toTensor(data)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Pytorch系列笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>1.1 操作系统概念与基础</title>
    <url>/2022/03/11/b7e4aac04426/</url>
    <content><![CDATA[<h3 id="一概念功能与目标">一、概念功能与目标</h3>
<h4 id="概念">1、概念</h4>
<p>操作系统（Operating System，OS）是指控制和管理<strong>整个计算机系统的硬件和软件资源</strong>，并合理地组织调度计算机的工作和资源的分配，以提供给用户和其他软件方便的接口和环境，它是计算机系统中最基本的<strong>系统软件</strong>。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220311205142106.png" style="zoom: 67%;" /></p>
<p>较为直观的例子：Windows的任务管理器</p>
<h4 id="功能与目标">2、功能与目标：</h4>
<h5 id="系统资源的管理者">1) 系统资源的管理者：</h5>
<p>提供4个功能：</p>
<ul>
<li>CPU管理</li>
<li>存储器管理（内存&amp;外存）</li>
<li>文件管理</li>
<li>硬件设备管理</li>
</ul>
<p>目标：安全 + 高效</p>
<h5 id="作为用户和计算机硬件之间的接口">2）作为用户和计算机硬件之间的接口：</h5>
<p>提供3个功能：</p>
<ul>
<li>命令接口
<ul>
<li>联机命令接口（交互式命令接口）：用户说一句，系统做一句。比如win中的<code>cmd</code>命令解释器</li>
<li>脱机命令接口（批处理命令接口）：用户说一堆，系统做一堆。win中的<code>*.bat</code>文件执行</li>
</ul></li>
<li>程序接口
<ul>
<li>如win中，程序员在程序中调用<code>*.dll</code>（该调用过程即为<strong>系统调用</strong>）可以实现某些功能。这类接口只能通过用户程序<strong>间接使用</strong></li>
</ul></li>
<li>GUI图形用户界面
<ul>
<li>删除文件：拖拽至回收站</li>
</ul></li>
</ul>
<h5 id="作为最接近硬件的层次">3） 作为最接近硬件的层次：</h5>
<p>需要实现堆硬件机器的拓展，没有任何软件支持的计算机称为<strong>裸机</strong>。</p>
<p>通常把覆盖了软件的机器成为<strong>扩充机器</strong>，又称之为<strong>虚拟机</strong></p>
<h3 id="二操作系统的特征">二、操作系统的特征</h3>
<h4 id="并发最基本的特征之一">1、并发（最基本的特征之一）</h4>
<p>​ 指两个或多个事件在同一时间间隔内发生。<strong>这些事件宏观上是同时发生的，但微观上是交替发生的。</strong></p>
<p>​ 操作系统的并发性指<strong>计算机系统中同时存在着多个运行着的程序</strong>。</p>
<p>​ 一个单核处理机（CPU）同一时刻只能执行一个程序，因此<strong>操作系统会负责协调多个程序交替执行（这些程序微观上是交替执行的，但宏观上看起来就像在同时执行）</strong></p>
<p>​ 我们现在的4核CPU处理器，意味着同一时刻可以有4个程序<strong>并行</strong>执行，但是操作系统的<strong>并发性</strong>必不可少。</p>
<h4 id="共享最基本的特征之二">2、共享（最基本的特征之二）</h4>
<p>​ 资源共享，是指<strong>系统中的资源可供内存中多个并发执行的进程共同使用。</strong></p>
<ul>
<li>互斥共享方式：系统中的<strong>某些资源，虽然可以提供给多个进程使用，但一个时间段内只允许一个进程访问该资源。</strong>比如说：使用QQ和微信视频，<strong>同一时间段摄像头只能分配给其中一个进程。</strong></li>
<li>同时共享方式：系统中的某些资源，允许一个时间段内由多个进程<strong>“同时”</strong>对它们进行访问。比如说：使用QQ发送文件A，同时使用微信发送文件B。<strong>宏观上看，两边都在同时读取并发送文件，</strong>说明两个进程都在访问硬盘资源，从中读取数据。<strong>微观上看，两个进程是交替着访问硬盘的。</strong></li>
</ul>
<h4 id="虚拟">3、虚拟</h4>
<p>​ 虚拟是指<strong>把一个物理上的实体变为若干个逻辑上的对应物</strong>：物理实体（前者）是实际存在的，而<strong>逻辑上对应物（后者）是用户感受到的。</strong></p>
<h5 id="虚拟技术">1）虚拟技术</h5>
<ul>
<li><p>空分复用技术：如虚拟存储器技术</p></li>
<li><p>时分复用技术：如虚拟处理器</p></li>
<li><p>问题1：GTA5需要4GB的运行内存，QQ需要256MB的内存，迅雷需要256MB的内存，网易云音乐需要256MB的内存……而我的电脑只有4GB内存，这些程序同时运行需要的内存远大于4GB，那么为什么它们还可以在我的电脑上同时运行呢？</p></li>
<li><p>答：这是虚拟存储器技术。实际只有4GB的内存，在用户看来似乎远远大于4GB。<strong>即空分复用技术</strong></p></li>
<li><p>问题2：既然一个程序需要被分配CPU才能正常执行，那么为什么单核CPU的电脑中能同时运行这么多个程序呢？</p></li>
<li><p>答：这是虚拟处理器技术。实际上只有一个单核CPU，在用户看来似乎有6个CPU在同时为自己服务。<strong>即时分复用技术</strong></p></li>
</ul>
<h4 id="异步">4、异步</h4>
<p>​ 异步是指，在多道程序环境下，允许多个程序并发执行，<strong>但由于资源有限，进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进，</strong>这就是进程的异步性。</p>
<h3 id="三操作系统的发展与分类">三、操作系统的发展与分类：</h3>
<h4 id="手工操作阶段">1、手工操作阶段：</h4>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313105737330.png" alt="手工操作阶段" /><figcaption aria-hidden="true">手工操作阶段</figcaption>
</figure>
<p><strong>主要缺点：</strong>用户独占全机、人机速度矛盾导致资源利用率极低</p>
<h4 id="批处理阶段">2、批处理阶段：</h4>
<h5 id="单道批处理系统">1）单道批处理系统</h5>
<p>​ 引入脱机输入输出技术（用磁带完成），并由监督程序负责控制作业的输入输出。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313110520259.png" alt="单道批处理系统" /><figcaption aria-hidden="true">单道批处理系统</figcaption>
</figure>
<p><strong>主要优点：</strong>缓解了一定程度的人机速度矛盾，资源利用率有所提升。</p>
<p><strong>主要缺点：</strong>内存中仅能有一道程序运行，只有该程序运行结束之后才能调入下一道程序。CPU有大量的时间是在空闲等待l/0完成。资源利用率依然很低。</p>
<h5 id="多道批处理系统">2）多道批处理系统</h5>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313110759912.png" alt="多道批处理系统" /><figcaption aria-hidden="true">多道批处理系统</figcaption>
</figure>
<p><strong>主要优点：</strong>多道程序并发执行，共享计算机资源。资源利用率大幅提升，CPU和其他资源保持“忙碌”状态，系统吞吐量增大。</p>
<p><strong>主要缺点：</strong>用户响应时间长，没有人机交互功能（用户提交自己的作业（程序）之后就只能等待计算机处理完成，中间不能控制自己的作业执行）</p>
<h4 id="分时操作系统">3、分时操作系统：</h4>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313111132639.png" alt="分时操作系统" /><figcaption aria-hidden="true">分时操作系统</figcaption>
</figure>
<p>​ 计算机以<strong>时间片</strong>（例如50ms）为单位<strong>轮流为各个用户/作业服务</strong>，各个用户可通过终端与计算机进行交互。</p>
<p><strong>王要优点：用户请求可以被即时响应，群决了人机交互问题。</strong>允许多个用尸同时使用一台计算机，并且用户对计算机的操作相互独立，感受不到别人的存在。</p>
<p><strong>主要缺点：</strong>不能优先处理一些紧急任务。操作系统对各个用户/作业都是完全公平的，循环地为每个用户作业服务一个时间片，<strong>不区分任务的紧急性</strong>。</p>
<h4 id="实时操作系统">4、实时操作系统：</h4>
<ul>
<li>硬实时系统：必须在绝对严格的规定时间内完成处理（如导弹控制系统、自动驾驶等）</li>
<li>软实时系统：能接受偶尔违反时间规定</li>
</ul>
<p>主要优点：能够优先响应一些紧急任务，某些紧急任务不需时间片排队。</p>
<p>在实时操作系统的控制下，计算机系统接收到外部信号后<strong>及时进行处理</strong>，并且要在严格的时限内处理完事件。实时操作系统的主要特点是<strong>及时性和可靠性</strong></p>
<h4 id="其他操作系统">5、其他操作系统：</h4>
<ul>
<li>网络操作系统：是伴随着计算机网络的发展而诞生的，能把网络中各个计算机有机地结合起来，实现数据传送等功能，实现网络中各种资源的共享（如文件共享）和各台计算机之间的通信。（如：Windows NT就是一种典型的网络操作系统，网站服务器就可以使用）</li>
<li>分布式操作系统：主要特点是<strong>分布性和并行性</strong>。系统中的各台计算机地位相同，任何工作都可以分布在这些计算机上，由它们并行、协同完成这个任务。</li>
<li>个人计算机操作系统：如WindowsXP、MacOs，方便个人使用。</li>
</ul>
<h3 id="四操作系统的运行机制">四、操作系统的运行机制：</h3>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313111750626.png" alt="“指令”和&quot;代码&quot;的区别" /><figcaption aria-hidden="true">“指令”和"代码"的区别</figcaption>
</figure>
<h4 id="两种指令">1、两种指令：</h4>
<h5 id="特权指令如内存清零指令不允许用户程序使用">1） 特权指令：如内存清零指令，不允许用户程序使用</h5>
<h5 id="非特权指令如普通的运算指令">2） 非特权指令：如普通的运算指令</h5>
<h4 id="两种处理器状态">2、两种处理器状态：</h4>
<p>用于判断当前是否可以执行特权指令</p>
<h5 id="用户态目态只能执行非特权指令">1） 用户态（目态）：只能执行非特权指令</h5>
<h5 id="核心态管态两种指令都可以执行">2） 核心态（管态）：两种指令都可以执行</h5>
<h4 id="两种程序">3、两种程序：</h4>
<h5 id="内核程序">1）内核程序：</h5>
<p>​ 操作系统的内核程序是系统的管理者，既可以执行特权指令，也可以执行非特权指令，运行在核心态。</p>
<h5 id="应用程序">2）应用程序：</h5>
<p>​ 为了保证系统能安全运行，普通应用程序只能执行非特权指令，运行在用户态</p>
<h3 id="五操作系统内核">五、操作系统内核：</h3>
<h4 id="内核总览示意图">1、内核总览示意图：</h4>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313112448980.png" alt="计算机系统的层次结构" /><figcaption aria-hidden="true">计算机系统的层次结构</figcaption>
</figure>
<p>​ <strong>原子性</strong>指该程序在开始执行后，中间不能被中断。</p>
<p>​ 内核是计算机上配置的底层软件，是操作系统最基本、最核心的部分。实现操作系统内核功能的那些程序就是内核程序。</p>
<h4 id="操作系统的体系结构">2、操作系统的体系结构：</h4>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313112907278.png" /></p>
<h5 id="大内核">1） 大内核：</h5>
<p>将操作系统的主要功能模块都作为系统内核，运行在核心态</p>
<p>优点：高性能</p>
<p>缺点：内核代码庞大，结构混乱，难以维护</p>
<h5 id="微内核">2）微内核：</h5>
<p>只把最基本的功能保留在内核</p>
<p>优点：内核功能少，结构清晰，方便维护</p>
<p>缺点：需要频繁地在核心态和用户态之间切换，性能低</p>
<h3 id="六中断和异常">六、中断和异常：</h3>
<h4 id="中断机制的诞生缘由">1、中断机制的诞生缘由：</h4>
<p>​ 早期计算机各个程序只能串行执行程序，系统资源利用率会较低。为了解决该问题，就发明了操作系统，引入中断机制，实现了多道程序的并发执行。</p>
<p><strong>本质</strong>： 发生中断，就意味着需要操作系统接入，进行管理.具体如下:</p>
<p>​ 我们假设3个进程同时放入内存中进行执行,首先CPU执行进程1,一段时间后,CPU收到计时硬件发出的中断信号,就会切换至<strong>核心态</strong>,CPU知晓进程1的时间片已经用完了,就切换进程2运行.完成该系列操作后,CPU又会切换至<strong>用户态</strong>,然后开始运行进程2,在进程2运行过程中,进程2发出<strong>系统调用(内中断信号)</strong>,请求输出.<strong>(由于输入输出是特权指令,普通程序不能直接调用,只能通过向操作系统申请,即主动发出中断信号)</strong>,此时CPU将切换到<strong>核心态</strong>,<strong>由操作系统内核进行接管</strong>,负责执行输出内容,比如其让打印机IO设备开始工作,<strong>此时进程2就需要暂停运行等待IO完成,故而操作系统此时让进程3先运行</strong>.CPU重新切换为<strong>用户态,</strong>执行进程3.在CPU执行进程3的过程中,IO也在同步进行,当IO完成时,IO设备(打印机)就会向CPU发出中断信号,CPU收到IO设备发来的中断信号,又会切换至<strong>核心态</strong>,<strong>交由操作系统内核进行处理</strong>.此时,操作系统发现是进程2的IO结束了,就会让进程2恢复运行,CPU切换为用户态.进程2继续完成内容.</p>
<h4 id="中断的概念和作用">2、中断的概念和作用：</h4>
<ul>
<li>当中断发生时，CPU立即进入核心态</li>
<li>当中断发生后，当前运行的进程暂停运行，并由操作系统内核对中断进行处理</li>
<li>对于不同的中断信号，会进行不同的处理</li>
</ul>
<p>​ 发生了中断，就意味着需要<strong>操作系统介入，开展管理工作。</strong>由于操作系统的管理工作（比如进程切换、分配I/O设备等）需要使用特权指令，因此CPU要从<strong>用户态转为核心态</strong>。<strong>中断可以使CPU从用户态切换为核心态，使操作系统获得计算机的控制权。</strong> <strong>有了中断，才能实现多道程序并发执行。</strong></p>
<p><strong>用户态</strong>到<strong>核心态</strong>的切换是通过<strong>中断</strong>实现的，并且中断是唯一途径。</p>
<p><strong>核心态</strong>到<strong>用户态</strong>的切换是通过<strong>执行一个特权指令，将PSW标志位设置</strong>实现的。</p>
<h4 id="中断的分类">3、中断的分类:</h4>
<p>两者的本质区别： 信号的来源是CPU内部还是CPU外部。与当前的执行的指令是否有关</p>
<h5 id="内中断异常例外陷入-来源于cpu内部与当前执行的指令有关">1）内中断（异常、例外、陷入）： 来源于CPU内部，与当前执行的指令有关</h5>
<ul>
<li>指令中断：系统调用</li>
<li>强迫中断
<ul>
<li>硬件故障</li>
<li>软件中断（如整数除0）</li>
</ul></li>
</ul>
<h5 id="外中断来源于cpu外部与当前执行的指令无关">2）外中断：来源于CPU外部，与当前执行的指令无关</h5>
<ul>
<li>外设请求：I/0操作完成发出的中断信号</li>
<li>人工干预：用户强行终止一个进程</li>
</ul>
<p>另一种分类：</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313130033093.png" alt="另一种中断的分类" /><figcaption aria-hidden="true">另一种中断的分类</figcaption>
</figure>
<h4 id="外中断的处理过程">4、外中断的处理过程：</h4>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313130249004.png" alt="外中断的处理过程" /><figcaption aria-hidden="true">外中断的处理过程</figcaption>
</figure>
<ul>
<li>Step1：执行完每个指令之后，CPU都要检查当前是否有外部中断信号</li>
<li>Step2：如果检测到外部中断信号，则需要保护被中断进程的CPU环境（如程序状态字PSW、程序计数器PC、各种通用寄存器)</li>
<li>Step3：根据中断信号类型转入相应的中断处理程序</li>
<li>Step 4：恢复原进程的CPU环境并退出中断，返回原进程继续往下执行</li>
</ul>
<h3 id="七系统调用">七、系统调用：</h3>
<h4 id="什么是系统调用">1、什么是系统调用：</h4>
<p>​ 操作系统作为用户和计算机硬件之间的接口，需要向上提供一些简单易用的服务。主要包括命令接口和程序接口。其中，程序接口由<strong>一组系统调用组成</strong>。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313141435648.png" /></p>
<p>​ “系统调用”是<strong>操作系统提供给应用程序</strong>（程序员/编程人员)使用的接口，可以理解为一种<strong>可供应用程序调用的特殊函数，应用程序可以发出系统调用请求来获得操作系统的服务</strong>。</p>
<p>​</p>
<h4 id="系统调用有什么作用">2、系统调用有什么作用？</h4>
<p>​ <strong>应用程序通过系统调用请求操作系统的服务。系统中的各种共享资源都由操作系统统一掌管，因此在用户程序中，凡是与资源有关的操作（如存储分配、I/O操作、文件管理等），都必须通过系统调用的方式向操作系统提出服务请求，由操作系统代为完成。这样可以保证系统的稳定性和安全性，防止用户进行非法操作。</strong></p>
<p><strong>系统调用</strong>会使得处理器从<strong>用户态</strong>进入<strong>核心态</strong>。</p>
<h4 id="系统调用分类">3、系统调用分类：</h4>
<p>​ 系统调用相关处理涉及到对系统资源的管理、对进程的控制，这些功能需要执行一些特权指令才能完成，因此系统调用的相关处理需要在核心态下进行。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313142304849.png" alt="系统调用分类" /><figcaption aria-hidden="true">系统调用分类</figcaption>
</figure>
<h4 id="系统调用与库函数的区别">4、系统调用与库函数的区别：</h4>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313142453847.png" style="zoom:50%;" /></p>
<p>从下层至上层如下：</p>
<ul>
<li><strong>裸机</strong></li>
<li><strong>操作系统</strong>：向上提供系统调用</li>
<li><strong>编程语言</strong>：向上提供库函数。有时会将系统调用封装成库函数，以隐藏系统调用的一些细节，使上层进行系统调用更加方便。</li>
<li><strong>普通应用程序</strong>：可直接进行系统调用，也可使用库函数。</li>
</ul>
<p>注意：有的库函数涉及系统调用，有的不涉及</p>
<h4 id="系统调用背后的过程">5、系统调用背后的过程：</h4>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220313142828536.png" alt="系统调用背后的过程" /><figcaption aria-hidden="true">系统调用背后的过程</figcaption>
</figure>
<p><code>int x</code>指令的参数x，指明了系统调用号。此处的int是interrupt的缩写，执行该指令后，权限就交给了操作系统来接管，切换至核心态处理系统调用相关代码。</p>
<p><strong>注意：</strong></p>
<p>1.陷入指令是在<strong>用户态执行的</strong>，执行陷入指令之后立即引发一个内中断，从而CPU进入核心态 2.<strong>发出系统调用请求是在用户态</strong>，而对系统调用的相应处理在核心态下进行 3.<strong>陷入指令是唯一一个只能在用户态执行，而不可在核心态执行的指令</strong></p>
]]></content>
      <categories>
        <category>⓻ 基础类笔记</category>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Operating System</tag>
      </tags>
  </entry>
  <entry>
    <title>用Python搭建深度学习框架系列笔记5——逻辑回归中的损失函数节点</title>
    <url>/2022/03/02/c830e3a9e023/</url>
    <content><![CDATA[<h3 id="一感知机损失与对数损失">一、感知机损失与对数损失：</h3>
<h4 id="原理及利弊">1、原理及利弊</h4>
<p>​ <strong>感知机损失</strong>在原点处有一个硬转折，该点不可导。同时，在x大于0的区间范围内，其函数值一直为0，但这并不太好，虽然此部分的模型分类正确，但是我们希望模型能够更正确，也就是x越大越好。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_03_02_20_45_52_846.png" style="zoom: 50%;" /></p>
<p>​ 介于上述情况，引入了<strong>对数损失函数</strong>，<span class="math inline">\(L(x) = log(1+e^{-x})\)</span>，处处可导，且在x&gt;0的时候，x越大，函数值越接近0，作了一定的区分。也就是说，对不那么正确的情况施加了一定的惩罚。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_03_02_20_46_33_157.png" style="zoom:50%;" /></p>
<h4 id="代码实现">2、代码实现：</h4>
<h5 id="损失函数抽象类">1）损失函数抽象类：</h5>
<p>​ 按照先前所述，损失函数也可以抽象为计算图中的一个节点，首先定义一个抽象类，继承Node类</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LossFunction</span>(<span class="params">Node</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    定义损失函数抽象类</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<h5 id="实现感知机损失">2）实现感知机损失：</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PerceptionLoss</span>(<span class="params">LossFunction</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    感知机损失，输入为正时为0，输入为负时为输入的相反数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute</span>(<span class="params">self</span>):</span> </span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(self.parents) == <span class="number">1</span>  <span class="comment"># 只接受一个父节点</span></span><br><span class="line">        </span><br><span class="line">        x = self.parents[<span class="number">0</span>].value </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 对父节点中每一个元素，执行上述操作</span></span><br><span class="line">        self.value = np.mat( np.where( x &gt;= <span class="number">0.0</span>, <span class="number">0.0</span>, -x ) )  </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_jacobi</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        雅克比矩阵为对角阵，每个对角线元素对应一个父节点元素。若父节点元素大于0，则</span></span><br><span class="line"><span class="string">        相应对角线元素（偏导数）为0，否则为-1。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        diag = np.where(parent.value &gt;= <span class="number">0.0</span>, <span class="number">0.0</span>, -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> np.diag(diag.ravel())  </span><br><span class="line">    	<span class="comment"># ravel 函数将 多维数组 扁平化展开</span></span><br><span class="line">        <span class="comment"># np.diag(array) 中</span></span><br><span class="line">        <span class="comment"># array是一个1维数组时，结果形成一个以一维数组为对角线元素的矩阵</span></span><br><span class="line">        <span class="comment"># array是一个二维矩阵时，结果输出矩阵的对角线元素</span></span><br></pre></td></tr></table></figure>
<h5 id="实现对数损失类">3）实现对数损失类：</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogLoss</span>(<span class="params">LossFunction</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute</span>(<span class="params">self</span>):</span>  <span class="comment"># 根据父节点的值，计算该节点的值</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(self.parents) == <span class="number">1</span>  <span class="comment"># 只接受一个父节点</span></span><br><span class="line"></span><br><span class="line">        x = self.parents[<span class="number">0</span>].value </span><br><span class="line"></span><br><span class="line">        self.value = np.log(<span class="number">1</span> + np.power(np.e, np.where(-x &gt; <span class="number">1e2</span>, <span class="number">1e2</span>, -x))) <span class="comment"># 对于父节点的每个元素都依据公式进行运算，为了防止溢出，对指数进行了截断</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_jacobi</span>(<span class="params">self, parent</span>):</span> <span class="comment"># 计算本节点对某个父节点的雅可比矩阵</span></span><br><span class="line"></span><br><span class="line">        x = parent.value</span><br><span class="line">        diag = -<span class="number">1</span> / (<span class="number">1</span> + np.power(np.e, np.where(x &gt; <span class="number">1e2</span>, <span class="number">1e2</span>, x))) <span class="comment"># 通过计算可以得到，其实就是对数损失的导数，放在对角线的每个元素上</span></span><br><span class="line">        <span class="keyword">return</span> np.diag(diag.ravel())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="二logistic函数">二、Logistic函数</h3>
<h4 id="原理及操作">1、原理及操作：</h4>
<p><span class="math display">\[
Logistic(x) = \frac{1}{1 + e^{-x}}
\]</span></p>
<p><img src="https://bkimg.cdn.bcebos.com/pic/f3d3572c11dfa9ec71464f3e60d0f703918fc1ab?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5/format,f_auto" style="zoom:50%;" /></p>
<p>​ 我们可以对模型的线性部分施加这个变换，来代替原先的阶跃函数。</p>
<h4 id="logistic操作节点实现">2、Logistic操作节点实现：</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Logistic</span>(<span class="params">Operator</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    对向量的分量施加Logistic函数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute</span>(<span class="params">self</span>):</span></span><br><span class="line">        x = self.parents[<span class="number">0</span>].value</span><br><span class="line">        <span class="comment"># 对父节点的每个分量施加Logistic</span></span><br><span class="line">        self.value = np.mat(</span><br><span class="line">            <span class="number">1.0</span> / (<span class="number">1.0</span> + np.power(np.e, np.where(-x &gt; <span class="number">1e2</span>, <span class="number">1e2</span>, -x))))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_jacobi</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.diag(np.mat(np.multiply(self.value, <span class="number">1</span> - self.value)).A1)  <span class="comment"># 这个计算依赖于Logistic函数对x的导数，在化简后其实就等于 Logistic(x) * (1-Logistic(x))</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="三逻辑回归">三、逻辑回归：</h3>
<h4 id="二分类逻辑回归">1、二分类逻辑回归：</h4>
<p>​ 当我们将先前的AdaLine模型的阶跃函数替换成Logistic函数，得到输出。并且对线性部分施加对数损失，就可以得到逻辑回归模型。</p>
<p>​ 需要注意的是：由于我们的训练集男女标签为1/-1，但是使用Logistic函数输出的值是在0-1之间的，输出的内容是正类（男性）的概率值，而没有判定样本具体的类别。所以我们可以以0.5为阈值，进行判定。阈值大小也是可以根据具体情况自定义的。</p>
<p>​ <strong>故而，二分类逻辑回归模型只提供概率，选择阈值的决定权还是在人</strong></p>
<p>​ <strong>总结</strong>：</p>
<p>​ 用Logistic函数，得到<strong>最终的概率值输出</strong>。</p>
<p>​ 对线性部分施加<strong>对数损失，以用于训练</strong>。</p>
<h4 id="多分类逻辑回归">2、多分类逻辑回归：</h4>
<p>​ 我们一般采用SoftMax来代替“硬”的Max函数，将所有值归约至0-1之间，进而进行概率值的输出</p>
<h5 id="softmax节点实现">SoftMax节点实现：</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SoftMax</span>(<span class="params">Operator</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    SoftMax函数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">softmax</span>(<span class="params">a</span>):</span></span><br><span class="line">        a[a &gt; <span class="number">1e2</span>] = <span class="number">1e2</span>  <span class="comment"># 防止指数过大</span></span><br><span class="line">        ep = np.power(np.e, a)</span><br><span class="line">        <span class="keyword">return</span> ep / np.<span class="built_in">sum</span>(ep)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.value = SoftMax.softmax(self.parents[<span class="number">0</span>].value)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_jacobi</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        我们不实现SoftMax节点的get_jacobi函数，        训练时，不会通过SoftMax节点进行反向传播</span></span><br><span class="line"><span class="string">        训练时使用CrossEntropyWithSoftMax节点</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError(<span class="string">&quot;Don&#x27;t use SoftMax&#x27;s get_jacobi&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>​ 一般使用交叉熵，来衡量SoftMax输出的分布，与真实标签的分布是否相似，具体的公式见常见的损失函数章节。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=H%28p%2Cq%29%3D-%5Csum_%7Bi%3D1%7D%5Enp%28x_i%29log%28q%28x_i%29%29" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>​ <span class="math inline">\(q(x_i)\)</span>是预测分布，<span class="math inline">\(p(x_i)\)</span>是标签的分布。交叉熵是符合直觉得，当样本属于第i类的时候，只有<span class="math inline">\(p(x_i)\)</span>为1，其他p的分量都为0，最小化交叉熵函数，其实就是在最大化<span class="math inline">\(log(q(x_i))\)</span>这一项的值，也就是在最大化<span class="math inline">\(q(x_i)\)</span>，及最大化模型输出的第i类概率。</p>
<h5 id="crossentropywithsoftmax-实现">CrossEntropyWithSoftMax 实现：</h5>
<p>​ 在上面实现Softmax节点的时候，并没有实现get_jacobi方法，原因就是它的输出会和独热向量一起被送给交叉熵。计算交叉熵对于线性部分的雅可比矩阵，比计算对Softmax输出的雅可比矩阵会更容易。Pytorch框架中也是这么干的。将Softmax操作附在了CrossEntropy损失函数中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CrossEntropyWithSoftMax</span>(<span class="params">LossFunction</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    对第一个父节点施加SoftMax之后，再以第二个父节点为标签One-Hot向量计算交叉熵</span></span><br><span class="line"><span class="string">    self.parents[0] 为logit向量，也就是线性部分</span></span><br><span class="line"><span class="string">    self.parents[1] 为One-Hot编码的向量标签</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute</span>(<span class="params">self</span>):</span></span><br><span class="line">        prob = SoftMax.softmax(self.parents[<span class="number">0</span>].value)      </span><br><span class="line">        self.value = np.mat(</span><br><span class="line">            -np.<span class="built_in">sum</span>(np.multiply(self.parents[<span class="number">1</span>].value, np.log(prob + <span class="number">1e-10</span>))))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_jacobi</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        <span class="comment"># 这里存在重复计算，但为了代码清晰简洁，舍弃进一步优化</span></span><br><span class="line">        <span class="comment"># 推导见下，参考《用Python实现深度学习框架》</span></span><br><span class="line">        prob = SoftMax.softmax(self.parents[<span class="number">0</span>].value)</span><br><span class="line">        <span class="keyword">if</span> parent <span class="keyword">is</span> self.parents[<span class="number">0</span>]:</span><br><span class="line">            <span class="keyword">return</span> (prob - self.parents[<span class="number">1</span>].value).T</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (-np.log(prob)).T</span><br></pre></td></tr></table></figure>
<h4 id="带交叉熵的多分类逻辑回归计算图示例">3、带交叉熵的多分类逻辑回归计算图示例：</h4>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/654F54B060F55AD5E7433929CC7A48B3.jpg" style="zoom: 25%;" /></p>
<p>​</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
        <category>Python搭建简易框架笔记</category>
      </categories>
      <tags>
        <tag>Framework</tag>
      </tags>
  </entry>
  <entry>
    <title>用Python搭建深度学习框架系列笔记4——优化器类的代码实现（下）</title>
    <url>/2022/02/28/d9d77f183b68/</url>
    <content><![CDATA[<h4 id="六momentum冲量优化器的实现">六、Momentum冲量优化器的实现：</h4>
<h5 id="公式">1、公式：</h5>
<p>​ 由于先前的梯度下降法的速度向量v只依赖于当前的梯度，而不参考历史梯度，很容易让优化器陷入Critical Point中。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/6E1655AA36BAFF6E77328731A966D476.jpg" style="zoom:33%;" /></p>
<p>​ <span class="math inline">\(\beta\)</span> 为衰减系数，一般为0.9</p>
<h5 id="代码">2、代码：</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Momentum</span>(<span class="params">Optimizer</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    冲量法</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, graph, target, learning_rate=<span class="number">0.01</span>, momentum=<span class="number">0.9</span></span>):</span></span><br><span class="line"></span><br><span class="line">        Optimizer.__init__(self, graph, target)</span><br><span class="line">        self.learning_rate = learning_rate</span><br><span class="line">        <span class="comment"># 衰减系数，默认为0.9</span></span><br><span class="line">        self.momentum = momentum</span><br><span class="line">        <span class="comment"># 积累历史速度的字典</span></span><br><span class="line">        self.v = <span class="built_in">dict</span>()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_update</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> self.graph.nodes:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(node, Variable) <span class="keyword">and</span> node.trainable:</span><br><span class="line">                <span class="comment"># 取得该节点在当前批的平均梯度</span></span><br><span class="line">                gradient = self.get_gradient(node)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 该节点没有历史速度，也就是说如果是第一次对该节点更新梯度</span></span><br><span class="line">                <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> self.v:</span><br><span class="line">                    self.v[node] = - self.learning_rate * gradient</span><br><span class="line">                <span class="keyword">else</span>: <span class="comment"># 如果该节点有历史速度</span></span><br><span class="line">                    <span class="comment"># 更新当前节点的速度</span></span><br><span class="line">                    self.v[node] = self.momentum * self.v[node] - self.learning_rate * gradient</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 利用计算所得的速度 更新变量节点的值</span></span><br><span class="line">                node.set_value(node.value + self.v[node])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="七adagrad优化器的实现">七、AdaGrad优化器的实现：</h4>
<h5 id="公式-1">1、公式：</h5>
<p>​ <strong>针对梯度的每个分量各自的历史，采用不同的学习率。</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/B02ADB3A208B90C7E30118C018E24361.jpg" style="zoom: 25%;" /></p>
<p>​ s 是 一个和梯度同维度的向量，<strong>其会在各个分量上累加历史梯度各个分量的平方</strong>。<strong>更新梯度时，求s各个分量的平方根,然后用学习率去除，得到自适应的一个向量，里面每个分量代表的就是各个分量对应的合适的学习率</strong>，将这个向量与梯度向量做内积，就可以得到一个合理的下降方向。从严格意义上来讲，这已经不是再向梯度的反方向下降了。<span class="math inline">\(\epsilon\)</span>是用于防止除数为0.</p>
<p>​ <span class="math inline">\(\bigotimes\)</span> 代表向量内各个分量分别相乘，将会得到一个和原来向量维度一致的新向量</p>
<h5 id="代码-1">2、代码：</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdaGrad</span>(<span class="params">Optimizer</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    不同分量，自适应学习率</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, graph, target, learning_rate=<span class="number">0.01</span></span>):</span></span><br><span class="line"></span><br><span class="line">        Optimizer.__init__(self, graph, target)</span><br><span class="line">        self.learning_rate = learning_rate</span><br><span class="line">        <span class="comment"># 极小量，为了防止除数为0</span></span><br><span class="line">        self.epsilon = <span class="number">1e-10</span></span><br><span class="line">        <span class="comment"># 积累历史梯度向量的字典</span></span><br><span class="line">        self.s = <span class="built_in">dict</span>()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_update</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> self.graph.nodes:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(node, Variable) <span class="keyword">and</span> node.trainable:</span><br><span class="line">                <span class="comment"># 取得该节点在当前批的平均梯度</span></span><br><span class="line">                gradient = self.get_gradient(node)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 该节点没有历史的向量s，也就是说如果是第一次对该节点更新梯度</span></span><br><span class="line">                <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> self.s:</span><br><span class="line">                    self.s[node] = np.power(gradient,<span class="number">2</span>)</span><br><span class="line">                <span class="keyword">else</span>: <span class="comment"># 如果该节点有历史累积的向量s</span></span><br><span class="line">                    <span class="comment"># 更新当前节点的历史累积的s</span></span><br><span class="line">                    self.s[node] = self.s[node] + np.power(gradient,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 利用计算所得的速度 更新变量节点的值</span></span><br><span class="line">                node.set_value(node.value - self.learning_rate * gradient / (np.sqrt(self.s[node] + self.epsilon)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="八rmsprop优化器的实现">八、RMSProp优化器的实现：</h4>
<h5 id="公式-2">1、公式：</h5>
<p>​ AdaGrad累积了全部的历史梯度，而我们其实应该更多地考虑近期地历史梯度。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/35459FAB3F235381D94DED311CECB887.jpg" style="zoom:25%;" /></p>
<p>​ <span class="math inline">\(\beta\)</span> 为衰减系数，一般为0.9</p>
<h5 id="代码-2">2、代码：</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RMSProp</span>(<span class="params">Optimizer</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    RMSProp优化器</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, graph, target, learning_rate=<span class="number">0.01</span>, beta=<span class="number">0.9</span></span>):</span></span><br><span class="line"></span><br><span class="line">        Optimizer.__init__(self, graph, target)</span><br><span class="line"></span><br><span class="line">        self.learning_rate = learning_rate</span><br><span class="line">        <span class="comment"># 极小量，为了防止除数为0</span></span><br><span class="line">        self.epsilon = <span class="number">1e-10</span></span><br><span class="line">        <span class="comment"># 衰减系数</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="number">0.0</span> &lt; beta &lt; <span class="number">1.0</span></span><br><span class="line">        self.beta = beta</span><br><span class="line">        <span class="comment"># 积累历史梯度向量的字典</span></span><br><span class="line">        self.s = <span class="built_in">dict</span>()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_update</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> self.graph.nodes:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(node, Variable) <span class="keyword">and</span> node.trainable:</span><br><span class="line">                <span class="comment"># 取得该节点在当前批的平均梯度</span></span><br><span class="line">                gradient = self.get_gradient(node)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 滑动加权累积梯度各分量的平方和</span></span><br><span class="line">                <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> self.s:</span><br><span class="line">                    self.s[node] = np.power(gradient, <span class="number">2</span>) <span class="comment"># 注意此处不要乘系数</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.s[node] = self.beta * self.s[node] + (<span class="number">1</span> - self.beta) * np.power(gradient, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 更新变量节点的值</span></span><br><span class="line">                node.set_value(node.value - self.learning_rate *</span><br><span class="line">                               gradient / (np.sqrt(self.s[node] + self.epsilon)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="九adam优化器的实现">九、Adam优化器的实现：</h4>
<h5 id="公式-3">1、公式：</h5>
<p>​ 集大成者，结合冲量与RMSProp的思想：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/F34B46DEC057822E872DE8B45F0EDB3F.jpg" style="zoom:25%;" /></p>
<h5 id="代码-3">2、代码：</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Adam</span>(<span class="params">Optimizer</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Adam优化器</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, graph, target, learning_rate=<span class="number">0.01</span>, beta1=<span class="number">0.9</span>,beta2=<span class="number">0.99</span></span>):</span></span><br><span class="line"></span><br><span class="line">        Optimizer.__init__(self, graph, target)</span><br><span class="line"></span><br><span class="line">        self.learning_rate = learning_rate</span><br><span class="line">        <span class="comment"># 极小量，为了防止除数为0</span></span><br><span class="line">        self.epsilon = <span class="number">1e-10</span></span><br><span class="line">        <span class="comment"># 衰减系数1</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="number">0.0</span> &lt; beta1 &lt; <span class="number">1.0</span></span><br><span class="line">        self.beta1 = beta1</span><br><span class="line">        <span class="comment"># 衰减系数2</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="number">0.0</span> &lt; beta2 &lt; <span class="number">1.0</span></span><br><span class="line">        self.beta2 = beta2</span><br><span class="line">        <span class="comment"># 积累历史梯度向量的字典</span></span><br><span class="line">        self.s = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="comment"># 积累历史速度向量的字典</span></span><br><span class="line">        self.v = <span class="built_in">dict</span>()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_update</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> self.graph.nodes:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(node, Variable) <span class="keyword">and</span> node.trainable:</span><br><span class="line">                <span class="comment"># 取得该节点在当前批的平均梯度</span></span><br><span class="line">                gradient = self.get_gradient(node)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 滑动加权累积梯度各分量的平方和</span></span><br><span class="line">                <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> self.s:</span><br><span class="line">                    self.s[node] = np.power(gradient, <span class="number">2</span>) <span class="comment"># 注意此处不要乘系数</span></span><br><span class="line">                    self.v[node] = gradient <span class="comment"># 注意此处不要乘系数</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 梯度累积</span></span><br><span class="line">                    self.v[node] = self.beta1 * self.v[node] + (<span class="number">1</span> - self.beta1) * gradient</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 各分量平方累积</span></span><br><span class="line">                    self.s[node] = self.beta2 * self.s[node] + (<span class="number">1</span> - self.beta2) * np.power(gradient, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 更新变量节点的值</span></span><br><span class="line">                node.set_value(node.value - self.learning_rate *</span><br><span class="line">                               self.v[node] / np.sqrt(self.s[node] + self.epsilon))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
        <category>Python搭建简易框架笔记</category>
      </categories>
      <tags>
        <tag>Framework</tag>
      </tags>
  </entry>
  <entry>
    <title>毕业相关事项</title>
    <url>/2022/02/26/84b3fb3c559e/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="5f2832a9d17d20fa058514dfe360c6848d2427e84c6d3c3633ffec46b45dcfec">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>⓽ 其他内容</category>
      </categories>
  </entry>
  <entry>
    <title>DFS系列——DFS多种形式变体整理</title>
    <url>/2022/02/26/3e00524469fb/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-080.-含有-k-个元素的组合"><a href="https://leetcode-cn.com/problems/uUsW3B/">剑指 Offer II 080. 含有 k 个元素的组合</a></h4>
<p>​ 给定两个整数 <code>n</code> 和 <code>k</code>，返回 <code>1 ... n</code> 中所有可能的 <code>k</code> 个数的组合。</p>
<p>示例 1:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: n = 4, k = 2</span><br><span class="line">输出:</span><br><span class="line">[</span><br><span class="line">  [2,4],</span><br><span class="line">  [3,4],</span><br><span class="line">  [2,3],</span><br><span class="line">  [1,2],</span><br><span class="line">  [1,3],</span><br><span class="line">  [1,4],</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h5 id="解题思路">解题思路：</h5>
<p>​ 该题是最经典的无限制的DFS，注意剪枝来降低整体的时间复杂度。</p>
<h5 id="解题代码">解题代码：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    <span class="keyword">int</span> k;</span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">combine</span>(<span class="keyword">int</span> n, <span class="keyword">int</span> k) &#123;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; tmp;</span><br><span class="line">        <span class="keyword">this</span>-&gt;k = k;</span><br><span class="line">        <span class="keyword">this</span>-&gt;n = n;</span><br><span class="line">        <span class="built_in">permute</span>(tmp,<span class="number">1</span>,<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">permute</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt; &amp;tmp,<span class="keyword">int</span> curr,<span class="keyword">int</span> count)</span></span>&#123;</span><br><span class="line">        <span class="comment">//curr代表当前 轮到的数字</span></span><br><span class="line">        <span class="comment">//count代表当前已经 放入集合中的数字个数</span></span><br><span class="line">        <span class="keyword">if</span>(count &gt; k) <span class="keyword">return</span>; <span class="comment">//剪枝</span></span><br><span class="line">        <span class="keyword">if</span>(curr == n+<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(count == k)&#123;</span><br><span class="line">                <span class="comment">//这轮完结了，将tmp添加进入curr中</span></span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//遍历两种情况 ： 要不要这个数字</span></span><br><span class="line">        <span class="comment">//Case1: 要这个数字</span></span><br><span class="line">        tmp.<span class="built_in">push_back</span>(curr);</span><br><span class="line">        <span class="built_in">permute</span>(tmp,curr+<span class="number">1</span>,count+<span class="number">1</span>);</span><br><span class="line">        tmp.<span class="built_in">pop_back</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//Case2: 不要这个数字</span></span><br><span class="line">        <span class="built_in">permute</span>(tmp,curr+<span class="number">1</span>,count);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="剑指-offer-ii-081.-允许重复选择元素的组合"><a href="https://leetcode-cn.com/problems/Ygoe9J/">剑指 Offer II 081. 允许重复选择元素的组合</a></h4>
<p>​ 给定一个无重复元素的正整数数组 candidates 和一个正整数 target ，找出 candidates 中所有可以使数字和为目标数 target 的唯一组合。</p>
<p>​ candidates 中的数字可以无限制重复被选取。如果至少一个所选数字数量不同，则两种组合是不同的。</p>
<p>​ 对于给定的输入，保证和为 target 的唯一组合数少于 150 个。</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: candidates = [2,3,6,7], target = 7</span><br><span class="line">输出: [[7],[2,2,3]]</span><br></pre></td></tr></table></figure>
<h5 id="解题思路-1">解题思路：</h5>
<p>​ 相比于上一题而言，该题允许重复选择元素，大致框架类似，但是在DFS的过程中，分支的选项需要改变，同样也是选择当前元素和不选择当前元素两条分支，之前无论选不选当前元素，下一轮递归的时候都会去判断下一个元素，而在本题中，如果选择当前元素，那么下一轮递归还应该是本元素。</p>
<h5 id="解题代码-1">解题代码：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">combinationSum</span>(vector&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; tmp;</span><br><span class="line">        <span class="built_in">permute</span>(candidates,target,tmp,<span class="number">0</span>,<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">permute</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; candidates,<span class="keyword">int</span> target,vector&lt;<span class="keyword">int</span>&gt; &amp;tmp,<span class="keyword">int</span> sum,<span class="keyword">int</span> curr)</span></span>&#123;</span><br><span class="line">        <span class="comment">//当前vector，当前sum</span></span><br><span class="line">        <span class="keyword">if</span>(curr &gt;= candidates.<span class="built_in">size</span>()) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">if</span>(sum == target)&#123;</span><br><span class="line">            res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//Case1: 不选择当前元素：</span></span><br><span class="line">        <span class="built_in">permute</span>(candidates,target,tmp,sum,curr+<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Case2: 选择当前元素：</span></span><br><span class="line">        <span class="keyword">if</span>(sum + candidates[curr] &gt; target) <span class="keyword">return</span>;</span><br><span class="line">        tmp.<span class="built_in">push_back</span>(candidates[curr]);</span><br><span class="line">        <span class="built_in">permute</span>(candidates,target,tmp,sum + candidates[curr],curr);</span><br><span class="line">        tmp.<span class="built_in">pop_back</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="剑指-offer-ii-082.-含有重复元素集合的组合"><a href="https://leetcode-cn.com/problems/4sjJUc/">剑指 Offer II 082. 含有重复元素集合的组合</a></h4>
<p>​ 给定一个可能有重复数字的整数数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。</p>
<p>​ candidates 中的每个数字在每个组合中只能使用一次，解集不能包含重复的组合。</p>
<p>示例 1:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: candidates = [10,1,2,7,6,1,5], target = 8,</span><br><span class="line">输出:</span><br><span class="line">[</span><br><span class="line">    [1,1,6],</span><br><span class="line">    [1,2,5],</span><br><span class="line">    [1,7],</span><br><span class="line">    [2,6]</span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="解题思路-2">解题思路：</h5>
<p>​ 本题跟上题不一样的点在于：本题每个元素都只能使用一次，但是可选的元素数组中会出现重复的元素，这也就意味着如果按照正常的DFS下来，是会出现重复的组合的。此处，我们按照如下思想来处理：</p>
<p>​ 我们先将它提供的整数数组进行排序，使其成为有序的数组。</p>
<p>​ 每一轮DFS的时候，记录上一轮有没有选择元素</p>
<ul>
<li><p>如果上一轮没有选择元素，并且当前元素和上一轮元素一样：那么该轮也只能选择 “不选择当前元素”，原因是如果两轮元素一致，"上一轮没选这一轮选了"，那么势必会和 "上一轮选了，这一轮不选"，这种情况产生重复。</p></li>
<li><p>如果上一轮选择了元素，那么该轮就可以正常操作：可以选择当前元素，也可以不选择当前元素。</p></li>
</ul>
<h5 id="解题代码-2">解题代码：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">combinationSum2</span>(vector&lt;<span class="keyword">int</span>&gt;&amp; candidates, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; tmp;</span><br><span class="line">        <span class="built_in">sort</span>(candidates.<span class="built_in">begin</span>(),candidates.<span class="built_in">end</span>());</span><br><span class="line">        <span class="built_in">permute</span>(candidates,target,tmp,<span class="number">0</span>,<span class="number">0</span>,<span class="literal">true</span>);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">permute</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; candidates,<span class="keyword">int</span> target,vector&lt;<span class="keyword">int</span>&gt; &amp;tmp,<span class="keyword">int</span> sum,<span class="keyword">int</span> curr,<span class="keyword">bool</span> choose)</span></span>&#123;</span><br><span class="line">        <span class="comment">//当前vector，当前sum</span></span><br><span class="line">        <span class="keyword">if</span>(sum == target)&#123;</span><br><span class="line">            res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(curr &gt;= candidates.<span class="built_in">size</span>()) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">if</span>(curr &gt;= <span class="number">1</span> &amp;&amp; candidates[curr] == candidates[curr<span class="number">-1</span>] &amp;&amp; !choose)&#123;</span><br><span class="line">            <span class="comment">//Case1: 不选择当前元素：</span></span><br><span class="line">            <span class="built_in">permute</span>(candidates,target,tmp,sum,curr+<span class="number">1</span>,<span class="literal">false</span>);  </span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="comment">//Case1: 不选择当前元素：</span></span><br><span class="line">            <span class="built_in">permute</span>(candidates,target,tmp,sum,curr+<span class="number">1</span>,<span class="literal">false</span>);  </span><br><span class="line"></span><br><span class="line">            <span class="comment">// Case2: 选择当前元素：</span></span><br><span class="line">            <span class="keyword">if</span>(sum + candidates[curr] &gt; target) <span class="keyword">return</span>;</span><br><span class="line">            tmp.<span class="built_in">push_back</span>(candidates[curr]);</span><br><span class="line">            <span class="built_in">permute</span>(candidates,target,tmp,sum + candidates[curr],curr+<span class="number">1</span>,<span class="literal">true</span>);</span><br><span class="line">            tmp.<span class="built_in">pop_back</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="剑指-offer-ii-083.-没有重复元素集合的全排列"><a href="https://leetcode-cn.com/problems/VvJkup/">剑指 Offer II 083. 没有重复元素集合的全排列</a></h4>
<p>给定一个不含重复数字的整数数组 nums ，返回其 所有可能的全排列 。可以 按任意顺序 返回答案。</p>
<p>示例 1：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [1,2,3]</span><br><span class="line">输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]</span><br></pre></td></tr></table></figure>
<p>提示：</p>
<pre><code>1 &lt;= nums.length &lt;= 6
-10 &lt;= nums[i] &lt;= 10
nums 中的所有整数 互不相同</code></pre>
<h5 id="解题思路-3">解题思路：</h5>
<p>​ 本题跟直接求1-n这n个数的全排列是一样的思想，基本就是每一轮确定第curr个数是什么，如果<code>curr==nums.size()</code>就输出该种可能。并且我们需要一个<code>hasInclude[]</code>数组记录，某个数有没有被访问过。</p>
<h5 id="解题代码-3">解题代码：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">permute</span>(vector&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">        vector&lt;<span class="keyword">bool</span>&gt; hasInclude;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            hasInclude.<span class="built_in">push_back</span>(<span class="literal">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; tmp;</span><br><span class="line">        <span class="built_in">dfs</span>(<span class="number">0</span>,tmp,nums,hasInclude,res);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> curr,vector&lt;<span class="keyword">int</span>&gt;&amp; tmp,vector&lt;<span class="keyword">int</span>&gt;&amp; nums,vector&lt;<span class="keyword">bool</span>&gt; &amp;hasInclude,vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; &amp;res)</span></span>&#123;</span><br><span class="line">        <span class="comment">//确定第curr个数是什么</span></span><br><span class="line">        <span class="keyword">if</span>(curr == nums.<span class="built_in">size</span>())&#123;</span><br><span class="line">            <span class="comment">//代表到底了</span></span><br><span class="line">            res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(!hasInclude[i])&#123;</span><br><span class="line">                hasInclude[i] = <span class="literal">true</span>;</span><br><span class="line">                tmp.<span class="built_in">push_back</span>(nums[i]);</span><br><span class="line">                <span class="built_in">dfs</span>(curr+<span class="number">1</span>,tmp,nums,hasInclude,res);</span><br><span class="line">                tmp.<span class="built_in">pop_back</span>();</span><br><span class="line">                hasInclude[i] = <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="剑指-offer-ii-084.-含有重复元素集合的全排列"><a href="https://leetcode-cn.com/problems/7p8L0Z/">剑指 Offer II 084. 含有重复元素集合的全排列</a></h4>
<p>给定一个可包含重复数字的整数集合 nums ，按任意顺序 返回它所有不重复的全排列。</p>
<p>示例 1：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [1,1,2]</span><br><span class="line">输出：</span><br><span class="line">[[1,1,2],</span><br><span class="line"> [1,2,1],</span><br><span class="line"> [2,1,1]]</span><br></pre></td></tr></table></figure>
<h5 id="解题思路-4">解题思路：</h5>
<p>​ 084这题相对于083而言，就像是082相对于081而言，多了一个重复元素。我们就需要排除重复的信息。一种朴素的想法是，用hash表记录每一个全排列的情况，然后每产生一个全排列就去Hash表里找有没有一样的，这是一种方法，但时间复杂度肯定较高。</p>
<p>​ 比较优化的方法思想其实和082相似，也是需要先对数组进行排序，得到有序的nums.</p>
<p>​ 我们在DFS的时候，如果当前元素和前面元素一样，并且前面的元素还没有被选择，那么该元素也不在本轮被选择。原因也和082一致，如果前面的元素没被选，而当前元素被选了，势必会和正常流程中，"前面元素选了，当前元素未选"的排列造成重复。所以只有当前面的元素已经被使用了，确定好位置了，后面的相同的元素才有机会被使用。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">permuteUnique</span>(vector&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">        vector&lt;<span class="keyword">bool</span>&gt; hasInclude;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            hasInclude.<span class="built_in">push_back</span>(<span class="literal">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; tmp;</span><br><span class="line">        <span class="built_in">sort</span>(nums.<span class="built_in">begin</span>(),nums.<span class="built_in">end</span>());</span><br><span class="line">        <span class="built_in">dfs</span>(<span class="number">0</span>,tmp,nums,hasInclude,res);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> curr,vector&lt;<span class="keyword">int</span>&gt;&amp; tmp,vector&lt;<span class="keyword">int</span>&gt;&amp; nums,vector&lt;<span class="keyword">bool</span>&gt; &amp;hasInclude,vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; &amp;res)</span></span>&#123;</span><br><span class="line">        <span class="comment">//确定第curr个数是什么</span></span><br><span class="line">        <span class="keyword">if</span>(curr == nums.<span class="built_in">size</span>())&#123;</span><br><span class="line">            <span class="comment">//代表到底了</span></span><br><span class="line">            res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i &gt;= <span class="number">1</span> &amp;&amp; nums[i] == nums[i<span class="number">-1</span>] &amp;&amp; !hasInclude[i<span class="number">-1</span>])&#123;</span><br><span class="line">                <span class="comment">//前面元素和当前一样，并且前面的元素还没用掉，直接不选跳过</span></span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(!hasInclude[i])&#123;</span><br><span class="line">                hasInclude[i] = <span class="literal">true</span>;</span><br><span class="line">                tmp.<span class="built_in">push_back</span>(nums[i]);</span><br><span class="line">                <span class="built_in">dfs</span>(curr+<span class="number">1</span>,tmp,nums,hasInclude,res);</span><br><span class="line">                tmp.<span class="built_in">pop_back</span>();</span><br><span class="line">                hasInclude[i] = <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="剑指-offer-ii-085.-生成匹配的括号"><a href="https://leetcode-cn.com/problems/IDBivT/">剑指 Offer II 085. 生成匹配的括号</a></h4>
<p>正整数 <code>n</code> 代表生成括号的对数，请设计一个函数，用于能够生成所有可能的并且 <strong>有效的</strong> 括号组合。</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：n = 3</span><br><span class="line">输出：[&quot;((()))&quot;,&quot;(()())&quot;,&quot;(())()&quot;,&quot;()(())&quot;,&quot;()()()&quot;]</span><br></pre></td></tr></table></figure>
<h5 id="解题思路-5">解题思路：</h5>
<p>​ 这是一道比较有趣的DFS的题目，DFS分支的条件比较难想，整体代码较为简单。</p>
<p>​ 要想清楚，为什么此处我仅用两个Case就可以完成DFS分支的遍历，在最终输出的时候又做了哪些操作。</p>
<h5 id="解题代码-4">解题代码：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;string&gt; <span class="title">generateParenthesis</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        vector&lt;string&gt; res;</span><br><span class="line">        string tmp;</span><br><span class="line">        <span class="built_in">dfs</span>(<span class="number">0</span>,<span class="number">0</span>,n,tmp,res);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> left_curr,<span class="keyword">int</span> right_curr,<span class="keyword">int</span> n,string tmp,vector&lt;string&gt; &amp;res)</span></span>&#123;</span><br><span class="line">        <span class="comment">//left_curr当前加到第几个（了，right_curr 代表已经加了几个 ）</span></span><br><span class="line">        <span class="keyword">if</span>(left_curr == n)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=right_curr;i&lt;n;i++)&#123;</span><br><span class="line">                tmp += <span class="string">&quot;)&quot;</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//Case1: 仅加左括号</span></span><br><span class="line">        <span class="keyword">if</span>(left_curr &lt; n) <span class="built_in">dfs</span>(left_curr+<span class="number">1</span>,right_curr,n,tmp+<span class="string">&quot;(&quot;</span>,res);</span><br><span class="line">        <span class="comment">//Case2: 加一对右括号</span></span><br><span class="line">        <span class="keyword">if</span>(right_curr &lt; left_curr &amp;&amp; right_curr &lt; n) <span class="built_in">dfs</span>(left_curr,right_curr+<span class="number">1</span>,n,tmp+<span class="string">&quot;)&quot;</span>,res);</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>DFS与BFS系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>DFS</tag>
      </tags>
  </entry>
  <entry>
    <title>图系列——重建序列</title>
    <url>/2022/02/26/16bfad4011e0/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-115.-重建序列"><a href="https://leetcode-cn.com/problems/ur2n8P/">剑指 Offer II 115. 重建序列</a></h4>
<p>请判断原始的序列 org 是否可以从序列集 seqs 中唯一地 重建 。</p>
<p>序列 org 是 1 到 n 整数的排列，其中 1 ≤ n ≤ 10^4。重建 是指在序列集 seqs 中构建最短的公共超序列，即 seqs 中的任意序列都是该最短序列的子序列。</p>
<p>示例 1：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: org = [1,2,3], seqs = [[1,2],[1,3]]</span><br><span class="line">输出: false</span><br><span class="line">解释：[1,2,3] 不是可以被重建的唯一的序列，因为 [1,3,2] 也是一个合法的序列。</span><br></pre></td></tr></table></figure>
<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: org = [1,2,3], seqs = [[1,2]]</span><br><span class="line">输出: false</span><br><span class="line">解释：可以重建的序列只有 [1,2]。</span><br></pre></td></tr></table></figure>
<p>示例 3：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: org = [1,2,3], seqs = [[1,2],[1,3],[2,3]]</span><br><span class="line">输出: true</span><br><span class="line">解释：序列 [1,2], [1,3] 和 [2,3] 可以被唯一地重建为原始的序列 [1,2,3]。</span><br></pre></td></tr></table></figure>
<p>提示：</p>
<pre><code>1 &lt;= n &lt;= 10^4
org 是数字 1 到 n 的一个排列
1 &lt;= segs[i].length &lt;= 10^5
seqs[i][j] 是 32 位有符号整数</code></pre>
<h5 id="解题思路">解题思路：</h5>
<p>​ 本题与<a href="https://blog.slks.xyz/2022/02/25/4e6244e39183/">[外星文字典](https://blog.slks.xyz/2022/02/25/4e6244e39183/)</a> 相似，都是通过序列seqs获取拓扑排序信息，然后依据拓扑排序，观察是否与org一致，从而达到题目要求目的。具体可以参照官方思路，本题因为已经过了一刷测试点，仅在此记录</p>
<h5 id="解题代码">解题代码：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">sequenceReconstruction</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; org, vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt;&amp; seqs)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = org.<span class="built_in">size</span>();</span><br><span class="line">        <span class="comment">// 边集</span></span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">edges</span>(n + <span class="number">1</span>);</span><br><span class="line">        <span class="comment">// 入度</span></span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">inDegree</span><span class="params">(n + <span class="number">1</span>)</span></span>;</span><br><span class="line">        <span class="comment">// 记录seqs中的结点，可能有不在org里的这时候就要停了返回false</span></span><br><span class="line">        <span class="comment">// org 是一定是数字 1 到 n 的一个排列， 但seqs很自由</span></span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">nodes</span><span class="params">(n + <span class="number">1</span>)</span></span>; </span><br><span class="line">        <span class="keyword">int</span> cnt = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">const</span> vector&lt;<span class="keyword">int</span>&gt;&amp; seq : seqs) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; seq.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">                <span class="comment">// 不再org范围了</span></span><br><span class="line">                <span class="keyword">if</span> (seq[i] &lt; <span class="number">0</span> || seq[i] &gt; n) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                <span class="comment">// 记录出现结点数</span></span><br><span class="line">                <span class="keyword">if</span> (++nodes[seq[i]] == <span class="number">1</span>) cnt++;</span><br><span class="line">                <span class="keyword">if</span> (i == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">                edges[seq[i - <span class="number">1</span>]].<span class="built_in">push_back</span>(seq[i]);</span><br><span class="line">                inDegree[seq[i]]++;</span><br><span class="line">            &#125;            </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 结点数不同</span></span><br><span class="line">        <span class="keyword">if</span> (cnt != n) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="comment">// 用队列和栈都可</span></span><br><span class="line">        queue&lt;<span class="keyword">int</span>&gt; q;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n; ++i)</span><br><span class="line">            <span class="keyword">if</span> (inDegree[i] == <span class="number">0</span>) q.<span class="built_in">push</span>(i);</span><br><span class="line">        <span class="keyword">int</span> index = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (!q.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            <span class="comment">// 队列中有2个以上结点，就有2种以上可能不唯一了</span></span><br><span class="line">            <span class="keyword">if</span> (q.<span class="built_in">size</span>() &gt; <span class="number">1</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">int</span> node = q.<span class="built_in">front</span>();</span><br><span class="line">            <span class="keyword">if</span> (org[index] != node) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            index++;   </span><br><span class="line">            q.<span class="built_in">pop</span>();</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= edges[node].<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">                <span class="keyword">if</span> (--inDegree[edges[node][i - <span class="number">1</span>]] == <span class="number">0</span>)</span><br><span class="line">                    q.<span class="built_in">push</span>(edges[node][i - <span class="number">1</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> index == n;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>图系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>graph</tag>
        <tag>topological sort</tag>
      </tags>
  </entry>
  <entry>
    <title>数组系列——值和下标之差都在给定范围内</title>
    <url>/2022/02/26/994b03ade281/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-057.-值和下标之差都在给定的范围内"><a href="https://leetcode-cn.com/problems/7WqeDu/">剑指 Offer II 057. 值和下标之差都在给定的范围内</a></h4>
<p>​ 给你一个整数数组 nums 和两个整数 k 和 t 。请你判断是否存在 两个不同下标 i 和 j，使得 abs(nums[i] - nums[j]) &lt;= t ，同时又满足 abs(i - j) &lt;= k 。</p>
<p>​ 如果存在则返回 true，不存在返回 false。</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [1,2,3,1], k = 3, t = 0</span><br><span class="line">输出：true</span><br></pre></td></tr></table></figure>
<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [1,0,1,1], k = 1, t = 2</span><br><span class="line">输出：true</span><br></pre></td></tr></table></figure>
<p><strong>示例 3：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [1,5,9,1,5,9], k = 2, t = 3</span><br><span class="line">输出：false</span><br></pre></td></tr></table></figure>
<p>提示：</p>
<pre><code>0 &lt;= nums.length &lt;= 2 * 10^4
-2^31 &lt;= nums[i] &lt;= 2^31 - 1
0 &lt;= k &lt;= 10^4
0 &lt;= t &lt;= 2^31 - 1</code></pre>
<p>参考官方题解：https://leetcode-cn.com/problems/7WqeDu/solution/zhi-he-xia-biao-zhi-chai-du-zai-gei-ding-94ei/</p>
<p><strong>解题思路</strong>：</p>
<p>​ 对于序列中每一个元素x左侧的最多k个元素而言，如果这k个元素中存在一个元素落在区间<code>[x-t,x+t]</code>中，那么就可以找到一对符合条件的元素。<strong>注意到对于两个相邻的元素而言，它们左侧的k个元素中有k-1个是重合的，所以可以考虑滑动窗口的思路，维护一个大小为k的滑动窗口，每次遍历到元素x的时候，滑动窗口中包含x前面的k个元素，我们只需要检查窗口中是否有元素满足要求即可。</strong></p>
<p>​ 此时，问题就来了：<strong>如果使用队列维护滑动窗口内的元素，由于元素是无序的，我们只能对于每个元素都遍历一次队列来检查是否有元素符合条件。</strong>如果数组的长度为 n，则使用队列的时间复杂度为 O(nk)，这样跟暴力求解没有区别了。所以我们需要一个数据结构能够来用于维护滑动窗口，该容器需要满足：</p>
<ul>
<li>支持添加+删除元素</li>
<li>内部元素有序，我们可以快速判断是否有满足条件的元素。（具体而言，对于元素 x，当我们希望判断滑动窗口中是否存在某个数 y 落在区间 <code>[x - t, x + t]</code>中，只需要判断滑动窗口中所有大于等于 x−t 的元素中的最小元素是否小于等于 x+t 即可。</li>
</ul>
<p><strong>注意</strong></p>
<p>​ 如果当前有序集合中存在相同元素，那么此时程序将直接返回 true。因此本题中的有序集合无需处理相同元素的情况。</p>
<h5 id="官方解题代码">官方解题代码：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">containsNearbyAlmostDuplicate</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> k, <span class="keyword">int</span> t)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        set&lt;<span class="keyword">int</span>&gt; rec;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">            <span class="keyword">auto</span> iter = rec.<span class="built_in">lower_bound</span>(<span class="built_in">max</span>(nums[i], INT_MIN + t) - t);</span><br><span class="line">            <span class="keyword">if</span> (iter != rec.<span class="built_in">end</span>() &amp;&amp; *iter &lt;= <span class="built_in">min</span>(nums[i], INT_MAX - t) + t) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            rec.<span class="built_in">insert</span>(nums[i]);</span><br><span class="line">            <span class="keyword">if</span> (i &gt;= k) &#123;</span><br><span class="line">                rec.<span class="built_in">erase</span>(nums[i - k]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">作者：LeetCode-Solution</span><br><span class="line">链接：https:<span class="comment">//leetcode-cn.com/problems/7WqeDu/solution/zhi-he-xia-biao-zhi-chai-du-zai-gei-ding-94ei/</span></span><br><span class="line">来源：力扣（LeetCode）</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>数组系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>array</tag>
      </tags>
  </entry>
  <entry>
    <title>图系列——外星文字典</title>
    <url>/2022/02/25/4e6244e39183/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-114.-外星文字典"><a href="https://leetcode-cn.com/problems/Jf1JuT/">剑指 Offer II 114. 外星文字典</a></h4>
<p>现有一种使用英语字母的外星文语言，这门语言的字母顺序与英语顺序不同。</p>
<p>给定一个字符串列表 words ，作为这门语言的词典，words 中的字符串已经 按这门新语言的字母顺序进行了排序</p>
<p>请你根据该词典还原出此语言中已知的字母顺序，并 按字母递增顺序 排列。若不存在合法字母顺序，返回 "" 。若存在多种可能的合法字母顺序，返回其中 任意一种 顺序即可。</p>
<p>字符串 s 字典顺序小于 字符串 t 有两种情况：</p>
<ul>
<li>在第一个不同字母处，如果 s 中的字母在这门外星语言的字母顺序中位于 t 中字母之前，那么 s 的字典顺序小于 t 。</li>
<li>如果前面 min(s.length, t.length) 字母都相同，那么 s.length &lt; t.length 时，s 的字典顺序也小于 t 。</li>
</ul>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：words = [&quot;wrt&quot;,&quot;wrf&quot;,&quot;er&quot;,&quot;ett&quot;,&quot;rftt&quot;]</span><br><span class="line">输出：&quot;wertf&quot;</span><br></pre></td></tr></table></figure>
<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：words = [&quot;z&quot;,&quot;x&quot;]</span><br><span class="line">输出：&quot;zx&quot;</span><br></pre></td></tr></table></figure>
<p><strong>示例 3：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：words = [&quot;z&quot;,&quot;x&quot;,&quot;z&quot;]</span><br><span class="line">输出：&quot;&quot;</span><br><span class="line">解释：不存在合法字母顺序，因此返回 &quot;&quot; 。</span><br></pre></td></tr></table></figure>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 还是比较容易想到 建图 + 拓扑排序的。整体而言复杂度较高，但是思路应该比较清晰，主要过程就是分为两步：1、建图，从相邻的单词之间获取信息 2、拓扑排序，得到结果。</p>
<p>​ 其中两个工具函数比较重要：<strong>一个是常见的transform函数</strong>，能够以O(1)的时间复杂度，用哈希表给每个字符赋予一个ID，方便后续进行拓扑排序。<strong>另一个就是getInfo函数</strong>，其接受两个字符串s1和s2，已知s1&lt;s2的情况下，返回一个<code>vector&lt;char&gt;</code>，第一位代表状态，第二三位代表其能够从中得到的字符字典序信息。具体见代码注释：</p>
<h5 id="解题代码"><strong>解题代码</strong>：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    unordered_map&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt; char2int;</span><br><span class="line">    unordered_map&lt;<span class="keyword">int</span>,<span class="keyword">char</span>&gt; int2char;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">transform</span><span class="params">(<span class="keyword">char</span> c)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(char2int.<span class="built_in">find</span>(c) == char2int.<span class="built_in">end</span>())&#123;</span><br><span class="line">            char2int[c] = char2int.<span class="built_in">size</span>();</span><br><span class="line">            int2char[char2int.<span class="built_in">size</span>() - <span class="number">1</span>] = c;</span><br><span class="line">            <span class="keyword">return</span> char2int.<span class="built_in">size</span>() - <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> char2int[c];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">string <span class="title">alienOrder</span><span class="params">(vector&lt;string&gt;&amp; words)</span> </span>&#123;</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">graph</span>(<span class="number">26</span>);</span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">bool</span>&gt; <span class="title">isVisited</span><span class="params">(<span class="number">26</span>*<span class="number">26</span>,<span class="literal">false</span>)</span></span>;</span><br><span class="line">        <span class="comment">//先把所有字符添加进去</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;words.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;words[i].<span class="built_in">length</span>();j++)&#123;</span><br><span class="line">                <span class="built_in">transform</span>(words[i][j]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//构建图</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;words.<span class="built_in">size</span>()<span class="number">-1</span>;i++)&#123;</span><br><span class="line">            vector&lt;<span class="keyword">char</span>&gt; t = <span class="built_in">getInfo</span>(words[i],words[i+<span class="number">1</span>]);</span><br><span class="line">            <span class="keyword">if</span>(t[<span class="number">0</span>] == <span class="string">&#x27;2&#x27;</span>) <span class="keyword">continue</span>;  <span class="comment">// 仅长度不一样，无信息</span></span><br><span class="line">            <span class="keyword">if</span>(t[<span class="number">0</span>] == <span class="string">&#x27;0&#x27;</span>) <span class="keyword">return</span> <span class="string">&quot;&quot;</span>; <span class="comment">//直接不需要后续的操作了，因为已经违反规则了</span></span><br><span class="line">            <span class="comment">// t[1] &lt; t[2] , 构建图 , t[1] -&gt; t[2]</span></span><br><span class="line">            <span class="keyword">int</span> idx1 = <span class="built_in">transform</span>(t[<span class="number">1</span>]);</span><br><span class="line">            <span class="keyword">int</span> idx2 = <span class="built_in">transform</span>(t[<span class="number">2</span>]);</span><br><span class="line">            <span class="keyword">if</span>(!isVisited[idx1 * <span class="number">26</span> + idx2])&#123;  <span class="comment">//用于记录 idx1-&gt;idx2这个关系有没有添加过</span></span><br><span class="line">                isVisited[idx1 * <span class="number">26</span> + idx2] = <span class="literal">true</span>;</span><br><span class="line">                graph[idx1].<span class="built_in">push_back</span>(idx2);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//拓扑排序：</span></span><br><span class="line">        <span class="keyword">int</span> n = char2int.<span class="built_in">size</span>(); <span class="comment">// 节点个数</span></span><br><span class="line">        <span class="comment">// 如果图中有环，则不存在合理的情况 拓扑排序会失败。节点数不=n</span></span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">inDegree</span><span class="params">(n)</span></span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            <span class="comment">//遍历每一个节点，计算入度</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;graph[i].<span class="built_in">size</span>();j++)&#123;</span><br><span class="line">                inDegree[graph[i][j]]++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//对于所有入度为0的节点入队列</span></span><br><span class="line">        queue&lt;<span class="keyword">int</span>&gt; q;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(inDegree[i] == <span class="number">0</span>) q.<span class="built_in">push</span>(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        string res = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="keyword">while</span>(!q.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            <span class="keyword">int</span> curr = q.<span class="built_in">front</span>();</span><br><span class="line">            q.<span class="built_in">pop</span>();</span><br><span class="line">            res += int2char[curr];</span><br><span class="line">            count++;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;graph[curr].<span class="built_in">size</span>();j++)&#123;</span><br><span class="line">                inDegree[graph[curr][j]]--;</span><br><span class="line">                <span class="keyword">if</span>(inDegree[graph[curr][j]] == <span class="number">0</span>) q.<span class="built_in">push</span>(graph[curr][j]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(count == n) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">vector&lt;<span class="keyword">char</span>&gt; <span class="title">getInfo</span><span class="params">(string &amp;s1,string &amp;s2)</span></span>&#123;</span><br><span class="line">        <span class="comment">// 该函数用于返回从字符串s1&lt;s2这个信息中获得的有用信息，第一位为状态判断位，供函数调用者判断状态</span></span><br><span class="line">        <span class="comment">// 0 - 代表排序有误：该状态代表 s1比s2长，且公共部分内容相同，但是却判断s1&lt;s2，调用者遇到此状态上层可直接返回不合理即可。</span></span><br><span class="line">        <span class="comment">// 1 - 代表有可用信息: t[1] 在 t[2] 前面</span></span><br><span class="line">        <span class="comment">// 2 - 代表无可用信息，代表 s1&lt;s2 仅因为长度不同导致，无法获取字符的前后顺序</span></span><br><span class="line">        vector&lt;<span class="keyword">char</span>&gt; res;</span><br><span class="line">        <span class="keyword">int</span> len1 = s1.<span class="built_in">length</span>();</span><br><span class="line">        <span class="keyword">int</span> len2 = s2.<span class="built_in">length</span>();</span><br><span class="line">        <span class="keyword">int</span> min_len = <span class="built_in">min</span>(len1,len2);</span><br><span class="line">        <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;min_len;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(s1[i] != s2[i])&#123;</span><br><span class="line">                flag = <span class="literal">true</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(<span class="string">&#x27;1&#x27;</span>);   <span class="comment">//第一位为状态判断位 1-代表有可用信息</span></span><br><span class="line">                res.<span class="built_in">push_back</span>(s1[i]);</span><br><span class="line">                res.<span class="built_in">push_back</span>(s2[i]);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(len1 &gt; len2 &amp;&amp; !flag)&#123;</span><br><span class="line">            <span class="comment">//如果s1比s2长，且在公共部分没找到内容的话，已经就不可能了</span></span><br><span class="line">            res.<span class="built_in">push_back</span>(<span class="string">&#x27;0&#x27;</span>); <span class="comment">//第一位为状态判断位 0-代表有信息：这个信息告诉我们排序已经不可能了</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(len1 &lt;= len2 &amp;&amp; !flag)&#123;</span><br><span class="line">            res.<span class="built_in">push_back</span>(<span class="string">&#x27;2&#x27;</span>); <span class="comment">//第一位为状态判断位 2-代表无有用信息</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;  </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>图系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>graph</tag>
        <tag>topological sort</tag>
      </tags>
  </entry>
  <entry>
    <title>BFS系列——单词演变(困难)</title>
    <url>/2022/02/24/64f7eff00abc/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-108.-单词演变"><a href="https://leetcode-cn.com/problems/om3reC/">剑指 Offer II 108. 单词演变</a></h4>
<p>在字典（单词列表） wordList 中，从单词 beginWord 和 endWord 的 转换序列 是一个按下述规格形成的序列：</p>
<pre><code>序列中第一个单词是 beginWord 。
序列中最后一个单词是 endWord 。
每次转换只能改变一个字母。
转换过程中的中间单词必须是字典 wordList 中的单词。</code></pre>
<p>​ 给定两个长度相同但内容不同的单词 beginWord 和 endWord 和一个字典 wordList ，找到从 beginWord 到 endWord 的 最短转换序列 中的 单词数目 。如果不存在这样的转换序列，返回 0。</p>
<p>示例 1：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：beginWord = &quot;hit&quot;, endWord = &quot;cog&quot;, wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]</span><br><span class="line">输出：5</span><br><span class="line">解释：一个最短转换序列是 &quot;hit&quot; -&gt; &quot;hot&quot; -&gt; &quot;dot&quot; -&gt; &quot;dog&quot; -&gt; &quot;cog&quot;, 返回它的长度 5。</span><br></pre></td></tr></table></figure>
<p>示例 2：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：beginWord = &quot;hit&quot;, endWord = &quot;cog&quot;, wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;]</span><br><span class="line">输出：0</span><br><span class="line">解释：endWord &quot;cog&quot; 不在字典中，所以无法进行转换。</span><br></pre></td></tr></table></figure>
<p>提示：</p>
<pre><code>1 &lt;= beginWord.length &lt;= 10
endWord.length == beginWord.length
1 &lt;= wordList.length &lt;= 5000
wordList[i].length == beginWord.length
beginWord、endWord 和 wordList[i] 由小写英文字母组成
beginWord != endWord
wordList 中的所有字符串 互不相同</code></pre>
<p>来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/om3reC 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 题目本身还是比较好理解的，最开始的思路也比较好想，就是将一个个单词赋予ID（使用Hash表），然后根据邻居关系建图，在知道起点与终点的情况下进行BFS即可。值得注意的点是：该题目作为一道困难的题目，时间限制卡的还是比较紧的。我们来看一下上述过程中可能耗费时间比较长的步骤：</p>
<ul>
<li>1、在建立图的时候，要判断单词与单词之间是不是邻居，就需要比较每个单词和每个单词是否只相差一个字母，时间复杂度为O(n^2 * C) , n为单词数量，C为单词长度。</li>
<li>2、在BFS搜索的时候，由于wordList长度上限为5000，整体来说还是比较大的一个图，需要耗费一定的时间。</li>
</ul>
<p>​ 针对上述两个点，都有对应得优化算法，比较经典的就是用于替代单向BFS的<strong>双向BFS</strong>，可以大大缩短BFS的搜寻时间。<strong>我最开始就是做了双向BFS的优化，但是还是超时了。超时代码如下：</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    unordered_map&lt;string,<span class="keyword">int</span>&gt; str2int;</span><br><span class="line">    unordered_map&lt;<span class="keyword">int</span>,string&gt; int2str;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">transform</span><span class="params">(string str)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(str2int.<span class="built_in">find</span>(str) == str2int.<span class="built_in">end</span>())&#123;</span><br><span class="line">            str2int[str] = str2int.<span class="built_in">size</span>();</span><br><span class="line">            int2str[str2int.<span class="built_in">size</span>()<span class="number">-1</span>] = str;</span><br><span class="line">            <span class="keyword">return</span> str2int.<span class="built_in">size</span>()<span class="number">-1</span>;</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">return</span> str2int[str];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isNeighbor</span><span class="params">(<span class="keyword">int</span> idx1,<span class="keyword">int</span> idx2)</span></span>&#123;</span><br><span class="line">        string str1 = int2str[idx1];</span><br><span class="line">        string str2 = int2str[idx2];</span><br><span class="line">        <span class="keyword">if</span>(str1.<span class="built_in">length</span>() != str2.<span class="built_in">length</span>()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;str1.<span class="built_in">length</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(str1[i] != str2[i]) count++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(count != <span class="number">1</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">ladderLength</span><span class="params">(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> begin = <span class="built_in">transform</span>(beginWord);</span><br><span class="line">        <span class="keyword">int</span> end = <span class="built_in">transform</span>(endWord);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;wordList.<span class="built_in">size</span>();i++) <span class="built_in">transform</span>(wordList[i]);</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">graph</span>(str2int.<span class="built_in">size</span>());</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">isNeighbor</span>(begin,end))&#123;</span><br><span class="line">            graph[begin].<span class="built_in">push_back</span>(end);</span><br><span class="line">            graph[end].<span class="built_in">push_back</span>(begin);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//构建图</span></span><br><span class="line">        <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;wordList.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="comment">//对于每个word均判断其和begin 或是 end是不是邻居，以及判断其和前面的wordList中的word是不是邻居</span></span><br><span class="line">            <span class="keyword">int</span> wordIdx = <span class="built_in">transform</span>(wordList[i]);</span><br><span class="line">            <span class="keyword">if</span>(wordIdx == end) flag = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span>(wordIdx == begin || wordIdx == end) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">isNeighbor</span>(begin,wordIdx))&#123;</span><br><span class="line">                graph[begin].<span class="built_in">push_back</span>(wordIdx);</span><br><span class="line">                graph[wordIdx].<span class="built_in">push_back</span>(begin);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">isNeighbor</span>(end,wordIdx))&#123;</span><br><span class="line">                graph[end].<span class="built_in">push_back</span>(wordIdx);</span><br><span class="line">                graph[wordIdx].<span class="built_in">push_back</span>(end);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;i;j++)&#123;</span><br><span class="line">                <span class="keyword">int</span> wordIdx2 = <span class="built_in">transform</span>(wordList[j]);</span><br><span class="line">                <span class="keyword">if</span>(<span class="built_in">isNeighbor</span>(wordIdx2,wordIdx))&#123;</span><br><span class="line">                    graph[wordIdx2].<span class="built_in">push_back</span>(wordIdx);</span><br><span class="line">                    graph[wordIdx].<span class="built_in">push_back</span>(wordIdx2);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(!flag) <span class="keyword">return</span> <span class="number">0</span>; <span class="comment">//如果终点不在列表中，则直接返回0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 输出图代码，证明图构建正确</span></span><br><span class="line">        <span class="comment">// for(int i=0;i&lt;graph.size();i++)&#123;</span></span><br><span class="line">        <span class="comment">//     cout &lt;&lt; i &lt;&lt; &quot; :&quot;;</span></span><br><span class="line">        <span class="comment">//     for(int j=0;j&lt;graph[i].size();j++)&#123;</span></span><br><span class="line">        <span class="comment">//         cout &lt;&lt; graph[i][j] &lt;&lt; &quot; &quot;;</span></span><br><span class="line">        <span class="comment">//     &#125;</span></span><br><span class="line">        <span class="comment">//     cout &lt;&lt; endl;</span></span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//双向BFS</span></span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">vis</span><span class="params">(str2int.size())</span></span>;</span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">res</span><span class="params">(str2int.size())</span></span>;</span><br><span class="line">        queue&lt;<span class="keyword">int</span>&gt; q1; <span class="comment">//正向队列</span></span><br><span class="line">        queue&lt;<span class="keyword">int</span>&gt; q2; <span class="comment">//逆向队列</span></span><br><span class="line">        q1.<span class="built_in">push</span>(begin);</span><br><span class="line">        q2.<span class="built_in">push</span>(end);</span><br><span class="line">        res[begin] = <span class="number">0</span>;</span><br><span class="line">        res[end] = <span class="number">0</span>;</span><br><span class="line">        vis[begin] = <span class="number">1</span>;</span><br><span class="line">        vis[end] = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">while</span>(!q1.<span class="built_in">empty</span>() &amp;&amp; !q2.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            <span class="keyword">int</span> idx;</span><br><span class="line">            <span class="keyword">bool</span> flag;</span><br><span class="line">            <span class="keyword">if</span>(q1.<span class="built_in">size</span>() &lt; q2.<span class="built_in">size</span>())&#123;  <span class="comment">// 正向BFS</span></span><br><span class="line">                flag = <span class="literal">true</span>;</span><br><span class="line">                idx = q1.<span class="built_in">front</span>();</span><br><span class="line">                q1.<span class="built_in">pop</span>();</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                flag = <span class="literal">false</span>;</span><br><span class="line">                idx = q2.<span class="built_in">front</span>();</span><br><span class="line">                q2.<span class="built_in">pop</span>();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;graph[idx].<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">                <span class="comment">//入队</span></span><br><span class="line">                <span class="keyword">if</span>(vis[graph[idx][i]] == <span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="comment">//没访问过</span></span><br><span class="line">                    <span class="keyword">if</span>(flag) q1.<span class="built_in">push</span>(graph[idx][i]);</span><br><span class="line">                    <span class="keyword">else</span> q2.<span class="built_in">push</span>(graph[idx][i]);</span><br><span class="line">                    res[graph[idx][i]] = res[idx] + <span class="number">1</span>;</span><br><span class="line">                    vis[graph[idx][i]] = vis[idx];</span><br><span class="line">                &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(vis[graph[idx][i]]  + vis[idx] == <span class="number">3</span>)&#123;</span><br><span class="line">                        <span class="comment">//如果curr点和领居点的vst相加=3，意味着两者一个是正向搜索序列，一个是逆向搜索序列，相遇了，所以此时我们可以返回结果，不用继续下去了</span></span><br><span class="line">                        <span class="keyword">return</span> res[idx] + res[graph[idx][i]] + <span class="number">1</span> + <span class="number">1</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">               </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​ 针对于另外一个可优化的点，其实先前博客中也记录过，针对于这种仅差一个字符的字符串相似的情况，我们叫做“字符串的广义邻居”，在该文章中提及过：<a href="https://blog.slks.xyz/2022/02/08/4ccc50ba5a4e">奇妙应用—字符串的广义邻居</a></p>
<p>​ 在建图阶段，依据朴素的思路，就是像上面的代码一样枚举每一对单词的组合，判断它们是否恰好相差一个字符，以判断这两个单词对应的节点是否能够相连。但是这样效率太低，我们可以<strong>优化建图</strong>。</p>
<p>​ <strong>具体地，我们可以创建虚拟节点。对于单词 hit，我们创建三个虚拟节点<code>*it、h*t、hi*</code>，并让 hit 向这三个虚拟节点分别连一条边即可。如果一个单词能够转化为 hit，那么该单词必然会连接到这三个虚拟节点之一。对于每一个单词，我们枚举它连接到的虚拟节点，把该单词对应的 id 与这些虚拟节点对应的 id 相连即可。</strong></p>
<h5 id="解题代码"><strong>解题代码</strong>：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    unordered_map&lt;string,<span class="keyword">int</span>&gt; str2int;</span><br><span class="line">    unordered_map&lt;<span class="keyword">int</span>,string&gt; int2str;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">transform</span><span class="params">(string str)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(str2int.<span class="built_in">find</span>(str) == str2int.<span class="built_in">end</span>())&#123;</span><br><span class="line">            str2int[str] = str2int.<span class="built_in">size</span>();</span><br><span class="line">            int2str[str2int.<span class="built_in">size</span>()<span class="number">-1</span>] = str;</span><br><span class="line">            <span class="keyword">return</span> str2int.<span class="built_in">size</span>()<span class="number">-1</span>;</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">return</span> str2int[str];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">constructNode</span><span class="params">(<span class="keyword">int</span> wordIdx, vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; &amp;graph)</span></span>&#123;</span><br><span class="line">        <span class="comment">//构建字符串word的广义邻居（虚拟节点），让其和自己的真实节点相连</span></span><br><span class="line">        <span class="comment">//例如 word = dog ，那么构建广义邻居节点 *og,d*g,do*,让这三个节点和 dog节点相连</span></span><br><span class="line">        string word = int2str[wordIdx];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;word.<span class="built_in">length</span>();j++)&#123;</span><br><span class="line">            <span class="comment">//将每一位变成*，形成虚拟节点,和当前节点连接</span></span><br><span class="line">            string tmp = word;</span><br><span class="line">            tmp[j] = <span class="string">&#x27;*&#x27;</span>;</span><br><span class="line">            <span class="keyword">int</span> tmpIdx = <span class="built_in">transform</span>(tmp);</span><br><span class="line">            graph[tmpIdx].<span class="built_in">push_back</span>(wordIdx);</span><br><span class="line">            graph[wordIdx].<span class="built_in">push_back</span>(tmpIdx);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">ladderLength</span><span class="params">(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 先将所有的原始字符串加入Hash表中</span></span><br><span class="line">        <span class="keyword">int</span> begin = <span class="built_in">transform</span>(beginWord);</span><br><span class="line">        <span class="keyword">int</span> end = <span class="built_in">transform</span>(endWord);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;wordList.<span class="built_in">size</span>();i++) <span class="built_in">transform</span>(wordList[i]);</span><br><span class="line">        <span class="comment">// 按照最坏情况分配空间</span></span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">graph</span>(str2int.<span class="built_in">size</span>() * (wordList[<span class="number">0</span>].<span class="built_in">length</span>() + <span class="number">1</span>));   </span><br><span class="line">        <span class="comment">// 构建图，对于每一个节点，构建其的广义邻居以及自己的节点连接关系</span></span><br><span class="line">        <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">        <span class="built_in">constructNode</span>(begin,graph);</span><br><span class="line">        <span class="built_in">constructNode</span>(end,graph);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;wordList.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> wordIdx = <span class="built_in">transform</span>(wordList[i]); </span><br><span class="line">            <span class="keyword">if</span>(wordIdx == end) flag = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">if</span>(wordIdx == begin || wordIdx == end) <span class="keyword">continue</span>;  <span class="comment">//如果是beginWord或endWord就不需要处理了，已经处理过</span></span><br><span class="line">            <span class="built_in">constructNode</span>(wordIdx,graph);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(!flag) <span class="keyword">return</span> <span class="number">0</span>; <span class="comment">//如果终点不在列表中，则直接返回0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 输出图代码，证明图构建正确</span></span><br><span class="line">        <span class="comment">// for(int i=0;i&lt;str2int.size();i++)&#123;</span></span><br><span class="line">        <span class="comment">//     cout &lt;&lt; i &lt;&lt; &quot;-&quot; &lt;&lt; int2str[i] &lt;&lt; &quot; :&quot;;</span></span><br><span class="line">        <span class="comment">//     for(int j=0;j&lt;graph[i].size();j++)&#123;</span></span><br><span class="line">        <span class="comment">//         cout &lt;&lt; graph[i][j] &lt;&lt; &quot; &quot;;</span></span><br><span class="line">        <span class="comment">//     &#125;</span></span><br><span class="line">        <span class="comment">//     cout &lt;&lt; endl;</span></span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//双向BFS</span></span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">vis</span><span class="params">(str2int.size())</span></span>;</span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">res</span><span class="params">(str2int.size())</span></span>;</span><br><span class="line">        queue&lt;<span class="keyword">int</span>&gt; q1; <span class="comment">//正向队列</span></span><br><span class="line">        queue&lt;<span class="keyword">int</span>&gt; q2; <span class="comment">//逆向队列</span></span><br><span class="line">        q1.<span class="built_in">push</span>(begin);</span><br><span class="line">        q2.<span class="built_in">push</span>(end);</span><br><span class="line">        res[begin] = <span class="number">0</span>;</span><br><span class="line">        res[end] = <span class="number">0</span>;</span><br><span class="line">        vis[begin] = <span class="number">1</span>;</span><br><span class="line">        vis[end] = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">while</span>(!q1.<span class="built_in">empty</span>() &amp;&amp; !q2.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            <span class="keyword">int</span> idx;</span><br><span class="line">            <span class="keyword">bool</span> flag;</span><br><span class="line">            <span class="keyword">if</span>(q1.<span class="built_in">size</span>() &lt; q2.<span class="built_in">size</span>())&#123;  <span class="comment">// 正向BFS</span></span><br><span class="line">                flag = <span class="literal">true</span>;</span><br><span class="line">                idx = q1.<span class="built_in">front</span>();</span><br><span class="line">                q1.<span class="built_in">pop</span>();</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                flag = <span class="literal">false</span>;</span><br><span class="line">                idx = q2.<span class="built_in">front</span>();</span><br><span class="line">                q2.<span class="built_in">pop</span>();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;graph[idx].<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">                <span class="comment">//入队</span></span><br><span class="line">                <span class="keyword">if</span>(vis[graph[idx][i]] == <span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="comment">//没访问过</span></span><br><span class="line">                    <span class="keyword">if</span>(flag) q1.<span class="built_in">push</span>(graph[idx][i]);</span><br><span class="line">                    <span class="keyword">else</span> q2.<span class="built_in">push</span>(graph[idx][i]);</span><br><span class="line">                    res[graph[idx][i]] = res[idx] + <span class="number">1</span>;</span><br><span class="line">                    vis[graph[idx][i]] = vis[idx];</span><br><span class="line">                &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(vis[graph[idx][i]]  + vis[idx] == <span class="number">3</span>)&#123;</span><br><span class="line">                        <span class="comment">//如果curr点和领居点的vst相加=3，意味着两者一个是正向搜索序列，一个是逆向搜索序列，相遇了，所以此时我们可以返回结果，不用继续下去了</span></span><br><span class="line">                        <span class="built_in"><span class="keyword">return</span></span> (res[idx] + res[graph[idx][i]] + <span class="number">1</span>) / <span class="number">2</span> + <span class="number">1</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">               </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>DFS与BFS系列</category>
        <category>字符串系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>BFS</tag>
      </tags>
  </entry>
  <entry>
    <title>则观云资源需求与分析</title>
    <url>/2022/02/24/8386be03d737/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="92a676e4bf82b4ce655ae5f31439de166224bfa67d2018f3a6874d694d565ab8">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>⓽ 其他内容</category>
      </categories>
  </entry>
  <entry>
    <title>动态规划——背包问题应用</title>
    <url>/2022/02/24/46f0b3257e29/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-102.-加减的目标值"><a href="https://leetcode-cn.com/problems/YaVDxD/">剑指 Offer II 102. 加减的目标值</a></h4>
<p>给定一个正整数数组 nums 和一个整数 target 。</p>
<p>向数组中的每个整数前添加 '+' 或 '-' ，然后串联起所有整数，可以构造一个 表达式：</p>
<ul>
<li>例如，nums = [2, 1] ，可以在 2 之前添加 '+' ，在 1 之前添加 '-' ，然后串联起来得到表达式 "+2-1"</li>
</ul>
<p>返回可以通过上述方法构造的、运算结果等于 target 的不同 表达式 的数目。</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [1,1,1,1,1], target = 3</span><br><span class="line">输出：5</span><br><span class="line">解释：一共有 5 种方法让最终目标和为 3.</span><br><span class="line">-1 + 1 + 1 + 1 + 1 = 3</span><br><span class="line">+1 - 1 + 1 + 1 + 1 = 3</span><br><span class="line">+1 + 1 - 1 + 1 + 1 = 3</span><br><span class="line">+1 + 1 + 1 - 1 + 1 = 3</span><br><span class="line">+1 + 1 + 1 + 1 - 1 = 3</span><br></pre></td></tr></table></figure>
<p><strong>提示</strong>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span> &lt;= nums.length &lt;= <span class="number">20</span></span><br><span class="line"><span class="number">0</span> &lt;= nums[i] &lt;= <span class="number">1000</span></span><br><span class="line"><span class="number">0</span> &lt;= <span class="built_in">sum</span>(nums[i]) &lt;= <span class="number">1000</span></span><br><span class="line"><span class="number">-1000</span> &lt;= target &lt;= <span class="number">1000</span></span><br></pre></td></tr></table></figure>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 在本题的背景下，<strong>一开始的错误思路：</strong>利用动态规划的思想，定义二维数组res，<code>res[i][j]</code>代表前<code>i</code>个数，按照题目所给规则，计算得到<code>target = j</code>的方法数目。然后状态转移方程如下 <code>res[i][j] = res[i-1][j-ele] + res[i-1][j+ele]</code>，<code>ele</code>是第<code>i</code>个元素。这个思路基于的思想就是：第<code>i</code>个元素，我们可以给它添加<code>+</code>或者<code>-</code>号，这样的话和为前<code>i</code>个元素计算得到<code>target</code>为<code>j</code>的方法数只有两种可能的路径，就是前<code>i-1</code>个元素。</p>
<p>​ 但是代码写着写着，发现一个不太对的地方，那就是target目标是有可能负的，也就是说，我们需要初始化的<code>j</code>的维度需要代表从<code>-1000~target</code>，但是这样还不能解决问题，因为有可能<code>j-ele</code>是比<code>-1000</code>小的，小多少无从可知，所以我们就没有办法进行比较高效的动态规划。</p>
<p>​ <strong>正确思路</strong>： 我们可以将上述问题转化为，从前<code>i</code>个数字中，选取一定的数字，使得和为<code>j</code>，可能的方法数量。这个和上面的区别在于，我们不再考虑添加正负号，而是直接把上述问题转换为了一个背包问题。因为我们知道，如果正数和为<code>j</code>，那么剩余的负数和为<code>sum-j</code>，<code>sum</code>为<code>nums</code>数组中所有元素的和。那么最后只需要满足如下公式：<code>2 * j - sum = target</code>，就可以得到我们需要的对应方法的数量。也就是说，我们如果定义二维数组<code>res</code>，代表前<code>i</code>个数，选取一定数字，得到和为<code>j</code>的方法数目，那么我们最后<code>res[nums.size()][(sum + target) / 2]</code>即为我们所需要的答案。（注：如果<code>sum+target</code>是奇数，那么必定不存在任何一种方法）。</p>
<p>以下为动态规划的几个重要内容：</p>
<h5 id="动态规划思想"><strong>动态规划思想</strong>：</h5>
<pre><code>`res[i][j]`，代表前`i`个数，选取一定数字，得到和为`j`的方法数目</code></pre>
<h5 id="初始化状态"><strong>初始化状态</strong>：</h5>
<pre><code>`res[0][0-target] `都置为0，且 `res[0][0]` 置为 1</code></pre>
<h5 id="状态转移方程"><strong>状态转移方程</strong>：</h5>
<p>​ <code>res[i][j] = res[i-1][j] + res[i-1][j-ele] (if j - ele &gt;= 0)</code></p>
<p>​ <code>res[i][j] = res[i-1][j] (if j - ele &lt; 0)</code></p>
<p>​ <code>ele = nums[i-1]</code></p>
<h5 id="代码如下"><strong>代码如下</strong>：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">findTargetSumWays</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            sum += nums[i];</span><br><span class="line">        &#125;</span><br><span class="line">		</span><br><span class="line">        <span class="keyword">if</span>((sum+target) % <span class="number">2</span> != <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> need_size = (sum + target) / <span class="number">2</span>;</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">res</span>(nums.<span class="built_in">size</span>()+<span class="number">1</span>,vector&lt;<span class="keyword">int</span>&gt;(need_size+<span class="number">1</span>));</span><br><span class="line">        <span class="comment">//初始化状态： res[0][0-target] 都置为0，且 res[0][0] 置为 1</span></span><br><span class="line">        <span class="comment">//状态转移： res[i][j] = res[i-1][j] + res[i-1][j-ele] 前提是 j-ele 存在</span></span><br><span class="line">        <span class="comment">//如果j-ele 不存在 res[i][j] = res[i-1][j] </span></span><br><span class="line">        res[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> ele = nums[i<span class="number">-1</span>];</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;=need_size;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(j &gt;= ele)&#123;</span><br><span class="line">                    res[i][j] = res[i<span class="number">-1</span>][j] + res[i<span class="number">-1</span>][j-ele];</span><br><span class="line">                &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                    res[i][j] = res[i<span class="number">-1</span>][j];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res[nums.<span class="built_in">size</span>()][need_size];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="剑指-offer-ii-103.-最少的硬币数目"><a href="https://leetcode-cn.com/problems/gaM7Ch/">剑指 Offer II 103. 最少的硬币数目</a></h4>
<p>给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合能组成总金额，返回 -1。</p>
<p>你可以认为每种硬币的数量是无限的。</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：coins = [1, 2, 5], amount = 11</span><br><span class="line">输出：3 </span><br><span class="line">解释：11 = 5 + 5 + 1</span><br></pre></td></tr></table></figure>
<h5 id="解题思路-1"><strong>解题思路</strong>：</h5>
<p>其实本题就是一道完全背包问题，稍加转换即可：</p>
<h5 id="定义"><strong>定义</strong>：</h5>
<pre><code>前`i`个硬币，构成金额`j`，所需要的最少的硬币个数为 `res[i][j]`</code></pre>
<h5 id="初始化状态-1"><strong>初始化状态</strong>：</h5>
<pre><code>`res[0][0-amount] = -1  res[0][0] = 0`</code></pre>
<h5 id="状态转移"><strong>状态转移</strong>：</h5>
<pre><code>`res[i][j] = min( res[i][j-ele] + 1 , res[i-1][j] )`</code></pre>
<p>需要注意的是，因为我们初始化不存在解的值为-1，所以在后续状态转移判定的时候，情况较多，具体见代码：</p>
<h5 id="解题代码">解题代码：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">coinChange</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; coins, <span class="keyword">int</span> amount)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 前i个硬币，构成金额j，所需要的最少的硬币个数为 res[i][j]</span></span><br><span class="line">        <span class="comment">// 初始化状态： res[0][0-amount] = -1  res[0][0] = 0</span></span><br><span class="line">        <span class="comment">// 状态转移： res[i][j] = min( res[i][j-ele] + 1 , res[i-1][j] )</span></span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">res</span>(coins.<span class="built_in">size</span>() + <span class="number">1</span>,vector&lt;<span class="keyword">int</span>&gt;(amount+<span class="number">1</span>,<span class="number">-1</span>));</span><br><span class="line">        res[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=coins.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> ele = coins[i<span class="number">-1</span>];</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;=amount;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(j &gt;= ele)&#123;</span><br><span class="line">                    <span class="keyword">int</span> r1 = res[i<span class="number">-1</span>][j];</span><br><span class="line">                    <span class="keyword">int</span> r2 = res[i][j-ele];</span><br><span class="line">                    <span class="keyword">if</span>(r1 == <span class="number">-1</span> &amp;&amp; r2 != <span class="number">-1</span>)&#123;  <span class="comment">// r1 不存在 , r2 存在，那么参照r2 + 1</span></span><br><span class="line">                        res[i][j] = r2+<span class="number">1</span>;</span><br><span class="line">                    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(r1 != <span class="number">-1</span> &amp;&amp; r2 == <span class="number">-1</span>)&#123; <span class="comment">// r1 存在 , r2 不存在，那么参照 r1</span></span><br><span class="line">                        res[i][j] = r1; </span><br><span class="line">                    &#125;<span class="keyword">else</span> <span class="keyword">if</span>(r1 != <span class="number">-1</span> &amp;&amp; r2 != <span class="number">-1</span>)&#123;  <span class="comment">// r1 存在 , r2 存在，那么参照min(r2+1,r1)</span></span><br><span class="line">                        res[i][j] = <span class="built_in">min</span>(r1,r2+<span class="number">1</span>);</span><br><span class="line">                    &#125;<span class="keyword">else</span>&#123;   <span class="comment">// r1 不存在 , r2 不存在，那么也不存在  = -1</span></span><br><span class="line">                        res[i][j] = <span class="number">-1</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                    res[i][j] = res[i<span class="number">-1</span>][j];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res[coins.<span class="built_in">size</span>()][amount];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>动态规划系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>dynamic programming</tag>
      </tags>
  </entry>
  <entry>
    <title>用Python搭建深度学习框架系列笔记3——优化器类的代码实现（上）</title>
    <url>/2022/02/23/c051c3782dfb/</url>
    <content><![CDATA[<p><strong>前言</strong>： 优化器的理论部分以及各种常见的优化器可以参见如下博客：<a href="https://blog.slks.xyz/2022/02/11/ced858ce48dc/">机器学习基础系列笔记16——常见的梯度下降优化器整理</a></p>
<p>本文所讲的是如何使用Python搭建优化器类，从而帮助实现整个机器学习的训练过程。</p>
<h4 id="一在不封装优化器的时候如何在计算图上执行梯度下降法">一、在不封装优化器的时候，如何在计算图上执行梯度下降法？</h4>
<p>当我们还没有明确提出优化器这个概念的时候，我们遵循如下过程去在计算图上执行梯度下降来优化损失函数：</p>
<ul>
<li>1）对结果节点的上游变量节点(Variable)赋值或初始化【包括输入向量节点和训练参数节点】</li>
<li>2）在结果节点上调用forward，计算出它的值，数据前向传播</li>
<li>3）在所有需要训练的变量节点( Variable, trainable = True )上调用backward方法，梯度反向传播，计算出结果节点对该节点的雅可比矩阵。【仅包括训练参数节点】</li>
<li>4）根据变量节点的jacobi属性中的值，从变量节点的当前值中减去 用学习率 * 梯度的值即为更新后的值。</li>
<li>5）清除所有节点的value和jacobi属性，回到第2步</li>
</ul>
<h4 id="二优化器的封装">二、优化器的封装</h4>
<p>​ 其实，优化器所实现的功能就是上述训练过程中对可训练的变量节点的值进行优化的过程。但是由于，可能存在各种多种多样的优化器，为了便于外层用户使用，代码的整洁，我们需要将优化器的功能封装起来，然后进行使用。</p>
<p>​ 抽象而言，整个更新计算图中变量的普适流程可以抽象为3步：</p>
<ul>
<li>调用Loss节点的Forward方法，这会递归调用所有上游节点的forward方法进行前向传播</li>
<li>对于计算图中需要更新的变量节点，利用Backward方法，计算出Loss节点对他们的雅可比矩阵</li>
<li>使用雅可比矩阵，根据梯度下降法更新参数节点。</li>
</ul>
<p>​ 当然，在理论部分已经知道了，会有不同形式的梯度下降方法，那么在实现中，自然而然的解决方案就是：**将上述流程封装进入一个抽象类：Optimizer中，然后将不同的算法封装进不同的子类里面，实现各自个性化的部分。</p>
<h4 id="三优化器基类optimizer类">三、优化器基类（Optimizer类）：</h4>
<h5 id="part1构造函数">Part1：构造函数</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Optimizer</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    优化器基类</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, graph, target, learning_rate=<span class="number">0.01</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        优化器的构造函数接受计算图对象，目标节点对象(往往就是Loss函数损失值节点，为了方便期间，该框架只支持优化一个目标节点，且我们暂时假设该目标节点最终结果为标量)以及学习率</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(target, Node) <span class="keyword">and</span> <span class="built_in">isinstance</span>(graph, Graph)</span><br><span class="line">        self.graph = graph</span><br><span class="line">        self.target = target</span><br><span class="line">        self.learning_rate = learning_rate</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 为每个参与训练的节点累加一个Mini Batch的全部样本的梯度（具体作用见后）</span></span><br><span class="line">        self.acc_gradient = <span class="built_in">dict</span>()</span><br><span class="line">        self.acc_no = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h5 id="part2核心函数">Part2：核心函数</h5>
<h6 id="核心函数1forward_backward">核心函数1：forward_backward()</h6>
<p>​ 该函数抽象了先前我们所说的优化器普适流程中的前两步，完成前向传播计算结果节点target的值，然后遍历所有的计算图中的节点，找到那些<strong>需要训练的变量节点</strong>，然后对它们执行backward，求出结果节点对这些变量节点的雅可比矩阵。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_backward</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">       前向传播计算结果节点的值并反向传播计算结果节点对各个节点的雅可比矩阵</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">       <span class="comment"># 清除计算图中所有节点的雅可比矩阵</span></span><br><span class="line">       self.graph.clear_jacobi()</span><br><span class="line"></span><br><span class="line">       <span class="comment"># 前向传播计算结果节点</span></span><br><span class="line">       self.target.forward()</span><br><span class="line"></span><br><span class="line">       <span class="comment"># 反向传播计算雅可比矩阵</span></span><br><span class="line">       <span class="keyword">for</span> node <span class="keyword">in</span> self.graph.nodes:</span><br><span class="line">           <span class="keyword">if</span> <span class="built_in">isinstance</span>(node, Variable) <span class="keyword">and</span> node.trainable:</span><br><span class="line">               node.backward(self.target)</span><br><span class="line"></span><br><span class="line">               <span class="comment"># 我们会得到 目标节点对参数节点的雅可比矩阵，将其转置以后即为目标节点对某变量节点的梯度</span></span><br><span class="line">               <span class="comment"># 目标节点（如果是标量的话）对节点值的雅可比是一个行向量，其转置是梯度（列向量）</span></span><br><span class="line">               <span class="comment"># 这里将梯度reshape成与节点值相同的形状，好对节点值进行更新。</span></span><br><span class="line">               <span class="comment"># node 节点的 shape 应当是一个矩阵，矩阵中元素为 N 个。</span></span><br><span class="line">               <span class="comment"># 从 目标节点 对 node 节点的雅可比矩阵相当于是 N维 -》 1维的变换</span></span><br><span class="line">               <span class="comment"># 故而 jacobi 的 shape 应该是 1 * N 维，所以要将其Reshape成Node节点形状，才方便对Node节点中的各个值进行梯度的累加。</span></span><br><span class="line">               gradient = node.jacobi.T.reshape(node.shape())</span><br><span class="line">               <span class="comment"># 如果该节点不在acc_gradient里面，就新建一个key-value</span></span><br><span class="line">               <span class="keyword">if</span> node <span class="keyword">not</span> <span class="keyword">in</span> self.acc_gradient:</span><br><span class="line">                   self.acc_gradient[node] = gradient</span><br><span class="line">               <span class="keyword">else</span>: <span class="comment"># 如果该节点已经在acc_gradient里面，就将梯度进行一个累加</span></span><br><span class="line">                   self.acc_gradient[node] += gradient</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h6 id="核心函数2update">核心函数2：update()：</h6>
<p>​ 该函数封装了优化过程的第三步，参数更新。在Optimizer类中，update方法调用_update这个抽象方法，其具体的方法由具体的子类覆写。执行完参数的更新以后，我们需要将先前累积的梯度给清零。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self, var_gradients=<span class="literal">None</span></span>):</span></span><br><span class="line"><span class="comment"># 该部分作用暂时还未解释，用于分布式训练，该处暂时无用，可以忽略</span></span><br><span class="line">      <span class="keyword">if</span> var_gradients <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">          self.apply_gradients(var_gradients)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 执行更新</span></span><br><span class="line">      self._update()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 清除累加梯度</span></span><br><span class="line">      self.acc_gradient.clear()</span><br><span class="line">      self.acc_no = <span class="number">0</span></span><br><span class="line">  </span><br><span class="line"><span class="meta">  @abc.abstractmethod</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_update</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">      抽象方法，执行具体的梯度更新算法，由子类实现</span></span><br><span class="line"><span class="string">      &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h5 id="part3入口函数">Part3：入口函数：</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">one_step</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算并累加样本的梯度</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    self.forward_backward()</span><br><span class="line">    self.acc_no += <span class="number">1</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="part4-其他辅助函数">Part4: 其他辅助函数：</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apply_gradients</span>(<span class="params">self, node_gradients_dict, summarize=<span class="literal">False</span>, acc_no=<span class="literal">None</span></span>):</span></span><br><span class="line">	<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	此处暂时先不提这个函数，用于分布式训练</span></span><br><span class="line"><span class="string">	&quot;&quot;&quot;</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">get_gradient</span>(<span class="params">self, node</span>):</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">       返回样本的平均梯度</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       <span class="keyword">assert</span> node <span class="keyword">in</span> self.acc_gradient</span><br><span class="line">       <span class="keyword">return</span> self.acc_gradient[node] / self.acc_no</span><br></pre></td></tr></table></figure>
<h4 id="四bgd和sgd和mbgd的数学表达">四、BGD和SGD和MBGD的数学表达：</h4>
<h5 id="bgd">1、BGD</h5>
<p>​ 计算所有样本的平均损失值对参数的梯度，由于求梯度的过程是线性运算，所以<strong>所有样本的平均损失值对参数的梯度就等于每个样本的损失值对参数的梯度的平均：如下公式所示</strong> <span class="math display">\[
\grad(\frac{1}{N}\sum_{i=1}^Nloss{(w|x_i)} ) = \frac{1}{N}\sum_{i=1}^N \grad(loss{(w|x_i)} )
\]</span> ​ 所以，在实现中，我们可以以此计算出训练集中每个样本的损失值对参数的梯度，然后再求这些梯度的平均值。这也是为什么在Optimizer的基类中，我们需要设置<code>self.acc_gradient</code>用于累加每个样本的梯度，然后设置<code>self.acc_no</code>记录累加的样本的数量。</p>
<h5 id="sgd">2、 SGD</h5>
<p>​ 每计算一个样本的损失值，然后就进行参数的更新。</p>
<h5 id="mbgd">3、MBGD</h5>
<p>​ 以一部分样本的损失之进行计算。</p>
<h5 id="总结">总结：</h5>
<p>​ 所以，其实针对于以上三种，在代码实现泛化的时候，我们可以用批大小来进行泛化。batch size = 1即为SGD，反之极端为BDG。在代码中，其实就是 调用 <code>batch_size</code> 次 <code>one_step()</code>函数，然后等到一个Batch的样本梯度累加结束后，再调用<code>update</code>函数即可，<code>update</code>函数会调用子类的<code>_update</code>函数，子类的<code>_update</code>函数中，会调用<code>get_gradient</code>函数，来得到样本的平均梯度然后进行处理。</p>
<h4 id="五matrixslow优化器mbgd实现-其他框架实现方式">五、MatrixSlow优化器MBGD实现 &amp; 其他框架实现方式：</h4>
<h5 id="优化器mbgd实现">1、 优化器MBGD实现</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GradientDescent</span>(<span class="params">Optimizer</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    梯度下降优化器</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, graph, target, learning_rate=<span class="number">0.01</span></span>):</span></span><br><span class="line"></span><br><span class="line">        Optimizer.__init__(self, graph, target)</span><br><span class="line">        self.learning_rate = learning_rate</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_update</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        朴素梯度下降法</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> self.graph.nodes:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(node, Variable) <span class="keyword">and</span> node.trainable:</span><br><span class="line">                <span class="comment"># 取得该节点在当前批的平均梯度</span></span><br><span class="line">                gradient = self.get_gradient(node)</span><br><span class="line">                <span class="comment"># 用朴素梯度下降法更新变量节点的值</span></span><br><span class="line">                node.set_value(node.value - self.learning_rate * gradient)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​ 按照上述非常简单好理解的代码实现，我们可以将整一个优化训练代码的过程简化如下：就是像上一段中描述的那样，调用 <code>batch_size</code> 次 <code>one_step()</code>函数，然后等到一个Batch的样本梯度累加结束后，再调用<code>update</code>函数即可，<code>update</code>函数会调用子类的<code>_update</code>函数，子类的<code>_update</code>函数中，会调用<code>get_gradient</code>函数，来得到样本的平均梯度然后进行处理。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer = ms.optimizer.Adam(ms.default_graph, loss, learning_rate)</span><br><span class="line"></span><br><span class="line">mini_batch_size = <span class="number">8</span></span><br><span class="line">cur_batch_size = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练执行50个epoch</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历训练集中的样本</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(train_set)):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 取第i个样本的前4列（除最后一列的所有列），构造3x1矩阵对象</span></span><br><span class="line">        features = np.mat(train_set[i, :-<span class="number">1</span>]).T</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 取第i个样本的最后一列，是该样本的性别标签（1男，-1女），构造1x1矩阵对象</span></span><br><span class="line">        l = np.mat(train_set[i, -<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将特征赋给x节点，将标签赋给label节点</span></span><br><span class="line">        x.set_value(features)</span><br><span class="line">        label.set_value(l)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 优化器执行一次前向传播和一次后向传播</span></span><br><span class="line">        optimizer.one_step()</span><br><span class="line">        cur_batch_size += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 当积累到一个mini batch的时候，完成一次参数更新</span></span><br><span class="line">        <span class="keyword">if</span> (cur_batch_size == mini_batch_size):</span><br><span class="line">            optimizer.update()</span><br><span class="line">            cur_batch_size = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每个epoch结束后评价模型的正确率</span></span><br><span class="line">    pred = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历训练集，计算当前模型对每个样本的预测值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(train_set)):</span><br><span class="line"></span><br><span class="line">        features = np.mat(train_set[i, :-<span class="number">1</span>]).T</span><br><span class="line">        x.set_value(features)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在模型的predict节点上执行前向传播</span></span><br><span class="line">        predict.forward()</span><br><span class="line">        pred.append(predict.value[<span class="number">0</span>, <span class="number">0</span>])  <span class="comment"># 模型的预测结果：1男，0女</span></span><br><span class="line"></span><br><span class="line">    pred = np.array(pred) * <span class="number">2</span> - <span class="number">1</span>  <span class="comment"># 将1/0结果转化成1/-1结果，好与训练标签的约定一致</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断预测结果与样本标签相同的数量与训练集总数量之比，即模型预测的正确率</span></span><br><span class="line">    accuracy = (train_set[:, -<span class="number">1</span>] == pred).astype(np.<span class="built_in">int</span>).<span class="built_in">sum</span>() / <span class="built_in">len</span>(train_set)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印当前epoch数和模型在训练集上的正确率</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;epoch: &#123;:d&#125;, accuracy: &#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>, accuracy))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="其他框架对于minibatch的实现方式">2、 其他框架对于MiniBatch的实现方式：</h5>
<p>​ 其实，上述MatrixSlow实现MiniBatch梯度计算的方式，并不是工业上最佳的。但是我认为是在学习的过程中比较好的方式。其把 MiniBatch样本和计算图完全分隔开，概念很清晰。<strong>那么在一些工业级的框架中，一般是怎么做的呢？</strong></p>
<p>​ 在其他一些框架中（比如<strong>Pytorch</strong>），可能会用一个变量节点来存储整批样本，<strong>比如样本为n维向量，批大小维m，那么就用一个<span class="math inline">\(m \times n\)</span>的矩阵来存储。</strong>后续计算节点的计算都是对存储数据矩阵的每一行进行的，<strong>然后这一整批的数据都会在计算图里像前面流动，直到损失值节点</strong></p>
<p>​ 总结来说，就是以下几步：</p>
<ul>
<li>添加一个维度，用一个变量节点存储整个minibatch的样本</li>
<li>前向传播对整个batch的样本计算</li>
<li>以平均损失值节点为目标节点</li>
<li>以平均损失之节点对参数的梯度更新参数。</li>
</ul>
<p>​ 这样子的好处在于什么呢？<strong>这种方法所进行计算的性能更好，可以在高效率的利用GPU的并行计算能力，并且能够支持高阶的张量。</strong></p>
<p>​ 以下代码是书中，对于先前的AdaLine的寻阿联例子，如果使用工业框架的方法，应当是如何训练的，给出了一个示例（没有进行封装）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&#x27;../..&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matrixslow <span class="keyword">as</span> ms</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造训练集</span></span><br><span class="line">male_heights = np.random.normal(<span class="number">171</span>, <span class="number">6</span>, <span class="number">500</span>)</span><br><span class="line">female_heights = np.random.normal(<span class="number">158</span>, <span class="number">5</span>, <span class="number">500</span>)</span><br><span class="line"></span><br><span class="line">male_weights = np.random.normal(<span class="number">70</span>, <span class="number">10</span>, <span class="number">500</span>)</span><br><span class="line">female_weights = np.random.normal(<span class="number">57</span>, <span class="number">8</span>, <span class="number">500</span>)</span><br><span class="line"></span><br><span class="line">male_bfrs = np.random.normal(<span class="number">16</span>, <span class="number">2</span>, <span class="number">500</span>)</span><br><span class="line">female_bfrs = np.random.normal(<span class="number">22</span>, <span class="number">2</span>, <span class="number">500</span>)</span><br><span class="line"></span><br><span class="line">male_labels = [<span class="number">1</span>] * <span class="number">500</span></span><br><span class="line">female_labels = [-<span class="number">1</span>] * <span class="number">500</span></span><br><span class="line"></span><br><span class="line">train_set = np.array([np.concatenate((male_heights, female_heights)),</span><br><span class="line">                      np.concatenate((male_weights, female_weights)),</span><br><span class="line">                      np.concatenate((male_bfrs, female_bfrs)),</span><br><span class="line">                      np.concatenate((male_labels, female_labels))]).T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机打乱样本顺序</span></span><br><span class="line">np.random.shuffle(train_set)</span><br><span class="line"><span class="comment"># 批大小</span></span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line"><span class="comment"># batch_size x 3矩阵，每行保存一个样本，整个节点保存一个mini batch的样本</span></span><br><span class="line">X = ms.core.Variable(dim=(batch_size, <span class="number">3</span>), init=<span class="literal">False</span>, trainable=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 保存一个mini batch的样本的类别标签</span></span><br><span class="line">label = ms.core.Variable(dim=(batch_size, <span class="number">1</span>), init=<span class="literal">False</span>, trainable=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 权值向量，3x1矩阵</span></span><br><span class="line">w = ms.core.Variable(dim=(<span class="number">3</span>, <span class="number">1</span>), init=<span class="literal">True</span>, trainable=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 阈值</span></span><br><span class="line">b = ms.core.Variable(dim=(<span class="number">1</span>, <span class="number">1</span>), init=<span class="literal">True</span>, trainable=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 全1向量，维数是batch_size，不可训练</span></span><br><span class="line">ones = ms.core.Variable(dim=(batch_size, <span class="number">1</span>), init=<span class="literal">False</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">ones.set_value(np.mat(np.ones(batch_size)).T)</span><br><span class="line"><span class="comment"># 用阈值（标量）乘以全1向量</span></span><br><span class="line">bias = ms.ops.ScalarMultiply(b, ones)</span><br><span class="line"><span class="comment"># 对一个mini batch的样本计算输出</span></span><br><span class="line">output = ms.ops.Add(ms.ops.MatMul(X, w), bias)</span><br><span class="line">predict = ms.ops.Step(output)</span><br><span class="line"><span class="comment"># 一个mini batch的样本的损失函数</span></span><br><span class="line">loss = ms.ops.loss.PerceptionLoss(ms.ops.Multiply(label, output))</span><br><span class="line"><span class="comment"># 一个mini batch的平均损失</span></span><br><span class="line">B =  ms.core.Variable(dim=(<span class="number">1</span>, batch_size), init=<span class="literal">False</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">B.set_value(<span class="number">1</span> / batch_size * np.mat(np.ones(batch_size)))</span><br><span class="line">mean_loss = ms.ops.MatMul(B, loss)</span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">learning_rate = <span class="number">0.0001</span></span><br><span class="line"><span class="comment"># 训练，这个步骤之后没啥区别</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">    <span class="comment"># 遍历训练集中的样本</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">0</span>, <span class="built_in">len</span>(train_set), batch_size):</span><br><span class="line">        <span class="comment"># 取一个mini batch的样本的特征</span></span><br><span class="line">        features = np.mat(train_set[i:i + batch_size, :-<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># 取一个mini batch的样本的标签</span></span><br><span class="line">        l = np.mat(train_set[i:i + batch_size, -<span class="number">1</span>]).T</span><br><span class="line">        <span class="comment"># 将特征赋给X节点，将标签赋给label节点</span></span><br><span class="line">        X.set_value(features)</span><br><span class="line">        label.set_value(l)</span><br><span class="line">        <span class="comment"># 在平均损失节点上执行前向传播</span></span><br><span class="line">        mean_loss.forward()</span><br><span class="line">        <span class="comment"># 在参数节点上执行反向传播</span></span><br><span class="line">        w.backward(mean_loss)</span><br><span class="line">        b.backward(mean_loss)</span><br><span class="line">        <span class="comment"># 更新参数</span></span><br><span class="line">        w.set_value(w.value - learning_rate * w.jacobi.T.reshape(w.shape()))</span><br><span class="line">        b.set_value(b.value - learning_rate * b.jacobi.T.reshape(b.shape()))</span><br><span class="line">        ms.default_graph.clear_jacobi()</span><br><span class="line">    <span class="comment"># 每个epoch结束后评价模型的正确率</span></span><br><span class="line">    pred = []</span><br><span class="line">    <span class="comment"># 遍历训练集，计算当前模型对每个样本的预测值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">0</span>, <span class="built_in">len</span>(train_set), batch_size):</span><br><span class="line">        features = np.mat(train_set[i:i + batch_size, :-<span class="number">1</span>])</span><br><span class="line">        X.set_value(features)</span><br><span class="line">        <span class="comment"># 在模型的predict节点上执行前向传播</span></span><br><span class="line">        predict.forward()</span><br><span class="line">        <span class="comment"># 当前模型对一个mini batch的样本的预测结果</span></span><br><span class="line">        pred.extend(predict.value.A.ravel())</span><br><span class="line">    pred = np.array(pred) * <span class="number">2</span> - <span class="number">1</span></span><br><span class="line">    accuracy = (train_set[:, -<span class="number">1</span>] == pred).astype(np.<span class="built_in">int</span>).<span class="built_in">sum</span>() / <span class="built_in">len</span>(train_set)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;epoch: &#123;:d&#125;, accuracy: &#123;:.3f&#125;&quot;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>, accuracy))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
        <category>Python搭建简易框架笔记</category>
      </categories>
      <tags>
        <tag>Framework</tag>
      </tags>
  </entry>
  <entry>
    <title>用Python搭建深度学习框架系列笔记2——计算图、前向传播、反向传播与自动微分的代码实现</title>
    <url>/2022/02/22/6bfa5496ebc4/</url>
    <content><![CDATA[<p>​ 首先，我们看完上一节的理论以后，应该需要知晓在上述过程中，我们需要在代码中实现的最核心的节点相关的类如下所示，我们以以下这张经典的计算图来分析：</p>
<p>​ 其中，存储整个图我们需要一个类，<strong>也就是计算图类</strong>，然后图中又有许多类型的节点，第一种类型的节点是<strong>变量节点</strong>，也就是x、w这种，是无父节点的，第二种类型是<strong>Op操作符节点</strong>，也就是+、x这种节点，剩下的就是普通的中间节点。故而我们需要实现的类如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_10_15_03_30_21.png" /></p>
<p>​</p>
<ul>
<li><strong>Node类（基类-非抽象类）</strong>
<ul>
<li>普通中间节点（直接使用Node类即可）</li>
<li>变量节点（继承Node类，无父节点，构造函数接受变量的形状，是否初始化以及是否参与训练的标识）</li>
<li><strong>Op操作符节点（继承Node类，抽象类，然后根据不同的运算符定义类来继承它，其他运算符类需要实现两个方法：compute 和 get_jacobi，</strong>分别用于<strong>根据父节点的值计算本节点的值</strong>，以及<strong>计算本节点对某个父节点的雅可比矩阵</strong>）。</li>
</ul></li>
<li><strong>Graph计算图类</strong></li>
</ul>
<p>接下来，我们来一一看它们的实现代码：</p>
<h3 id="graph计算图类-一些基本函数">1、Graph计算图类 （一些基本函数）</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Graph</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算图类</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.nodes = []  <span class="comment"># 计算图内的节点的列表</span></span><br><span class="line">        self.name_scope = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_node</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        添加节点</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.nodes.append(node)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clear_jacobi</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        清除图中全部节点的雅可比矩阵</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> self.nodes:</span><br><span class="line">            node.clear_jacobi()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reset_value</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重置图中全部节点的值</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> self.nodes:</span><br><span class="line">            node.reset_value(<span class="literal">False</span>)  <span class="comment"># 每个节点不递归清除自己的子节点的值</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">node_count</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.nodes)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 全局默认计算图</span></span><br><span class="line">default_graph = Graph()</span><br></pre></td></tr></table></figure>
<h3 id="node类基类---非抽象类">2、Node类（基类 - 非抽象类）</h3>
<ul>
<li><strong>Part1：构造函数</strong>
<ul>
<li>此部分较好理解，做一些初始化，将节点添加到计算图的list里，然后将该节点添加到父节点的子节点列表中。</li>
<li>需要注意的是：构造函数需要传入两个参数，第一个参数是父节点列表，第二个参数是一些参数列表</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算图节点类基类</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *parents, **kargs</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算图对象，默认为全局对象default_graph</span></span><br><span class="line">        self.kargs = kargs</span><br><span class="line">        self.graph = kargs.get(<span class="string">&#x27;graph&#x27;</span>, default_graph) <span class="comment"># 节点所属的计算图，默认为 全局计算图default_graph</span></span><br><span class="line">        self.need_save = kargs.get(<span class="string">&#x27;need_save&#x27;</span>, <span class="literal">True</span>)  <span class="comment"># 是否需要被保存</span></span><br><span class="line">        self.gen_node_name(**kargs)     <span class="comment"># 依据参数生成节点名称，节点名称在模型保存和导入时会用到</span></span><br><span class="line"></span><br><span class="line">        self.parents = <span class="built_in">list</span>(parents)  <span class="comment"># 父节点列表</span></span><br><span class="line">        self.children = []  <span class="comment"># 子节点列表</span></span><br><span class="line">        self.value = <span class="literal">None</span>  <span class="comment"># 本节点的值，Numpy的Matrix类</span></span><br><span class="line">        self.jacobi = <span class="literal">None</span>  <span class="comment"># 结果节点对本节点的雅可比矩阵</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将本节点添加到父节点的子节点列表中</span></span><br><span class="line">        <span class="keyword">for</span> parent <span class="keyword">in</span> self.parents:</span><br><span class="line">            parent.children.append(self)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将本节点添加到计算图中</span></span><br><span class="line">        self.graph.add_node(self)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Part2: 常见函数</strong>:
<ul>
<li>此部分也是Node类中一些基本的工具型函数，其中gen_node_name就是在构造函数中生成节点名称用的。</li>
<li>dimension 和 shape 函数是用来返回节点值的维度的</li>
<li>reset_value 递归重置该节点 + 该节点下游的节点的值</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_parents</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">       获取本节点的父节点</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       <span class="keyword">return</span> self.parents</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">get_children</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">       获取本节点的子节点</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       <span class="keyword">return</span> self.children</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">gen_node_name</span>(<span class="params">self, **kargs</span>):</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">       生成节点名称，如果用户不指定，则根据节点类型生成类似于&quot;MatMul:3&quot;的节点名，</span></span><br><span class="line"><span class="string">       如果指定了name_scope，则生成类似&quot;Hidden/MatMul:3&quot;的节点名</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       self.name = kargs.get(<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;&#123;&#125;:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">           self.__class__.__name__, self.graph.node_count()))</span><br><span class="line">       <span class="keyword">if</span> self.graph.name_scope:</span><br><span class="line">           self.name = <span class="string">&#x27;&#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(self.graph.name_scope, self.name)</span><br><span class="line">       <span class="function"><span class="keyword">def</span> <span class="title">clear_jacobi</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">       清空结果节点对本节点的雅可比矩阵</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       self.jacobi = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">dimension</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">       返回本节点的值展平成向量后的维数</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       <span class="keyword">return</span> self.value.shape[<span class="number">0</span>] * self.value.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">shape</span>(<span class="params">self</span>):</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">       返回本节点的值作为矩阵的形状：（行数，列数）</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line">       <span class="keyword">return</span> self.value.shape</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">reset_value</span>(<span class="params">self, recursive=<span class="literal">True</span></span>):</span></span><br><span class="line">       <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">       重置本节点的值，并递归重置本节点的下游节点的值。（因为如果本节点的值被重置了，所有下游子节点的值也就都失去了意义，下游子节点的值是依赖于该节点进行计算的）</span></span><br><span class="line"><span class="string">       &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">       self.value = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">       <span class="keyword">if</span> recursive:</span><br><span class="line">           <span class="keyword">for</span> child <span class="keyword">in</span> self.children:</span><br><span class="line">               child.reset_value()</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Part3：虚函数</strong>：
<ul>
<li>这两个函数，是等会儿 操作符节点需要重载的函数内容，在forward和backword中有用到。</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@abc.abstractmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    抽象方法，根据父节点的值计算本节点的值，用于前向传播中计算该节点的值</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@abc.abstractmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_jacobi</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    抽象方法，计算本节点对某个父节点的雅可比矩阵的计算，因为计算父节点的雅可比矩阵可能需要该父节点以及其他父节点的值，所以只能够在子节点中完成。父节点调用子节点的getjacobi方法，就可以得到子节点对自己的雅可比矩阵。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Part4：核心函数</strong>：
<ul>
<li>forward() 和 backward() 函数, 都是以递归的形式进行计算，请注意这边的两个函数的含义和pytorch库中的同名函数含义相差较大，不要搞混。</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self</span>):</span></span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">      前向传播计算本节点的值，若父节点的值未被计算，则递归调用父节点的forward方法</span></span><br><span class="line"><span class="string">      &quot;&quot;&quot;</span></span><br><span class="line">      <span class="keyword">for</span> node <span class="keyword">in</span> self.parents:</span><br><span class="line">          <span class="keyword">if</span> node.value <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">              node.forward()</span><br><span class="line"><span class="comment"># 递归完成，所有父节点的值都就位了，调用子类已经覆写好的compute函数，根据父节点的值计算该节点值，例如如果该节点是 + 号 类节点，compute函数中，就会书写将所有的父节点的值相加的过程。</span></span><br><span class="line">      self.compute()</span><br><span class="line">	</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  属性jacobi用于保存最终结果对自己的雅可比矩阵，在代码一开始先判断自己的jacobi属性是否为None,如果不是说明最终结果对自己的雅可比矩阵已经计算过了（因为一次反向传播中，某个节点可能被多次访问）。</span></span><br><span class="line"><span class="string">  result参数传进来的是最终的结果节点。</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self, result</span>):</span></span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">      反向传播，计算结果节点对本节点的雅可比矩阵</span></span><br><span class="line"><span class="string">      &quot;&quot;&quot;</span></span><br><span class="line">      <span class="keyword">if</span> self.jacobi <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">          <span class="keyword">if</span> self <span class="keyword">is</span> result:  <span class="comment"># 如果本节点自身就是最终的结果节点</span></span><br><span class="line">              self.jacobi = np.mat(np.eye(self.dimension()))  <span class="comment">#构造一个维度正确的单位矩阵即可</span></span><br><span class="line">          <span class="keyword">else</span>:   <span class="comment"># 如果本节点不是最终的结果节点，而是正常的一个节点</span></span><br><span class="line">              self.jacobi = np.mat(  <span class="comment"># 先构造一个维度正确的全为0的矩阵，作为之后的累加器</span></span><br><span class="line">                  np.zeros((result.dimension(), self.dimension())))</span><br><span class="line">		<span class="comment"># 然后遍历所有子节点</span></span><br><span class="line">              <span class="keyword">for</span> child <span class="keyword">in</span> self.get_children():</span><br><span class="line">                   <span class="comment"># 如果子节点的值不为空，说明它在本次的计算路径上，因为对于某些复杂的计算图而言，有些节点可能不在某次前向传播的计算路径上，它们是无关的节点。</span></span><br><span class="line">                  <span class="keyword">if</span> child.value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                      <span class="comment"># 递归调用child的backward()方法，得到最终结果对子节点的雅可比，再乘上 子节点对该节点的雅可比，就得到了最终结果对该节点的雅可比，将其累加到之前初始化好的全为0的矩阵中。</span></span><br><span class="line">                      self.jacobi += child.backward(result) * child.get_jacobi(self)</span><br><span class="line"><span class="comment"># 返回雅可比矩阵即可</span></span><br><span class="line">      <span class="keyword">return</span> self.jacobi</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="变量节点继承自node类">3、变量节点（继承自Node类）：</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Variable</span>(<span class="params">Node</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    变量节点</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim, init=<span class="literal">False</span>, trainable=<span class="literal">True</span>, **kargs</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        变量节点没有父节点，构造函数接受变量的形状，是否初始化以及是否参与训练的标识</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        Node.__init__(self,  **kargs)</span><br><span class="line">        self.dim = dim</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果需要初始化，则以正态分布随机初始化变量的值</span></span><br><span class="line">        <span class="comment"># 像保存样本和标签的节点不用初始化，而保存参数的节点需要初始化</span></span><br><span class="line">        <span class="keyword">if</span> init:</span><br><span class="line">            self.value = np.mat(np.random.normal(<span class="number">0</span>, <span class="number">0.001</span>, self.dim))</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 变量节点是否参与训练，比如样本和标签不参与训练，可以不计算它们的雅可比矩阵，而参数参与训练，就需要计算雅可比矩阵。</span></span><br><span class="line">        self.trainable = trainable</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_value</span>(<span class="params">self, value</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        为变量赋值</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 判定赋值的值matrix 是不是和dim一致</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(value, np.matrix) <span class="keyword">and</span> value.shape == self.dim</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 先重置该节点及所有下游节点的值，然后再对该节点进行赋值</span></span><br><span class="line">        self.reset_value()</span><br><span class="line">        self.value = value</span><br></pre></td></tr></table></figure>
<h3 id="运算符操作子节点继承自node类需要覆写compute和get_jacobi两个函数">4、运算符操作子节点（继承自Node类，需要覆写compute和get_jacobi两个函数）</h3>
<p>抽象类如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Operator</span>(<span class="params">Node</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    定义操作符抽象类</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<h5 id="定义-add-操作符">1） 定义 Add 操作符：</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Add</span>(<span class="params">Operator</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    （多个）矩阵加法</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">	<span class="comment">## 根据父节点的值计算本节点的值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># assert len(self.parents) == 2 and self.parents[0].shape() == self.parents[1].shape()</span></span><br><span class="line">        self.value = np.mat(np.zeros(self.parents[<span class="number">0</span>].shape()))</span><br><span class="line">		<span class="comment"># 把所有的父节点的值相加，就是正向传播计算的值</span></span><br><span class="line">        <span class="keyword">for</span> parent <span class="keyword">in</span> self.parents:</span><br><span class="line">            self.value += parent.value</span><br><span class="line">            </span><br><span class="line">	<span class="comment">## 计算本节点对某个父节点的雅可比矩阵的计算</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_jacobi</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.mat(np.eye(self.dimension()))  <span class="comment"># 矩阵之和对其中任一个矩阵的雅可比矩阵是单位矩阵</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">## 比如说： 父节点为矩阵 A，B(维度为 3 * 2)，子节点为矩阵 A + B（维度为3 * 2）</span></span><br><span class="line"><span class="comment">## 子节点为 Add操作符节点</span></span><br><span class="line"><span class="comment">## 那么这样一个映射函数就是 6维向量 -》映射到-》 6维向量 的映射函数</span></span><br><span class="line"><span class="comment">## A 展平 [ a1 a2 a3 a4 a5 a6 ] B 展平 [ b1 b2 b3 b4 b5 b6]  均为6维向量</span></span><br><span class="line"><span class="comment">## A+B 展平 [a1+b1 a2+b2 a3+b3 a4+b4 a5+b5 a6+b6] 6维向量</span></span><br><span class="line"><span class="comment">## 最终得到的雅可比矩阵是 6 * 6 的单位阵</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   [d(a1+b1)/d(a1) d(a1+b1)/d(a2) d(a1+b1)/d(a3) d(a1+b1)/d(a4) d(a1+b1)/d(a5) d(a1+b1)/d(a6)  ]</span></span><br><span class="line"><span class="string">   [d(a2+b2)/d(a1) d(a2+b2)/d(a2) d(a2+b2)/d(a3) d(a2+b2)/d(a4) d(a2+b2)/d(a5) d(a2+b2)/d(a6)  ]</span></span><br><span class="line"><span class="string">    	……………………………………………………………………………………………………………………………………………………………………………………………………………………</span></span><br><span class="line"><span class="string">        ……………………………………………………………………………………………………………………………………………………………………………………………………………………</span></span><br><span class="line"><span class="string">        ……………………………………………………………………………………………………………………………………………………………………………………………………………………</span></span><br><span class="line"><span class="string">   [d(a6+b6)/d(a1) d(a6+b6)/d(a2) d(a6+b6)/d(a3) d(a6+b6)/d(a4) d(a6+b6)/d(a5) d(a6+b6)/d(a6)  ]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   [1 0 0 0 0 0]</span></span><br><span class="line"><span class="string">   [0 1 0 0 0 0]</span></span><br><span class="line"><span class="string">   [0 0 1 0 0 0]</span></span><br><span class="line"><span class="string">   [0 0 0 1 0 0]</span></span><br><span class="line"><span class="string">   [0 0 0 0 1 0]</span></span><br><span class="line"><span class="string">   [0 0 0 0 0 1]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h5 id="定义-matmul-操作符">2） 定义 Matmul 操作符：</h5>
<p>推导如下：</p>
<ul>
<li><p>定义矩阵A： 形状为 M x N</p></li>
<li><p>定义矩阵B： 形状为 N x K</p></li>
<li><p>矩阵乘法得到的结果C： 形状为 M X K</p></li>
</ul>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/92352E558AF386F3CEFAE57985019633.jpg" /></p>
<p>​ 我们先求解<strong>矩阵C对矩阵A的雅可比矩阵</strong>：</p>
<p>​ 我们将矩阵乘法视为多到多映射，如下：以左矩阵A为自变量，以右矩阵B为常量，将矩阵A视为 <span class="math inline">\(M \times N\)</span> 维的向量，将映射的结果矩阵C视为 <span class="math inline">\(M \times K\)</span> 维的向量。如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/202202271a.png" style="zoom: 50%;" /></p>
<p>​ 最终获得的雅可比矩阵的第一行，就是C矩阵的第1个元素，分别对A 的 MN 个元素求导：得到的如下所示：C的第一个分量对A的第一行元素的偏导数就是B的第一列，对A其余元素的偏导数是0，所以雅可比矩阵的第一行如下：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/F9061B9E26F869EA36F4575B07A65B27.jpg" style="zoom: 25%;" /></p>
<p>​ 第二行同理，如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/BD69F402E360C2A1B6CCD85DF5881C28.jpg" style="zoom:25%;" /></p>
<p>​ 一直到雅可比矩阵的第K行，都是这样的规律。然后接下去雅可比矩阵的K+1行是这样的：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/7FFCABE5A3D35DAAD995E76633F94DDE.jpg" style="zoom:25%;" /></p>
<p>​ 我们会发现一个规律，如下所示，也就是最终的结论：C对A的雅可比矩阵如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/15BB5E4AF6FBE51D7701F361B7BE64FE.jpg" /></p>
<p>​ <span class="math inline">\(B^T 是 B的转置\)</span>，我们把 m 个 形状为 <span class="math inline">\(K \times N\)</span> 的<span class="math inline">\(B^T\)</span>矩阵放在对角线上，得到一个 <span class="math inline">\(MK \times MN\)</span> 的矩阵。</p>
<p>​</p>
<p>​ 然后来看<strong>矩阵C对矩阵B的雅可比矩阵</strong>：</p>
<p>​ 同样我们将矩阵乘法视为多到多映射，如下：以左矩阵A为常量，以右矩阵B为自变量，将矩阵B视为 <span class="math inline">\(N \times K\)</span> 维的向量，将映射的结果矩阵C视为 <span class="math inline">\(M \times K\)</span> 维的向量。如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/2022020272258.png" style="zoom:33%;" /></p>
<p>​ 这是一个NK维向量，C对B的雅可比矩阵是<span class="math inline">\(MK \times NK\)</span> 的矩阵。C的第一个分量对B的第1列元素的偏导数就是A的第一行，所以雅可比矩阵的第1行如下：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/C165EA4E4C9DE67CF1EE6AF9551DB327.jpg" style="zoom: 33%;" /></p>
<p>​ 雅可比矩阵的第2行如下：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/B504A835005C3AAF0BA61984E976F3F9.jpg" style="zoom: 33%;" /></p>
<p>​ 这一行中每个长度维k的段的第2个元素是A的第1行的对应元素，其余元素维0.以此类推，雅可比矩阵的前k行是一个<span class="math inline">\(k \times NK\)</span>的矩阵，包含横着排列的N个对角阵。整个雅可比矩阵由M个这样的矩阵竖着摞在一起构成。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/64F57EE82EDE412BA304CD345F290E57.jpg" style="zoom:50%;" /></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MatMul</span>(<span class="params">Operator</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    矩阵乘法</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(self.parents) == <span class="number">2</span> <span class="keyword">and</span> self.parents[<span class="number">0</span>].shape()[</span><br><span class="line">            <span class="number">1</span>] == self.parents[<span class="number">1</span>].shape()[<span class="number">0</span>]</span><br><span class="line">        self.value = self.parents[<span class="number">0</span>].value * self.parents[<span class="number">1</span>].value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_jacobi</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        将矩阵乘法视作映射，求映射对参与计算的矩阵的雅克比矩阵。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        zeros = np.mat(np.zeros((self.dimension(), parent.dimension())))</span><br><span class="line">        <span class="keyword">if</span> parent <span class="keyword">is</span> self.parents[<span class="number">0</span>]:  <span class="comment"># C对A的雅可比矩阵</span></span><br><span class="line">            <span class="keyword">return</span> fill_diagonal(zeros, self.parents[<span class="number">1</span>].value.T)</span><br><span class="line">        <span class="keyword">else</span>:	<span class="comment"># C对B的雅可比矩阵</span></span><br><span class="line">            jacobi = fill_diagonal(zeros, self.parents[<span class="number">0</span>].value)</span><br><span class="line">            row_sort = np.arange(self.dimension()).reshape(</span><br><span class="line">                self.shape()[::-<span class="number">1</span>]).T.ravel()</span><br><span class="line">            col_sort = np.arange(parent.dimension()).reshape(</span><br><span class="line">                parent.shape()[::-<span class="number">1</span>]).T.ravel()</span><br><span class="line">            <span class="keyword">return</span> jacobi[row_sort, :][:, col_sort]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="定义-relu-操作符">3） <strong>定义 ReLU 操作符：</strong></h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReLU</span>(<span class="params">Operator</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    对矩阵的元素施加ReLU函数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    nslope = <span class="number">0.1</span>  <span class="comment"># 负半轴的斜率</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.value = np.mat(np.where(</span><br><span class="line">            self.parents[<span class="number">0</span>].value &gt; <span class="number">0.0</span>,</span><br><span class="line">            self.parents[<span class="number">0</span>].value,</span><br><span class="line">            self.nslope * self.parents[<span class="number">0</span>].value)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_jacobi</span>(<span class="params">self, parent</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.diag(np.where(self.parents[<span class="number">0</span>].value.A1 &gt; <span class="number">0.0</span>, <span class="number">1.0</span>, self.nslope))</span><br></pre></td></tr></table></figure>
<p><strong>参考资料：</strong></p>
<p>代码实现参考：https://github.com/zc911/MatrixSlow</p>
<p>1、《用python实现深度学习框架》张觉非、陈震</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
        <category>Python搭建简易框架笔记</category>
      </categories>
      <tags>
        <tag>Framework</tag>
      </tags>
  </entry>
  <entry>
    <title>BFS系列——开密码锁</title>
    <url>/2022/02/22/2c663a313e31/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-109.-开密码锁"><a href="https://leetcode-cn.com/problems/zlDJc7/">剑指 Offer II 109. 开密码锁</a></h4>
<p>​ 一个密码锁由 4 个环形拨轮组成，每个拨轮都有 10 个数字： '0', '1', '2', '3', '4', '5', '6', '7', '8', '9' 。每个拨轮可以自由旋转：例如把 '9' 变为 '0'，'0' 变为 '9' 。每次旋转都只能旋转一个拨轮的一位数字。</p>
<p>​ 锁的初始数字为 '0000' ，一个代表四个拨轮的数字的字符串。</p>
<p>​ 列表 deadends 包含了一组死亡数字，一旦拨轮的数字和列表里的任何一个元素相同，这个锁将会被永久锁定，无法再被旋转。</p>
<p>​ 字符串 target 代表可以解锁的数字，请给出解锁需要的最小旋转次数，如果无论如何不能解锁，返回 -1 。</p>
<ul>
<li>示例 1:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：deadends = [&quot;0201&quot;,&quot;0101&quot;,&quot;0102&quot;,&quot;1212&quot;,&quot;2002&quot;], target = &quot;0202&quot;</span><br><span class="line">输出：6</span><br><span class="line">解释： 可能的移动序列为 &quot;0000&quot; -&gt; &quot;1000&quot; -&gt; &quot;1100&quot; -&gt; &quot;1200&quot; -&gt; &quot;1201&quot; -&gt; &quot;1202&quot; -&gt; &quot;0202&quot;。</span><br><span class="line">注意 &quot;0000&quot; -&gt; &quot;0001&quot; -&gt; &quot;0002&quot; -&gt; &quot;0102&quot; -&gt; &quot;0202&quot; 这样的序列是不能解锁的，因为当拨动到 &quot;0102&quot; 时这个锁就会被锁定。</span><br></pre></td></tr></table></figure>
<h5 id="解题思路1单向bfs"><strong>解题思路1：单向BFS</strong>：</h5>
<p>​ 本题可以采用BFS搜索进行求解，但是由于每一个数字，其对应的领居有高达8个，再不断的扩展的过程中，搜索的空间会非常大，就会导致比较大的复杂度。在本题的BFS过程中，需要注意的是，还有死亡数字列表，一种方案是我们可以使用哈希表存储死亡数字，在每次遍历获取邻居的时候，判断是否为死亡数字，如果为死亡数字，那么就不将其考虑在内。这样子需要多出一定的空间和时间来进行处理。</p>
<p>​ 其实，我们可以不需要额外的空间来进行处理。因为在BFS的过程中，我们会记录哪些节点被访问过，就不要重复入队，故而，只需要提前将所有的死亡数字，都设定为已经被访问过，那么就不会被考虑在内。</p>
<h5 id="解题代码1"><strong>解题代码1</strong>：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">openLock</span><span class="params">(vector&lt;string&gt;&amp; deadends, string target)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//构建hash表，方便进行查询</span></span><br><span class="line">        unordered_map&lt;string,<span class="keyword">int</span>&gt; dead;</span><br><span class="line">        unordered_map&lt;string,<span class="keyword">int</span>&gt; res;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;deadends.<span class="built_in">size</span>();i++) dead[deadends[i]] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(dead.<span class="built_in">find</span>(<span class="string">&quot;0000&quot;</span>) != dead.<span class="built_in">end</span>()) <span class="keyword">return</span> <span class="number">-1</span>; </span><br><span class="line">        <span class="comment">//开启广度优先搜索</span></span><br><span class="line">        queue&lt;string&gt; q;</span><br><span class="line">        q.<span class="built_in">push</span>(<span class="string">&quot;0000&quot;</span>);</span><br><span class="line">        res[<span class="string">&quot;0000&quot;</span>] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(!q.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            string curr = q.<span class="built_in">front</span>();</span><br><span class="line">            q.<span class="built_in">pop</span>();</span><br><span class="line">            <span class="comment">//将curr的16个领居全部进入队列，并更新结果表，(如果存在dead点，则不进入队列)</span></span><br><span class="line">            vector&lt;string&gt; neighbor = <span class="built_in">getNeighbor</span>(curr);</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;neighbor.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(dead.<span class="built_in">find</span>(neighbor[i]) != dead.<span class="built_in">end</span>()) <span class="keyword">continue</span>;</span><br><span class="line">                <span class="keyword">if</span>(res.<span class="built_in">find</span>(neighbor[i]) == res.<span class="built_in">end</span>())&#123;</span><br><span class="line">                    q.<span class="built_in">push</span>(neighbor[i]);</span><br><span class="line">                    res[neighbor[i]] = res[curr] + <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(res.<span class="built_in">find</span>(target) == res.<span class="built_in">end</span>()) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">return</span> res[target];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">vector&lt;string&gt; <span class="title">getNeighbor</span><span class="params">(string str)</span></span>&#123;</span><br><span class="line">        vector&lt;string&gt; res;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">4</span>;i++)&#123;</span><br><span class="line">            string tmp = str;</span><br><span class="line">            <span class="keyword">if</span>(tmp[i] == <span class="string">&#x27;0&#x27;</span>)&#123;</span><br><span class="line">                tmp[i] = <span class="string">&#x27;9&#x27;</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">                tmp[i] = <span class="string">&#x27;1&#x27;</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(tmp[i] == <span class="string">&#x27;9&#x27;</span>)&#123;</span><br><span class="line">                tmp[i] = <span class="string">&#x27;8&#x27;</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">                tmp[i] = <span class="string">&#x27;0&#x27;</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                tmp[i] = tmp[i] + <span class="number">1</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">                tmp[i] = tmp[i] - <span class="number">2</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/mac/截屏2022-02-22%20下午2.31.38.png" /></p>
<p>​ 此方法花费的执行用时和内存消耗都是下下选。</p>
<h5 id="解题思路2双向bfs"><strong>解题思路2：双向BFS</strong>：</h5>
<p>​ 双向bfs适用于知道起点和终点的状态下使用，从起点和终点两个方向开始进行搜索，可以非常大的提高单个bfs的搜索效率</p>
<p>​ 同样，实现也是通过队列的方式，可以设置两个队列，一个队列保存从起点开始搜索的状态，另一个队列用来保存从终点开始搜索的状态，如果某一个状态下出现相交的情况，那么就出现了答案，用一张图来进行说明如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/mac/jevyd2TPC7FX6GA.png" alt="jevyd2TPC7FX6GA" style="zoom: 33%;" /></p>
<p>​ 具体如何实现判断相遇，见如下的代码：我们构建vis，代表某个字符串的位置是否被访问过。这个在单向的BFS中，我们不需要设置，因为我们可以通过res这个Hash表有没有某个元素来进行判断，实际上此处的vis起到的也并不是判断有没有被访问过的作用（后面代码还是通过res中有没有某个元素来判断的），此处的vis最大的作用是记录某个节点是被正向搜索访问过，还是被反向搜索访问过，如果被正向访问过设置为1，被反向搜索访问过设置为2。</p>
<p>​ 同时，在每一遍while中，我们扩展<strong>较小的搜索队列</strong>，并利用flag记录扩展的是前向还是反向。如果在遍历某一轮的领居的过程中，发现：curr点和领居点的vst相加=3，意味着两者一个是正向搜索序列，一个是逆向搜索序列，相遇了，所以此时我们可以返回结果，不用继续下去了。</p>
<h5 id="解题代码2">解题代码2：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">openLock</span><span class="params">(vector&lt;string&gt;&amp; deadends, string target)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//构建hash表，方便进行查询结果</span></span><br><span class="line">        unordered_map&lt;string,<span class="keyword">int</span>&gt; res;</span><br><span class="line">        <span class="comment">//构建vis，代表某个字符串的位置是否被访问过 被正向访问过为1，被反向搜索访问过为2</span></span><br><span class="line">        unordered_map&lt;string,<span class="keyword">int</span>&gt; vis;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;deadends.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            res[deadends[i]] = <span class="number">-1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(res.<span class="built_in">find</span>(<span class="string">&quot;0000&quot;</span>) != res.<span class="built_in">end</span>()) <span class="keyword">return</span> <span class="number">-1</span>; </span><br><span class="line">        <span class="keyword">if</span>(target == <span class="string">&quot;0000&quot;</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//开启广度优先搜索</span></span><br><span class="line">        queue&lt;string&gt; q1;  <span class="comment">//前向搜索序列</span></span><br><span class="line">        queue&lt;string&gt; q2;  <span class="comment">//反向搜索序列</span></span><br><span class="line">        q1.<span class="built_in">push</span>(<span class="string">&quot;0000&quot;</span>);   <span class="comment">//前向搜索初始化</span></span><br><span class="line">        q2.<span class="built_in">push</span>(target);   <span class="comment">//反向搜索初始化</span></span><br><span class="line">        res[<span class="string">&quot;0000&quot;</span>] = <span class="number">0</span>;   <span class="comment">//前向搜索初始化</span></span><br><span class="line">        res[target] = <span class="number">0</span>;   <span class="comment">//反向搜索初始化</span></span><br><span class="line">        vis[<span class="string">&quot;0000&quot;</span>] = <span class="number">1</span>;	 <span class="comment">//前向搜索初始化</span></span><br><span class="line">        vis[target] = <span class="number">2</span>;	 <span class="comment">//反向搜索初始化</span></span><br><span class="line">        <span class="keyword">while</span>(!q1.<span class="built_in">empty</span>() &amp;&amp; !q2.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            <span class="comment">//在每一遍while中，我们扩展 较小的搜索队列,利用flag记录扩展的是前向还是反向</span></span><br><span class="line">            string curr;</span><br><span class="line">            <span class="keyword">bool</span> flag;</span><br><span class="line">            <span class="keyword">if</span>(q1.<span class="built_in">size</span>() &lt; q2.<span class="built_in">size</span>())&#123;</span><br><span class="line">                flag = <span class="literal">true</span>;</span><br><span class="line">                curr = q1.<span class="built_in">front</span>();</span><br><span class="line">                q1.<span class="built_in">pop</span>();</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                flag = <span class="literal">false</span>;</span><br><span class="line">                curr = q2.<span class="built_in">front</span>();</span><br><span class="line">                q2.<span class="built_in">pop</span>();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//将curr的16个领居全部进入队列，并更新结果表，(如果存在dead点，则不进入队列)</span></span><br><span class="line">            vector&lt;string&gt; neighbor = <span class="built_in">getNeighbor</span>(curr);</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;neighbor.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(res.<span class="built_in">find</span>(neighbor[i]) == res.<span class="built_in">end</span>())&#123; <span class="comment">//如果这个领居点从来没被访问过 </span></span><br><span class="line">                    <span class="keyword">if</span>(flag) q1.<span class="built_in">push</span>(neighbor[i]);</span><br><span class="line">                    <span class="keyword">else</span> q2.<span class="built_in">push</span>(neighbor[i]);</span><br><span class="line">                    res[neighbor[i]] = res[curr] + <span class="number">1</span>;</span><br><span class="line">                    vis[neighbor[i]] = vis[curr];  <span class="comment">//继承当前访问的队列编号，1为正向，2为反向</span></span><br><span class="line">                &#125;<span class="keyword">else</span>&#123;  <span class="comment">//如果这个领居点被访问过：</span></span><br><span class="line">                    <span class="keyword">if</span>(vis[neighbor[i]] + vis[curr] == <span class="number">3</span>)&#123;</span><br><span class="line">                        <span class="comment">//如果curr点和领居点的vst相加=3，意味着两者一个是正向搜索序列，一个是逆向搜索序列，相遇了，所以此时我们可以返回结果，不用继续下去了</span></span><br><span class="line">                        <span class="keyword">return</span> res[curr] + res[neighbor[i]] + <span class="number">1</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">vector&lt;string&gt; <span class="title">getNeighbor</span><span class="params">(string str)</span></span>&#123;</span><br><span class="line">        vector&lt;string&gt; res;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">4</span>;i++)&#123;</span><br><span class="line">            string tmp = str;</span><br><span class="line">            <span class="keyword">if</span>(tmp[i] == <span class="string">&#x27;0&#x27;</span>)&#123;</span><br><span class="line">                tmp[i] = <span class="string">&#x27;9&#x27;</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">                tmp[i] = <span class="string">&#x27;1&#x27;</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(tmp[i] == <span class="string">&#x27;9&#x27;</span>)&#123;</span><br><span class="line">                tmp[i] = <span class="string">&#x27;8&#x27;</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">                tmp[i] = <span class="string">&#x27;0&#x27;</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                tmp[i] = tmp[i] + <span class="number">1</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">                tmp[i] = tmp[i] - <span class="number">2</span>;</span><br><span class="line">                res.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/mac/截屏2022-02-22%20下午2.30.39.png" /></p>
<p>可以看到，使用双向BFS比先前的单向BFS节省了非常多的时间与空间复杂度。</p>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>DFS与BFS系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>BFS</tag>
      </tags>
  </entry>
  <entry>
    <title>DFS系列——最长递增路径</title>
    <url>/2022/02/22/cd538be761a4/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-112.-最长递增路径"><a href="https://leetcode-cn.com/problems/fpTFWP/">剑指 Offer II 112. 最长递增路径</a></h4>
<p>​ 给定一个 m x n 整数矩阵 matrix ，找出其中 最长递增路径 的长度。</p>
<p>​ 对于每个单元格，你可以往上，下，左，右四个方向移动。 不能 在 对角线 方向上移动或移动到 边界外（即不允许环绕）。</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：matrix = [[9,9,4],[6,6,8],[2,1,1]]</span><br><span class="line">输出：4 </span><br><span class="line">解释：最长递增路径为 [1, 2, 6, 9]。</span><br></pre></td></tr></table></figure>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/grid1.jpg" /></p>
<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：matrix = [[3,4,5],[3,2,6],[2,2,1]]</span><br><span class="line">输出：4 </span><br><span class="line">解释：最长递增路径是 [3, 4, 5, 6]。注意不允许在对角线方向上移动。</span><br></pre></td></tr></table></figure>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/tmp-grid.jpg" /></p>
<p>参考：https://leetcode-cn.com/problems/fpTFWP/solution/zui-chang-di-zeng-lu-jing-by-leetcode-so-1chr/</p>
<h5 id="解题思路1dfs进阶记忆化深度优先搜索">解题思路1：DFS进阶—记忆化深度优先搜索：</h5>
<p>​ 拿到题目以后，将其看作一个图，然后从一个单元格开始进行深度优先搜索，即可找到从该单元格开始的最长递增路径。对每个单元格分别进行深度优先搜索之后，即可得到矩阵中的最长递增路径的长度。这是一个非常朴素且好用的办法，但是仔细想一下以后，时间复杂度肯定是指数级的，会超出时间限制，所以需要优化。</p>
<p>​ 常见的优化方式，就是<strong>记忆化深度优先搜索</strong>，思路如下：</p>
<p>​ <strong>朴素深度优先搜索的时间复杂度过高的原因是进行了大量的重复计算，同一个单元格会被访问多次，每次访问都要重新计算。由于同一个单元格对应的最长递增路径的长度是固定不变的，因此可以使用记忆化的方法进行优化</strong>。用矩阵 <code>res</code>作为缓存矩阵，已经计算过的单元格的结果存储到缓存矩阵中。</p>
<p>​ 使用记忆化深度优先搜索，当访问到一个单元格<code>(i,j)</code>时，如果 <code>res[i][j] != 0</code>，说明该单元格的结果已经计算过，则直接从缓存中读取结果，如果 <code>res[i][j] == 0</code>，说明该单元格的结果尚未被计算过，则进行搜索，并将计算得到的结果存入缓存中。</p>
<p>​ 遍历完矩阵中的所有单元格之后，即可得到矩阵中的最长递增路径的长度。</p>
<h5 id="解题代码1">解题代码1：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; dirs = &#123;&#123;<span class="number">-1</span>,<span class="number">0</span>&#125;,&#123;<span class="number">1</span>,<span class="number">0</span>&#125;,&#123;<span class="number">0</span>,<span class="number">-1</span>&#125;,&#123;<span class="number">0</span>,<span class="number">1</span>&#125;&#125;; <span class="comment">//四个邻居坐标</span></span><br><span class="line">    <span class="keyword">int</span> m;</span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">longestIncreasingPath</span><span class="params">(vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt;&amp; matrix)</span> </span>&#123;</span><br><span class="line">        m = matrix.<span class="built_in">size</span>();</span><br><span class="line">        n = matrix[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">res</span>(m,vector&lt;<span class="keyword">int</span>&gt;(n));</span><br><span class="line">        <span class="keyword">int</span> max = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; m;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; n;j++)&#123;</span><br><span class="line">                <span class="keyword">int</span> dis = <span class="built_in">dfs</span>(i,j,matrix,res);</span><br><span class="line">                <span class="keyword">if</span>(dis &gt; max) max = dis;</span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;    </span><br><span class="line">        <span class="keyword">return</span> max;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> row,<span class="keyword">int</span> column,vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt;&amp; matrix,vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt;&amp; res)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> m = matrix.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">int</span> n = matrix[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line">        <span class="comment">//如果已经计算过该点的值，我们直接返回(相比于传统的DFS，其实就多了这一步)</span></span><br><span class="line">        <span class="keyword">if</span> (res[row][column] != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> res[row][column];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果该点的值没有计算过，先将该点的值 +1，代表路径长度为1.</span></span><br><span class="line">        ++res[row][column];</span><br><span class="line">        <span class="comment">//遍历4个周围的邻居，进行递归，深度优先遍历</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">            <span class="keyword">int</span> new_row = row + dirs[i][<span class="number">0</span>];</span><br><span class="line">            <span class="keyword">int</span> new_column = column + dirs[i][<span class="number">1</span>];</span><br><span class="line">            <span class="keyword">if</span> (new_row &gt;= <span class="number">0</span> &amp;&amp; new_row &lt; m &amp;&amp; </span><br><span class="line">                new_column &gt;= <span class="number">0</span> &amp;&amp; new_column &lt; n &amp;&amp; </span><br><span class="line">                matrix[new_row][new_column] &gt; matrix[row][column]        <span class="comment">//如果周围比该点大，则进行深度遍历</span></span><br><span class="line">            )&#123;</span><br><span class="line">                <span class="comment">//最终的结果 为当前的最长递增路径 和 周围邻居的最长路径 + 1，两者中大的那个值</span></span><br><span class="line">                res[row][column] = <span class="built_in">max</span>(res[row][column], <span class="built_in">dfs</span>(new_row, new_column,matrix, res) + <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res[row][column];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h5 id="解题思路2动态规划拓扑排序">解题思路2：动态规划（拓扑排序）</h5>
<p>​ 一开始，我看到此题，没有想到去优化DFS，而是直接转到了动态规划的思路上，刚开始觉得这题如果使用动态规划非常方便，每个节点它的最长递增路径，无非就是周围的邻居中，选一个最长递增路径最大，并且比自己值大的节点 + 1，就可以了，即<code>res[i][j]=max&#123;res[x][y]&#125;+1 (其中(x,y)与(i,j)在矩阵中相邻且matrix[x][y] &gt; matrix[i][j])</code>。</p>
<p>​ 事实确实是这样，但是没想到此题如果使用动态规划，关键问题并不是状态转移方程，而是初始化条件和如何去进行状态转移.按照通常的思路,我想到了从左上角向右下角遍历,此时仅考虑左边和上面的点,然后从右下角至左上角遍历,此时仅考虑右边和下面的点,这样子由于缓存的关系相当于也考虑了周围的四个邻居,类似于<a href="https://blog.slks.xyz/2022/02/21/80b7b127a404/">图系列——矩阵中的距离</a>这道题目的动态规划方法,代码如下:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">longestIncreasingPath</span><span class="params">(vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt;&amp; matrix)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> m = matrix.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">int</span> n = matrix[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">res</span>(m,vector&lt;<span class="keyword">int</span>&gt;(n));</span><br><span class="line">        <span class="comment">//从左上角向右下角遍历</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;m;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;n;j++)&#123;</span><br><span class="line">                <span class="keyword">int</span> ele = matrix[i][j];</span><br><span class="line">                <span class="comment">//检查邻居的值，如果左边和上面的值符合递增效果，则叠加</span></span><br><span class="line">                <span class="keyword">if</span>(i!=<span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="comment">//检查上方</span></span><br><span class="line">                    <span class="keyword">int</span> ele_up = matrix[i<span class="number">-1</span>][j];</span><br><span class="line">                    <span class="keyword">if</span>(ele_up &gt; ele) res[i][j] = <span class="built_in">max</span>(res[i][j] , res[i<span class="number">-1</span>][j] + <span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(j!=<span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="comment">//检查左方</span></span><br><span class="line">                    <span class="keyword">int</span> ele_left = matrix[i][j<span class="number">-1</span>];</span><br><span class="line">                    <span class="keyword">if</span>(ele_left &gt; ele) res[i][j] =  <span class="built_in">max</span>(res[i][j] ,res[i][j<span class="number">-1</span>] + <span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=m<span class="number">-1</span>;i&gt;=<span class="number">0</span>;i--)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=n<span class="number">-1</span>;j&gt;=e;j--)&#123;</span><br><span class="line">                <span class="keyword">int</span> ele = matrix[i][j];</span><br><span class="line">                <span class="comment">//检查邻居的值，如果左边和上面的值符合递增效果，则叠加</span></span><br><span class="line">                <span class="keyword">if</span>(i!=m<span class="number">-1</span>)&#123;</span><br><span class="line">                    <span class="comment">//检查下方</span></span><br><span class="line">                    <span class="keyword">int</span> ele_down = matrix[i+<span class="number">1</span>][j];</span><br><span class="line">                    <span class="keyword">if</span>(ele_down &gt; ele) res[i][j] =  <span class="built_in">max</span>(res[i][j] ,res[i+<span class="number">1</span>][j] + <span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(j!=n<span class="number">-1</span>)&#123;</span><br><span class="line">                    <span class="comment">//检查右方</span></span><br><span class="line">                    <span class="keyword">int</span> ele_right = matrix[i][j+<span class="number">1</span>];</span><br><span class="line">                    <span class="keyword">if</span>(ele_right &gt; ele ) res[i][j] =  <span class="built_in">max</span>(res[i][j] ,res[i][j+<span class="number">1</span>] + <span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> max = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;m;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;n;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(res[i][j] &gt; max) max = res[i][j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> max+<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​ <strong>但这个题目这样子做是会出问题的,具体出问题的原因我也搞清楚了,大致是因为某个元素更新后,会导致先前已经通过该元素更新的元素变得无效,但是思考了很久,至今还是没有完全想通,为什么<矩阵中的距离>这道题目可以用这种方式递归,而该题目无法用这种形式递归</strong></p>
<p>​ <strong>我们先看正确方法:这题的关键在于如何定义初始化状态和计算流程:</strong></p>
<p>​ 动态规划除了状态定义和状态转移方程，还需要考虑边界情况。这里的边界情况是什么呢？</p>
<p>​ 如果一个单元格的值比它的所有相邻单元格的值都要大，那么这个单元格对应的最长递增路径是 1，这就是边界条件。这个边界条件并不直观，而是<strong>需要根据矩阵中的每个单元格的值找到作为边界条件的单元格</strong>。</p>
<p>​ 仍然使用方法一的思想，将矩阵看成一个有向图，计算每个单元格对应的出度，即有多少条边从该单元格出发。对于作为边界条件的单元格，该单元格的值比所有的相邻单元格的值都要大，因此作为边界条件的单元格的出度都是 0。</p>
<p>​ <strong>基于出度的概念，可以使用拓扑排序求解。从所有出度为 0 的单元格开始广度优先搜索，每一轮搜索都会遍历当前层的所有单元格，更新其余单元格的出度，并将出度变为 0 的单元格加入下一层搜索。当搜索结束时，搜索的总层数即为矩阵中的最长递增路径的长度。</strong></p>
<h5 id="解题代码2官方代码">解题代码2(官方代码):</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">int</span> dirs[<span class="number">4</span>][<span class="number">2</span>] = &#123;&#123;<span class="number">-1</span>, <span class="number">0</span>&#125;, &#123;<span class="number">1</span>, <span class="number">0</span>&#125;, &#123;<span class="number">0</span>, <span class="number">-1</span>&#125;, &#123;<span class="number">0</span>, <span class="number">1</span>&#125;&#125;;</span><br><span class="line">    <span class="keyword">int</span> rows, columns;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">longestIncreasingPath</span><span class="params">(vector&lt; vector&lt;<span class="keyword">int</span>&gt; &gt; &amp;matrix)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (matrix.<span class="built_in">size</span>() == <span class="number">0</span> || matrix[<span class="number">0</span>].<span class="built_in">size</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        rows = matrix.<span class="built_in">size</span>();</span><br><span class="line">        columns = matrix[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">auto</span> outdegrees = vector&lt; vector&lt;<span class="keyword">int</span>&gt; &gt; (rows, vector &lt;<span class="keyword">int</span>&gt; (columns));</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rows; ++i) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; columns; ++j) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; <span class="number">4</span>; ++k) &#123;</span><br><span class="line">                    <span class="keyword">int</span> newRow = i + dirs[k][<span class="number">0</span>], newColumn = j + dirs[k][<span class="number">1</span>];</span><br><span class="line">                    <span class="keyword">if</span> (newRow &gt;= <span class="number">0</span> &amp;&amp; newRow &lt; rows &amp;&amp; newColumn &gt;= <span class="number">0</span> &amp;&amp; newColumn &lt; columns &amp;&amp; matrix[newRow][newColumn] &gt; matrix[i][j]) &#123;</span><br><span class="line">                        ++outdegrees[i][j];</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        queue &lt; pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; &gt; q;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; rows; ++i) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; columns; ++j) &#123;</span><br><span class="line">                <span class="keyword">if</span> (outdegrees[i][j] == <span class="number">0</span>) &#123;</span><br><span class="line">                    q.<span class="built_in">push</span>(&#123;i, j&#125;);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> ans = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (!q.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            ++ans;</span><br><span class="line">            <span class="keyword">int</span> size = q.<span class="built_in">size</span>();</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line">                <span class="keyword">auto</span> cell = q.<span class="built_in">front</span>(); q.<span class="built_in">pop</span>();</span><br><span class="line">                <span class="keyword">int</span> row = cell.first, column = cell.second;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; <span class="number">4</span>; ++k) &#123;</span><br><span class="line">                    <span class="keyword">int</span> newRow = row + dirs[k][<span class="number">0</span>], newColumn = column + dirs[k][<span class="number">1</span>];</span><br><span class="line">                    <span class="keyword">if</span> (newRow &gt;= <span class="number">0</span> &amp;&amp; newRow &lt; rows &amp;&amp; newColumn &gt;= <span class="number">0</span> &amp;&amp; newColumn &lt; columns &amp;&amp; matrix[newRow][newColumn] &lt; matrix[row][column]) &#123;</span><br><span class="line">                        --outdegrees[newRow][newColumn];</span><br><span class="line">                        <span class="keyword">if</span> (outdegrees[newRow][newColumn] == <span class="number">0</span>) &#123;</span><br><span class="line">                            q.<span class="built_in">push</span>(&#123;newRow, newColumn&#125;);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">作者：LeetCode-Solution</span><br><span class="line">链接：https:<span class="comment">//leetcode-cn.com/problems/fpTFWP/solution/zui-chang-di-zeng-lu-jing-by-leetcode-so-1chr/</span></span><br><span class="line">来源：力扣（LeetCode）</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>DFS与BFS系列</category>
        <category>动态规划系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>DFS</tag>
        <tag>dynamic programming</tag>
      </tags>
  </entry>
  <entry>
    <title>图系列——多余的边（DSU应用）</title>
    <url>/2022/02/21/0f9e9b187c29/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-118.-多余的边"><a href="https://leetcode-cn.com/problems/7LpjUW/">剑指 Offer II 118. 多余的边</a></h4>
<p>​ 树可以看成是一个连通且 无环 的 无向 图。</p>
<p>​ 给定往一棵 n 个节点 (节点值 1～n) 的树中添加一条边后的图。添加的边的两个顶点包含在 1 到 n 中间，且这条附加的边不属于树中已存在的边。图的信息记录于长度为 n 的二维数组 edges ，edges[i] = [ai, bi] 表示图中在 ai 和 bi 之间存在一条边。</p>
<p>​ 请找出一条可以删去的边，删除后可使得剩余部分是一个有着 n 个节点的树。如果有多个答案，则返回数组 edges 中最后出现的边。</p>
<p><strong>示例 1：</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/mac/1626676174-hOEVUL-image.png" style="zoom: 50%;" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: edges = [[1,2],[1,3],[2,3]]</span><br><span class="line">输出: [2,3]</span><br></pre></td></tr></table></figure>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 一开始，我的思路是找到一种方法，能够判断一个图有无环。毫无疑问，我们可以使用拓扑排序去进行这个思路，但是这样子的话，对于每删掉一条边就要进行一次拓扑排序来判断，时间复杂度无疑是比较高的。</p>
<p>​ 这个时候，查看官方解答，原来这类题目还可以使用<strong>并查集</strong>来做：</p>
<p>​ 初始时，每个节点都属于不同的连通分量。遍历每一条边，判断这条边连接的两个顶点是否属于相同的连通分量。</p>
<ul>
<li>如果两个顶点属于不同的连通分量，则说明在遍历到当前的边之前，这两个顶点之间不连通，因此当前的边不会导致环出现，合并这两个顶点的连通分量。</li>
<li>如果两个顶点属于相同的连通分量，则说明在遍历到当前的边之前，这两个顶点之间已经连通，因此当前的边导致环出现，为多余的边，将当前的边作为答案返回。</li>
</ul>
<h5 id="解题代码"><strong>解题代码</strong>：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">findRedundantConnection</span><span class="params">(vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt;&amp; edges)</span> </span>&#123;</span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">root</span><span class="params">(<span class="number">1001</span>,<span class="number">-1</span>)</span></span>;</span><br><span class="line">        <span class="keyword">int</span> i;</span><br><span class="line">        <span class="keyword">for</span>(i =<span class="number">0</span>;i&lt;edges.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">bool</span> res = <span class="built_in">unionTwo</span>(edges[i][<span class="number">0</span>],edges[i][<span class="number">1</span>],root);</span><br><span class="line">            <span class="keyword">if</span>(!res) <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> edges[i]; </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getRoot</span><span class="params">(<span class="keyword">int</span> index,vector&lt;<span class="keyword">int</span>&gt; &amp;root)</span></span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(root[index] != <span class="number">-1</span>)&#123;</span><br><span class="line">            index = root[index];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> index;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">unionTwo</span><span class="params">(<span class="keyword">int</span> index1,<span class="keyword">int</span> index2,vector&lt;<span class="keyword">int</span>&gt; &amp;root)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> root1 = <span class="built_in">getRoot</span>(index1,root);</span><br><span class="line">        <span class="keyword">int</span> root2 = <span class="built_in">getRoot</span>(index2,root);</span><br><span class="line">        <span class="keyword">if</span>(root1 != root2)&#123;</span><br><span class="line">            root[root1] = root2;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;  </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>图系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>graph</tag>
        <tag>DSU</tag>
      </tags>
  </entry>
  <entry>
    <title>图系列——矩阵中的距离</title>
    <url>/2022/02/21/80b7b127a404/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-107.-矩阵中的距离"><a href="https://leetcode-cn.com/problems/2bCMpM/">剑指 Offer II 107. 矩阵中的距离</a></h4>
<p>​ 给定一个由 0 和 1 组成的矩阵 mat ，请输出一个大小相同的矩阵，其中每一个格子是 mat 中对应位置元素到最近的 0 的距离。</p>
<p>​ 两个相邻元素间的距离为 1 。</p>
<p><strong>示例 1：</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/mac/1626667201-NCWmuP-image.png" alt="img" style="zoom: 50%;" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：mat = [[0,0,0],[0,1,0],[0,0,0]]</span><br><span class="line">输出：[[0,0,0],[0,1,0],[0,0,0]]</span><br></pre></td></tr></table></figure>
<h5 id="解题思路1多源bfs"><strong>解题思路1:多源BFS</strong></h5>
<p>​ 一开始看这题，应当能够较快的反应使用BFS进行解答，但核心的问题在于，如果使用传统 的BFS进行解答，起点是任意一个节点，终点为任意一个值为0的节点，我们需要做很多遍BFS才能够解决问题。</p>
<p>​ 故而，本题中所涉及到的是一个叫做<strong>多源BFS</strong>的方法，其实多源的BFS和单源BFS非常相似，在上述问题中，整体思路如下：首先我们遍历整个矩阵，将所有的值为0的节点得出结果，并加入到队列中去。我们采用逆向思维的方法，将这些值为0的节点全部放入队列中，且这些值为0的节点对应的结果距离也为0，后续经由它们扩散得到的别的点的距离，是在它们的距离0的基础上逐渐进行叠加的，直到扩散至全图范围，我们的多源BFS也就完成了。</p>
<p>​ 有一个可能会令人担忧的问题：那就是如果某一个点一开始被遍历到，设定好值以后，后面再作为别人的领居北遍历到的时候，会不会要设定的值比之前设定的值小呢？这是不可能的，因为我们采用的是BFS，一层层像波纹一样向外扩散，后遍历到的设定的值，必定大于或等于先前设定的值。所以不需要担心。</p>
<h5 id="解题代码"><strong>解题代码：</strong></h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; neighbor = &#123; &#123;<span class="number">-1</span>,<span class="number">0</span>&#125;,&#123;<span class="number">0</span>,<span class="number">-1</span>&#125;,&#123;<span class="number">1</span>,<span class="number">0</span>&#125;,&#123;<span class="number">0</span>,<span class="number">1</span>&#125; &#125;;</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">updateMatrix</span>(vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt;&amp; mat) &#123;</span><br><span class="line">        <span class="keyword">int</span> m = mat.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">int</span> n = mat[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">res</span>(m,vector&lt;<span class="keyword">int</span>&gt;(n,<span class="number">-1</span>)); <span class="comment">//初始化为-1，代表未访问过的点</span></span><br><span class="line">        queue&lt;pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt;&gt; q;</span><br><span class="line">        <span class="comment">// 初始化那些0的点，res也应当为0，将他们入队</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;m;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;n;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(mat[i][j] == <span class="number">0</span>)&#123;</span><br><span class="line">                    q.<span class="built_in">push</span>(&#123;i,j&#125;);</span><br><span class="line">                    res[i][j] = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="keyword">while</span>(!q.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            <span class="keyword">int</span> x = q.<span class="built_in">front</span>().first;</span><br><span class="line">            <span class="keyword">int</span> y = q.<span class="built_in">front</span>().second;</span><br><span class="line">            q.<span class="built_in">pop</span>();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">4</span>;i++)&#123;</span><br><span class="line">                <span class="keyword">int</span> new_x = x + neighbor[i][<span class="number">0</span>];</span><br><span class="line">                <span class="keyword">int</span> new_y = y + neighbor[i][<span class="number">1</span>];</span><br><span class="line">              	<span class="comment">//如果节点不合法，或者节点已经访问过了，直接跳过</span></span><br><span class="line">                <span class="keyword">if</span>(new_x &lt; <span class="number">0</span> || new_x &gt;= m || new_y &lt; <span class="number">0</span> || new_y &gt;= n || res[new_x][new_y] != <span class="number">-1</span>) <span class="keyword">continue</span>;</span><br><span class="line">              	<span class="comment">//计算res，push进入</span></span><br><span class="line">                res[new_x][new_y] = res[x][y] + <span class="number">1</span>;</span><br><span class="line">                q.<span class="built_in">push</span>(&#123;new_x,new_y&#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h5 id="解题思路2动态规划"><strong>解题思路2:动态规划</strong></h5>
<p>​ <strong>采用DP，状态转移方程如下：</strong> <span class="math display">\[
f(i,j) =  1 + min(\ f(i − 1, j),\  f(i, j − 1),\ f(i + 1, j), \ f(i, j + 1) \ \ )\ \ \ \ \  if (matrix[i][j] == 1)
\]</span></p>
<p><span class="math display">\[
f(i,j)=  0 \ \ \ \ \ \   if (matrix[i][j] == 0)
\]</span></p>
<p>​ 此时，我们需要注意，按照上述状态转移方程，我们好像没有一个办法遍历<code>i，j</code>，能够保证满足，在计算<span class="math inline">\(f(i,j)\)</span>前，我们一定已经获知了<span class="math inline">\(f(i-1,j)\)</span> 和<span class="math inline">\(f(i+1,j)\)</span> 和<span class="math inline">\(f(i,j-1)\)</span> 和<span class="math inline">\(f(i,j+1)\)</span>这四个节点的状态。所以，我们需要分两步来进行计算遍历，先从左上角往右下角计算一遍，计算的时候仅考虑 <span class="math inline">\(f(i-1,j)\)</span> 和<span class="math inline">\(f(i,j-1)\)</span> 这两个节点。再从右下角往左上角计算一遍，计算的时候仅考虑 <span class="math inline">\(f(i+1,j)\)</span> 和<span class="math inline">\(f(i,j+1)\)</span> 这两个节点。由于在前面一遍遍历中，会将结果存在<span class="math inline">\(f(i,j)\)</span>中，再第二轮遍历的时候，只要将那两个节点和当前节点比较，就相当于完成了和上一轮遍历中的两个节点比较。故而能够达到和上述状态转移方程一致的效果，具体请看代码：</p>
<h5 id="解题代码-1"><strong>解题代码：</strong></h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">updateMatrix</span>(vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt;&amp; mat) &#123;</span><br><span class="line">        <span class="keyword">int</span> m = mat.<span class="built_in">size</span>(), n = mat[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">dp</span>(m, vector&lt;<span class="keyword">int</span>&gt;(n));</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; m; i++) </span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; n; j++) </span><br><span class="line">                dp[i][j] = mat[i][j] == <span class="number">0</span> ? <span class="number">0</span> : <span class="number">1e7</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 从左上角开始</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; m; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; n; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (i - <span class="number">1</span> &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                    dp[i][j] = <span class="built_in">min</span>(dp[i][j], dp[i - <span class="number">1</span>][j] + <span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (j - <span class="number">1</span> &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                    dp[i][j] = <span class="built_in">mibn</span>(dp[i][j], dp[i][j - <span class="number">1</span>] + <span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 从右下角开始</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = m - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = n - <span class="number">1</span>; j &gt;= <span class="number">0</span>; j--) &#123;</span><br><span class="line">                <span class="keyword">if</span> (i + <span class="number">1</span> &lt; m) &#123;</span><br><span class="line">                    dp[i][j] = <span class="built_in">min</span>(dp[i][j], dp[i + <span class="number">1</span>][j] + <span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (j + <span class="number">1</span> &lt; n) &#123;</span><br><span class="line">                    dp[i][j] = <span class="built_in">min</span>(dp[i][j], dp[i][j + <span class="number">1</span>] + <span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>DFS与BFS系列</category>
        <category>动态规划系列</category>
        <category>图系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>BFS</tag>
        <tag>dynamic programming</tag>
        <tag>graph</tag>
      </tags>
  </entry>
  <entry>
    <title>动态规划——排列的数目</title>
    <url>/2022/02/21/9ee9d017b9d4/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-104.-排列的数目"><a href="https://leetcode-cn.com/problems/D0F0SV/">剑指 Offer II 104. 排列的数目</a></h4>
<p>​ 给定一个由 不同 正整数组成的数组 nums ，和一个目标整数 target 。请从 nums 中找出并返回总和为 target 的元素组合的个数。数组中的数字可以在一次排列中出现任意次，但是顺序不同的序列被视作不同的组合。</p>
<p>​ 题目数据保证答案符合 32 位整数范围。</p>
<ul>
<li>示例 1：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [1,2,3], target = 4</span><br><span class="line">输出：7</span><br><span class="line">解释：</span><br><span class="line">所有可能的组合为：</span><br><span class="line">(1, 1, 1, 1)</span><br><span class="line">(1, 1, 2)</span><br><span class="line">(1, 2, 1)</span><br><span class="line">(1, 3)</span><br><span class="line">(2, 1, 1)</span><br><span class="line">(2, 2)</span><br><span class="line">(3, 1)</span><br><span class="line">请注意，顺序不同的序列被视作不同的组合。</span><br></pre></td></tr></table></figure>
<p>提示：</p>
<pre><code>1 &lt;= nums.length &lt;= 200
1 &lt;= nums[i] &lt;= 1000
nums 中的所有元素 互不相同
1 &lt;= target &lt;= 1000</code></pre>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>参考官方解答： https://leetcode-cn.com/problems/D0F0SV/solution/pai-lie-de-shu-mu-by-leetcode-solution-og7w/</p>
<p>​ 该题目中，比较棘手的问题，是我们需要计算排列数目，一开始看到题目，还是想着背包问题的解法，被背包问题局限死了思路，总想着先计算组合数目，再计算排列数目，但后来发现并不是很合理，如果需要这样子的话，我不仅需要记录组合的数目，我还要计算每一组组合是什么，以便后续根据其内容计算排列数目。</p>
<p>​ 其实，跳出整一个背包问题的思路，我们采用动态规划的思想去思考：假设我们定义<code>res[i][j]</code>为前<code>i</code>个元素，达到<code>target=j</code>所有的排列数目，然后去思考转移方程，好像没法做，因为其并不能考虑排列，而是考虑的组合数目。故而正确的思路应当如下：</p>
<h5 id="定义"><strong>定义</strong>：</h5>
<pre><code>`res[target]`为达到目标整数target，可以出现的排列个数</code></pre>
<h5 id="初始化"><strong>初始化</strong>：</h5>
<pre><code>`res[0] = 1`，因为，要想达到目标整数0，只有一种排列方式，就是什么都不选。毕竟每一个元素都大于0.</code></pre>
<h5 id="状态转移分析"><strong>状态转移分析</strong>：</h5>
<pre><code>状态转移较为麻烦，对于`res[i]`而言，如何通过子问题的解来进行计算目标为`i`时候的排列数呢？</code></pre>
<p>​ 对于一个排列而言，肯定存在最后一个数，我们假定最后这个数为<code>num</code>,这个数肯定是<code>nums</code>中的一个。那么这个排列前面的这些数，它们的和就是<code>i - num</code>，也就是说<code>res[i-num]</code>所记录的排列数量，其中的每个排列，加上最后那个数num，会形成一个新的排列，这个排列就是满足<code>target = i</code>中的一个排列，所以<code>res[i] = res[i-num]</code>，这对吗？这不完全对！我们的<code>res[i]</code>的来源可不仅仅一个num，之前说了我们假定最后这个数为<code>num</code>，其实最后这个数可以是<code>nums</code>中的任意一个数，也就是说，我们要遍历<code>nums</code>中的所有数，看某一个数能不能作为最后一个数（只要num &lt;= i即可），如果能，那么<code>res[i] += res[i-num]</code>。最终，<code>res[i]</code>应该是一系列的数值加和得到的结果。</p>
<h5 id="状态转移方程"><strong>状态转移方程</strong>：</h5>
<p>​ <code>res[i] = sum&#123; res[i-num] for each num in nums &#125; ( num &lt;= i)</code></p>
<h5 id="解题代码"><strong>解题代码</strong>：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">combinationSum4</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">res</span><span class="params">(target+<span class="number">1</span>)</span></span>;</span><br><span class="line">        res[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=target;i++)&#123;</span><br><span class="line">            <span class="keyword">unsigned</span> <span class="keyword">int</span> tmp = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;nums.<span class="built_in">size</span>();j++)&#123;</span><br><span class="line">                <span class="keyword">int</span> num = nums[j];</span><br><span class="line">                <span class="keyword">if</span>(num &lt;= i)&#123;</span><br><span class="line">                    tmp += res[i-num];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            res[i] = tmp;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res[target];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h5 id="进阶问题"><strong>进阶问题：</strong></h5>
<pre><code>如果给定的数组中含有负数会发生什么？问题会产生何种变化？如果允许负数出现，需要向题目中添加哪些限制条件？</code></pre>
<h5 id="解答"><strong>解答</strong>：</h5>
<pre><code>如果给定的数组中含有负数，则会导致出现无限长度的排列。</code></pre>
<p>​ 例如，假设数组 nums 中含有正整数 a 和负整数 −b（其中 a&gt;0,b&gt;0,−b&lt;0），则有 a×b+(−b)×a=0，对于任意一个元素之和等于 target 的排列，在该排列的后面添加 b 个 a 和 a 个 −b 之后，得到的新排列的元素之和仍然等于 target，而且还可以在新排列的后面继续 b 个 a 和 a 个 −b。因此只要存在元素之和等于 target 的排列，就能构造出无限长度的排列。</p>
<p>​ 如果允许负数出现，则必须限制排列的最大长度，避免出现无限长度的排列，才能计算排列数</p>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>动态规划系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>dynamic programming</tag>
      </tags>
  </entry>
  <entry>
    <title>动态规划——经典背包问题及扩展</title>
    <url>/2022/02/21/8eca8d666ea6/</url>
    <content><![CDATA[<h3 id="一背包问题简介">一、背包问题简介</h3>
<p>​ 背包问题其实分很多种，此类问题的一般描述为：能否选择若干物品，使它们刚好放满一个容量为 t 的背包。在该篇博文中，我对其进行了详细的梳理。</p>
<ul>
<li><p>若每种物品可以选择拿一部分，则为<strong>分数背包问题</strong>，可以使用贪婪解决。</p></li>
<li><p>若每种物品只有一个，只能拿或者不拿，则为<strong>0-1背包问题</strong>，贪婪无法得到最优解，需用DP。</p></li>
<li><p>若每个物品的个数有限，则为<strong>多重背包问题</strong>；</p></li>
<li><p>若每个物品的个数无限，则为<strong>完全背包问题</strong>。</p></li>
</ul>
<h3 id="二分数背包问题">二、分数背包问题：</h3>
<p>​ 分数背包问题思路非常简单，采用贪婪的思路，我们只需要先计算每一种物品，它的性价比，然后进行排序，拿性价比高的物品，直到背包被装满即可。 <span class="math display">\[
性价比 = 物品总价值 / 物品总体积
\]</span></p>
<h3 id="三0-1背包问题">三、0-1背包问题：</h3>
<h4 id="题目描述">题目描述：</h4>
<p>​ 一共有N件物品，第i（i从1开始）件物品的重量为w[i]，价值为v[i]。在总重量不超过背包承载上限W的情况下，能够装入背包的最大价值是多少？</p>
<h4 id="分析">分析：</h4>
<p>​ 如果采用暴力穷举的方式，每件物品都存在装入和不装入两种情况，所以总的时间复杂度是O(2^N)，这是不可接受的。而使用动态规划可以将复杂度降至O(NW)。我们的<strong>目标是书包内物品的总价值，而变量是物品和书包的限重</strong>，所以我们可有如下解决方案</p>
<ul>
<li><p>定义规则如下：</p>
<ul>
<li><code>dp[i][j]</code> 表示将前i件物品装进限重为j的背包可以获得的最大价值,其中 <code>0&lt;=i&lt;=N, 0&lt;=j&lt;=W</code></li>
</ul></li>
<li><p>初始化状态：</p>
<ul>
<li>将<code>dp[0][0...W]</code>初始化为0，表示将前0个物品（即没有物品）装入书包的最大价值为0。</li>
</ul></li>
<li><p>状态转移方程：</p>
<ul>
<li><p>当 i &gt; 0 时<code>dp[i][j]</code> 有两种情况：</p>
<ol type="1">
<li>不装入第i件物品，即<code>dp[i-1][j]</code> ；</li>
<li>装入第 i 件物品（前提是能装下），即 <code>dp[i−1][j−w[i]] + v[i]</code>。</li>
</ol></li>
<li><p>``` dp[i][j] = max(dp[i−1][j], dp[i−1][j−w[i]]+v[i])        if( j &gt;= w[i] ) <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">    从上述方程中，我们知晓`dp[i][j]`的值只与`dp[i-1][0,...,j-1]`有关，就可以开始书写动态规划代码，</span><br><span class="line"></span><br><span class="line">    第 i 件物品装入或者不装入而获得的最大价值完全可以由前面 i-1 件物品的最大价值决定，暴力枚举忽略了这个事实</span><br><span class="line"></span><br><span class="line">- 核心代码：</span><br><span class="line"></span><br><span class="line">  ```C++</span><br><span class="line">  for(int i=0;i&lt;n;i++)</span><br><span class="line">  	for(int j=0;j&lt;W;j++)</span><br><span class="line">  		dp[i][j] = max(dp[i−1][j], dp[i−1][j−w[i]]+v[i])</span><br></pre></td></tr></table></figure></p></li>
</ul></li>
</ul>
<h4 id="题目示例">题目示例：</h4>
<p>​ <a href="https://leetcode-cn.com/problems/YaVDxD/">剑指 Offer II 102. 加减的目标值</a></p>
<h3 id="四完全背包问题">四、完全背包问题：</h3>
<h4 id="题目描述-1">题目描述：</h4>
<p>​ 完全背包（unbounded knapsack problem）与01背包不同就是每种物品可以有无限多个：一共有N种物品，每种物品有无限多个，第i（i从1开始）种物品的重量为w[i]，价值为v[i]。在总重量不超过背包承载上限W的情况下，能够装入背包的最大价值是多少？</p>
<h4 id="分析思路1">分析思路1：</h4>
<p>​ 大体的规则与初始化状态都和0-1背包问题一致，在状态转移方程处有所区别：</p>
<ul>
<li><p>定义规则如下：</p>
<ul>
<li><code>dp[i][j]</code> 表示将前i件物品装进限重为j的背包可以获得的最大价值,其中 <code>0&lt;=i&lt;=N, 0&lt;=j&lt;=W</code></li>
</ul></li>
<li><p>初始化状态：</p>
<ul>
<li>将<code>dp[0][0...W]</code>初始化为0，表示将前0个物品（即没有物品）装入书包的最大价值为0。</li>
</ul></li>
<li><p>状态转移方程：</p>
<ul>
<li><p>当 i &gt; 0 时<code>dp[i][j]</code> 有两种情况：</p>
<ol type="1">
<li>不装入第i件物品，即<code>dp[i-1][j]</code> ；</li>
<li>装入第i种物品，此时和0-1背包不太一样，因为每种物品有无限个（但注意书包限重是有限的），所以此时不应该转移到<code>dp[i−1][j−w[i]]</code>而应该转移到<code>dp[i][j−w[i]]</code>，即装入第 i种商品后还可以再继续装入第i种商品。</li>
</ol></li>
<li><p>``` dp[i][j] = max(dp[i−1][j], dp[i][j−w[i]]+v[i]) if( j &gt;= w[i] ) <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  从上述方程中，我们知晓`dp[i][j]`的值只与`dp[i-1][0,...,j-1]`有关，就可以开始书写动态规划代码，</span><br><span class="line"></span><br><span class="line">  此解法时间复杂度为O(NW)</span><br><span class="line"></span><br><span class="line">- 伪代码：</span><br><span class="line"></span><br></pre></td></tr></table></figure> for(int i=0;i&lt;n;i++) for(int j=0;j&lt;W;j++) dp[i][j] = max(dp[i−1][j], dp[i][j−w[i]]+v[i]) <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#### 分析思路2：</span><br><span class="line"></span><br><span class="line">​	我们从装入第 `i `种物品多少件出发，0-1背包只有两种情况即取0件和取1件，而这里是取0件、1件、2件...直到超过限重（k &gt; j/w[i]），所以状态转移方程为：</span><br><span class="line"></span><br><span class="line">- 定义规则如下：与0-1相同</span><br><span class="line">  - `dp[i][j]` 表示将前i件物品装进限重为j的背包可以获得的最大价值,其中  `0&lt;=i&lt;=N, 0&lt;=j&lt;=W`</span><br><span class="line"></span><br><span class="line">- 初始化状态：与0-1相同</span><br><span class="line"></span><br><span class="line">  - 将`dp[0][0...W]`初始化为0，表示将前0个物品（即没有物品）装入书包的最大价值为0。</span><br><span class="line"></span><br><span class="line">- 状态转移方程：</span><br><span class="line"></span><br><span class="line">  - ```text</span><br><span class="line">    # k为装入第i种物品的件数, k &lt;= j/w[i]</span><br><span class="line">    dp[i][j] = max&#123;(dp[i-1][j − k*w[i]] + k*v[i]) for every k&#125;</span><br></pre></td></tr></table></figure></p>
<p>从上述方程中，我们知晓<code>dp[i][j]</code>的值只与<code>dp[i-1][0,...,j-1]</code>有关，就可以开始书写动态规划代码</p></li>
</ul></li>
<li><p>伪代码：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;W;j++)</span><br><span class="line">        <span class="keyword">for</span>（<span class="keyword">int</span> k = <span class="number">0</span>;k&lt;j/w[i];k++)  <span class="comment">// j / w[i] 为可以装进的最大数目</span></span><br><span class="line">            dp[i][j] = <span class="built_in">max</span>(dp[i<span class="number">-1</span>][j], dp[i][j−k*w[i]]+k*v[i])</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="题目示例-1">题目示例：</h4>
<p>​ <a href="https://leetcode-cn.com/problems/gaM7Ch/">剑指 Offer II 103. 最少的硬币数目</a></p>
<h3 id="五多重背包问题">五、多重背包问题：</h3>
<h4 id="题目描述-2">题目描述：</h4>
<p>​ 多重背包（bounded knapsack problem）与前面不同就是<strong>每种物品是有限个</strong>：一共有N种物品，第i（i从1开始）种物品的数量为n[i]，重量为w[i]，价值为v[i]。在总重量不超过背包承载上限W的情况下，能够装入背包的最大价值是多少？</p>
<h4 id="分析-1">分析：</h4>
<p>​ 大体的规则与初始化状态都和完全背包的分析2角度一致，就是在状态转移方程处的k的大小有了一个更高的限制。</p>
<ul>
<li><p>定义规则如下：</p>
<ul>
<li><code>dp[i][j]</code> 表示将前i件物品装进限重为j的背包可以获得的最大价值,其中 <code>0&lt;=i&lt;=N, 0&lt;=j&lt;=W</code></li>
</ul></li>
<li><p>初始化状态：</p>
<ul>
<li>将<code>dp[0][0...W]</code>初始化为0，表示将前0个物品（即没有物品）装入书包的最大价值为0。</li>
</ul></li>
<li><p>状态转移方程：</p>
<ul>
<li>```text # k为装入第i种物品的件数, k &lt;= min(n[i], j/w[i]) dp[i][j] = max{(dp[i-1][j − k<em>w[i]] + k</em>v[i]) for every k} <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">  从上述方程中，我们知晓`dp[i][j]`的值只与`dp[i-1][0,...,j-1]`有关，就可以开始书写动态规划代码，</span><br><span class="line"></span><br><span class="line">- 伪代码：</span><br><span class="line"></span><br><span class="line">  ```C++</span><br><span class="line">  for(int i=0;i&lt;n;i++)</span><br><span class="line">  	for(int j=0;j&lt;W;j++)</span><br><span class="line">          for（int k = 0;k&lt;min(n[i], j/w[i]);k++)  // min(n[i], j/w[i]) 为可以装进的背包的最大数目</span><br><span class="line">              dp[i][j] = max(dp[i-1][j], dp[i-1][j−k*w[i]]+k*v[i])</span><br></pre></td></tr></table></figure></li>
</ul></li>
</ul>
<h3 id="六备注">六、备注：</h3>
<p>​ 上述所有的算法，由于状态转移方程的特殊性，所以其实在空间复杂度上是可以进行优化的，我们可以使用<strong>滚动数组</strong>的方法来进行优化，就比如最普通的0-1问题，使用滚动数组优化后，我们可以仅用一个一维数组来存储结果，丢掉原先二维数组的第1个维度。</p>
<p>​ 但是需要注意的是，在对j遍历的时候，必须逆向枚举，这是为了防止上一层循环的<code>dp[0,...,j-1]</code>被覆盖。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">dp[<span class="number">0</span>,...,W] = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span>,...,N</span><br><span class="line">    <span class="keyword">for</span> j = W,...,w[i] <span class="comment">// 必须逆向枚举!!!</span></span><br><span class="line">        dp[j] = <span class="built_in">max</span>(dp[j], dp[j−w[i]]+v[i])</span><br></pre></td></tr></table></figure>
<p>参考：<strong>https://zhuanlan.zhihu.com/p/93857890</strong></p>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>动态规划系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>dynamic programming</tag>
        <tag>knapsack problem</tag>
      </tags>
  </entry>
  <entry>
    <title>字符串交织问题</title>
    <url>/2022/02/21/f178664086c4/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-096.-字符串交织"><a href="https://leetcode-cn.com/problems/IY6buf/">剑指 Offer II 096. 字符串交织</a></h4>
<p>给定三个字符串 s1、s2、s3，请判断 s3 能不能由 s1 和 s2 交织（交错） 组成。</p>
<p>两个字符串 s 和 t 交织 的定义与过程如下，其中每个字符串都会被分割成若干 非空 子字符串：</p>
<pre><code>s = s1 + s2 + ... + sn
t = t1 + t2 + ... + tm
|n - m| &lt;= 1
交织 是 s1 + t1 + s2 + t2 + s3 + t3 + ... 或者 t1 + s1 + t2 + s2 + t3 + s3 + ...</code></pre>
<p>提示：a + b 意味着字符串 a 和 b 连接。</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：s1 = &quot;aabcc&quot;, s2 = &quot;dbbca&quot;, s3 = &quot;aadbbcbcac&quot;</span><br><span class="line">输出：true</span><br></pre></td></tr></table></figure>
<h5 id="解题思路1"><strong>解题思路1</strong>：</h5>
<p>​ 该题其实可以使用非常方便的回溯法思想进行解题，利用递归的形式：我们定义三个指针i，j，k，分别指向三个字符串，如果s1[i] == s3[k]，那么递归处理(i+1,j,k+1)。同理，如果s2[j] == s3[k]，那么递归处理(i,j+1,k+1)。递归边界是：如果i，j，k都到达了字符串的最后，就代表能够完成字符串交织。</p>
<h5 id="代码如下"><strong>代码如下：</strong></h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isInterleave</span><span class="params">(string s1, string s2, string s3)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">backtrace</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,s1,s2,s3);</span><br><span class="line">        <span class="keyword">return</span> flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">backtrace</span><span class="params">(<span class="keyword">int</span> i,<span class="keyword">int</span> j,<span class="keyword">int</span> k,string &amp;s1, string &amp;s2, string &amp;s3)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(i == s1.<span class="built_in">length</span>() &amp;&amp; j == s2.<span class="built_in">length</span>() &amp;&amp; k == s3.<span class="built_in">length</span>())&#123;</span><br><span class="line">            <span class="keyword">this</span>-&gt;flag = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(i&lt;s1.<span class="built_in">length</span>() &amp;&amp; s1[i] == s3[k]) <span class="built_in">backtrace</span>(i+<span class="number">1</span>,j,k+<span class="number">1</span>,s1,s2,s3);</span><br><span class="line">        <span class="keyword">if</span>(j&lt;s2.<span class="built_in">length</span>() &amp;&amp; s2[j] == s3[k]) <span class="built_in">backtrace</span>(i,j+<span class="number">1</span>,k+<span class="number">1</span>,s1,s2,s3);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>此时，会出现一个严重的问题，对于一些较长的序列来说，会通不过，运行超时。这是因为，这个回溯法，在分支进行的过程中，是很容易出现非常多的分支，并且会容易递归很多次的。所以，对于一些已经递归过的i，j，k结果，我们需要直接让它返回，不要继续递归计算，也就是对回溯法进行剪枝的操作。</p>
<h5 id="优化代码如下"><strong>优化代码如下：</strong></h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isInterleave</span><span class="params">(string s1, string s2, string s3)</span> </span>&#123;</span><br><span class="line">        unordered_map&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; m; </span><br><span class="line">        <span class="built_in">backtrace</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,s1,s2,s3,m);</span><br><span class="line">        <span class="keyword">return</span> flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">backtrace</span><span class="params">(<span class="keyword">int</span> i,<span class="keyword">int</span> j,<span class="keyword">int</span> k,string &amp;s1, string &amp;s2, string &amp;s3,unordered_map&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; &amp;m)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(i == s1.<span class="built_in">length</span>() &amp;&amp; j == s2.<span class="built_in">length</span>() &amp;&amp; k == s3.<span class="built_in">length</span>())&#123;</span><br><span class="line">            <span class="keyword">this</span>-&gt;flag = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> checkpoint = i * <span class="number">100</span> + j * <span class="number">10</span> + k;</span><br><span class="line">        <span class="keyword">if</span>(m.<span class="built_in">find</span>(checkpoint) != m.<span class="built_in">end</span>()) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">else</span> m[checkpoint] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(i&lt;s1.<span class="built_in">length</span>() &amp;&amp; s1[i] == s3[k]) <span class="built_in">backtrace</span>(i+<span class="number">1</span>,j,k+<span class="number">1</span>,s1,s2,s3,m);</span><br><span class="line">        <span class="keyword">if</span>(j&lt;s2.<span class="built_in">length</span>() &amp;&amp; s2[j] == s3[k]) <span class="built_in">backtrace</span>(i,j+<span class="number">1</span>,k+<span class="number">1</span>,s1,s2,s3,m);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/mac/截屏2022-02-21%20下午2.48.28.png" /></p>
<h5 id="解题思路2dynamic-programming-动态规划"><strong>解题思路2：Dynamic Programming 动态规划</strong></h5>
<p><strong>参考题解：</strong>https://leetcode-cn.com/problems/IY6buf/solution/jian-zhi-offerguan-jie-de-ge-ren-li-jie-gpspb/</p>
<p>https://leetcode-cn.com/problems/IY6buf/solution/jian-zhi-offer-2-mian-shi-ti-96-shu-zhon-5kc7/</p>
<p>​ 可以把题目进行一定的等效转换。约定从s1和s2中按从头到尾的顺序，依次取出一个字符（每次可以从s1中取，也可以从s2中取），加入字符串s3中，这样s3一定是s1和s2交错组成的结果。</p>
<p>​ 那么问题就转换为在按顺序取的情况下，s1的前i个字符和s2的前jjj个字符是否能构成s3的前i+j个字符？</p>
<h6 id="状态转移方程用fij表示s10i和s20j能否组成s30ij1"><strong>状态转移方程</strong>：用f(i,j)表示s1[0:i]和s2[0:j]能否组成s3[0:i+j+1]</h6>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if s3[i+j+1] == s1[i]</span><br><span class="line">    f(i,j) = f(i-1,j)</span><br><span class="line">if s3[i+j+1] == s2[j]</span><br><span class="line">    f(i,j) = f(i,j-1)</span><br><span class="line">if s3[i+j+1] == s1[i] == s2[j]</span><br><span class="line">    f(i,j) = f(i-1,j) || f(i,j-1)</span><br></pre></td></tr></table></figure>
<h6 id="状态转移方程的原理-对于字符串s30ij1的最后一个字符"><strong>状态转移方程的原理:</strong> 对于字符串s3[0:i+j+1]的最后一个字符：</h6>
<ul>
<li>如果该字符等于s1最后一个字符，原问题变为子问题1： s3[0:i+j]是否可以由s1[0:i-1]与s2[0:j]构成；</li>
<li>如果该字符等于s2最后一个字符，原问题变为子问题2： s3[0:i+j]可以由s1[0:i]与s2[0:j-1]构成。</li>
<li>如果该字符等于s2最后一个字符，也等于s1最后一个字符，那么子问题1和子问题2中任何一个成立，都可以推出原问题成立</li>
</ul>
<p><strong>其余注意初始状态即可</strong>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isInterleave</span><span class="params">(string s1, string s2, string s3)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s1.<span class="built_in">size</span>() + s2.<span class="built_in">size</span>() != s3.<span class="built_in">size</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">bool</span>&gt;&gt; <span class="built_in">dp</span>(s1.<span class="built_in">size</span>() + <span class="number">1</span>, vector&lt;<span class="keyword">bool</span>&gt;(s2.<span class="built_in">size</span>() + <span class="number">1</span>, <span class="literal">false</span>));</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; s2.<span class="built_in">size</span>() &amp;&amp; s2[j] == s3[j]; ++j) &#123;</span><br><span class="line">            dp[<span class="number">0</span>][j + <span class="number">1</span>] = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; s1.<span class="built_in">size</span>() &amp;&amp; s1[i] == s3[i]; ++i) &#123;</span><br><span class="line">            dp[i + <span class="number">1</span>][<span class="number">0</span>] = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; s1.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; s2.<span class="built_in">size</span>(); ++j) &#123; </span><br><span class="line">                <span class="keyword">char</span> ch1 = s1[i];</span><br><span class="line">                <span class="keyword">char</span> ch2 = s2[j];</span><br><span class="line">                <span class="keyword">char</span> ch3 = s3[i + j + <span class="number">1</span>];</span><br><span class="line">                dp[i + <span class="number">1</span>][j + <span class="number">1</span>] = ((ch1 == ch3) &amp;&amp; dp[i][j + <span class="number">1</span>]) || ((ch2 == ch3) &amp;&amp; dp[i + <span class="number">1</span>][j]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dp[s1.<span class="built_in">size</span>()][s2.<span class="built_in">size</span>()];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>动态规划系列</category>
        <category>字符串系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>dynamic programming</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title>数组系列——最长斐波那契数列</title>
    <url>/2022/02/21/aa9aa6191741/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-093.-最长斐波那契数列"><a href="https://leetcode-cn.com/problems/Q91FMA/">剑指 Offer II 093. 最长斐波那契数列</a></h4>
<p>如果序列 X_1, X_2, ..., X_n 满足下列条件，就说它是 斐波那契式 的：</p>
<pre><code>n &gt;= 3
对于所有 i + 2 &lt;= n，都有 X_i + X_&#123;i+1&#125; = X_&#123;i+2&#125;</code></pre>
<p>给定一个严格递增的正整数数组形成序列 arr ，找到 arr 中最长的斐波那契式的子序列的长度。如果一个不存在，返回 0 。</p>
<p>示例 1：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: arr = [1,2,3,4,5,6,7,8]</span><br><span class="line">输出: 5</span><br><span class="line">解释: 最长的斐波那契式子序列为 [1,2,3,5,8] 。</span><br></pre></td></tr></table></figure>
<p>示例 2：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入: arr = [1,3,7,11,12,14,18]</span><br><span class="line">输出: 3</span><br><span class="line">解释: 最长的斐波那契式子序列有 [1,11,12]、[3,11,14] 以及 [7,11,18] 。</span><br></pre></td></tr></table></figure>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 本题在LeetCode上，大多采用动态规划的方法解决，我借鉴了部分思路后，发现其实可以用与动态规划时间复杂度类似的算法解决。如下所示：</p>
<p>​ <strong>对于一个斐波那契数列来说，其性质给它带来了一个非常重要特性：也就是我们只要知道斐波那契数列中的最后两个数，或者前两个数，亦或者中间的任意的连续的两个数，我们就能够确定一整个斐波那契数列的元素</strong></p>
<p>​ 举例而言，我们知道一个斐波那契数列中，有两个连续的数为5，8，那么整个斐波那契数列前面可能拥有的数为3，再前面可能的数为2，再前面可能的数为1。反之，再后面的数为13，再后面的数为21，等等。</p>
<p>​ 之所以称之为可能的数，是因为我们并不知道斐波那契数列的长度，所以可能不存在这些数。放到这道题目中，我们可以用两个指针，i和j，遍历arr中所有的元素，例如：当i=2，j=4的时候，我们就假设arr[i]和arr[j]是斐波那契数列的最后两个数，然后循环的向前计算，观察arr中是否有满足条件的前面的数。</p>
<p>​ 遍历整个数列的时间复杂度为O(n^2)，而查找arr中是否有满足条件的数，我们可以使用Hash表来完成，先再代码开始处，用O(n)的时间，进行插入，后续查找都只需要O(1)的时间。</p>
<h5 id="解题代码"><strong>解题代码</strong>：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lenLongestFibSubseq</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; arr)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = arr.<span class="built_in">size</span>();</span><br><span class="line">      	<span class="comment">//构建hash表，以便后续查找</span></span><br><span class="line">        unordered_map&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; m;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            m[arr[i]] = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      	<span class="comment">//遍历i，j，计算以arr[i]和arr[j]为最后两个元素的斐波那契数列的长度</span></span><br><span class="line">        <span class="keyword">int</span> maxLen = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=i+<span class="number">1</span>;j&lt;n;j++)&#123;</span><br><span class="line">                <span class="keyword">int</span> res = <span class="built_in">calculateMaxLen</span>(arr[i],arr[j],m);</span><br><span class="line">                <span class="keyword">if</span>( res &gt; maxLen)&#123;</span><br><span class="line">                    maxLen = res;</span><br><span class="line">                &#125;   </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxLen;</span><br><span class="line">    &#125;</span><br><span class="line">		</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">calculateMaxLen</span><span class="params">(<span class="keyword">int</span> ele1,<span class="keyword">int</span> ele2,unordered_map&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; &amp;m)</span></span>&#123;</span><br><span class="line">        <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">int</span> len = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="comment">// 如果找不到的话，退出循环</span></span><br><span class="line">            <span class="keyword">if</span>(ele2 - ele1 &gt;= ele1) <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">if</span>(m.<span class="built_in">find</span>(ele2-ele1) == m.<span class="built_in">end</span>()) <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="comment">//如果找到了,迭代：继续循环</span></span><br><span class="line">                flag = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">int</span> tmp = ele2-ele1;</span><br><span class="line">                ele2 = ele1;</span><br><span class="line">                ele1 = tmp;</span><br><span class="line">                len++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(!flag) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> len;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>数组系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>array</tag>
      </tags>
  </entry>
  <entry>
    <title>动态规划——最少回文分割问题（待更新）</title>
    <url>/2022/02/18/52df1a6e55af/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-094.-最少回文分割"><a href="https://leetcode-cn.com/problems/omKAoA/">剑指 Offer II 094. 最少回文分割</a></h4>
<p>给定一个字符串 <code>s</code>，请将 <code>s</code> 分割成一些子串，使每个子串都是回文串。</p>
<p>返回符合要求的 <strong>最少分割次数</strong> 。</p>
<p><strong>示例 1：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：s = &quot;aab&quot;</span><br><span class="line">输出：1</span><br><span class="line">解释：只需一次分割就可将 s 分割成 [&quot;aa&quot;,&quot;b&quot;] 这样两个回文子串。</span><br></pre></td></tr></table></figure>
<p><strong>示例 2：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：s = &quot;a&quot;</span><br><span class="line">输出：0</span><br></pre></td></tr></table></figure>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 其内部其实含有两个DP子问题：</p>
<ul>
<li>1、字符串所有的子串，它们是不是回文串。即 s[i, j] 这一段是不是回文字符串</li>
<li>2、如何分割能够有最少的分割次数</li>
</ul>
<h5 id="子问题1"><strong>子问题1：</strong></h5>
<p>​ 我们用一个二维数组 isPalindrome 来进行记录，初始化为false。按照len长度进行遍历：状态转移方程如下所示： <span class="math display">\[
s[i][j] = true  \ \ \ \ \ (len = 1)
\]</span></p>
<p><span class="math display">\[
s[i][j] = (s[i] == s[j])  \ \ \ \ \ (len = 2)
\]</span></p>
<p><span class="math display">\[
s[i][j] = (s[i] == s[j] \ \ \ \&amp;\&amp; \ \ \ isPalindrome[i+1][j-1])  \ \ \ \ (len &gt; 2)
\]</span></p>
<h5 id="代码1">代码1：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> n = s.<span class="built_in">length</span>();</span><br><span class="line"><span class="comment">// 初始化全false</span></span><br><span class="line">vector&lt;vector&lt;<span class="keyword">bool</span>&gt;&gt; <span class="built_in">isPalindrome</span>(n, vector&lt;<span class="keyword">bool</span>&gt;(n, <span class="literal">false</span>));</span><br><span class="line"><span class="comment">// 长度为1的是回文串</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) isPalindrome[i][i] = <span class="literal">true</span>;</span><br><span class="line"><span class="comment">// 从长度为2的子串开始枚举[left, right]</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> len = <span class="number">2</span>; len &lt;= n; ++len)&#123;</span><br><span class="line">    <span class="comment">// 左端点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> left = <span class="number">0</span>; left + len &lt;= n; ++left) &#123;</span><br><span class="line">        <span class="comment">// 右端点</span></span><br><span class="line">        <span class="keyword">int</span> right = left + len - <span class="number">1</span>;</span><br><span class="line">        <span class="comment">// 长度为2就是这俩是否相等</span></span><br><span class="line">        <span class="keyword">if</span> (len == <span class="number">2</span>) isPalindrome[left][right] = (s[left] == s[right]);</span><br><span class="line">        <span class="comment">// 长度大于2, 端点相同的同时，内侧也要是回文</span></span><br><span class="line">        <span class="keyword">if</span> (len &gt; <span class="number">2</span>) isPalindrome[left][right] = (s[left] == s[right]) &amp;&amp; isPalindrome[left + <span class="number">1</span>][right - <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="子问题2"><strong>子问题2：</strong></h5>
<p>​ 我们用一维数组存储，字符串从「起点字符」到「第 i 个字符」组成的子串，最少需要多少分割次数。<code>dp[i]</code> 为将 <code>[0,i]</code> 这一段字符分割为若干回文串的最小分割次数，状态转移方程如下：</p>
<ul>
<li><p>从「起点字符」到「第 i 个字符」能形成回文串。那么最小分割次数为 0，此时有 <code>dp[i] = 0</code>； <span class="math display">\[
dp[i] = 0 \ \ \ \ \ ( isPalindrome[0][i] == true)
\]</span></p></li>
<li><p>从「起点字符」到「第 i 个字符」不能形成回文串。此时我们需要枚举左端点<code>l</code>，如果<code>[l, i]</code> 这一段是回文串的话，那么有 <code>dp[i] = dp[l- 1] + 1</code> ( 满足回文要求的左端点位置 l 可能有很多个，取最小</p></li>
</ul>
<p><span class="math display">\[
dp[i] = min(dp[l_0-1],dp[l_1-1],……,dp[l_{i} - 1]  ) + 1 \ \ \ ( isPalindrome[0][i] == false)(l_i = i)
\]</span></p>
<h5 id="代码2">代码2：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// n = s.length()</span></span><br><span class="line"><span class="comment">//2、res[i]代表从「起点字符」到「第 i 个字符」组成的子串要分割成回文串最少的分割次数</span></span><br><span class="line"><span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">res</span><span class="params">(n)</span></span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">    <span class="keyword">if</span>(isPalindrome[<span class="number">0</span>][i]) res[i] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">int</span> min = <span class="number">1e9</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> l=<span class="number">0</span>;l&lt;=i;l++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(isPalindrome[l][i] &amp;&amp; res[l<span class="number">-1</span>] &lt; min)&#123;</span><br><span class="line">                min = res[l<span class="number">-1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        res[i] = min + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="总解题代码">总解题代码：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">minCut</span><span class="params">(string s)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1、需要预先知道 i - j 的字符串是不是回文串 ( i &lt; j) </span></span><br><span class="line">        <span class="comment">//isPalindrome[i][j] 代表 i - j 子串</span></span><br><span class="line">        <span class="keyword">int</span> n = s.<span class="built_in">length</span>();</span><br><span class="line">        <span class="comment">// 初始化全false</span></span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">bool</span>&gt;&gt; <span class="built_in">isPalindrome</span>(n, vector&lt;<span class="keyword">bool</span>&gt;(n, <span class="literal">false</span>));</span><br><span class="line">        <span class="comment">// 长度为1的是回文串</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) isPalindrome[i][i] = <span class="literal">true</span>;</span><br><span class="line">        <span class="comment">// 从长度为2的子串开始枚举[left, right]</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> len = <span class="number">2</span>; len &lt;= n; ++len)&#123;</span><br><span class="line">            <span class="comment">// 左端点</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> left = <span class="number">0</span>; left + len &lt;= n; ++left) &#123;</span><br><span class="line">                <span class="comment">// 右端点</span></span><br><span class="line">                <span class="keyword">int</span> right = left + len - <span class="number">1</span>;</span><br><span class="line">                <span class="comment">// 长度为2就是这俩是否相等</span></span><br><span class="line">                <span class="keyword">if</span> (len == <span class="number">2</span>) isPalindrome[left][right] = (s[left] == s[right]);</span><br><span class="line">                <span class="comment">// 长度大于2, 端点相同的同时，内侧也要是回文</span></span><br><span class="line">                <span class="keyword">if</span> (len &gt; <span class="number">2</span>) isPalindrome[left][right] = (s[left] == s[right]) &amp;&amp; isPalindrome[left + <span class="number">1</span>][right - <span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//2、res[i]代表从「起点字符」到「第 i 个字符」组成的子串要分割成回文串最少的分割次数</span></span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">res</span><span class="params">(n)</span></span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(isPalindrome[<span class="number">0</span>][i]) res[i] = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">int</span> min = <span class="number">1e9</span>;</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> l=<span class="number">0</span>;l&lt;=i;l++)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(isPalindrome[l][i] &amp;&amp; res[l<span class="number">-1</span>] &lt; min)&#123;</span><br><span class="line">                        min = res[l<span class="number">-1</span>];</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                res[i] = min + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res[n<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>动态规划系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>dynamic programming</tag>
      </tags>
  </entry>
  <entry>
    <title>动态规划——房屋偷盗问题</title>
    <url>/2022/02/17/d13b71a5983a/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-089.-房屋偷盗"><a href="https://leetcode-cn.com/problems/Gu0c2T/">剑指 Offer II 089. 房屋偷盗</a></h4>
<p>​ 一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响小偷偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。</p>
<p>​ 给定一个代表每个房屋存放金额的非负整数数组 nums ，请计算 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。</p>
<p>示例 1：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [1,2,3,1]</span><br><span class="line">输出：4</span><br><span class="line">解释：偷窃 1 号房屋 (金额 = 1) ，然后偷窃 3 号房屋 (金额 = 3)。</span><br></pre></td></tr></table></figure>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 从纯解题的角度而言，本题是可以采用DFS进行的，但是使用DFS会超时，我们需要时间复杂度更为简单的算法。动态规划就起到了比较大的作用：</p>
<h5 id="定义">定义：</h5>
<p>​ 设动态规划列表 dp ，dp[i] 代表前 i 个房子在满足条件下的能偷盗到的最高金额。</p>
<h5 id="状态转移方程">状态转移方程：</h5>
<p><span class="math display">\[
dp[n+1]=max(dp[n],dp[n−1]+num)
\]</span> ​ 其中，<span class="math inline">\(dp[n]\)</span> 来源于：我们不抢第n+1个房子。</p>
<p>​ 其中，<span class="math inline">\(dp[n−1]+num[n+1]\)</span> 来源于：我们抢当前的房子，这样的话第n个房子就不能再抢了，所以我们只要加上前n-1个房子能抢到的最大金额即可。</p>
<h5 id="解题代码"><strong>解题代码</strong>：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">rob</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">maxNum</span><span class="params">(nums.size()+<span class="number">1</span>)</span></span>;</span><br><span class="line">        maxNum[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        maxNum[<span class="number">1</span>] = nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">2</span>;i&lt;=nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            maxNum[i] = <span class="built_in">max</span>(maxNum[i<span class="number">-1</span>],maxNum[i<span class="number">-2</span>] + nums[i<span class="number">-1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxNum[nums.<span class="built_in">size</span>()];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h4 id="剑指-offer-ii-090.-环形房屋偷盗"><a href="https://leetcode-cn.com/problems/PzWKhm/">剑指 Offer II 090. 环形房屋偷盗</a></h4>
<p>一个专业的小偷，计划偷窃一个环形街道上沿街的房屋，每间房内都藏有一定的现金。这个地方所有的房屋都 围成一圈 ，这意味着第一个房屋和最后一个房屋是紧挨着的。同时，相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警 。</p>
<p>给定一个代表每个房屋存放金额的非负整数数组 nums ，请计算 在不触动警报装置的情况下 ，今晚能够偷窃到的最高金额。</p>
<p>示例 1：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [2,3,2]</span><br><span class="line">输出：3</span><br><span class="line">解释：你不能先偷窃 1 号房屋（金额 = 2），然后偷窃 3 号房屋（金额 = 2）, 因为他们是相邻的。</span><br></pre></td></tr></table></figure>
<h5 id="解题思路-1"><strong>解题思路</strong>：</h5>
<p>​ 与上题其实大体一致，只不过需要转一个脑筋急转弯：</p>
<p>​ 环状排列意味着第一个房子和最后一个房子中只能选择一个偷盗，因此可以把此环状排列房间问题约化为两个单排排列房间子问题：</p>
<ul>
<li><p>在不偷盗第一个房子的情况下（即 nums[1:]），最大金额是 p1 ；</p></li>
<li><p>在不偷盗最后一个房子的情况下（即 nums[:n−1]），最大金额是 p2 。</p></li>
<li><p>综合偷盗最大金额： 为以上两种情况的较大值，即 max(p1,p2)。</p></li>
</ul>
<h5 id="解题代码-1">解题代码：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">rob</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.<span class="built_in">size</span>() == <span class="number">1</span>) <span class="keyword">return</span> nums[<span class="number">0</span>];</span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">dp1</span><span class="params">(nums.size())</span></span>;</span><br><span class="line">        <span class="function">vector&lt;<span class="keyword">int</span>&gt; <span class="title">dp2</span><span class="params">(nums.size())</span></span>;</span><br><span class="line">        <span class="comment">//dp1 不把nums[0]计算入</span></span><br><span class="line">        dp1[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        dp1[<span class="number">1</span>] = nums[<span class="number">1</span>];</span><br><span class="line">        <span class="comment">//dp2 不把nums[nums.size()-1]计算入</span></span><br><span class="line">        dp2[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        dp2[<span class="number">1</span>] = nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">2</span>;i&lt;nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            dp1[i] = <span class="built_in">max</span>(dp1[i<span class="number">-1</span>],dp1[i<span class="number">-2</span>] + nums[i]);</span><br><span class="line">            dp2[i] = <span class="built_in">max</span>(dp2[i<span class="number">-1</span>],dp2[i<span class="number">-2</span>] + nums[i<span class="number">-1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(dp1[nums.<span class="built_in">size</span>()<span class="number">-1</span>],dp2[nums.<span class="built_in">size</span>()<span class="number">-1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>动态规划系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>dynamic programming</tag>
      </tags>
  </entry>
  <entry>
    <title>动态规划——经典最长公共子序列问题</title>
    <url>/2022/02/16/513d3a9242d5/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-095.-最长公共子序列"><a href="https://leetcode-cn.com/problems/qJnOS7/">剑指 Offer II 095. 最长公共子序列</a></h4>
<p>给定两个字符串 text1 和 text2，返回这两个字符串的最长 公共子序列 的长度。如果不存在 公共子序列 ，返回 0 。一个字符串的 子序列 是指这样一个新的字符串：它是由原字符串在不改变字符的相对顺序的情况下删除某些字符（也可以不删除任何字符）后组成的新字符串。</p>
<ul>
<li>例如，"ace" 是 "abcde" 的子序列，但 "aec" 不是 "abcde" 的子序列。</li>
</ul>
<p>两个字符串的 公共子序列 是这两个字符串所共同拥有的子序列。</p>
<ul>
<li><code>text1</code> 和 <code>text2</code> 仅由小写英文字符组成。</li>
</ul>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 最长公共子序列问题是典型的二维动态规划问题。</p>
<p>​ 我们设定一个二维数组 res, <span class="math inline">\(res[i][j]\)</span> 代表text1的前i个字符和text2的前j个字符的最长公共子序列。当i = 0或j=0时，均初始化为0，然后我们写出递归表达式： <span class="math display">\[
res[i][j] = res[i-1][j-1] + 1  \ \ \ \ \ (if \ \ \ \ text1[i-1] == text2[j-1])
\]</span></p>
<p><span class="math display">\[
res[i][j] = max(res[i-1][j],res[i][j-1])  \ \ \ \ \ (if \ \ \ \ text1[i-1] != text2[j-1])
\]</span></p>
<p>​ 然后按照动态规划规则，进行循环求解即可。</p>
<h5 id="解题代码"><strong>解题代码</strong>：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">longestCommonSubsequence</span><span class="params">(string text1, string text2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> len_1 = text1.<span class="built_in">length</span>();</span><br><span class="line">        <span class="keyword">int</span> len_2 = text2.<span class="built_in">length</span>();</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">res</span>(len_1 + <span class="number">1</span>,vector&lt;<span class="keyword">int</span>&gt;(len_2 + <span class="number">1</span>));</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=len_1;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;=len_2;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(text1[i<span class="number">-1</span>] == text2[j<span class="number">-1</span>])&#123;</span><br><span class="line">                    res[i][j] = res[i<span class="number">-1</span>][j<span class="number">-1</span>] + <span class="number">1</span>; </span><br><span class="line">                &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                    res[i][j] = <span class="built_in">max</span>(res[i<span class="number">-1</span>][j] , res[i][j<span class="number">-1</span>]);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res[len_1][len_2];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p><strong>C++代码技巧注意</strong>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//初始化二维数组的方法</span></span><br><span class="line">vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">dp</span>(m + <span class="number">1</span>, vector&lt;<span class="keyword">int</span>&gt;(n + <span class="number">1</span>));</span><br></pre></td></tr></table></figure>
<p>​</p>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>动态规划系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>dynamic programming</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记18——常见的位置编码Position Encoding方法</title>
    <url>/2022/02/15/c20d8f810e24/</url>
    <content><![CDATA[<h3 id="一固定的绝对位置编码">一、固定的绝对位置编码：</h3>
<p>​ 在Transformer中使用的就是绝对位置编码，我们会将输入的序列首先通过Linear Embedding的形式，编码成 $ n d_{model}$ 的形式，<span class="math inline">\(n\)</span> 代表token的数量，<span class="math inline">\(d_{model}\)</span> 代表一个token的维度。</p>
<p>​ 然后我们会生成位置编码，绝对位置编码是固定值，其能够支持较长的序列，我们假设支持最长的序列长度为5000，那么就应当先生成一个维度为 $ 5000 d_{model}$ 的矩阵，具体公式如下：（不唯一）</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220215094001163.png" /></p>
<p>​ 使用如上所述的公式，代表不同频率的正弦和余弦函数进行表示：pos代表 第1个维度，也就是5000那个维度， i代表<span class="math inline">\(d_{model}\)</span>那个维度，对于一个固定的<span class="math inline">\(i\)</span>而言，我们会发现，其就是关于pos的正弦或余弦函数，对于不同的i而言，就是不同的频率而已。这样子预先计算好一个 $ 5000 d_{model}$ 的矩阵以后：</p>
<p>​ 等到要使用了，我们检测到token的数量是n，那么就直接取前整个矩阵的前 $ n d_{model}$切片就可以，然后与序列的Linear Embedding相加即可。</p>
<h3 id="二可学习的绝对位置编码-learned-positional-embedding">二、可学习的绝对位置编码 Learned Positional Embedding：</h3>
<p>​ <strong>直接对不同的位置随机初始化一个postion embedding</strong>，加到word embedding上输入模型，<strong>作为参数进行训练。</strong>使用Learned Positional Embedding编码，位置之间没有约束关系，我们只能期待它隐式地学到，是否有更合理的方法能够显示的让模型理解位置的相对关系呢？见后：</p>
<h3 id="三相对位置编码-rpe">三、相对位置编码 RPE：</h3>
<p>​ 在Swin Transformer中，使用的就是相对位置编码，使用绝对位置编码，不同位置对应的positional embedding固然不同，但是位置1和位置2的距离比位置3和位置10的距离更近，位置1和位置2与位置3和位置4都只相差1，这些关于位置的相对含义模型能够通过绝对位置编码get到吗？并不太行。</p>
<p>​ 在Swin Transformer中，这种相对位置编码在计算Attention的时候进行应用：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120718204.png" /></p>
<p>​ 相对位置偏差是怎么确定的呢？如下所示，假设我们的特征图是左侧的2*2的格子，下方是我们熟知的绝对位置索引，相对位置索引如右侧上面一排所示，其实就是当前计算格子的绝对位置索引减去其他格子的绝对位置索引。然后将四个像素的相对位置索引展开后拼接在一起形成一个新的矩阵。这个矩阵就是二维的相对位置索引矩阵。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/iiioio.png" /> 在作者的源码中，其使用的是1维的的相对位置索引矩阵，我们不能简单的将x,y相加，不然可能导致不同位置的相对位置索引一致，导致出现问题。所以作者在源码中经过了一个简单处理。我们先把所有的行列标加上M-1，然后再将行标乘2M-1，然后再将行列标相加，得到的矩阵。</p>
<p>​ 然后我们需要把Relative Position Index通过一张Bias Table映射成relative position bias才是用于计算Self-Attention最终用于计算的Bias值，也就是公式里的矩阵B。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120814669.png" /></p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Position Encoding</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记17——常见的Loss损失函数整理</title>
    <url>/2022/02/11/a5a0c2a08899/</url>
    <content><![CDATA[<h3 id="一多类别分类任务常用损失信息熵交叉熵相对熵的概念与应用">一、多类别分类任务常用损失：信息熵、交叉熵、相对熵的概念与应用</h3>
<h4 id="信息熵">1、信息熵</h4>
<ol type="1">
<li>随机变量 <span class="math inline">\(x\)</span> 的自信息 (self-information)，描述的是随机变量的某个事件发生所带来的信息量。</li>
</ol>
<p>​ <span class="math inline">\(I(x) = -log(p(x))\)</span></p>
<ol start="2" type="1">
<li><strong>信息熵</strong>即所有信息量的期望,其中<span class="math inline">\(n\)</span>为事件的所有可能性。</li>
</ol>
<figure>
<img src="https://www.zhihu.com/equation?tex=H%28X%29%3D%E2%88%92%E2%88%91_xp%28x%29log%28p%28x%29%29%3D%E2%88%92%E2%88%91_%7Bi%3D1%7D%5Enp%28x_i%29log%28p%28x_i%29%29" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h4 id="相对熵">2、相对熵</h4>
<p>​ KL散度，如果对于同一个随机变量x有两个单独的概率分布 <span class="math inline">\(p(x)\)</span>和 <span class="math inline">\(q(x)\)</span>，可以使用相对熵来衡量这两个分布的差异。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=D_%7BKL%7D%28p%7C%7Cq%29%3D%5Csum_%7Bi%3D1%7D%5Enp%28x_i%29log%28%5Cfrac%7Bp%28x_i%29%7D%7Bq%28x_i%29%7D%29" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>​ K-L散度其实是<strong>数据的原始分布p和近似分布q之间的对数差值的期望</strong>。</p>
<p>​ K-L散度<strong>并非距离，其不满足对称性</strong>，即 $D_{KL}(p||q) $ <span class="math inline">\(!=\)</span> $D_{KL}(q||p) $</p>
<h4 id="交叉熵">3、交叉熵：</h4>
<figure>
<img src="https://www.zhihu.com/equation?tex=H%28p%2Cq%29%3D-%5Csum_%7Bi%3D1%7D%5Enp%28x_i%29log%28q%28x_i%29%29" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>​ 在机器学习中，往往用 <span class="math inline">\(p(x)\)</span> 用来描述<strong>真实分布</strong>， <span class="math inline">\(q(x)\)</span> 用来描述模型<strong>预测的分布</strong>。</p>
<p>​ 计算损失，理应使用相对熵来计算概率分布的差异，然而由相对熵推导出的结果看：</p>
<p>​ 由于信息熵描述的是消除 p (即真实分布) 的不确定性所需信息量的度量，所以其值应该是最小的、固定的。那么：<strong>优化相对熵也就是优化交叉熵，所以在机器学习中使用交叉熵就可以了</strong></p>
<h4 id="为什么使用交叉熵">4、为什么使用交叉熵：</h4>
<p>​ 在机器学习中，我们希望模型在训练数据上学到的<strong>预测数据分布</strong>与<strong>真实数据分布</strong>越相近越好，上面讲过了，用相对熵，但是为了简便计算使用交叉熵就可以了。</p>
<p>在二分类中，交叉熵损失函数如下：<span class="math inline">\(y\)</span>是实际标签，<span class="math inline">\(\hat y\)</span> 是预测值z经过sigmoid函数之后的预测概率。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=L%3D-%5Bylog+\hat+y%2B(1-y)log+(1-\hat+y)%5D" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>Sigmoid函数如下：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=\sigma(z)+%3D+\frac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>​ 交叉熵损失函数一般用来代替均方差损失函数与sigmoid激活函数的组合：对于sigmoid函数，当 <span class="math inline">\(x\)</span> 的取值越大或越小，函数曲线变得越平缓，意味着导数<span class="math inline">\(\sigma(x)&#39;\)</span> 越趋近于0。以单个样本的梯度下降为例子：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=z%3D+wx%2Bb" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=\hat%7By%7D%3D+a+%3D\sigma(z)" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=L_1(y%2Ca)%3D\frac%7B1%7D%7B2%7D(y-a)%5E2" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=L_2%28y%2Ca%29%3D-%28ylog%28a%29%2B%281-y%29log%281-a%29%29" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>​ 前两个公式是前向传播过程中线性的部分，和非线性的部分。L1是MSE损失函数，L2是交叉熵损失函数。然后我们分别用L1和L2对参数w和b，利用链式法则求解梯度。</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=\frac%7B\partial+L_1(y%2Ca)%7D%7B\partial+w%7D%3D-%7Cy-\sigma(z)%7C\sigma&#39;(z)x" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=\frac%7B\partial+L_1(y%2Ca)%7D%7B\partial+b%7D%3D-%7Cy-\sigma(z)%7C\sigma&#39;(z)" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=\frac%7B\partial+L_2(y%2Ca)%7D%7B\partial+w%7D%3Dx%5B\sigma(z)-y%5D" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img src="https://www.zhihu.com/equation?tex=\frac%7B\partial+L_2(y%2Ca)%7D%7B\partial+b%7D%3D\sigma(z)-y" alt="[公式]" /><figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>​ 可以看出，<strong>均方差</strong>对参数的偏导的结果都<strong>乘了sigmoid的导数</strong> <span class="math inline">\(\sigma(z)&#39;\)</span> ，而之前看图发现sigmoid导数在其变量值很大或很小时趋近于0，所以偏导数很有可能接近于0。反观<strong>交叉熵</strong>对参数的偏导就<strong>没有sigmoid导数</strong>，所以不存在这个问题。<strong>这就是选择交叉熵而不选择均方差的原因。</strong></p>
<p><strong>分类任务的学习过程：</strong></p>
<p>​ 用神经网络最后一层输出的情况，来看一眼整个模型预测、获得损失和学习的流程：</p>
<ol type="1">
<li>神经网络最后一层得到每个类别的得分<strong>scores（也叫logits）</strong>；</li>
<li>该得分经过<strong>sigmoid(或softmax)函数</strong>获得概率输出；</li>
<li>模型预测的类别概率输出与真实类别的one hot形式进行交叉熵损失函数的计算。</li>
</ol>
<h3 id="二多标签分类任务">二、多标签分类任务：</h3>
<p>​ 在多标签分类任务中，一般采用<strong>sigmoid</strong>作为输出层的激活函数，使用 binary_crossentropy（二分类交叉熵损失函数）作为损失函数. <span class="math display">\[
\sigma(x) = \frac{1}{1 + e^{-x}}
\]</span> ​ 其中<span class="math inline">\(a\)</span>表示使用 sigmoid 函数激活输出层对应的神经元，<strong>此时最后一层的输出就不能看成一个分布了，因为加起来不为 1，现在把输出层每个神经元看作是一个二项分布， 这相当于将一个多标签问题转化为了在每个标签上的二分类问题。</strong></p>
<p>​ <img src="https://www.zhihu.com/equation?tex=L_2(y%2Ca)%3D-(ylog(a)%2B(1-y)log(1-a))" alt="[公式]" /></p>
<p>​ 计算一个样本各个标签的损失，然后取平均值，得到最后的损失。</p>
<h3 id="三回归任务常用损失">三、回归任务常用损失：</h3>
<h4 id="l1-loss-平均绝对误差">1、L1 Loss 平均绝对误差</h4>
<p>​ <strong>目标变量和预测变量之间绝对差值之和</strong></p>
<p>​ MAE曲线连续，但是在<em>y</em>−<em>f</em>(<em>x</em>)=0处不可导。而且 MAE 大部分情况下梯度都是相等的，这意味着即使对于小的损失值，其梯度也是大的。这不利于函数的收敛和模型的学习。但是，无论对于什么样的输入值，都有着稳定的梯度，不会导致梯度爆炸问题，具有较为稳健性的解。</p>
<p>​ MAE有个优点就是，对于离群点不那么敏感。因为MAE计算的是误差<em>y</em>−<em>f</em>(<em>x</em>) 的绝对值，对于任意大小的差值，其惩罚都是固定的。<strong>针对带有离群点的数据，MAE的效果要好于MSE。</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_12_11_35_15_642.png" style="zoom:50%;" /></p>
<h4 id="l2-loss-均方误差mse">3、L2 Loss 均方误差MSE</h4>
<p>​ MSE的函数曲线光滑、连续，处处可导，便于使用梯度下降算法，是一种常用的损失函数。 而且，随着误差的减小，梯度也在减小，这有利于收敛，即使使用固定的学习速率，也能较快的收敛到最小值。</p>
<p>​ 当<span class="math inline">\(y\)</span>和<span class="math inline">\(f(x)\)</span>也就是真实值和预测值的差值大于1时，会放大误差；而当差值小于1时，则会缩小误差，这是平方运算决定的。MSE对于较大的误差（&gt;1）给予较大的惩罚，较小的误差（&lt;1）给予较小的惩罚。也就是说，<strong>对离群点比较敏感，受其影响较大。</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_12_11_35_12_56.png" style="zoom:50%;" /></p>
<h4 id="smooth-l1-loss">3、Smooth L1 Loss</h4>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_12_12_04_33_822.png" style="zoom: 50%;" /></p>
<p>​ 从下图种中可以看出，该函数实际是一个分段函数，既解决了L1不光滑的问题，也解决了L2容易产生梯度爆炸的问题。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_12_12_05_00_718.png" style="zoom:50%;" /></p>
<p><strong>Smooth L1的优点</strong></p>
<ul>
<li>相比于L1损失函数，可以收敛得更快。</li>
<li>相比于L2损失函数，对离群点、异常值不敏感，梯度变化相对更小，训练时不容易跑飞。</li>
</ul>
<p><strong>参考：</strong></p>
<p>https://zhuanlan.zhihu.com/p/35709485</p>
<p>https://www.zhihu.com/question/336677048/answer/761385679</p>
<p>https://www.cnblogs.com/wangguchangqing/p/12021638.html</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Loss Function</tag>
      </tags>
  </entry>
  <entry>
    <title>博文复习日志1</title>
    <url>/2022/02/11/6f5929549220/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="5734a7de8e600d231091ff676bd42181369bfba87d201edfc5c14b2e92db6878">0b64cd3abe5b0a0a039a37d86c66d75eaeb9cde5c6dadc3c6d4d424e956e68e5859de93c067c256c245d75df485065102f6e2903c24acc225d3947c06b46eb863dd4b5852f98aab38803012f003c6c5ce6fff79afb10e1792ca7214d925987e0c717d406814885b789fb91e2e91f62e79489c1eb338c6615f677769d830ccf190fb9bbb686abd703322115c45664a457c7196ebc5128f0dbc61fa90adc2470af75105015c70e866cf9e65b8431b286f91724aada9a9fd5965d62719e3af60032aa7a2f77ed452eac7ab39f33c601c5d6de7df46cb4de25570ccbf95f141c0967a7b34c72683919d199358e5f05f83fc8af0d4a187180a67e0dfe958e0af9d66d33ab8d086e02df177e615e8042752039b5aa8ebbbf03fd595157a16f93e9d8aa7f0b856ccb5a1ec0ac5a77b1362d12bdc9c4ff39d2127ba4fa1a34736ed266b04fafccd0a982584b7e617ef2c7abee5c2cc4fbc96fa0391fe18bb0613a55fbdf71d01cafec27c0e41772b97d10dd173daa0e0dc1b05aa7b9d97e8244f9fba4f4018e4818e86e70f34c862bd69d9675ed15877d5449c4b7e8a6d6bc656ea82eba26ae72ad6ef75be44700be429e708bf43289740b82d67832194999149db733dd79f9775627aca1553102949d134429a4b5ec014c19965b51aacdd0b8af88faa8f0dd23ee465a91973610403e7f7015e27c4ca73425c835a103746324927ac9961a1fbbfa364ec6f09dca400884a8cd26d49df0e797f917bf5e1ddd4ce84f68c180d01f4a2b8fa7ffb12c378c27f7d149c0574024f6c7d997926a562382a75b7df0671abdb0741935b21dd625401ae2c8d83fe10f25ad46985c2442617293a87fa44bbe23878f5f0a341dd752b7d2f22ca0c80b746b4da56555f586c5ff770b6bc47b247939fd87fd97df54dee143d09a3572eb4097e5f0acb6a7c82b3d0bd31f0a92cb99e2c8c3cab16ed7b365b2a600a5fa080289d1d865a6b4c227ecbbb2fd1d2fdfd66082ef6074198a5aaa6aba8d4829da5c094a86176a0841491ccf4dc7ee545dd7a034ee8259f5f0011b7db9e433b4673050c085dd734b2e70a09f2866709876a15e124d99989ea943727a984ca6d5fc822e64d93de977821ab9d78a78ef14d4567d09ff69b40b6e6c01fc6b8680b5e704e23e00aedbcbea610a97288743de8f574fb680a2444d1c9d3f94bab3288a3ad504535c89a6c20f7dc83354a56877fb4beb4518dfce2d32f5293c16af8aa7f66eb6226c5fa93f423ffb44e166affdca16f9a05ffbdb05f1f2538680745a068f73f4f030afaf58b008316ecabc4bf15eeeed12b2a52f68c9ea007ac8768c5c6369f545833605181f6bac06257a122e6ffbee6c14cf2560e5a3b90604789144a509dcffc9236565ac7c26ffdac2199fbd3f470921f9c58fce79be41fd174f513de5530a298d2163c94cb7367570c6d709e3c6eedf24bc7f3e257d899a37ee636ba4fe04cb801f41d3c5b0716f199f23245ae06122c75a258215886896d8e941bf301108f3462f67f73121ea5b0aa5cabb8acfc32b4daa04a6014d2b05523627fb55d8b62b8565d6f2742035f260619cdae288d7b95e305a7b63421ceea761a047995e93ac206cdbf1fe479b687041f30d9083acd89f42d977a9257aa6f25950b3aeb3f06861ce31b9a0be69af54e637cb197c1238eb3fadd76adb0a97a323c64e2a34f9bdd00d779740449a5558edfc0187cd35c7a2ee95e0c21a0d27cd826e9416d9c405093e796a880a3a0cc20dec018e9c71f66aab54c8ebc7b2080498895a41512129103fa751121bd758cbd12e794685d1087a2844eb0494812bd86a5ca45157ca56a8e9451ea285e0f4c4aa3fcf8ea8af6c5021bba6fd67f9c2e3fc9aa5ac9f3c02a1cb57ce09b545d81b93cf3a9ed1c9cea76e5f2c8324a405e21bec4f37dd50b47d82cf68e0be38d9c8abcb3dfdf7086e46fe9a474e8253fc2d4a50b1ea681c53f39eb8051d3d1d7100b6184437a37ff53f34faf3f2b2e76e117ce47273c0fe4f75873df7fc377e1c3b7e8a180207ec326f2caaa79e5e672744f6795f10a78abef27b27e0953f29e2feb01fd6200284d0fb97e16534f8a234e4cc3134f5a103d2143b40523d277cda610eb3ebb53cce25b589fb3202da36018584b201f0efa38ec2d614a655cf21a56a0cbf67f439514f3445a07592f65ade23ac22f420830df90c395561b29e21156abd5e8af33cfd468013c1f04c0e3220820eeb86cc17d45798140c744c786b738ba23ae99675f189ee70dcf02cf5744c19b5c1084f3400caf5fc6b6456c8832e41d92cb1b664fd0297157d64629fd388961ee389a5226b60068a0eb0a78d48af553412d2e0866a1acbb5fb1f1754dd617e9f97b7c8f52cf8f2e76ec50e6c35ab04a5db2145b09344ec548405ca26274d6ac8471a1cb6dfbb1b616c26b2e45c85e87bd1a542563eb2b0c0d8f1ba79af341c4734c93cda4e93e05a8e1963c7ed0d320281388e552965dd33ac8f4e7ab0e38b7eb506e41b123c270fba5731b62372f40e5a4723155543790496c3e13e8999601978f9b51cfeffd3384b131367ea10bf445e905999513d0fae7f1293d91824a27fd8ebac8a0d614838ffbeb5d96f92522291435daba7c4fd34641136cc74009ce4da35484a180b2cf738d560196729705a95fc6e4a0a131e7ad1f6e58c6a5509fc0d193db3581f1529c91ba368f33d8d436d1c57eeb9efc2222b43f9c05ef45ef9cc7af5d44d73b8eee95061490f3755d80b7401f215ed7d358736f9e39b8664b73b50b8f6928a09bb3e3ec9f7f0b12dcb33638e684fb1ea23e182002d69213033ff32081f3677d4da9f4da9a6200d32af6345611f43a811b90c14b113e7efe51db0ffa66c63d8c7ef4b8f8c4c18346de3ebc2904386dc5909f3fcf87c3e538f98362ebc9ce8a2b9a3f1ee4e98c79ffe505049bf3ecb03d052e3c9005687ce224189a0a7b2cad32cd6e833f8d5bb900d08735398e5b930bce023d6700a90d05ee7774743910920e9e3127b35043485ca0fba788a988c514c45f8771f704a5c934f4ea0f6bee0a9dd76d8b493f470fb2e321558b3ef19151eb97ea08471a0b12c6ecadf139849d1609986cb0dafe576df189a60085cd29ade011e7cf9c7b63c5f4ed81c9bd40c26fef4b225d8b26ed8ec94338e3a651d4f2573204f1488c488aed9af338a630e02ee8b4ab8727adfc060d3c1dd2ae37f8c589666037a6718cccae93b8f3b976b4b5a17affd40008cae1689ee249ef445d8a5315cd21a1b957efffd6524bf3645cdc95869f2a43dfce4d6bb71ba4008f2ae005ecdb12f9bea4722ad836b1f6abd424ad3f02a02c048567c3bdcf7f489566d44c5f3a21877698bf9163989c22dcc3647e3340e114266381801df786c6fde82b052c4a521fb2b26565c0c5ccb2569dde84414de256a78df1118cbb08cfdb14bb87ec1ded2f0b7e718e31e7288850d76205ab005d98a8374a0b8f55645919e7cc4380538b0079f8f97a3568c338015907111df6c0e490ee582677d72b80b33f01aac61326d41897a9d56dff2b683c7624b4bb4e71cd22e78f8d73d7a99607cef2ad26379416f969a7aa52ad973121799a09771d8c6e53787477eb859168e7a1b0705df97724abce2aba5d1b56616715438c4340e26268622e3b36c0fcd21b2fd51b0ef6b9489a6abc6299b6589ac3b59bcd182369968bce00bc7499b75faba475e52194c0d7351be37c8b220308c3aa04af599c19818cf275ff8409f84d3ed6846706f63b57c0520e3d3914f32bf9daceed10d3923508aad66e5468cdef671d6521c001af5d1056db3a104ad7eda6df050b83fdb74b20ccb7d2e55d060e3e13e41bfc5c1768305bfcf8b2a2e42eedb1f7d4c36b3ec4e182c858f6935e0659eef7cb687f654e27c4194c9690f8913e66a1df9f524b93faf1789cd5aa85d303f47e741041046f82f08bd7c186492824236abd0e446e6668669e787aec7195a62c0775beae4a1e902b976bf92055a89300f02a909011cab0c27d2796204280c654837ae9c8f9122a7004b475c557bc45c80dc58806692cd0fd0d31efef3b0b78a034bd978ed5eac292439b347619017aa2e96d1e3f4325baa0c72ec635a6e5f52164cde2d4e9640539292bb73e7f5ee283b22c89d8b5b047a7e835e5ae71f23f7a1391a735b7eaceb8006a384090ae9c60a55e646c29d9f7141c65360a2b6c14b8756fc4b1aa57b0b508e790ea9aa9ee476cfeda4b335003a1506e077a46819ae03478c3328fa711e339f8a83d194f3f271d284cf56410a66913032300b1660600e9d4cb1ccca83ba64e82aebe7ed490752ea7f85b452bc926b29c274d7976e84b14b96d60b6103de6990eceba1785cc968ba8bf003632b5c42bd8d7bc428d575a0dfc28434f04a008fe3571db357061ce0a52686f153fc95b1163722a42484c46a50227bcc61fa812e4fcf1f8deb5164206ef0a5d6976c81b28888be0ebe0b15d4186a084d0442e090406df08a6449ed0400e4c275d266ce520441fbbc7a72c6f23767c2c6cf1eb12c2b6c574679cc6e2ed3e4c4c8203828aac4e811fac757e2eb640aee657e2c2df6b747ba2148964098a70616aee179d08afa935f4013a7d8a8747d20759588abf3420ad24950aa867d50d54fe2e1c25df5dddaa8b528013e82ff13ff3d6a94e2453a3f1c44024d3daf08477e62ea9494b1fd37fe96baf126122816ac7becc18721535254e657e5f5194e4698f87626ad56ba7ac6d7a13a8818bf2bc6b293b1a93979836ded825d23e77f0d8d13a333851c0897c56edff76e90d5cd6f3956da857ad6c4538dbdcbdfb83c4d307961b4c7f4d9dcc59ad2994bfced36a2d4f54a43d18272c3de1ffe3806d6206fd3a81df1558f3f5f6e2b52aa631c999cf7b9758f9fdb60bf553ebd7430ecc62e7d888f1c0be56df04b55189b8292f93d809ee1ce46aea0cea359105d122c8e9be28a1a796440d7b125590e949dc1665e3e1a17a7c7322012999d1ab5bcb3710d376765c9cba6bff8fbf79b894b3c6ce0ea8ce3072f4de8584e353395aeeb46c9504e3357c6b8b5fc2e6e71b19a70374b926af0f3b49843f49c1254e53e7c4257c56752ecde0bb756a828c05be23127cdd6afa7ee7d611b832c10e8e51d63e6d4f1947eb2808e8ec48fa1340e8742dc9d7523cb6c18d6e96b1e3b70051fa908557652d98ba77317c8af4adfbcc54cd6783861d5e8965a073aee61401856f454ae1dc0abad74d98d23ae757bc5368be0fcc3ea6366fe6dc7bcde2c86491e16d40a7463202d272b42efa0a38a41d53523eb75a17ce0379a09ed353a15d29d2885ff58df61ddb082a8082377e471a85ff6c3ae1a9a4924d08aef7d7980d972f5686d4be2185f70d1df8cb4b152df63e07784d0f0ea4c7b606770c042a40e6aca834e3c6846f064a7bb99d7167833bd40ab4786766d4527e8474936d56853f84d9f2097551789cc804655229011a5b202cd2c95046074484c93e60b4e4f635145290743188dca22011b75d539aa09a98fd37de1d62f8eff7dc45563090b4684b6bcef6f6eeb7e486d916cbde2ed84eb34a23f0c62b98fa37be5f3b883202230217d5b9b6e3bd897b845defebd0977afa5f702fffd0a8e29978d86ac1ca2751946261a7c9afd189853f30a5a183bc7fd9c63b466544d5afe730e77f920caf673f019c762f1f2d3b4d58fdc6b7f115433f60518d1944a780a4668cd5a08cdd4769f8d810a8434f90c281abef969cb6730b0f9a5a34bad2625135c0cd7474976557df8bdbd276fe6d6970f928e4845ef852323f390ade0728b721567926287b68830edd81c1bdebf325dd73e6536feb100516cbbe02b61009856a42089bc0b670acb1d988606150ff32529bd16987d8fbc8aba08d8f04a4955a1f529ba8285b5db99ab0f77dc5365b629c11f1479fa8ec4e8556b171c4b5a53cd63189b0791d67eb304f8b5517e2e0cde44d4cb2d78638835ad4235276411c14415e401c08f1842efae0f459858907f4131876be1c32f823cbc2910990994d5862257490b08351180fcc0feb0e68cbc5d84e4c75d187fbfa8b3dbe8660561521cc1f19c7ffc79d1e998f2a3702121054aa7374600551166a2dda64f3bd682f0ec606b9741816d5d258385cffef3ee87e7f7275c0ce5270a4d7855b8ee545a79149a79f6ac212688dd43e963edf51369938a1ae026f216bfa621b2894ea35bcfc7a303380d310758862ad2d72871669d6494fac26c04a1b6e1ae73e5c1cf2d45677363ec956baea1eea23b00fdbc77f8d4e1a87e84cea7fa79b68a16be064cc23b8dab2aa0d1e356853b60b392bee92296292e42df1950d2a9c14b4815ec5e3d95fe462d52e7556075141e4cc08ed512f89a7f112a5665655e6640cbb057711f63aa5d823faa41ea40ffc088bf7947dd2ffee21b42e21c1c2c865fc752d2010bdcdbb5f4f487b9f54ea6dced854039bb67ad0b22a1fb64cb13d63d29eba83cee898c7e51b53ab8f24313c0d52663387b3a98e57ba7d37b4da339648af591e7afc228e34df64ab1aede31157ee67cef4daf1e2b3dd414bbc0684189c042d24c0da3653aa71343c015506391ddfc52548b5a5a1b8e46de5fbb405306d6e0af078eb0e221250a58968b07189b6ff60b53ff9c5a4b1a02e13b00bf5afeffc747baff22f3f91b547abbc2444a73ac5380c35bad2f4be96e4cafdd85caf55b73ad8ffb66838dbe982577a2d3078defe26f0f4b81d8ba1953c918d0be4b692490d21e0b327c8a5d19efba8152fc976eba198597c36ae69cd579ec088cf0e23e4e57edc7903d5674168248a2245ed45cdc4f4a9d00c88c2f5c3d94fd74b0fcde5ad73bad8f3596e8b6d9028edd38717e44c8b84ff505bbc386793ad97ec571ce2abbb26173bb7faaa270a821ec4e670a6e97b7eb278f6b479e40855dc8eb4b0c991bd23fe041835985747934435f4f38618f5bd5a6b487001ad4fb8a08853bf40920ee89792b8136b0e1d8b87bd7b8ddaf9a1c6900c546a1cb8a4460c53d2297eb93a418308c9c8a0b8ced525fbbbf5f4e8cfb025ced158b3054eb6bfa3fd647b2fea0fd06ea98bf57111a138eb2f5f4141417ad6da249429ce53842b694b8a730a87ec42ee46907e52e501812a15846f829b97cd95d72eef27856e7661f3453d7699eef0fea7a622b0cf94f8c6b4d0f6f0ff02d2bb265cebe52cfca7094387f404381f66f837b86dc4f7afa69d1291bb48304e78a073556b1f3a612bfd108163d6c798cece9c2d23268cf204bd602ee0cae3640292956dbea8eabe7095f69c44d976824e5244e411946f77ae9daf6f0d1bbb813dc9c1dee7a9fe7c1f2fb64d506e1ebbf423e4acf3579d82c0a50e69d87b8ada137b260730d57a82781bb894c66eb55a9565268ea956c70334b92572aafe49a27393a26aef71dc1eba3e3f8c68d38866d0314d95340779c645c18ede7d71eae6324c47165c19b4b93d530f0f541a649b81ca3166597405b0d08dd6fec64fcabf124618bb422694a73682d1bd30a686fe88d3c15fec4de474da92f07fa0400a9353bced7f2a9089faff3770acc39a1c38d65c37bb82298ab599f7c9963a852ff793afee1a40720d0d86a020585759a45f51d88a021221b6ed08d33ad1d07124de78815c7f434edf83e8515c9d3c4845801e97d1daadf7a2a4dfc99e0d1a0739c8efeb4b52ec3c9dfe666dc78b5b19a4de94e2d03f05476996f87e0adb4c3f8979293408fe880d425a822c3464633c459ecf51c3ddac57197d72565e3bfcfe3b31f1df863f0d1d169c6b687bc8462794ac1735e854b44cdd3503b5e229b0283dc5554aec4f24d4f6cf7cb3a28ce42e05e07c5789a1c1b59756a447da7602a4bd26c8be62ba7eb0933795e3fd794d8226d9008115f42b3191563fd5bd816d4da78e0392763781216c1fb2dc44d06f2925bce5cd79e11bd7565c57f86d4f5688bf3b00bc1ad4efeebd0b9b21e56d2dad5d2f35041ff8fac5ea170081e38e615893ddff1e112f2b572b73fe2fadbdbe4c07669a65000a306d6a7cf8e7f8e7005c4c4662529185393fb5e9200ce61933dc08e94b3e6df3c06afeca74582f66dd0cbb392bf573009b052da8c754c417d1359923b7c7c79c9b22ddcfcb4d7f745ce47c0ece455829c74494c23ebb55647a0850e6052a88212b41dc37992db9261debc9449fdf499b6123c61c2ea74f59967291c2af9abcefbdc0e86111358251a5630aa71d4097abd0eb20519121d6004884d3da80241b2460aea9046b4c5ec79097aab5bcf8f8ee12f347e16ae4cf85cf8f8399148eae86d16495cdcf0eff613ef627d2633dc3f33e9818a4e53140a5a1b2aaf9316b586f07a072ac4a3010852af9cefe803f46edd26a8c72185e2a12102b5a4f54fc6dc181ad6c4dea2be7791c1acae6854a8ceb8a060852fa44f828ee7c7b755e893eaeed5fca4092cee1e226ee6c858615b09db63f377e94af7248e7c138f1371ee9039a3bfb1b106de26da962cf7f6e638dadcfb9fd2accf2c7b09f16b0016a8f4e7f310fbf5b390110f71bd791a1f9eee41bab61c015e07889ed137ed288e87c9bde88314690a356d47467e75b970eb2075403920acc8ae1e041b1e0fd4ca620bb5a2d25c49f9322df6be3fb3b5db134f081ee2ed477f54cb3a7d342f9820dd</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>⓼ 博文复习日志</category>
      </categories>
      <tags>
        <tag>Review</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记16——常见的梯度下降优化器整理</title>
    <url>/2022/02/11/ced858ce48dc/</url>
    <content><![CDATA[<h4 id="一批量梯度下降法bgd">一、批量梯度下降法BGD：</h4>
<p>​ 更新每一参数都用所有样本去进行更新，在下面例子中，总共有n个参数，m个样本，我们如果想要更新参数$ _j$ ，就需要遍历所有的m个训练样本，然后将所有的梯度累加起来取平均，然后再进行更新。</p>
<p>​ <img src="https://pic2.zhimg.com/80/v2-890e5ab2843f3b22467a5e6aeef58b59_720w.png" /></p>
<h4 id="二随机梯度下降法sgd">二、随机梯度下降法SGD：</h4>
<p>​ 由于BGD每跟新一个参数的时候，要用到所有的样本数，所以训练速度会随着样本数量的增加而变得非常缓慢。随机梯度下降正是为了解决这个办法而提出的。它是<strong>利用每个样本的损失函数</strong>对θ求偏导得到对应的梯度，来更新θ：</p>
<p><img src="https://pic1.zhimg.com/80/v2-65566b643790ca6c89919fd970f34e2c_720w.png" /></p>
<p>​ 随机梯度下降是通过每个样本来迭代更新一次，对比上面的批量梯度下降，迭代一次需要用到所有训练样本（<strong>往往如今真实问题训练数据都是非常巨大</strong>），一次迭代不可能最优，如果迭代10次的话就需要遍历训练样本10次。<strong>但是，SGD伴随的一个问题是噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。</strong></p>
<p>​ 但是可以并行化计算。</p>
<h4 id="三min-batch小批量梯度下降法-mbgd">三、<strong>min-batch</strong>小批量梯度下降法 MBGD：</h4>
<p>​ 我们假设每次更新参数的时候用到的样本数为10个</p>
<p><img src="https://pic2.zhimg.com/80/v2-9d473c89948f1ddc8c4f294c55123f59_720w.png" /></p>
<p>​ <strong>随机取batch个样本，</strong>而不是1个样本，然后对参数进行更新即可。</p>
<h4 id="四冲量优化器momentum">四、冲量优化器（Momentum）</h4>
<p>​ 在Gradient Descent + Momentum的算法如下：最开始第一步和原来的一样，从<span class="math inline">\(\theta^0\)</span>开始计算梯度，然后沿着梯度反方向移动下降，达到<span class="math inline">\(\theta^1\)</span>时，此时和原先就会发生不同了，其现在的移动会结合前一步的movement（即<span class="math inline">\(m^1\)</span>）以及当前点的梯度<span class="math inline">\(g^1\)</span>，计算出一个新的下降方向<span class="math inline">\(m^2\)</span>，然后进行更新。如图所示：<span class="math inline">\(m^2\)</span>是由 <span class="math inline">\(m^1\)</span>和 <span class="math inline">\(-g^1\)</span>两个向量相加所得到的。从公式上来讲就是$m^1 - g^1 $，两者都有自己的参数，来控制影响整个梯度下降方向的比例。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113022761.png" style="zoom:50%;" /></p>
<h4 id="五adagrad优化器auto-learning-rate">五、AdaGrad优化器（Auto Learning Rate）</h4>
<p>​ 如果Loss函数在某个方向上比较平坦,梯度比较小，那么我们希望Learning Rate比较大，快速的走过这一片平坦的区域。如果在某个方向上比较陡峭，我们希望Learning Rate比较小.</p>
<p>​ 将原来的学习率η修改成 $  <span class="math inline">\(, 这个\)</span>_{it}$既跟参数相关又跟训练步骤（不同点所在的梯度）相关。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220121170754841.png" /></p>
<p>​ 以下是σ的计算方式，通过计算每次更新得到的参数空间所在点的梯度的Norm值的平方的平均，即RMS来计算每步中σ。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113547513.png" alt="image-20220114113547513" style="zoom:25%;" /></p>
<h4 id="六rmsprop优化器">六、RMSProp优化器</h4>
<p>​ <strong>AdaGrad的进阶版本：</strong></p>
<p>​ 它在计算每一步的σ的时候，结合了上一步的σ以及该步的梯度g，同时还有一个超参数α，可以进行调整。如果我们调整α比较大的话，代表其参考当前的梯度较多，也就是说如果梯度突然产生较大变化，其就能快速的反应过来，对LearningRate进行快速的调整。相较于前RMS所有先前的梯度都平均权值考虑的做法，这一做法能够更快速的对梯度的变化进行响应。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113634056.png" alt="image-20220114113634056" style="zoom:25%;" /></p>
<h4 id="七adam优化器">七、Adam优化器：</h4>
<p>​ 综合了RMSProp和Momentum技术的优化</p>
<p>​ Adam可以理解为加了Momentum 的 RMSprop</p>
<p><img src="C:\Users\14012\Desktop\d50735fae6cd7b891692d4d0b34087a1d8330e56.jpeg" /></p>
<p>参考资料：https://zhuanlan.zhihu.com/p/25765735</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Gradient Descent</tag>
        <tag>Optimizer</tag>
      </tags>
  </entry>
  <entry>
    <title>科研方法经验整理帖（待更新）</title>
    <url>/2022/02/11/47deca447e0d/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="b4930639b86a22e78e2f34aded24395adc765efcbe3aa58debd225b115003347">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>⓻ 经验整理类笔记</category>
      </categories>
      <tags>
        <tag>Methods</tag>
      </tags>
  </entry>
  <entry>
    <title>Python搭建深度学习框架系列笔记1——计算图、梯度下降、反向传播、自动微分的理论部分</title>
    <url>/2022/02/10/f5cccb7aefe2/</url>
    <content><![CDATA[<h3 id="一深度学习训练逻辑框架梳理">一、深度学习训练逻辑框架梳理：</h3>
<p>​ 我们以解决一个简单的问题的深度学习训练逻辑为例，梳理一下在框架内部发生的整体步骤：</p>
<ul>
<li>1、构建模型函数 F（此步其实就是对应着用户传入的<strong>构建的深度学习模型model，深度学习模型model中又可能含有许多层layer</strong>）</li>
<li>2、确定损失函数 L （用户传入的损失函数，常见的有交叉熵、L1、L2等损失函数，还可能是混合损失函数）</li>
<li>3、依据 F 和 L 构建<strong>计算图 Graph</strong>（ 框架内部完成 ）</li>
<li>4、在each update中，干如下两件事情
<ul>
<li>将输入的数据，<strong>根据计算图</strong>进行前向传播计算，得到Loss值</li>
<li><strong>根据计算图</strong>，进行反向传播计算，获得 损失函数L 对 模型参数 w 的 梯度向量（具体采用的技术就是<strong>自动微分</strong>）</li>
</ul></li>
<li>5、将 梯度向量信息与 每个模型参数w 信息 传入<strong>优化器</strong>中，更新参数，然后回到步骤4，循环往复。（优化器往往也是框架在内部提前写好的，几个比较通用的优化器：Adam，Adagrad等）</li>
</ul>
<p><strong>注意</strong>：实际上，如果对于一些简单的模型函数，比如 wx + b , 我们是可以不定义计算图的，只要我们人工的实现了该模型的forward函数，以及该模型的backward函数，框架应当就会在前向传播和反向传播的过程中，调用这两个函数来进行计算。</p>
<p>​ 那么，计算图和自动微分的作用是什么呢？我们知道，在pytorch中，我们在一个模型中只需要定义forward函数即可，是不需要定义backward函数的，那么模型又应当怎么去定义反向传播的过程呢？这个时候就是计算图和自动微分起作用了。因为现在的模型函数F都非常复杂，人工求导是不现实的，所以我们就需要依据前向传播过程和损失函数，构建计算图，然后依据自动微分技术，用反向传播的形式，计算损失函数L 对 模型参数 w，最终实现梯度下降优化。</p>
<h3 id="二计算图反向传播自动微分详解">二、计算图、反向传播、自动微分详解：</h3>
<h4 id="最基本的计算图">1、最基本的计算图：</h4>
<p>​ 计算图是用来描述运算的有向无环图，有两个主要元素：节点 (Node) 和边 (Edge)。节点表示数据，如向量、矩阵、张量。边表示运算，如加减乘除卷积等。计算图中节点有不同的类型，不同类型的节点执行不同的计算。</p>
<p><img src="https://pic2.zhimg.com/80/v2-464ea7ee4475f3c7f08c389f65fd3e89_1440w.jpg" alt="img" style="zoom:50%;" /></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">w = torch.tensor([<span class="number">1.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">x = torch.tensor([<span class="number">2.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># y=(x+w)*(w+1)</span></span><br><span class="line">a = torch.add(w, x)     <span class="comment"># retain_grad()</span></span><br><span class="line">b = torch.add(w, <span class="number">1</span>)</span><br><span class="line">y = torch.mul(a, b)</span><br><span class="line"><span class="comment"># y 求导</span></span><br><span class="line">y.backward()</span><br><span class="line"><span class="comment"># 打印 w 的梯度，就是 y 对 w 的导数</span></span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br></pre></td></tr></table></figure>
<p>​ 在上面的例子中，x 和 w 是叶子节点，其他所有节点都依赖于叶子节点。叶子节点的概念主要是为了节省内存，<strong>在计算图中的一轮反向传播结束之后，非叶子节点的梯度是会被释放的。</strong></p>
<p>代码示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看叶子结点</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;is_leaf:\n&quot;</span>, w.is_leaf, x.is_leaf, a.is_leaf, b.is_leaf, y.is_leaf)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看梯度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;gradient:\n&quot;</span>, w.grad, x.grad, a.grad, b.grad, y.grad)</span><br></pre></td></tr></table></figure>
<p>结果为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">is_leaf:</span><br><span class="line"> True True False False False</span><br><span class="line">gradient:</span><br><span class="line"> tensor([5.]) tensor([2.]) None None None</span><br></pre></td></tr></table></figure>
<h4 id="计算图中的一些基本概念">2、计算图中的一些基本概念：</h4>
<h5 id="变量节点">1）变量节点：</h5>
<p>​ 这些节点没有父节点，它们的值不是计算出来的，而是被赋予的。具体到模型中，一般会是模型的输入、参数或者标签。</p>
<h5 id="内积节点">2）内积节点：</h5>
<p>​ 由于节点的值既可以是一个数，也可以是一个向量。内积节点就是将两个父节点视为向量，然后计算两个父节点的内积。</p>
<h5 id="前向传播">3）前向传播：</h5>
<p>​ 输入信息被赋予变量节点，沿着网络向前流动，最终流动到所要计算的结果节点，这就是计算图的前向传播过程。</p>
<h4 id="区分静态图和动态图">3、区分静态图和动态图：</h4>
<p>​ PyTorch 采用的是动态图机制 (Dynamic Computational Graph)，而 Tensorflow 采用的是静态图机制 (Static Computational Graph)。</p>
<ul>
<li><p><strong>动态图</strong>是运算和搭建同时进行，也就是可以先计算前面的节点的值，再根据这些值搭建后面的计算图。优点是灵活，易调节，易调试</p></li>
<li><p><strong>静态图</strong>是先搭建图，然后再输入数据进行运算。优点是高效，因为静态计算是通过先定义后运行的方式，之后再次运行的时候就不再需要重新构建计算图，所以速度会比动态图更快。但是不灵活。TensorFlow 每次运行的时候图都是一样的，是不能够改变的</p></li>
</ul>
<p>​ 所以，其实在pytorch中，比如你定义的一个继承自nn.Module的网络类中，你会重载这个类的forward函数，然后在网络训练运行的过程中，其就会根据你的forward里面张量的计算过程来搭建动态的计算图，并且依据此计算图，在反向传播的时候使用自动微分计算梯度。</p>
<h4 id="方向导数和梯度">4、方向导数和梯度</h4>
<h5 id="方向导数">1）方向导数：</h5>
<p>​ 方向导数的本质是一个数值，简单来说其定义为：<strong>一个函数沿指定方向的变化率。</strong>其最核心的两个要点是：</p>
<ul>
<li>函数</li>
<li>指定方向</li>
</ul>
<p>​ 当我们拥有一个函数，并且确定好一个方向以后，就可以计算得到该方向的方向导数，是一个数值。从下图中一个最简单的一维函数来看：</p>
<p><img src="C:\Users\14012\Desktop\屏幕捕获_2022_02_26_21_49_36_307.png" style="zoom:50%;" /></p>
<p>​ 我们指定E点，现在指定EC、EB、EA、ED四个方向，<strong>我们来看一下各自方向的方向导数，ED方向的方向导数最小，因为它是切线方向，且是朝下的，也就是说函数在该点往ED方向的变化率负方向最大，也就是值最小。之后依次是EA、EB、EC。ED的反方向DE，就是该点各个方向导数中，最大的那一个。</strong></p>
<h5 id="梯度">2) 梯度：</h5>
<p>​ 梯度与方向导数是有本质区别的，梯度其实是一个向量，其定义为：一个函数对于其自变量分别求偏导数，这些偏导数所组成的向量就是函数的梯度。</p>
<h5 id="梯度与方向导数的关系">3）梯度与方向导数的关系：</h5>
<p>​ <strong>函数在某点的梯度是这样一个向量，它的方向与取得最大方向导数的方向一致，而它的模为方向导数的最大值。</strong> 这个其实是比较直观能够去理解的一个维度：具体证明此处不涉及。</p>
<h4 id="梯度下降">5、梯度下降：</h4>
<p>​ 对于一个具有参数 <strong>w </strong>=（w1,w2,w3）和 b 的计算图，我们可以把所有参数看作一个大向量（<strong>w</strong>,b），然后以（<strong>w</strong>,b）为自变量，以损失值为函数值。求梯度就是求损失之对每个参数的偏导数，为了求这些偏导数，我们可以<strong>单独把每个参数节点视为自变量，求损失值对该节点的梯度</strong>（具体怎么求，见反向传播和自动微分方法）。</p>
<h4 id="什么是反向传播和自动微分">6、什么是反向传播和自动微分？</h4>
<h5 id="训练时自动微分在哪里应用">1）训练时自动微分在哪里应用？</h5>
<p>​ 自动微分用于反向传播的过程中，依据计算图计算<strong>损失函数对参数的梯度</strong>。在Pytorch常见的训练步骤中，应当就是封装在 .backward() 函数中的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_loss = criterion(outputs, labels) <span class="comment"># 通过损失函数，计算本次损失值</span></span><br><span class="line">batch_loss.backward()  <span class="comment"># 损失反向传播，计算梯度</span></span><br></pre></td></tr></table></figure>
<p>​ 举一个更简单明了的例子：考虑最简单的一层神经网络，输入 x，参数 w 和 b，以及一些损失函数。 它可以通过以下方式在 PyTorch 中定义：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">5</span>)  <span class="comment"># input tensor</span></span><br><span class="line">y = torch.zeros(<span class="number">3</span>)  <span class="comment"># expected output</span></span><br><span class="line">w = torch.randn(<span class="number">5</span>, <span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">z = torch.matmul(x, w)+b</span><br><span class="line">loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)</span><br></pre></td></tr></table></figure>
<p>pytorch在上述运算进行的过程中，就会搭建好如下的计算图。</p>
<figure>
<img src="https://pytorch.org/tutorials/_images/comp-graph.png" alt="avatar" /><figcaption aria-hidden="true">avatar</figcaption>
</figure>
<p>​ 然后，调用如下函数,即可计算梯度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss.backward() // 计算梯度</span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br><span class="line"><span class="built_in">print</span>(b.grad)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[0.2175, 0.0032, 0.1359],</span></span><br><span class="line"><span class="string">        [0.2175, 0.0032, 0.1359],</span></span><br><span class="line"><span class="string">        [0.2175, 0.0032, 0.1359],</span></span><br><span class="line"><span class="string">        [0.2175, 0.0032, 0.1359],</span></span><br><span class="line"><span class="string">        [0.2175, 0.0032, 0.1359]])</span></span><br><span class="line"><span class="string">tensor([0.2175, 0.0032, 0.1359])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>​ Pytorch 这边其实实际上隐藏了非常多的内部细节，从外表函数调用来看，根本看不到计算图、自动微分的逻辑，这是因为Pytorch都已经将其封装在了底层中。实际上，Pytorch的计算图是什么时候搭建的呢？其就是在每一个Tensor张量参与计算的时候进行搭建的：</p>
<p>例如，执行如下代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">z = torch.matmul(x, w)+b</span><br></pre></td></tr></table></figure>
<p>计算图中，关于x、w、b、z节点之间的DAG就已经搭建好了</p>
<p>再当执行如下代码的时候：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)</span><br></pre></td></tr></table></figure>
<p>​ Pytorch又将loss和z、y的节点关系加入计算图中了。</p>
<p>​ 同时，截至此时，x,y,w,z,loss 的值都已经计算出来了，也就是说已经完成了一遍前向传播，这时候这些值都被记录在这一个个Tensor中。（下图是torch.Tensor内部的成员变量，我们可以看到，其内部是记录了非常多东西的，前向传播的值就是记录在Tensor.data中，也就是其表现出来的值）</p>
<p><img src="https://pic2.zhimg.com/80/v2-3bc1ff0ab920582a3491111b81a32fe5_1440w.jpg" /></p>
<p>然后当我们在外层调用如下函数的时候:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss.backward()</span><br></pre></td></tr></table></figure>
<p>​ Pytorch 内部实际上就是开始反向传播，利用自动微分引擎，链式法则计算loss对参数w的梯度值。对于我们人而言，是如下的一个过程：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/dsa98uyc89dsahkj.jpg" style="zoom:33%;" /></p>
<p>​ 那么，这个时候我们就需要思考了，对于电脑来说我们根本没有告诉它，loss对参数w的导数怎么求啊？即使是按照上述靠链式法则去求，但是我们也没告诉它链式法则中的每一项的导数是什么（比如说loss对z的导数，z对w的导数），那怎么求呢？其实，这个时候Pytorch内部就是利用其带的自动微分引擎，去解析函数，然后进行计算的。从外层看来，我们只知道只要设定一些参数，调用backward()函数，就能够获得loss对某个参数w的梯度，外层完全不用关心内部的事情。我们再详细的先拓展一下反向传播的具体数学原理，随后会记录自动微分。</p>
<h5 id="反向传播的数学原理扩展">2）反向传播的数学原理扩展：</h5>
<p>​ 反向传播写成上面的链式传播导数的形式十分好理解，但是不仅仅是上述这样子。我们应该需要知道，上面我们都默认所有的字母都只是一个常量，而不是一个变量，就比如说 w 是一个值， x 也仅是一个值，这些节点，我们通常称之为变量节点，它们没有父节点，它们的值不是被计算出来的，而是被赋予的。但其实，节点的值可以是一个数，也可以是一个向量，我们可以用一个节点保存输入向量(x1,x2,x3)，再用一个节点保存权值向量(w1,w2,w3)。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_10_15_03_30_21.png" /></p>
<p>那么也就是说，其实<strong>计算图中每一个节点都是多个值到多个值的映射，也就是向量 到向量的映射，自变量是父节点，因变量是子节点。</strong>虽然一个子节点可能拥有多个父节点，但是我们在计算子节点对某一个父节点的梯度的时候，可以把其他的父节点视为常量。</p>
<p>​ 举例如下：比如我们从<strong>n维向量( w )，计算出m维向量的映射就可以视为m个标量函数</strong>：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/3FFA54BF58ADB73E2AB2959E12132F27.jpg" alt="img" style="zoom:33%;" /></p>
<p>​ 我们可以知道，每一个<span class="math inline">\(f_i(w)\)</span>对 <span class="math inline">\(w\)</span>来说，应该都有一个梯度 <span class="math inline">\(\nabla f_i(w)\)</span> ,而每一个梯度都是一个n维向量（因为自变量是n维向量）。</p>
<p>​ 以m个梯度作为行，每个梯度都是一个n维向量：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/C3DB7AD3158C70B1352C05AB2B03B655.jpg" style="zoom:33%;" /></p>
<p>​ 这个<span class="math inline">\(J_f(w)\)</span> 叫做映射 <span class="math inline">\(f(w)\)</span>在 w 处的雅可比矩阵。因为<span class="math inline">\(f(w)\)</span>是从n维到m维的映射，所以<strong>雅可比矩阵是一个$ m n<span class="math inline">\(的矩阵，它的每一行分别是\)</span>f(w)<span class="math inline">\(的每一个分量\)</span>f_{i}(w)<span class="math inline">\(在\)</span>w$处的梯度向量的转置。</strong></p>
<p>​ 故而，我们知道，<strong>对于计算图中的每一对父子节点，都可以计算出子节点对父节点的映射的雅可比矩阵。 雅克比矩阵其实也就是映射的每个分量对输入向量的每个分量的偏导数。</strong></p>
<p>​ 在上述图2-1中的内积节点x = (x1,x2,x3) ， w = (w1,w2,w3)，它们的子节点 对 他们的映射，就是一个 n维(n=3)到1维的映射，故而，子节点到父节点的雅可比矩阵应当是 $ 1 n$矩阵。</p>
<p>​ <strong>至此为止，我们已经能够知晓计算图中每一对父子节点的雅可比矩阵怎么求解了，可是，我们最终要求的是损失函数对参数w的雅可比矩阵</strong>。仍然如2-1所示，w节点是h节点的祖先，它必须要经过 内积节点、+节点、*节点后，才会最终到达h节点。 这个时候，我们就可以利用链式法则： 复合映射的雅可比矩阵式组成复合映射的多个映射的雅可比矩阵的乘积。</p>
<p>​ 即复合映射<span class="math inline">\(f(g(h(w))\)</span> 在w处的雅可比矩阵是 <span class="math inline">\(J_f\)</span> 、<span class="math inline">\(J_g\)</span> 、<span class="math inline">\(J_h\)</span>三个雅可比矩阵的乘积。</p>
<p>​ （我们先假设一个父节点只有一个子节点）<strong>那么所谓反向传播：就是从计算图中作为结果的节点开始，依次从后向前，每个节点都将 “结果对自己的雅可比矩阵” 和 “自己对父节点的雅可比矩阵” 传给自己的父节点，然后这个父节点再将 “结果节点对自己的雅可比矩阵” 和 “自己对父节点的雅可比矩阵” 传给父节点，再前面的父节点会将两矩阵相乘，得到 “结果对自己的雅可比矩阵” ，一直这样子到我们的 变量节点</strong>。</p>
<p>​ 所以“反向传播”传播的是结果节点对自己的雅可比矩阵，同时也将自己对父节点的雅可比矩阵传给父节点。父节点将这两个矩阵相乘，就得到最终结果对自己的雅可比矩阵。</p>
<p>​ 接下来就剩最后一个问题了，<strong>如果一个父节点有多个子节点，它应该如何得到结果对自己的雅可比矩阵呢？</strong>在数学上能够证明，其实就是先按照上述方法，将<strong>结果节点 对 各个子结点的雅可比矩阵 和 各个子节点对父节点的雅可比矩阵分别相乘，然后再相加即可 得到 结果节点对父节点的雅可比矩阵</strong>。如下所示：</p>
<p><span class="math display">\[
J_f = \Sigma_s J_{rs}J_{sf}
\]</span> ​ <span class="math inline">\(J_f\)</span>是最终结果节点对父节点f 的雅可比矩阵。</p>
<p>​ <span class="math inline">\(J_{rs}\)</span>是最终结果节点对某个子节点s的雅可比矩阵。</p>
<p>​ <span class="math inline">\(J_{sf}\)</span>是某个子节点对父节点f的雅可比矩阵。</p>
<p>【附：<strong>最开始的时候，结果节点对自己的雅可比矩阵是啥？ 回答：是一个单位矩阵，即对角线元素为1，其余元素都为0</strong>】</p>
<p>​ 具体的代码实现，见下一节中的Node类的backward方法的实现。</p>
<h5 id="自动微分的工作原理解析">3）自动微分的工作原理解析：</h5>
<p>​ 在上述描述的反向传播过程中，我们有一个核心的地方还没有细说，那就是如何让计算机计算 一对子节点和父节点 它们之间的雅可比矩阵，也就是它们之间的导数关系，如何计算？【此处留有陷阱，请继续往下看】</p>
<p>​ 让计算机实现微分功能有以下几种微分方式，</p>
<ul>
<li>手工计算出微分，然后编码进代码中</li>
<li>数值微分 (numerical differentiation)</li>
<li>符号微分 (symbolic differentiation)</li>
<li>自动微分</li>
</ul>
<figure>
<img src="https://pic4.zhimg.com/80/v2-4c305dc170d7a165aec1b5d7017828c7_1440w.jpg" alt="四种微分方式的对比。 手工微分、符号微分、 自动微分得出的都是精确解， 而数值微分得出的只是近似解。" /><figcaption aria-hidden="true">四种微分方式的对比。 手工微分、符号微分、 自动微分得出的都是精确解， 而数值微分得出的只是近似解。</figcaption>
</figure>
<p>我们简单的先介绍以下前三种方式，然后再着重介绍自动微分：</p>
<ul>
<li><p><strong>手工编码</strong>：故名思意，自己计算函数的导数然后编码入计算机代码中。</p></li>
<li><p><strong>数值差分</strong>，其分为两种方式—前向差分、中心差分</p></li>
</ul>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_10_17_31_03_38.png" /></p>
<p>​ 一般我们使用中心差分来对神经网络的反向传播进行 <strong>梯度检验</strong>， 前向差分很少使用， 因为前向差分的误差是 <span class="math inline">\(O(h)\)</span> , 而中心差分的误差是 <span class="math inline">\(O(h^2)\)</span> , 使用泰勒公式将上面的 <span class="math inline">\(f(x+h)\)</span> 和<span class="math inline">\(f(x-h)\)</span>展开，就能得出前向差分和中心差分的误差</p>
<ul>
<li><p><strong>符号微分：</strong></p>
<p>​ 类似于我们人的手工计算，它是计算机根据规则进行微分的方式。符号微分的明显的缺陷是容易产生 <strong>表达式膨胀</strong> (expression swell)。</p>
<figure>
<img src="https://pic3.zhimg.com/80/v2-fb2923b77c6a8cbed2716e58e44f191e_1440w.jpg" alt="符号微分的微分结果不一定是最简的形式" /><figcaption aria-hidden="true">符号微分的微分结果不一定是最简的形式</figcaption>
</figure></li>
<li><p><strong>自动微分：</strong></p>
<p>​ 自动微分将符号微分法应用于最基本的算子，比如常数，幂函数，指数函数，对数函数，三角函数等，然后代入数值，保留中间结果，最后再应用于整个函数。因此它应用相当灵活，可以做到完全向用户隐藏微分求解过程，由于它只对基本函数或常数运用符号微分法则。</p>
<p>​ 自动微分有前向模式和反向模式两种，<strong>当输出的维度大于输入的时候，适宜使用前向模式微分；当输出维度远远小于输入的时候，适宜使用反向模式微分。</strong>一般在神经网络中使用的都是反向模式。因为神经网路的输入通常 &gt;&gt; 输出，</p>
<p>​ 细节上来说，自动微分是将复合函数分解为输出量（根节点）和一系列的输入量（叶子节点）及基本函数（中间节点），构成一个计算图（Computational Graph），并以此计算任意两个节点间的梯度：</p>
<ul>
<li>加法法则：任意两个节点间的梯度为它们两节点之间所有路径的偏微分之和；</li>
<li>链式法则：一条路径的偏微分为路径上各相邻节点间偏微分的连乘。</li>
</ul></li>
</ul>
<p>​ <strong>看到这里，会觉得很熟悉，诶等等！这不就是反向传播干的事情吗，一摸一样！</strong>然后我就发现自己一开始理解错概念了，我一开始以为反向传播过程中计算一对父节点和子节点的雅可比矩阵 这边的过程用的是自动微分，其他都是反向传播的过程，其实从某种意义上来说，反向传播就是在计算自动微分的过程，而计算一对子节点和父节点它们之间的雅可比矩阵，其实就已经是分解到最基本的算子了。在后面的代码实现环节，会更清楚明了一些。</p>
<p>​ 总结一下，计算图的变量节点被赋值或初始化后，在结果节点（比如损失值节点）上调用 前向传播 ，递归计算路径上各个节点的值，信息沿着计算图向前传播，最终得到结果节点的值。之后，在需要更新的节点上调用 反向传播 方法，该方法会递归计算<strong>结果节点对路径上各个节点的雅可比矩阵，信息反向传播</strong>。如果有多个节点需要更新，比如权值向量节点和偏置节点，就在这些节点上分别调用 反向传播 方法。<strong>由于中间节点的雅可比矩阵（如果已经被计算）已经保存在了 节点的 jacobi 属性中，所以在多个节点上多次调用其 反向传播 方法时并不会增加额外的计算负担。</strong>这其实就是“反向传播”的精髓，它执行的无非就是复杂复合映射的求导链式法则，保存中间结果，从而以空间换时间。具体的内容会在下一节的实现中详解</p>
<p><strong>参考资料：</strong></p>
<p>代码实现参考：https://github.com/zc911/MatrixSlow</p>
<p>1、《用python实现深度学习框架》张觉非、陈震</p>
<p>2、https://zhuanlan.zhihu.com/p/191648279</p>
<p>3、https://zhuanlan.zhihu.com/p/61103504</p>
<p>4、https://blog.csdn.net/aws3217150/article/details/70214422</p>
<p>5、https://zhuanlan.zhihu.com/p/53506221</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
        <category>Python搭建简易框架笔记</category>
      </categories>
      <tags>
        <tag>Framework</tag>
      </tags>
  </entry>
  <entry>
    <title>奇妙应用——字符串比较中广义邻居的应用</title>
    <url>/2022/02/08/4ccc50ba5a4e/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-064.-神奇的字典"><a href="https://leetcode-cn.com/problems/US1pGT/">剑指 Offer II 064. 神奇的字典</a></h4>
<p>​ 设计一个使用单词列表进行初始化的数据结构，单词列表中的单词 互不相同 。 如果给出一个单词，请判定能否只将这个单词中一个字母换成另一个字母，使得所形成的新单词存在于已构建的神奇字典中。</p>
<p>实现 MagicDictionary 类：</p>
<ul>
<li>MagicDictionary() 初始化对象</li>
<li>void buildDict(String[] dictionary) 使用字符串数组 dictionary 设定该数据结构，dictionary 中的字符串互不相同</li>
<li>bool search(String searchWord) 给定一个字符串 searchWord ，判定能否只将字符串中 一个 字母换成另一个字母，使得所形成的新字符串能够与字典中的任一字符串匹配。如果可以，返回 true ；否则，返回 false 。</li>
</ul>
<p>示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入</span><br><span class="line">inputs = [&quot;MagicDictionary&quot;, &quot;buildDict&quot;, &quot;search&quot;, &quot;search&quot;, &quot;search&quot;, &quot;search&quot;]</span><br><span class="line">inputs = [[], [[&quot;hello&quot;, &quot;leetcode&quot;]], [&quot;hello&quot;], [&quot;hhllo&quot;], [&quot;hell&quot;], [&quot;leetcoded&quot;]]</span><br><span class="line">输出</span><br><span class="line">[null, null, false, true, false, false]</span><br><span class="line"></span><br><span class="line">解释</span><br><span class="line">MagicDictionary magicDictionary = new MagicDictionary();</span><br><span class="line">magicDictionary.buildDict([&quot;hello&quot;, &quot;leetcode&quot;]);</span><br><span class="line">magicDictionary.search(&quot;hello&quot;); // 返回 False</span><br><span class="line">magicDictionary.search(&quot;hhllo&quot;); // 将第二个 &#x27;h&#x27; 替换为 &#x27;e&#x27; 可以匹配 &quot;hello&quot; ，所以返回 True</span><br><span class="line">magicDictionary.search(&quot;hell&quot;); // 返回 False</span><br><span class="line">magicDictionary.search(&quot;leetcoded&quot;); // 返回 False</span><br></pre></td></tr></table></figure>
<p>提示：</p>
<pre><code>1 &lt;= dictionary.length &lt;= 100
1 &lt;= dictionary[i].length &lt;= 100
dictionary[i] 仅由小写英文字母组成
dictionary 中的所有字符串 互不相同
1 &lt;= searchWord.length &lt;= 100
searchWord 仅由小写英文字母组成
buildDict 仅在 search 之前调用一次
最多调用 100 次 search</code></pre>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 一开始看到这道题，想到前缀树，但是经过尝试，发现前缀树没法使用，判定两个字符串只差1个字符，非常非常绕，并且当如下情况出现时，会发生错误：</p>
<p>​ <strong>例如：字典中存在hello,hallo。我们查找hello，我的前缀树算法因为找到了完全匹配的hello，就会返回false，而忽略了字典中存在的hallo。</strong></p>
<p>​ 然后，我们发现，如果想要采用先前的方法，用一个vector(26)来统计字符串字符出现的个数，然后利用相差1个字符来进行判定也不可行，当如下情况出现时，会发生错误：</p>
<p>​ <strong>例如：字典中存在hello,我们查找llohh，在vector统计中，两者确实只在h的个数上有不同，但是问题是两个单词顺序完全不一样，vector统计会将单词的顺序信息丢失。</strong></p>
<p><strong>故而：这题需要一个全新的概念叫做 广义邻居：</strong></p>
<p><strong>思路引用</strong>：https://leetcode-cn.com/problems/US1pGT/solution/offerii064shen-qi-de-zi-dian-by-logilong-4hmn/</p>
<p><strong>广义邻居：</strong>也就是一字只差的单词，比如说【*pple, a*ple, ap*le, app*e, appl*】，这几个单词互为广义邻居。</p>
<p>然后，我们这道题就可以按照如下的步骤进行求解：</p>
<ul>
<li><p>初始化字典： 生成字典中所有单词的广义邻居，例如 apple 就生成上述五个广义邻居。将所有字典词的广义邻居都以 <code>&lt;广义邻居，个数&gt;</code> 保存到 <code>HashMap</code>。</p></li>
<li><p>查找：当我们需要在字典中查找是否有一个单词和 word 只有一字只差，那不就是查找第二步中 HashMap 中是否存在 word 的广义邻居吗？这时候我们就只要生成 word 所有的广义邻居，然后在 HashMap 中查找是否存在其中的一个就可以了。</p></li>
</ul>
<p><strong>关键疑问</strong>：为什么需要记录所有字典词的广义邻居数量？</p>
<p>​ <strong>这是为了防止字典中出现和查找词一摸一样的词，如果出现上述情况，则会找到符合条件的广义邻居，但是其实并不是邻居，而是它自己！</strong></p>
<p>所以，刚才的查找不是很完整，<strong>完整正确的查找应当如下</strong>：</p>
<p>​ 生成待查找词 word 的所有广义邻居。每个广义邻居都到 HashMap 中查找出现的次数，根据出现次数分为3种情况。</p>
<ul>
<li>广义邻居数 &gt; 1 ，则说明字典中肯定存在两个不同的字符，这两个字符互为广义邻居，且和查找字符也是广义邻居，由于字典中的单词是不重复的，所以此时满足条件。</li>
<li>广义邻居数 == 1 , 说明字典中可能存在一个广义邻居，也可能存在查找字符串本身，如果是广义邻居就满足条件，如果是查找字符串本身的话就不符合条件。</li>
<li>广义邻居数 == 0 , 说明不存在广义邻居，则继续遍历下一个广义邻居。</li>
</ul>
<h5 id="代码如下"><strong>代码如下</strong>：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MagicDictionary</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    unordered_map&lt;string,<span class="keyword">int</span>&gt; neighbors;</span><br><span class="line">    unordered_map&lt;string,<span class="keyword">int</span>&gt; dictionary;</span><br><span class="line">    <span class="comment">/** Initialize your data structure here. */</span></span><br><span class="line">    <span class="built_in">MagicDictionary</span>() &#123;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">generateNeighbors</span><span class="params">(string word)</span></span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;word.<span class="built_in">length</span>();i++)&#123;</span><br><span class="line">            string new_word = word;</span><br><span class="line">            new_word[i] = <span class="string">&#x27;*&#x27;</span>;</span><br><span class="line">            <span class="keyword">if</span>(neighbors.<span class="built_in">find</span>(new_word) == neighbors.<span class="built_in">end</span>()) neighbors[new_word] = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> neighbors[new_word]++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">buildDict</span><span class="params">(vector&lt;string&gt; dictionary)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;dictionary.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="built_in">generateNeighbors</span>(dictionary[i]);</span><br><span class="line">            <span class="keyword">this</span>-&gt;dictionary[dictionary[i]] = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">search</span><span class="params">(string searchWord)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">bool</span> res = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;searchWord.<span class="built_in">length</span>();i++)&#123;</span><br><span class="line">            string new_word = searchWord;</span><br><span class="line">            new_word[i] = <span class="string">&#x27;*&#x27;</span>;</span><br><span class="line">            <span class="keyword">if</span>(neighbors.<span class="built_in">find</span>(new_word) == neighbors.<span class="built_in">end</span>())&#123;&#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(neighbors[new_word] == <span class="number">1</span>)&#123;</span><br><span class="line">                <span class="comment">//可能存在广义邻居，需要看searchWord在不在dictionary种</span></span><br><span class="line">                <span class="keyword">if</span>(dictionary.<span class="built_in">find</span>(searchWord) == dictionary.<span class="built_in">end</span>())&#123;</span><br><span class="line">                    res = <span class="literal">true</span>;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(neighbors[new_word] &gt; <span class="number">1</span>)&#123;</span><br><span class="line">                res = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Your MagicDictionary object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"> * MagicDictionary* obj = new MagicDictionary();</span></span><br><span class="line"><span class="comment"> * obj-&gt;buildDict(dictionary);</span></span><br><span class="line"><span class="comment"> * bool param_2 = obj-&gt;search(searchWord);</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>字符串系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title>C++ 优先队列 PriorityQueue 容器使用</title>
    <url>/2022/02/08/945d3241b7fc/</url>
    <content><![CDATA[<p><strong>定义</strong>：<code>priority_queue&lt;Type, Container, Functional&gt;</code></p>
<p>​ Type 就是数据类型，Container 就是容器类型（Container必须是用数组实现的容器，比如vector,deque等等，但不能用 list。STL里面默认用的是vector），Functional 就是比较的方式，当需要用自定义的数据类型时才需要传入这三个参数，使用基本数据类型时，只需要传入数据类型，<strong>默认是大顶堆</strong></p>
<ul>
<li>1、一般情况：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//升序队列</span></span><br><span class="line">priority_queue &lt;<span class="keyword">int</span>,vector&lt;<span class="keyword">int</span>&gt;,greater&lt;<span class="keyword">int</span>&gt; &gt; q;</span><br><span class="line"><span class="comment">//降序队列</span></span><br><span class="line">priority_queue &lt;<span class="keyword">int</span>,vector&lt;<span class="keyword">int</span>&gt;,less&lt;<span class="keyword">int</span>&gt; &gt;q;</span><br></pre></td></tr></table></figure>
<ul>
<li>2、如果内部的元素是Pair的话，其也自带了比较函数,比较规则是先比较第一个元素，第一个相等比较第二个。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">priority_queue&lt;pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; &gt; a;</span><br><span class="line"><span class="function">pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; <span class="title">b</span><span class="params">(<span class="number">1</span>, <span class="number">2</span>)</span></span>;</span><br><span class="line"><span class="function">pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; <span class="title">c</span><span class="params">(<span class="number">1</span>, <span class="number">3</span>)</span></span>;</span><br><span class="line"><span class="function">pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; <span class="title">d</span><span class="params">(<span class="number">2</span>, <span class="number">5</span>)</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>3、内部为自定义元素：一个是通过重载自定义struct的 &lt; 规则</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">tmp1</span> //运算符重载&lt;</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> x;</span><br><span class="line">    <span class="built_in">tmp1</span>(<span class="keyword">int</span> a) &#123;x = a;&#125;</span><br><span class="line">    <span class="keyword">bool</span> <span class="keyword">operator</span>&lt;(<span class="keyword">const</span> tmp1&amp; a) <span class="keyword">const</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> x &lt; a.x; <span class="comment">//大顶堆</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">tmp1 <span class="title">a</span><span class="params">(<span class="number">1</span>)</span></span>;</span><br><span class="line"><span class="function">tmp1 <span class="title">b</span><span class="params">(<span class="number">2</span>)</span></span>;</span><br><span class="line"><span class="function">tmp1 <span class="title">c</span><span class="params">(<span class="number">3</span>)</span></span>;</span><br><span class="line">priority_queue&lt;tmp1&gt; d;</span><br></pre></td></tr></table></figure>
<ul>
<li>另一个方法是通过定义一个比较类：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> value;</span><br><span class="line">    <span class="keyword">int</span> priority;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 优先队列存放 Node* 时优先级的比较方法 */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Compare_Node_Pointer</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">/* Node::priority 大的优先 */</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">operator</span> <span class="params">()</span> <span class="params">(Node* &amp;a, Node* &amp;b)</span> <span class="keyword">const</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a-&gt;priority &lt; b-&gt;priority;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 用法 */</span></span><br><span class="line">std::priority_queue&lt;Node*, std::vector&lt;Node*&gt;, Compare_Node_Pointer&gt; my_queue;</span><br></pre></td></tr></table></figure>
<h4 id="剑指-offer-ii-061.-和最小的-k-个数对"><a href="https://leetcode-cn.com/problems/qn8gGX/">剑指 Offer II 061. 和最小的 k 个数对</a></h4>
<p><strong>题目描述</strong>：</p>
<p>​ 给定两个以升序排列的整数数组 nums1 和 nums2 , 以及一个整数 k 。定义一对值 (u,v)，其中第一个元素来自 nums1，第二个元素来自 nums2 。请找到和最小的 k 个数对 (u1,v1), (u2,v2) ... (uk,vk) 。</p>
<p><strong>解题思路</strong>：</p>
<p>​ 遍历nums1 和 nums2 ，然后将所有的组合push进入自定义的优先队列中，然后按照顺序，出队前k个元素或将队列出空即可。但是这样子的话，时间复杂度会达到O(mn)，也就是nums1和nums2的长度的乘积。其实，因为提供的数组是有序序列，所以我们只需要进队列 nums1的前k个和nums2的前k个的组合，也就是O(K^2)即可。</p>
<p><strong>解题代码</strong>：（熟悉priority queue的操作）</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> v1;</span><br><span class="line">    <span class="keyword">int</span> v2;</span><br><span class="line">    <span class="built_in">Node</span>(<span class="keyword">int</span> v1,<span class="keyword">int</span> v2)&#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;v1 = v1;</span><br><span class="line">        <span class="keyword">this</span>-&gt;v2 = v2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NodeCompare</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">operator</span><span class="params">()</span> <span class="params">(Node* &amp;a,Node* &amp;b)</span> <span class="keyword">const</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a-&gt;v1 + a-&gt;v2 &gt; b-&gt;v1 + b-&gt;v2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">kSmallestPairs</span>(vector&lt;<span class="keyword">int</span>&gt;&amp; nums1, vector&lt;<span class="keyword">int</span>&gt;&amp; nums2, <span class="keyword">int</span> k) &#123;</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">        priority_queue&lt;Node*,vector&lt;Node*&gt;,NodeCompare&gt; q;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;k &amp;&amp; i&lt;nums1.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;k &amp;&amp; j&lt;nums2.<span class="built_in">size</span>();j++)&#123;</span><br><span class="line">                Node* tmp = <span class="keyword">new</span> <span class="built_in">Node</span>(nums1[i],nums2[j]);</span><br><span class="line">                q.<span class="built_in">push</span>(tmp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(k-- &amp;&amp; q.<span class="built_in">size</span>()!=<span class="number">0</span>)&#123;</span><br><span class="line">            Node* tmp = q.<span class="built_in">top</span>();</span><br><span class="line">            res.<span class="built_in">push_back</span>(&#123;tmp-&gt;v1,tmp-&gt;v2&#125;);</span><br><span class="line">            q.<span class="built_in">pop</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>堆栈系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>priority queue</tag>
      </tags>
  </entry>
  <entry>
    <title>奇妙应用——&quot;动态数据流+第k大的数值&quot;相关问题优化</title>
    <url>/2022/02/08/42903a1f937a/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-059.-数据流的第-k-大数值"><a href="https://leetcode-cn.com/problems/jBjn9C/">剑指 Offer II 059. 数据流的第 K 大数值</a></h4>
<h5 id="题目描述"><strong>题目描述</strong>：</h5>
<p>​ 设计一个找到数据流中第 k 大元素的类（class）。注意是排序后的第 k 大元素，不是第 k 个不同的元素。</p>
<p>​ 请实现 KthLargest 类：</p>
<pre><code>KthLargest(int k, int[] nums) 使用整数 k 和整数流 nums 初始化对象。
int add(int val) 将 val 插入数据流 nums 后，返回当前数据流中第 k 大的元素。</code></pre>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 我对于这类没有设计类实现的题目，数据结构的敏感度不够高，基本上想起来都只能用最暴力的方法去解决。此题目，我一开始是想要在内部维护一个Vector，但是我发现，维护有序向量的成本太高了，虽然通过了测试点，但是时间复杂度等方面可以优化的内容实在太多了。</p>
<h5 id="优化思路"><strong>优化思路</strong>：</h5>
<p>​ 比较重要重要的信息点是 <strong>动态插入</strong>、<strong>第K大</strong>，这两个关键信息，应当能够导向一个动态的数据结构，也就是优先队列——堆。可以维护一个优先队列（最小堆），然后在其内维护最大的K个元素。这样的话，每次插入完需要返回第K大的元素的时候，直接返回堆顶的元素（堆顶的元素是堆中最小的那个元素，但是是所有数组中第K大的那个元素）即可。</p>
<p>​ 故而，在单次插入的操作中，我们首先将元素 val 加入到优先队列中。如果此时优先队列的大小大于 k，我们需要将优先队列的队头元素弹出，以保证优先队列的大小为 k。</p>
<h5 id="解题代码">解题代码：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KthLargest</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    priority_queue&lt;<span class="keyword">int</span>, vector&lt;<span class="keyword">int</span>&gt;, greater&lt;<span class="keyword">int</span>&gt;&gt; q;</span><br><span class="line">    <span class="keyword">int</span> k;</span><br><span class="line">    <span class="built_in">KthLargest</span>(<span class="keyword">int</span> k, vector&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;k = k;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">             <span class="built_in">add</span>(nums[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">        q.<span class="built_in">push</span>(val);</span><br><span class="line">        <span class="keyword">if</span> (q.<span class="built_in">size</span>() &gt; k) &#123;</span><br><span class="line">            q.<span class="built_in">pop</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> q.<span class="built_in">top</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​</p>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>堆栈系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>priority queue</tag>
      </tags>
  </entry>
  <entry>
    <title>奇妙应用——日程表类的设计优化思想</title>
    <url>/2022/02/08/e026aa44c5a7/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-058.-日程表"><a href="https://leetcode-cn.com/problems/fi9suh/">剑指 Offer II 058. 日程表</a></h4>
<h5 id="题目描述"><strong>题目描述</strong>：</h5>
<p>​ 请实现一个 MyCalendar 类来存放你的日程安排。如果要添加的时间内没有其他安排，则可以存储这个新的日程安排。</p>
<p>​ MyCalendar 有一个 book(int start, int end)方法。它意味着在 start 到 end 时间内增加一个日程安排，注意，这里的时间是半开区间，即 [start, end), 实数 x 的范围为， start &lt;= x &lt; end。</p>
<p>​ 当两个日程安排有一些时间上的交叉时（例如两个日程安排都在同一时间内），就会产生重复预订。</p>
<p>​ 每次调用 MyCalendar.book方法时，如果可以将日程安排成功添加到日历中而不会导致重复预订，返回 true。否则，返回 false 并且不要将该日程安排添加到日历中。</p>
<p>​ 请按照以下步骤调用 MyCalendar 类: MyCalendar cal = new MyCalendar(); MyCalendar.book(start, end)</p>
<p>提示：</p>
<pre><code>每个测试用例，调用 MyCalendar.book 函数最多不超过 1000次。
0 &lt;= start &lt; end &lt;= 109</code></pre>
<h5 id="我的解题思路"><strong>我的解题思路</strong>：</h5>
<pre><code>一开始看到每个测试用例，调用.book函数不超过1000次，我就使用了较为暴力的算法，使用成员变量记录先前所有的日程，然后新来一个日程以后，去判断和先前的有没有区间重复，代码如下：</code></pre>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCalendar</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; calendar;</span><br><span class="line">    <span class="built_in">MyCalendar</span>() &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">checkIsCollision</span><span class="params">(<span class="keyword">int</span> start,<span class="keyword">int</span> end)</span></span>&#123;</span><br><span class="line">        <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;calendar.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> tmp_start = calendar[i][<span class="number">0</span>];</span><br><span class="line">            <span class="keyword">int</span> tmp_end = calendar[i][<span class="number">1</span>];</span><br><span class="line">            <span class="keyword">if</span>(!(start &gt;= tmp_end || end &lt;= tmp_start))&#123;</span><br><span class="line">                flag = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">book</span><span class="params">(<span class="keyword">int</span> start, <span class="keyword">int</span> end)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(!<span class="built_in">checkIsCollision</span>(start,end))&#123;</span><br><span class="line">            calendar.<span class="built_in">push_back</span>(&#123;start,end&#125;);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Your MyCalendar object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"> * MyCalendar* obj = new MyCalendar();</span></span><br><span class="line"><span class="comment"> * bool param_1 = obj-&gt;book(start,end);</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>
<h5 id="优化思路"><strong>优化思路</strong>：</h5>
<pre><code>按照上述方法做的话，其实是比较浪费时间的，因为每新来一个日程，我们就需要去和先前所有的日程比较，从理论上来说，大部分的比较都是无效比较，我们其实只需要和最近的两个区间进行比较就可以了，因为已知先前的日程都是不重叠的，所以我们每次只需要查询最近的时间段的前后，看看起止时间有无冲突即可。</code></pre>
<p>​ 此时，我们会想，那我们不是需要维护日程vector，让它变得有序就可以了。思路没错！但是我们可以不用vector了，直接使用map。map是有序的key-value键值对，底层使用红黑树建立，更加方便而且高效。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyCalendar</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    map&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; calendar;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">MyCalendar</span>() &#123;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">book</span><span class="params">(<span class="keyword">int</span> start, <span class="keyword">int</span> end)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">auto</span> iter = calendar.<span class="built_in">lower_bound</span>(start);</span><br><span class="line">        <span class="comment">//第一个大于等于插入元素的时间段。这个时间段的起始时间不能小于插入时间的终止时间</span></span><br><span class="line">        <span class="keyword">if</span>(iter != calendar.<span class="built_in">end</span>() &amp;&amp; iter-&gt;first &lt; end)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="comment">//迭代器往前走一步就是小于等于当前时间段的最大时间段。这个时间段的终止时间不能大于插入的起始时间</span></span><br><span class="line">        <span class="keyword">if</span>(iter != calendar.<span class="built_in">begin</span>() &amp;&amp; (--iter)-&gt;second &gt; start)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        calendar[start] = end;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>参考：https://leetcode-cn.com/problems/fi9suh/solution/c-hong-hei-shu-map058-ri-cheng-biao-by-d-f7q9/</p>
<p>附录：</p>
<ul>
<li>map中的lower_bound和upper_bound函数：
<ul>
<li>map::lower_bound(key): 返回map中第一个大于或等于key的迭代器指针</li>
<li>map::upper_bound(key): 返回map中第一个大于key的迭代器指针</li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>容器设计系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>red black tree</tag>
      </tags>
  </entry>
  <entry>
    <title>奇妙应用——求解直方图最大矩形面积 &amp;&amp; 矩阵中最大的矩形求解</title>
    <url>/2022/02/08/faff2c35214a/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-039.-直方图最大矩形面积"><a href="https://leetcode-cn.com/problems/0ynMMM/">剑指 Offer II 039. 直方图最大矩形面积</a></h4>
<h5 id="题目描述"><strong>题目描述</strong>：</h5>
<pre><code>给定非负整数数组 `heights` ，数组中的数字用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 `1` 。求在该柱状图中，能够勾勒出来的矩形的最大面积。</code></pre>
<p><strong>示例1</strong>：<img src="https://assets.leetcode.com/uploads/2021/01/04/histogram.jpg" alt="img" /></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">输入：heights = [<span class="number">2</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">输出：<span class="number">10</span></span><br><span class="line">解释：最大的矩形为图中红色区域，面积为 <span class="number">10</span></span><br></pre></td></tr></table></figure>
<p>题解参考：https://leetcode-cn.com/problems/0ynMMM/solution/jian-zhi-offer-2-mian-shi-ti-39-shu-zhon-qzaw/</p>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<pre><code>本题如果采用暴搜的方法，O(n^2)复杂度，是比较简单易懂的，但是时间耗费太长，会超时。所以此篇博客要记录的是一个叫做 **“单调栈”**的解决方案：</code></pre>
<ul>
<li><p><strong>基本思想</strong>：<strong>保证存在栈中的柱子的高度是递增的。</strong>基础操作为，从左往右扫描数组内的柱子高度，若当前柱高大于栈顶柱高，那么该柱子下标入栈；反之，将栈顶柱子出栈，并计算栈顶的柱子高度为顶高的最高矩阵面积，直至可入栈。</p></li>
<li><p><strong>核心问题</strong>：如何确定以栈顶柱子高为顶的最大矩阵面积呢？</p>
<ul>
<li>该矩阵的宽度一定是，<strong>从栈顶柱子的两边出发直到遇到比该柱高矮的柱子所夹成的宽度</strong>。因为单调栈中保存的柱高是递增的，所以<strong>栈中位于栈顶柱子前面的柱子一定比栈顶柱子矮，同样当前扫描到的柱子也矮于位于栈顶的柱子</strong>，所以顶柱子为顶的最高矩阵的宽度就确定了，那么面积也就确定了。</li>
</ul></li>
<li><p><strong>操作示例</strong>：下面以 [2, 1, 5, 6, 2, 3] 为例说明，过程如图所示</p>
<ul>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/1629450891-DTWpaG-image.png" /></li>
<li>可以发现，最后栈中除了为了处理方便而加入的初始化的 -1 以外，还有 1, 4, 5 三个元素，说明以 1, 2, 3 柱高为顶的最大矩阵还未计算。这时候只要多想一步，它们未被计算是因为还未出现比它们矮的柱子。若假设最后再加入一个高度为 0 的柱高，那么栈中除了 -1 以外，所有的元素都会出栈，那么所有的柱子均被计算，计算完毕，继续的过程如下</li>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/1629451413-pOKglw-image.png" /></li>
</ul></li>
<li><p><strong>解题代码</strong>：</p>
<ul>
<li>以下代码是理解了上述所说以后书写的，和上述所说的细节部分有所不同，它是先往栈里面push了一个-1，保证栈不会空。而我没有这么干，我是在pop完了以后，在计算宽度的时候，会判断栈空了没有，如果空了则 new_top_idx = -1 ，如果没空就是 s.top();</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">largestRectangleArea</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; heights)</span> </span>&#123;</span><br><span class="line">        stack&lt;<span class="keyword">int</span>&gt; s;</span><br><span class="line">        heights.<span class="built_in">push_back</span>(<span class="number">0</span>);  <span class="comment">//先在最后加一个高度为0的柱子，方便后续操作</span></span><br><span class="line">        s.<span class="built_in">push</span>(<span class="number">0</span>); <span class="comment">//先把第一个元素push进去</span></span><br><span class="line">        <span class="keyword">int</span> maxValue = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;heights.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> top_idx = s.<span class="built_in">top</span>();</span><br><span class="line">            <span class="keyword">while</span>(heights[i] &lt; heights[top_idx])&#123;</span><br><span class="line">                s.<span class="built_in">pop</span>();</span><br><span class="line">                <span class="keyword">int</span> new_top_idx = s.<span class="built_in">empty</span>() ? <span class="number">-1</span> : s.<span class="built_in">top</span>();</span><br><span class="line">                <span class="comment">//计算pop出去的这个元素，maxValue</span></span><br><span class="line">                maxValue = <span class="built_in">max</span>(maxValue,heights[top_idx] * (i - new_top_idx - <span class="number">1</span>));</span><br><span class="line">                <span class="keyword">if</span>(s.<span class="built_in">empty</span>()) <span class="keyword">break</span>;</span><br><span class="line">                top_idx = s.<span class="built_in">top</span>();</span><br><span class="line">            &#125;</span><br><span class="line">            s.<span class="built_in">push</span>(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="剑指-offer-ii-040.-矩阵中最大的矩形"><a href="https://leetcode-cn.com/problems/PLYXKQ/">剑指 Offer II 040. 矩阵中最大的矩形</a></h4>
<h5 id="题目描述-1"><strong>题目描述</strong>：</h5>
<p>给定一个由 0 和 1 组成的矩阵 matrix ，找出只包含 1 的最大矩形，并返回其面积。</p>
<p>注意：此题 matrix 输入格式为一维 01 字符串数组。</p>
<p><strong>示例</strong>：<img src="https://assets.leetcode.com/uploads/2020/09/14/maximal.jpg" alt="img" /></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">输入：matrix = [<span class="string">&quot;10100&quot;</span>,<span class="string">&quot;10111&quot;</span>,<span class="string">&quot;11111&quot;</span>,<span class="string">&quot;10010&quot;</span>]</span><br><span class="line">输出：<span class="number">6</span></span><br><span class="line">解释：最大矩形如上图所示。</span><br></pre></td></tr></table></figure>
<h5 id="解题思路-1"><strong>解题思路</strong>：</h5>
<p>​ 本题可以用结合上一题的思路进行求解：</p>
<p>​ <strong>我们循环每一行，将每一行都看作是上一题中的一系列直方图。然后，某行某位置的高度，如果该位置是1，那么它的高度是上一行的该对应位置的直方图的高度+1.如果该位置是0，则该位置的直方图高度就直接清0.</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//即利用一个数组rectangular来记录直方图高度</span></span><br><span class="line"><span class="comment">//遍历每一行每一个位置，更新rectangular中的数值</span></span><br><span class="line"><span class="comment">//然后调用上一题中的方法，进行求解</span></span><br><span class="line"><span class="keyword">if</span>(nums[j] == <span class="string">&#x27;1&#x27;</span>)&#123;</span><br><span class="line"> 	rectangular[j]++;</span><br><span class="line"> &#125;<span class="keyword">else</span>&#123;</span><br><span class="line"> 	rectangular[j]=<span class="number">0</span>;<span class="comment">//这一行的某个字符为“0”，那就矩形高度清0</span></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p><strong>解题代码</strong>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">largestRectangleArea</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; heights)</span> </span>&#123;</span><br><span class="line">        stack&lt;<span class="keyword">int</span>&gt; s;</span><br><span class="line">        heights.<span class="built_in">push_back</span>(<span class="number">0</span>);  <span class="comment">//先在最后加一个高度为0的柱子，方便后续操作</span></span><br><span class="line">        s.<span class="built_in">push</span>(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">int</span> maxValue = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;heights.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> top_idx = s.<span class="built_in">top</span>();</span><br><span class="line">            <span class="keyword">while</span>(heights[i] &lt; heights[top_idx])&#123;</span><br><span class="line">                s.<span class="built_in">pop</span>();</span><br><span class="line">                <span class="keyword">int</span> new_top_idx = s.<span class="built_in">empty</span>() ? <span class="number">-1</span> : s.<span class="built_in">top</span>();</span><br><span class="line">                <span class="comment">//计算pop出去的这个元素，maxValue</span></span><br><span class="line">                maxValue = <span class="built_in">max</span>(maxValue,heights[top_idx] * (i - new_top_idx - <span class="number">1</span>));</span><br><span class="line">                <span class="keyword">if</span>(s.<span class="built_in">empty</span>()) <span class="keyword">break</span>;</span><br><span class="line">                top_idx = s.<span class="built_in">top</span>();</span><br><span class="line">            &#125;</span><br><span class="line">            s.<span class="built_in">push</span>(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxValue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maximalRectangle</span><span class="params">(vector&lt;string&gt;&amp; matrix)</span> </span>&#123;</span><br><span class="line">        vector&lt;<span class="keyword">int</span>&gt; rectangular;</span><br><span class="line">        <span class="keyword">int</span> maxValue = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;matrix.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            string row = matrix[i];</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;row.<span class="built_in">length</span>();j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(i==<span class="number">0</span>) rectangular.<span class="built_in">push_back</span>(row[j] - <span class="string">&#x27;0&#x27;</span>);</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(row[j] == <span class="string">&#x27;1&#x27;</span>)&#123;</span><br><span class="line">                        rectangular[j]++;</span><br><span class="line">                    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                        rectangular[j]=<span class="number">0</span>;<span class="comment">//这一行的某个字符为“0”，那就矩形高度清0</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//更新好了以后，计算改行的maxValue</span></span><br><span class="line">            maxValue = <span class="built_in">max</span>(maxValue,<span class="built_in">largestRectangleArea</span>(rectangular));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxValue;</span><br><span class="line">       </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>堆栈系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>stack</tag>
      </tags>
  </entry>
  <entry>
    <title>树系列——二叉树的序列化与反序列化（如何更好的用线性方式记录二叉树的结构）</title>
    <url>/2022/02/07/5f449aa44840/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-048.-序列化与反序列化二叉树"><a href="https://leetcode-cn.com/problems/h54YBf/">剑指 Offer II 048. 序列化与反序列化二叉树</a></h4>
<h5 id="题目描述"><strong>题目描述</strong>：</h5>
<p>​ 序列化是将一个数据结构或者对象转换为连续的比特位的操作，进而可以将转换后的数据存储在一个文件或者内存中，同时也可以通过网络传输到另一个计算机环境，采取相反方式重构得到原数据。</p>
<p>​ 请设计一个算法来实现二叉树的序列化与反序列化。这里不限定你的序列 / 反序列化算法执行逻辑，只需要保证一个二叉树可以被序列化为一个字符串并且将这个字符串反序列化为原始的树结构。</p>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 我们都很清楚，<strong>一个前序序列（后序/层序序列）+中序序列可以确定恢复一颗二叉树结构。</strong>在这个题目里的话，我一开始的思路是记录前序+ 中序序列，将它们变成字符串，然后反序列化的时候，再通过前序和中序序列重构即可。思路整体而言也较为清晰，但是当我写完所有代码的时候，发现了一个令人窒息的问题：</p>
<p>​ <strong>这个题目中树节点的值是可能重复的</strong>，这就会导致如果只记录节点的值，树的重构是会出问题的。如果，需要克服这个问题，我们还要给每个节点加上index，并且利用一个hash表记录节点index和值的对应关系。这是比较麻烦的。</p>
<p>​ 此Blog就是为了记录另一种解题思路：<strong>在特定条件下，我们可以仅凭借树的前序序列就能够确定恢复一颗唯一的二叉树</strong>。</p>
<p>​ <strong>如果想要达到上面的效果，那么我们的前序遍历序列是需要记录为Null的节点的，示例如下</strong>：</p>
<p><img src="https://assets.leetcode.com/uploads/2020/09/15/serdeser.jpg" alt="img" style="zoom:33%;" /></p>
<p>​ 对于上述二叉树，普通的前序序列应当为:</p>
<p>​ <strong>1 2 3 4 5 </strong></p>
<p>​ 而如果我们想要用来恢复树结构，前序序列应当为：</p>
<p>​ <strong>1 2 None None 3 4 None None 5 None None</strong></p>
<p>​ 具体如何操作，以及如何恢复见如下代码：先序遍历和正常的类似，只不过如果碰到了为NULL的节点，我们不是直接return，而是会将其记录入序列中。</p>
<p>​ 在重建操作中，我们将序列存入一个队列中操作较为方便，然后如果碰到None就返回NULL，否则就新建一个节点，利用递归的形式，确定左右子树节点，然后返回新建节点。最终就能完成一整颗树的重建。这种方法从时间复杂度和代码复杂度上都优于前一种通过两个序列进行重建的方法。但是局限就是，前序遍历得到的序列需要是你自己形成的“特殊”的前序遍历序列。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Codec</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">preOrder</span><span class="params">(TreeNode* root,string &amp;res)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="literal">NULL</span>)&#123;</span><br><span class="line">            res += <span class="string">&quot;None,&quot;</span>;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        res += <span class="built_in">to_string</span>(root-&gt;val) + <span class="string">&quot;,&quot;</span>;</span><br><span class="line">        <span class="built_in">preOrder</span>(root-&gt;left,res);</span><br><span class="line">        <span class="built_in">preOrder</span>(root-&gt;right,res);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Encodes a tree to a single string.</span></span><br><span class="line">    <span class="function">string <span class="title">serialize</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">        string str = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="comment">//需要一棵树的前序(P) + 中序遍历序列(I)才能够进行重构</span></span><br><span class="line">        <span class="built_in">preOrder</span>(root,str);</span><br><span class="line">        <span class="keyword">return</span> str;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">TreeNode* <span class="title">preOrderReverse</span><span class="params">(queue&lt;string&gt; &amp;q)</span></span>&#123;</span><br><span class="line">        string tmp = q.<span class="built_in">front</span>();</span><br><span class="line">        q.<span class="built_in">pop</span>();</span><br><span class="line">        <span class="keyword">if</span>(tmp == <span class="string">&quot;None&quot;</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        TreeNode* root = <span class="keyword">new</span> <span class="built_in">TreeNode</span>(<span class="built_in">stoi</span>(tmp));</span><br><span class="line">        root-&gt;left = <span class="built_in">preOrderReverse</span>(q);</span><br><span class="line">        root-&gt;right =<span class="built_in">preOrderReverse</span>(q);</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Decodes your encoded data to tree.</span></span><br><span class="line">    <span class="function">TreeNode* <span class="title">deserialize</span><span class="params">(string data)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 先把string转成序列的形式</span></span><br><span class="line">        queue&lt;string&gt; q;</span><br><span class="line">        <span class="keyword">while</span>(i&lt;data.<span class="built_in">length</span>()<span class="number">-1</span>)&#123;</span><br><span class="line">            <span class="comment">// i = 0 是第一个数字的起始位置，i = data.lenth()-1 是 I前面那个逗号的位置</span></span><br><span class="line">            string tmp_str = <span class="string">&quot;&quot;</span>;</span><br><span class="line">            <span class="keyword">while</span>(data[i]!=<span class="string">&#x27;,&#x27;</span>)&#123;</span><br><span class="line">                tmp_str += data[i];</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line">            i++;</span><br><span class="line">            q.<span class="built_in">push</span>(tmp_str);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//然后再通过序列重建树</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">preOrderReverse</span>(q);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>树系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>tree</tag>
      </tags>
  </entry>
  <entry>
    <title>树系列——当二叉树需要以层为单位计算时层序遍历的优化版本</title>
    <url>/2022/02/06/36f0ee63db4b/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-045.-二叉树最底层最左边的值"><a href="https://leetcode-cn.com/problems/LwUNpT/">剑指 Offer II 045. 二叉树最底层最左边的值</a></h4>
<h5 id="题目描述"><strong>题目描述</strong>：</h5>
<p>​ 给定一个二叉树的 <strong>根节点</strong> <code>root</code>，请找出该二叉树的 <strong>最底层 最左边</strong> 节点的值。假设二叉树中至少有一个节点。具体信息请点击链接查看。</p>
<h5 id="题目解答"><strong>题目解答</strong>：</h5>
<p>​ 思路是很简单的，一个层序遍历，然后最后一层层序遍历的第一个值返回即可，但是整个过程中还是有很多步骤可以优化的。以最简单的思想来讲，我们需要先来一遍层序遍历，确定总共有多少层，然后再来一遍层序遍历，当知道到最后一层的第一个节点的时候记录返回。但是其实可以只用一次层序遍历完成：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">findBottomLeftValue</span><span class="params">(TreeNode* root)</span> </span>&#123;</span><br><span class="line">        vector&lt;vector&lt;TreeNode*&gt;&gt; v;</span><br><span class="line">        queue&lt;TreeNode*&gt; q;</span><br><span class="line">        q.<span class="built_in">push</span>(root);  </span><br><span class="line">        <span class="keyword">while</span>(!q.<span class="built_in">empty</span>())&#123;</span><br><span class="line">            <span class="keyword">int</span> size = q.<span class="built_in">size</span>();</span><br><span class="line">            vector&lt;TreeNode*&gt; tmp;</span><br><span class="line">            <span class="keyword">while</span>(size--)&#123;          <span class="comment">// 最精妙的在于此</span></span><br><span class="line">                TreeNode* t = q.<span class="built_in">front</span>();</span><br><span class="line">                tmp.<span class="built_in">push_back</span>(t);</span><br><span class="line">                q.<span class="built_in">pop</span>();</span><br><span class="line">                <span class="keyword">if</span>(t-&gt;left) q.<span class="built_in">push</span>(t-&gt;left);</span><br><span class="line">                <span class="keyword">if</span>(t-&gt;right) q.<span class="built_in">push</span>(t-&gt;right);</span><br><span class="line">            &#125;</span><br><span class="line">            v.<span class="built_in">push_back</span>(tmp);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> v[v.<span class="built_in">size</span>()<span class="number">-1</span>][<span class="number">0</span>]-&gt;val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​ 上述层序遍历中，最为精髓的部分就是在while(!q.empty())中，加入了一个while(size--)的循环，而每次在这里面进行循环的，必定是同一层的节点。这一点尝试以后就会发现是正确的，如此一来就大大缩减了整个层序遍历的过程。如果这道题目需要找到每一层的最大值，也就不需要两次遍历了，我们只要在内循环中每次找到一个最大值，就是在每一层里找最大值。</p>
<p>​ 此篇博客就是为了记录这样一个小的Trick。</p>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>树系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>tree</tag>
      </tags>
  </entry>
  <entry>
    <title>容器设计——前缀树容器设计</title>
    <url>/2022/02/05/06a3e97dc7c2/</url>
    <content><![CDATA[<h4 id="剑指-offer-ii-062.-实现前缀树"><a href="https://leetcode-cn.com/problems/QC3q1f/">剑指 Offer II 062. 实现前缀树</a></h4>
<h5 id="题目描述"><strong>题目描述</strong>：</h5>
<p>​ Trie（发音类似 "try"）或者说 前缀树 是一种树形数据结构，用于高效地存储和检索字符串数据集中的键。这一数据结构有相当多的应用情景，例如<strong>自动补完和拼写检查</strong>。****</p>
<p>请你实现 Trie 类：</p>
<pre><code>Trie() 初始化前缀树对象。
void insert(String word) 向前缀树中插入字符串 word 。
boolean search(String word) 如果字符串 word 在前缀树中，返回 true（即，在检索之前已经插入）；否则，返回 false 。
boolean startsWith(String prefix) 如果之前已经插入的字符串 word 的前缀之一为 prefix ，返回 true ；否则，返回 false 。</code></pre>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ Trie，又称前缀树或字典树，是一棵有根树，其每个节点包含以下字段：</p>
<ul>
<li>指向子节点的指针数组 childrens。在本题中，这可以是一个动态的vector，也可以是一个大小定为26的vector，因为本文中的字符限定为小写字母。两者各有好处，动态的vector节省一些空间，静态的vector在查找和插入时节省一些时间，实现起来也较为方便一些。</li>
<li>布尔字段 isEnd，表示该节点是否为字符串的结尾。</li>
</ul>
<p>下面是一张比较清晰的图：非常明了</p>
<figure>
<img src="https://pic.leetcode-cn.com/1632672370-gVXuKM-image.png" alt="image.png" /><figcaption aria-hidden="true">image.png</figcaption>
</figure>
<h5 id="代码实现动态vector版本我写的"><strong>代码实现（动态vector版本，我写的）</strong>：</h5>
<p>​ Search操作和startsWith其实就是差一个判定字符串结尾的操作，所以我将两个函数合并成了一个，用一个形参来控制，使得代码尽量简介。Insert操作其实和Search操作也有大量的重复代码，循环判定都是一致的，就是判定后操作逻辑不太一样，但为了不混在一起，我还是将其分开写了。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_08_15_17_08_168.png" /></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyTreeNode</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">bool</span> isEnd;</span><br><span class="line">    <span class="keyword">char</span> character;</span><br><span class="line">    vector&lt;MyTreeNode*&gt; childrens;</span><br><span class="line">    <span class="built_in">MyTreeNode</span>()&#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;isEnd = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">MyTreeNode</span>(<span class="keyword">char</span> character,<span class="keyword">bool</span> isEnd)&#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;isEnd = isEnd;</span><br><span class="line">        <span class="keyword">this</span>-&gt;character = character;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trie</span> &#123;</span></span><br><span class="line">    MyTreeNode* root;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">/** Initialize your data structure here. */</span></span><br><span class="line">    <span class="built_in">Trie</span>() &#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;root = <span class="keyword">new</span> <span class="built_in">MyTreeNode</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** Inserts a word into the trie. */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(string word)</span> </span>&#123;</span><br><span class="line">        MyTreeNode* r = <span class="keyword">this</span>-&gt;root;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;word.<span class="built_in">length</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">int</span> j;</span><br><span class="line">            <span class="keyword">for</span>(j = <span class="number">0</span>;j&lt; r-&gt;childrens.<span class="built_in">size</span>();j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(r-&gt;childrens[j]-&gt;character == word[i])&#123;</span><br><span class="line">                    flag = <span class="literal">true</span>;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 如果没找到，插入一个新的节点</span></span><br><span class="line">            <span class="keyword">if</span>(!flag)&#123;</span><br><span class="line">                MyTreeNode* c = <span class="keyword">new</span> <span class="built_in">MyTreeNode</span>(word[i],i == word.<span class="built_in">length</span>()<span class="number">-1</span>);</span><br><span class="line">                r-&gt;childrens.<span class="built_in">push_back</span>(c);</span><br><span class="line">                r = c;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="comment">//如果找到了，那么继续下一个字符，</span></span><br><span class="line">                r = r-&gt;childrens[j];</span><br><span class="line">                <span class="keyword">if</span>(i == word.<span class="built_in">length</span>()<span class="number">-1</span>)&#123;  <span class="comment">//如果是最后一个字符，那么</span></span><br><span class="line">                    r-&gt;isEnd = <span class="literal">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** Returns if the word is in the trie. */</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">search</span><span class="params">(string word)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">mySearch</span>(word,<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** Returns if there is any word in the trie that starts with the given prefix. */</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">startsWith</span><span class="params">(string prefix)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">mySearch</span>(prefix,<span class="literal">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">mySearch</span><span class="params">(string word,<span class="keyword">bool</span> includePrefix)</span></span>&#123;</span><br><span class="line">        <span class="keyword">bool</span> res = <span class="literal">true</span>;</span><br><span class="line">        MyTreeNode* r = <span class="keyword">this</span>-&gt;root;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;word.<span class="built_in">length</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">int</span> j;</span><br><span class="line">            <span class="keyword">for</span>(j = <span class="number">0</span>;j&lt; r-&gt;childrens.<span class="built_in">size</span>();j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(r-&gt;childrens[j]-&gt;character == word[i])&#123;</span><br><span class="line">                    flag = <span class="literal">true</span>;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 如果没找到，返回false</span></span><br><span class="line">            <span class="keyword">if</span>(!flag)&#123;</span><br><span class="line">                res = <span class="literal">false</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="comment">//如果找到了，那么继续找下一个字符，</span></span><br><span class="line">                r = r-&gt;childrens[j];</span><br><span class="line">                <span class="keyword">if</span>(i == word.<span class="built_in">length</span>()<span class="number">-1</span> &amp;&amp; !includePrefix)&#123; <span class="comment">//如果是最后一个自符，还需要判定下一个r-&gt;isEnd</span></span><br><span class="line">                    <span class="keyword">if</span>(!r-&gt;isEnd) res = <span class="literal">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="代码实现静态vector版本引自leetcode题解"><strong>代码实现（静态vector版本，引自LeetCode题解）</strong>：</h5>
<p>​ 可以看到，其本身代码简洁程度较高，并且它将Trie直接视为一个节点了，没有建立额外的TreeNode类。运行时间上和我的算法类似，差别不是很大。但是其内存消耗是远大于我的算法的，</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_08_15_17_59_414.png" /></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trie</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    vector&lt;Trie*&gt; children;</span><br><span class="line">    <span class="keyword">bool</span> isEnd;</span><br><span class="line"></span><br><span class="line">    <span class="function">Trie* <span class="title">searchPrefix</span><span class="params">(string prefix)</span> </span>&#123;</span><br><span class="line">        Trie* node = <span class="keyword">this</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">char</span> ch : prefix) &#123;</span><br><span class="line">            ch -= <span class="string">&#x27;a&#x27;</span>;</span><br><span class="line">            <span class="keyword">if</span> (node-&gt;children[ch] == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            node = node-&gt;children[ch];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> node;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Trie</span>() : <span class="built_in">children</span>(<span class="number">26</span>), <span class="built_in">isEnd</span>(<span class="literal">false</span>) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(string word)</span> </span>&#123;</span><br><span class="line">        Trie* node = <span class="keyword">this</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">char</span> ch : word) &#123;</span><br><span class="line">            ch -= <span class="string">&#x27;a&#x27;</span>;</span><br><span class="line">            <span class="keyword">if</span> (node-&gt;children[ch] == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">                node-&gt;children[ch] = <span class="keyword">new</span> <span class="built_in">Trie</span>();</span><br><span class="line">            &#125;</span><br><span class="line">            node = node-&gt;children[ch];</span><br><span class="line">        &#125;</span><br><span class="line">        node-&gt;isEnd = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">search</span><span class="params">(string word)</span> </span>&#123;</span><br><span class="line">        Trie* node = <span class="keyword">this</span>-&gt;<span class="built_in">searchPrefix</span>(word);</span><br><span class="line">        <span class="keyword">return</span> node != <span class="literal">nullptr</span> &amp;&amp; node-&gt;isEnd;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">startsWith</span><span class="params">(string prefix)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>-&gt;<span class="built_in">searchPrefix</span>(prefix) != <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">作者：LeetCode-Solution</span><br><span class="line">链接：https:<span class="comment">//leetcode-cn.com/problems/QC3q1f/solution/shi-xian-qian-zhui-shu-by-leetcode-solut-un50/</span></span><br><span class="line">来源：力扣（LeetCode）</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure>
<p>再记录一道上述数据结构的应用题：</p>
<h4 id="剑指-offer-ii-063.-替换单词"><a href="https://leetcode-cn.com/problems/UhWRSj/">剑指 Offer II 063. 替换单词</a></h4>
<p>​ 在英语中，有一个叫做 词根(root) 的概念，它可以跟着其他一些词组成另一个较长的单词——我们称这个词为 继承词(successor)。例如，词根an，跟随着单词 other(其他)，可以形成新的单词 another(另一个)。</p>
<p>​ 现在，给定一个由许多词根组成的词典和一个句子，需要将句子中的所有继承词用词根替换掉。如果继承词有许多可以形成它的词根，则用最短的词根替换它。需要输出替换之后的句子。</p>
<p>​ 示例 1：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：dictionary = [&quot;cat&quot;,&quot;bat&quot;,&quot;rat&quot;], sentence = &quot;the cattle was rattled by the battery&quot;</span><br><span class="line">输出：&quot;the cat was rat by the bat&quot;</span><br></pre></td></tr></table></figure>
<p><strong>代码（Author: Fantast）</strong>：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_08_18_14_35_668.png" /></p>
<p>​ 主要思路就是实现一个前缀树，其中和上题不一样的是，上题是前缀找单词，这题是单词找前缀，反了反，所以我将startsWith改成了searchRoot函数，大体搜寻逻辑一致。然后再应用该数据结构解题即可。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyTreeNode</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">bool</span> isEnd;</span><br><span class="line">    <span class="keyword">char</span> character;</span><br><span class="line">    vector&lt;MyTreeNode*&gt; childrens;</span><br><span class="line">    <span class="built_in">MyTreeNode</span>()&#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;isEnd = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">MyTreeNode</span>(<span class="keyword">char</span> character,<span class="keyword">bool</span> isEnd)&#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;isEnd = isEnd;</span><br><span class="line">        <span class="keyword">this</span>-&gt;character = character;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trie</span> &#123;</span></span><br><span class="line">    MyTreeNode* root;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">/** Initialize your data structure here. */</span></span><br><span class="line">    <span class="built_in">Trie</span>() &#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;root = <span class="keyword">new</span> <span class="built_in">MyTreeNode</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** Inserts a word into the trie. */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(string word)</span> </span>&#123;</span><br><span class="line">        MyTreeNode* r = <span class="keyword">this</span>-&gt;root;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;word.<span class="built_in">length</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">int</span> j;</span><br><span class="line">            <span class="keyword">for</span>(j = <span class="number">0</span>;j&lt; r-&gt;childrens.<span class="built_in">size</span>();j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(r-&gt;childrens[j]-&gt;character == word[i])&#123;</span><br><span class="line">                    flag = <span class="literal">true</span>;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 如果没找到，插入一个新的节点</span></span><br><span class="line">            <span class="keyword">if</span>(!flag)&#123;</span><br><span class="line">                MyTreeNode* c = <span class="keyword">new</span> <span class="built_in">MyTreeNode</span>(word[i],i == word.<span class="built_in">length</span>()<span class="number">-1</span>);</span><br><span class="line">                r-&gt;childrens.<span class="built_in">push_back</span>(c);</span><br><span class="line">                r = c;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="comment">//如果找到了，那么继续下一个字符，</span></span><br><span class="line">                r = r-&gt;childrens[j];</span><br><span class="line">                <span class="keyword">if</span>(i == word.<span class="built_in">length</span>()<span class="number">-1</span>)&#123;  <span class="comment">//如果是最后一个字符，那么</span></span><br><span class="line">                    r-&gt;isEnd = <span class="literal">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** 查询字典中是否有该单词的词根，如果有返回词根，如果没有，返回原单词*/</span></span><br><span class="line">    <span class="function">string <span class="title">searchRoot</span><span class="params">(string word)</span> </span>&#123;</span><br><span class="line">        string res;</span><br><span class="line">        MyTreeNode* r = <span class="keyword">this</span>-&gt;root;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;word.<span class="built_in">length</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> j;</span><br><span class="line">            <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">for</span>(j = <span class="number">0</span>;j&lt; r-&gt;childrens.<span class="built_in">size</span>();j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(r-&gt;childrens[j]-&gt;character == word[i])&#123;</span><br><span class="line">                    flag = <span class="literal">true</span>;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 如果没找到，返回false</span></span><br><span class="line">            <span class="keyword">if</span>(!flag)&#123;</span><br><span class="line">                res = word;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="comment">//如果找到了，观察其是否是一个词根</span></span><br><span class="line">                r = r-&gt;childrens[j];</span><br><span class="line">                res += r-&gt;character;</span><br><span class="line">                <span class="keyword">if</span>(r-&gt;isEnd)&#123; <span class="comment">//如果是一整个词根，直接返回</span></span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">string <span class="title">replaceWords</span><span class="params">(vector&lt;string&gt;&amp; dictionary, string sentence)</span> </span>&#123;</span><br><span class="line">        Trie* t = <span class="keyword">new</span> <span class="built_in">Trie</span>();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;dictionary.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            t-&gt;<span class="built_in">insert</span>(dictionary[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        string res;</span><br><span class="line">        string word;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;sentence.<span class="built_in">length</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(sentence[i] == <span class="string">&#x27; &#x27;</span>)&#123;</span><br><span class="line">                res += t-&gt;<span class="built_in">searchRoot</span>(word) + <span class="string">&quot; &quot;</span>;</span><br><span class="line">                word = <span class="string">&quot;&quot;</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                word += sentence[i];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        res += t-&gt;<span class="built_in">searchRoot</span>(word);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>再记录一道上述数据结构的拓展应用题：</p>
<h4 id="剑指-offer-ii-067.-最大的异或"><a href="https://leetcode-cn.com/problems/ms70jA/">剑指 Offer II 067. 最大的异或</a></h4>
<p>给定一个整数数组 <code>nums</code> ，返回 <code>nums[i] XOR nums[j]</code> 的最大运算结果，其中 <code>0 ≤ i ≤ j &lt; n</code> 。</p>
<p><strong>提示：</strong></p>
<ul>
<li><code>1 &lt;= nums.length &lt;= 2 * 10^4</code></li>
<li><code>0 &lt;= nums[i] &lt;= 2^31 - 1</code></li>
</ul>
<p><strong>解题思路</strong>：</p>
<p>​ 将整数视为二进制字符串 0 / 1，此题目的字典树孩子仅有0和1，然后遍历所有数组中的元素，对于任意一个元素ai来说，通过字典树找到和它异或最大的那个值。遍历元素O(n)复杂度，通过字典树找到每个元素的异或最大的值为log(C)，故而总的时间复杂度为O(nlog(C))</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyTreeNode</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    MyTreeNode* left;  <span class="comment">// 0 </span></span><br><span class="line">    MyTreeNode* right; <span class="comment">// 1</span></span><br><span class="line">    <span class="built_in">MyTreeNode</span>()&#123;</span><br><span class="line">        <span class="keyword">this</span>-&gt;left = <span class="keyword">this</span>-&gt;right = <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Trie</span>&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    MyTreeNode* root;</span><br><span class="line">    <span class="built_in">Trie</span>()&#123;</span><br><span class="line">        root = <span class="keyword">new</span> <span class="built_in">MyTreeNode</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(<span class="keyword">int</span> val)</span></span>&#123;</span><br><span class="line">        MyTreeNode* r = <span class="keyword">this</span>-&gt;root;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">32</span>;i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> bit = (val &gt;&gt; (<span class="number">31</span>-i)) &amp; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span>(bit == <span class="number">0</span> &amp;&amp; r-&gt;left)&#123; <span class="comment">//找到这个节点了</span></span><br><span class="line">                r = r-&gt;left;</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(bit == <span class="number">1</span> &amp;&amp; r-&gt;right)&#123; <span class="comment">//找到这个节点了</span></span><br><span class="line">                r = r-&gt;right;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="comment">//没找到这个节点，进行插入</span></span><br><span class="line">                MyTreeNode* c = <span class="keyword">new</span> <span class="built_in">MyTreeNode</span>();</span><br><span class="line">                <span class="keyword">if</span>(bit == <span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="comment">//插入左侧</span></span><br><span class="line">                    r-&gt;left = c;</span><br><span class="line">                    r = r-&gt;left;</span><br><span class="line">                &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                    <span class="comment">//插入右侧</span></span><br><span class="line">                    r-&gt;right = c;</span><br><span class="line">                    r = r-&gt;right;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">calculateMax</span><span class="params">(<span class="keyword">int</span> val)</span></span>&#123;</span><br><span class="line">        MyTreeNode* r = <span class="keyword">this</span>-&gt;root;</span><br><span class="line">        <span class="keyword">int</span> multi_val = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">32</span>;i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> bit = (val &gt;&gt; (<span class="number">31</span>-i)) &amp; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span>(bit == <span class="number">0</span> &amp;&amp; r-&gt;right)&#123;</span><br><span class="line">                <span class="comment">//当前位为0，且有1，那么直接往1那边走</span></span><br><span class="line">                r = r-&gt;right;</span><br><span class="line">                multi_val = (multi_val &lt;&lt; <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(bit == <span class="number">1</span> &amp;&amp; r-&gt;left)&#123;</span><br><span class="line">                <span class="comment">//当前位为1，且有0，那么直接往0那边走</span></span><br><span class="line">                r = r-&gt;left;</span><br><span class="line">                multi_val = multi_val &lt;&lt; <span class="number">1</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(bit == <span class="number">0</span> &amp;&amp; !r-&gt;right &amp;&amp; r-&gt;left)&#123;</span><br><span class="line">                <span class="comment">//当前位为0，且无1，则往0那边走</span></span><br><span class="line">                r = r-&gt;left;</span><br><span class="line">                multi_val = multi_val &lt;&lt; <span class="number">1</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(bit == <span class="number">1</span> &amp;&amp; !r-&gt;left &amp;&amp; r-&gt;right)&#123;</span><br><span class="line">                <span class="comment">//当前位为1，且无0，那么直接往1那边走</span></span><br><span class="line">                r = r-&gt;right;</span><br><span class="line">                multi_val = (multi_val &lt;&lt; <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> multi_val ^ val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">findMaximumXOR</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        Trie* t = <span class="keyword">new</span> <span class="built_in">Trie</span>();</span><br><span class="line">        <span class="keyword">int</span> maxVal = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            t-&gt;<span class="built_in">insert</span>(nums[i]);</span><br><span class="line">            maxVal = <span class="built_in">max</span>(maxVal,t-&gt;<span class="built_in">calculateMax</span>(nums[i]));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxVal;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>字符串系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>container</tag>
      </tags>
  </entry>
  <entry>
    <title>容器设计——LRU最近最少使用缓存的容器设计</title>
    <url>/2022/02/05/4cd58a8a96c9/</url>
    <content><![CDATA[<h3 id="剑指-offer-ii-031.-最近最少使用缓存"><a href="https://leetcode-cn.com/problems/OrIXps/">剑指 Offer II 031. 最近最少使用缓存</a></h3>
<h5 id="题目简要描述"><strong>题目简要描述</strong>：</h5>
<p>​ 运用所掌握的数据结构，设计和实现一个 LRU (Least Recently Used，最近最少使用) 缓存机制 。</p>
<p><strong>实现 LRUCache 类：</strong></p>
<ul>
<li><p>LRUCache(int capacity) 以正整数作为容量 capacity 初始化 LRU 缓存</p></li>
<li><p>int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。</p></li>
<li><p>void put(int key, int value) 如果关键字已经存在，则变更其数据值；如果关键字不存在，则插入该组「关键字-值」。当缓存容量达到上限时，它应该在写入新数据之前删除最久未使用的数据值，从而为新的数据值留出空间。</p></li>
</ul>
<p><strong>类模版</strong>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">LRUCache</span>(<span class="keyword">int</span> capacity) &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">int</span> key, <span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ <strong>使用 双向链表 与 Hash 表</strong>，实现 LRU：将新插入的元素放在链表头部，或将最新访问的节点放在链表的头部。如果容量到达上限，去除链表最后的元素。在此期间，<strong>为了保证访问链表的头部和尾部都是O(1)时间，我们需要维护一个Head和一个Tail节点，分别指向双向链表的头部和尾部，这两个头部和尾部的节点中是不存放数据，留空的，仅为了进行指示。</strong>并且为了保证<strong>在O(1)时间内能够获取任意一个元素</strong>，我们还需要建立一个HashMap，将key值与对应的链表节点关联，以方便以O(1)时间进行访问。</p>
<p><strong>代码</strong>：以下代码我并没有做任何的优化，比如说合并一些可复用的函数，因为这样看上去更简单明了一些，其实比如说像一些将Node插入到链表前方的操作，以及删除链表最后一个元素的操作，都是可以写成函数封装起来的。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	Node* prev;</span><br><span class="line">	Node* next;</span><br><span class="line">	<span class="keyword">int</span> key;</span><br><span class="line">	<span class="keyword">int</span> value;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">Node</span>() &#123;</span><br><span class="line">		<span class="keyword">this</span>-&gt;prev = <span class="literal">NULL</span>;</span><br><span class="line">		<span class="keyword">this</span>-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">Node</span>(<span class="keyword">int</span> key, <span class="keyword">int</span> value) &#123;</span><br><span class="line">		<span class="keyword">this</span>-&gt;prev = <span class="literal">NULL</span>;</span><br><span class="line">		<span class="keyword">this</span>-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">		<span class="keyword">this</span>-&gt;key = key;</span><br><span class="line">		<span class="keyword">this</span>-&gt;value = value;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span> &#123;</span></span><br><span class="line">	<span class="keyword">int</span> capacity;</span><br><span class="line">	<span class="keyword">int</span> curr_size;</span><br><span class="line">	Node* head; <span class="comment">//链表头节点</span></span><br><span class="line">	Node* tail; <span class="comment">//链表尾巴节点</span></span><br><span class="line">	unordered_map&lt;<span class="keyword">int</span>, Node*&gt; key2Node; <span class="comment">//key - Node 的转换</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">LRUCache</span>(<span class="keyword">int</span> capacity) &#123;</span><br><span class="line">		<span class="keyword">this</span>-&gt;curr_size = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">this</span>-&gt;capacity = capacity;</span><br><span class="line">		<span class="keyword">this</span>-&gt;head = <span class="keyword">new</span> <span class="built_in">Node</span>();</span><br><span class="line">		<span class="keyword">this</span>-&gt;tail = <span class="keyword">new</span> <span class="built_in">Node</span>();</span><br><span class="line">		head-&gt;next = tail;</span><br><span class="line">		tail-&gt;prev = head;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (key2Node.<span class="built_in">find</span>(key) == key2Node.<span class="built_in">end</span>()) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">		Node* curr = key2Node[key];</span><br><span class="line">		<span class="comment">//将curr先从链表中删掉</span></span><br><span class="line">		Node* prev = curr-&gt;prev;</span><br><span class="line">		<span class="keyword">if</span> (prev) prev-&gt;next = curr-&gt;next;</span><br><span class="line">		<span class="keyword">if</span> (curr-&gt;next) curr-&gt;next-&gt;prev = prev;</span><br><span class="line">		<span class="comment">//然后添加到链表的最前面</span></span><br><span class="line">		Node* next = <span class="keyword">this</span>-&gt;head-&gt;next;</span><br><span class="line">		curr-&gt;prev = head;</span><br><span class="line">		head-&gt;next = curr;</span><br><span class="line">		curr-&gt;next = next;</span><br><span class="line">		next-&gt;prev = curr;</span><br><span class="line">		<span class="keyword">return</span> curr-&gt;value;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">int</span> key, <span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (key2Node.<span class="built_in">find</span>(key) != key2Node.<span class="built_in">end</span>()) &#123;</span><br><span class="line">			<span class="comment">//修改值并将该元素插到最前面</span></span><br><span class="line">			Node* curr = key2Node[key];</span><br><span class="line">			curr-&gt;value = value;</span><br><span class="line">			<span class="comment">//将curr先从链表中删掉</span></span><br><span class="line">			Node* prev = curr-&gt;prev;</span><br><span class="line">			<span class="keyword">if</span> (prev) prev-&gt;next = curr-&gt;next;</span><br><span class="line">			<span class="keyword">if</span> (curr-&gt;next) curr-&gt;next-&gt;prev = prev;</span><br><span class="line">			<span class="comment">//然后添加到链表的最前面</span></span><br><span class="line">			Node* next = <span class="keyword">this</span>-&gt;head-&gt;next;</span><br><span class="line">			curr-&gt;prev = head;</span><br><span class="line">			head-&gt;next = curr;</span><br><span class="line">			curr-&gt;next = next;</span><br><span class="line">			next-&gt;prev = curr;</span><br><span class="line">			<span class="keyword">return</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (<span class="keyword">this</span>-&gt;curr_size == <span class="keyword">this</span>-&gt;capacity) &#123;</span><br><span class="line">			<span class="comment">//如果容量满了,丢掉最尾巴的那个，然后插入到最前面</span></span><br><span class="line">			<span class="comment">//丢掉最尾巴那个</span></span><br><span class="line">			Node* prev = <span class="keyword">this</span>-&gt;tail-&gt;prev;</span><br><span class="line">			key2Node.<span class="built_in">erase</span>(prev-&gt;key); <span class="comment">//抹除key2Node里</span></span><br><span class="line">			<span class="keyword">if</span> (prev-&gt;prev) prev-&gt;prev-&gt;next = tail;</span><br><span class="line">			tail-&gt;prev = prev-&gt;prev;</span><br><span class="line">			prev-&gt;prev = prev-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">			<span class="comment">//插入该元素到最前面</span></span><br><span class="line">			Node* temp = <span class="keyword">new</span> <span class="built_in">Node</span>(key, value);</span><br><span class="line">			Node* next = <span class="keyword">this</span>-&gt;head-&gt;next;</span><br><span class="line">			temp-&gt;prev = head;</span><br><span class="line">			head-&gt;next = temp;</span><br><span class="line">			temp-&gt;next = next;</span><br><span class="line">			next-&gt;prev = temp;</span><br><span class="line">			key2Node[key] = temp;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="comment">//如果容量没满，元素插入到最前面，并加载入map中</span></span><br><span class="line">			Node* temp = <span class="keyword">new</span> <span class="built_in">Node</span>(key, value);</span><br><span class="line">			Node* next = <span class="keyword">this</span>-&gt;head-&gt;next;</span><br><span class="line">			temp-&gt;prev = head;</span><br><span class="line">			head-&gt;next = temp;</span><br><span class="line">			temp-&gt;next = next;</span><br><span class="line">			next-&gt;prev = temp;</span><br><span class="line">			key2Node[key] = temp;</span><br><span class="line">			<span class="keyword">this</span>-&gt;curr_size++;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p><strong>运行结果</strong>:</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_06_11_41_37_32.png" /></p>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>容器设计系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>container</tag>
      </tags>
  </entry>
  <entry>
    <title>容器设计——插入、删除和随机访问都是 O(1) 的容器设计</title>
    <url>/2022/02/05/233281550871/</url>
    <content><![CDATA[<h3 id="剑指-offer-ii-030.-插入删除和随机访问都是-o1-的容器"><a href="https://leetcode-cn.com/problems/FortPu/">剑指 Offer II 030. 插入、删除和随机访问都是 O(1) 的容器</a></h3>
<h5 id="题目简要描述"><strong>题目简要描述</strong>：</h5>
<p>设计一个支持在平均 时间复杂度 O(1) 下，执行以下操作的数据结构：</p>
<pre><code>insert(val)：当元素 val 不存在时返回 true ，并向集合中插入该项，否则返回 false 。
remove(val)：当元素 val 存在时返回 true ，并从集合中移除该项，否则返回 false 。
getRandom：随机返回现有集合中的一项。每个元素应该有 相同的概率 被返回。</code></pre>
<p><strong>类模版</strong>：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomizedSet</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">/** Initialize your data structure here. */</span></span><br><span class="line">    <span class="built_in">RandomizedSet</span>() &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/** Inserts a value to the set. Returns true if the set did not already contain the specified element. */</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">insert</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/** Removes a value from the set. Returns true if the set contained the specified element. */</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">remove</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/** Get a random element from the set. */</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getRandom</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 首先，题目要求插入和删除都需要是O(1)的时间复杂度，在我们熟知的数据结构中，<strong>只有Hash表能达到这个效果</strong>。但是，Hash表显然不能满足随机取getRandom这一操作，随机取的操作，<strong>底层应当是数组，而且最好是紧凑的连续存放内容的数组</strong>，这样才方便进行随机取的行为，并且概率一致。</p>
<p>​ 综上所述，我们应当设计这样一个数据结构，利用数组保存元素，然后利用哈希表保存元素值（key）和 该值在数组中存放的index（value），这样子就能实现上述的要求了。</p>
<p>​ 同时，我们还需要注意的一个细节就是，<strong>当我们删除元素时，不能直接将该元素在它的位置上删除</strong>，如果这样的话，就会导致数组存储元素的idx不连续，从而后续随机取元素的时候，各个元素的概率不再相等。我们应该用数组最后的那个元素将我们要删的元素进行替换，然后把数组最后的那个元素删除，最后更新哈希表中的idx即可。</p>
<h5 id="代码如下">代码如下：</h5>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomizedSet</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    unordered_map&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; m;</span><br><span class="line">  	vector&lt;<span class="keyword">int</span>&gt; v;</span><br><span class="line">    <span class="comment">/** Initialize your data structure here. */</span></span><br><span class="line">    <span class="built_in">RandomizedSet</span>() &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** Inserts a value to the set. Returns true if the set did not already contain the specified element. */</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">insert</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(m.<span class="built_in">find</span>(val) != m.<span class="built_in">end</span>()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        m[val] = v.<span class="built_in">size</span>();</span><br><span class="line">        v.<span class="built_in">push_back</span>(val);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** Removes a value from the set. Returns true if the set contained the specified element. */</span></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">remove</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(m.<span class="built_in">find</span>(val) == m.<span class="built_in">end</span>()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">int</span> idx = m[val];</span><br><span class="line">        <span class="keyword">int</span> max_idx = m.<span class="built_in">size</span>() - <span class="number">1</span>;</span><br><span class="line">        m[v[max_idx]] = idx;</span><br><span class="line">        m.<span class="built_in">erase</span>(val);</span><br><span class="line">        v[idx] = v[max_idx];</span><br><span class="line">        v.<span class="built_in">pop_back</span>();</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** Get a random element from the set. */</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getRandom</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> idx = <span class="built_in">rand</span>() % m.<span class="built_in">size</span>();</span><br><span class="line">        <span class="keyword">return</span> v[idx];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​</p>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>容器设计系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>container</tag>
      </tags>
  </entry>
  <entry>
    <title>链表系列——链表问题的常见技巧</title>
    <url>/2022/02/04/bb6e8e482b2b/</url>
    <content><![CDATA[<h3 id="一剑指-offer-ii-022.-链表中环的入口节点">一、<a href="https://leetcode-cn.com/problems/c32eOV/">剑指 Offer II 022. 链表中环的入口节点</a></h3>
<p><strong>题目简单描述</strong>：</p>
<p>​ 给定一个链表，需要返回链表开始入环的第一个节点。 从链表的头节点开始沿着 next 指针进入环的第一个节点为环的入口节点。如果链表无环，则返回 null。</p>
<p>​ 进阶：是否可以使用 O(1) 空间解决此题？</p>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 本题本身想要解答十分简单，将其放入博客中整理是想记录我们应该如何利用O(1)空间去解决这个题目呢？</p>
<p>​ <strong>快慢指针法</strong>，我们使用两个指针，fast 与 slow。它们起始都位于链表的头部。随后，slow 指针每次向后移动一个位置，而 fast 指针向后移动两个位置。如果链表中存在环，则 fast 指针最终将再次与 slow 指针在环中相遇。</p>
<p>​ 如下图所示，即可非常好的理解如下：那么，又该如何判断入环点的位置呢？我们先上结论：经过数学推断可以得知：</p>
<p>​ <strong>假设快慢指针相遇时，fast指针已经走完了环的n圈，那么</strong></p>
<p>​ <strong>从相遇点到入环点的距离加上 n−1 圈的环长，恰好等于从链表头部到入环点的距离。</strong></p>
<p>​ <strong>根据此结论，我们只需要在快慢指针相遇时，再加一个ptr指针，让其指向链表头部；随后，它和 slow 指针每次向后移动一个位置。最终，它们会在入环点相遇。</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/mac/截屏2022-02-04 下午2.06.49.png" alt="截屏2022-02-04 下午2.06.49" style="zoom:33%;" /></p>
<p>​ <strong>结论证明</strong>：设链表中环外部分的长度为 a。slow 指针进入环后，又走了 b 的距离与 fast 相遇。此时，fast 指针已经走完了环的 n 圈，因此它走过的总距离为 <span class="math inline">\(a + n \times (b+c) + b\)</span> ,而此时，slow指针走过的总距离为 <span class="math inline">\(a + b\)</span>。</p>
<p>​ <strong>【此处需要解释一下：为何fast与slow相遇时，slow必定还在走第一圈？】</strong>（我们假设fast和slow如果同时从入环点出发，由于速度是2倍的关系，slow走完1圈的时候，fast刚好走完2圈，他们会在起点相遇。但是现在，fast比slow先入环，也就是说slow入环的时候，fast不管在环的哪里，肯定能在slow走完一圈前，将其追上。）</p>
<p>​ 由于fast指针走的速度是slow指针的2倍，那么可以得到以下等式：$ a + n (b+c) = 2 (a + b)$ 所以可以得到如下结论： $ a = c + (n-1) (b+c)$ ,这也就意味着，最开始说的， 从相遇点到入环点的距离 + (n-1) 圈环的距离，等于链表头到入环点的距离。</p>
<p>​ 那么为什么说，如果相遇的时候，ptr从链表头出发，ptr和slow必定在入环口相遇呢？因为a的距离是c加上许多圈环的距离，所以当ptr到达链表入环口的时候，时间经过了a，此时slow必定出现在入环口处。所以我们可以根据此来判断，入环口的位置是哪一个节点。</p>
<h3 id="二剑指-offer-ii-023.-两个链表的第一个重合节点">二、<a href="https://leetcode-cn.com/problems/3u1WK4/">剑指 Offer II 023. 两个链表的第一个重合节点</a></h3>
<p><strong>简单题目描述</strong>：</p>
<p>​ 给定两个单链表的头节点 headA 和 headB ，请找出并返回两个单链表相交的起始节点。如果两个链表没有交点，返回 null 。详细见原网址</p>
<p><strong>解题思路</strong>：</p>
<p>参考：https://leetcode-cn.com/problems/3u1WK4/solution/liang-ge-lian-biao-de-di-yi-ge-zhong-he-0msfg/</p>
<p>此题难点在于设计一个时间复杂度 O(n) 、仅用 O(1) 内存的解决方案？</p>
<p>​ 我们可以考虑双指针的方法对两个链表进行求解，但是双指针的难点在于，两条链表的长度不同，无法做到一一对应。我们先给出<strong>解决方案</strong>：</p>
<p>​ 当链表 headA 和 headB 都不为空时，创建两个指针 pA 和 pB ，初始时分别指向两个链表的头节点 headA和 headB ，然后将两个指针依次遍历两个链表的每个节点。具体做法如下：</p>
<ul>
<li>每步操作需要同时更新指针 pA 和 pB。</li>
<li>如果指针 pA 不为空，则将指针 pA 移到下一个节点；如果指针 pB 不为空，则将指针 pB 移到下一个节点。</li>
<li>如果指针 pA 为空，则将指针 pA 移到链表 headB 的头节点；如果指针 pB 为空，则将指针 pB 移到链表 headA 的头节点。</li>
<li>当指针 pA 和 pB 指向同一个节点或者都为空时，返回它们指向的节点或者 null。</li>
</ul>
<p>​ <strong>乍一看，其中有一个非常奇怪的点</strong>，就是如果指针pA为空，那么将指针pA移动到链表headB的头节点。但其实仔细一想，这样子是没问题的。也正是因为这个操作，我们才能够得以解决两个链表长度不一致导致的不对应问题。较为详细的证明如下：</p>
<p>​ 我们先考虑<strong>两链表相交的情况</strong>，如果两链表长度一致，那不需要想，pA和pB必定同时到达某一个节点。</p>
<p>​ 如果两链表长度不一致，这样子的话，我们假设链表A、B长度为m和n，A、B的不相交部分节点数为a，b，相交部分节点数为c，那么m = a + c , n = b + c. pA和pB第一遍遍历完各自的链表后，他们不是同时到达尾部节点的，但是当pA遍历完 a + c + b个节点，当pB遍历完b + c + a个节点的时候，两者就会同时到达相交的节点。</p>
<p>​ 再证明<strong>两链表不相交的情况</strong>，如果两链表长度一致，那不需要想，pA和pB必定同时到达最终的NULL节点。</p>
<p>​ 如果两链表长度不一致，这样子的话，我们假设链表A、B的长度各位m和n，当pA 遍历完 m + n个节点，pB遍历完 n + m个节点的时候，必定同时到达尾部的NULL节点。</p>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>链表系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>linked list</tag>
      </tags>
  </entry>
  <entry>
    <title>数组系列——回文字符串相关处理技巧</title>
    <url>/2022/02/04/5959f8901103/</url>
    <content><![CDATA[<h4 id="一剑指-offer-ii-020.-回文子字符串的个数">一、<a href="https://leetcode-cn.com/problems/a7VOhD/">剑指 Offer II 020. 回文子字符串的个数</a></h4>
<h5 id="题目描述"><strong>题目描述：</strong></h5>
<p>给定一个字符串 s ，请计算这个字符串中有多少个回文子字符串。</p>
<p>具有不同开始位置或结束位置的子串，即使是由相同的字符组成，也会被视作不同的子串。</p>
<p>示例 1：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：s = &quot;abc&quot;</span><br><span class="line">输出：3</span><br><span class="line">解释：三个回文子串: &quot;a&quot;, &quot;b&quot;, &quot;c&quot;</span><br></pre></td></tr></table></figure>
<p>示例 2：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：s = &quot;aaa&quot;</span><br><span class="line">输出：6</span><br><span class="line">解释：6个回文子串: &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;aa&quot;, &quot;aa&quot;, &quot;aaa&quot;</span><br></pre></td></tr></table></figure>
<p>提示：</p>
<pre><code>1 &lt;= s.length &lt;= 1000
s 由小写英文字母组成</code></pre>
<h5 id="解题思路"><strong>解题思路</strong>：</h5>
<p>​ 引用：https://leetcode-cn.com/problems/a7VOhD/solution/jssan-jie-bao-li-shuang-zhi-zhen-zhong-x-qqq0/</p>
<ul>
<li><p>思路1: 暴力搜索</p>
<ul>
<li>搜索所有的子串，并分别判断是否为回文串</li>
<li>时间复杂度：O(n^3)</li>
<li>空间复杂度：O(1)</li>
</ul></li>
<li><p>思路2: 双指针，思路1的优化版本：</p>
<ul>
<li>先使用双指针 i 和 j 枚举所有子串的起点和终点，同时分别按顺序和逆序累加所有遍历过的字符得到字符串 s1 和 s2，判断是否回文只需对 s1 和 s2 判等即可。这里将回文判断的时间复杂度从 O(n)优化到 O(1)，但整体空间复杂度从 O(1)升到 O(n)，算是空间换时间。</li>
<li>但此思路的时间耗费仍然会较高，因为字符串的拼接操作都较为费时</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">countSubstrings</span><span class="params">(string s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span>;i&lt;s.<span class="built_in">length</span>();i++)&#123;</span><br><span class="line">            string s1,s2;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=i;j&lt;s.<span class="built_in">length</span>();j++)&#123;</span><br><span class="line">                s1 += s[j];</span><br><span class="line">                s2 = s[j] + s2;</span><br><span class="line">                <span class="keyword">if</span>(s1==s2) count++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>思路3: 中心扩展：</strong></p>
<ul>
<li><p>枚举所有可能的回文中心 s[i] 或 s[i]、s[i + 1]，若回文子串长度为奇数则其中心为 s[i]，回文子串长度为偶数则其中心为 s[i]、s[i + 1]；</p></li>
<li><p>以中心向左右两边扩展，即</p>
<ul>
<li>左边界 l 减 1</li>
<li>右边界 r 加1</li>
<li>如果 s[l] 与 s[r] 相等则回文数加1。</li>
</ul></li>
<li><div class="sourceCode" id="cb2"><pre class="sourceCode java"><code class="sourceCode java"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>  <span class="kw">class</span> Solution <span class="op">&#123;</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">public</span><span class="op">:</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>      <span class="dt">int</span> <span class="fu">countSubstrings</span><span class="op">(</span>string s<span class="op">)</span> <span class="op">&#123;</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>          <span class="dt">int</span> count <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>          <span class="cf">for</span><span class="op">(</span><span class="dt">int</span> i <span class="op">=</span><span class="dv">0</span><span class="op">;</span>i<span class="op">&lt;</span>s<span class="op">.</span><span class="fu">length</span><span class="op">();</span>i<span class="op">++)&#123;</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>              <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> l <span class="op">=</span> i<span class="op">,</span> r <span class="op">=</span> i<span class="op">;</span> l <span class="op">&gt;=</span> <span class="dv">0</span> <span class="op">&amp;&amp;</span> s<span class="op">[</span>l<span class="op">]</span> <span class="op">==</span> s<span class="op">[</span>r<span class="op">];</span> l<span class="op">--,</span> r<span class="op">++)</span> count<span class="op">++;</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>              <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> l <span class="op">=</span> i<span class="op">,</span> r <span class="op">=</span> i <span class="op">+</span> <span class="dv">1</span><span class="op">;</span> l <span class="op">&gt;=</span> <span class="dv">0</span> <span class="op">&amp;&amp;</span> s<span class="op">[</span>l<span class="op">]</span> <span class="op">==</span> s<span class="op">[</span>r<span class="op">];</span> l<span class="op">--,</span> r<span class="op">++)</span> count<span class="op">++;</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>          <span class="op">&#125;</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>          <span class="cf">return</span> count<span class="op">;</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>      <span class="op">&#125;</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="op">&#125;;</span></span></code></pre></div></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>字符串系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>array</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记13——Maven基础介绍（更新中）</title>
    <url>/2022/02/04/741ed1dfa248/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1255945359327200</p>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>数组系列——经典三数之和问题</title>
    <url>/2022/02/03/16dab5183b1f/</url>
    <content><![CDATA[<h3 id="q1剑指-offer-ii-007.-数组中和为-0-的三个数">Q1、<a href="https://leetcode-cn.com/problems/1fGaJU/">剑指 Offer II 007. 数组中和为 0 的三个数</a></h3>
<p>​ 给定一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a ，b ，c ，使得 a + b + c = 0 ？请找出所有和为 0 且 不重复 的三元组。</p>
<p>示例 1：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [-1,0,1,2,-1,-4]</span><br><span class="line">输出：[[-1,-1,2],[-1,0,1]]</span><br></pre></td></tr></table></figure>
<p>示例 2：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = []</span><br><span class="line">输出：[]</span><br></pre></td></tr></table></figure>
<p>示例 3：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">输入：nums = [0]</span><br><span class="line">输出：[]</span><br></pre></td></tr></table></figure>
<p>提示：</p>
<pre><code>0 &lt;= nums.length &lt;= 3000
-105 &lt;= nums[i] &lt;= 105</code></pre>
<h4 id="解题思路">解题思路：</h4>
<p>​ 该题最重要的是如何<strong>高效率的循环遍历</strong>以及 如何<strong>高效率的去除重复三元组</strong></p>
<p>​ 最简单的O(n^3)的暴力求解，对于该题而言时间复杂度会大大超出。所以我们考虑双指针的解法。<strong>双指针在三数之和中如何应用呢？</strong></p>
<p>​ <strong>无非是在传统双指针求法的前提上，在外层多加了一层循环</strong>，也就是先固定住一个元素，然后利用双指针，将内部O(n^2)的复杂度，缩减至O(n)，从而使得整个求解复杂度降至O(n ^2)。</p>
<p>​ 该题另外一个核心要点是，如何高效率的去除重复？我们当然可以去使用Hash表，然后每有一个元素就将其push进去，并进行比较，如果已经存在就不计入结果中。但是这样的方法仍然会导致大量的计算浪费。</p>
<p>​ 观察后，我们会发现，在循环的时候，有两种情况会导致重复：</p>
<p><strong>情况1</strong>：当外层循环的i , nums[i] == nums[i-1] 的时候，原因是，如果nums[i] == nums[i-1]，那么当前nums[i]能够找到的j和k，在nums[i-1]中必定已经出现过了，所以我们的处理方法是，直接跳过该次外层循环，进入下一个i</p>
<p><strong>情况2</strong>：出现在内部双指针运行的时候，如下述情况：i，j, k分别指向-4，-1，5，此时满足一组条件，我们会将 j++, 以让循环继续运行。此时，重复发生了，如果nums[j] == nums[j + 1]，那么nums[j+1]所产生的符合条件的三元组就会与之前的重复，所以我们采取的措施是，让j一直自增，直到其和下一个元素不相等或者到达k。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">	-4  -1  -1  -1  2  5</span><br><span class="line"></span><br><span class="line">​	i   j              k</span><br></pre></td></tr></table></figure>
<p>综上，代码书写如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; <span class="built_in">threeSum</span>(vector&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">        vector&lt;vector&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line">        <span class="built_in">sort</span>(nums.<span class="built_in">begin</span>(),nums.<span class="built_in">end</span>());</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i &gt;= <span class="number">1</span> &amp;&amp; nums[i] == nums[i<span class="number">-1</span>]) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">int</span> j = i+<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">int</span> k = nums.<span class="built_in">size</span>() - <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">while</span>(j&lt;k)&#123;</span><br><span class="line">                <span class="keyword">int</span> value = nums[i] + nums[j] + nums[k];</span><br><span class="line">                <span class="keyword">if</span>(value &gt; <span class="number">0</span>) k--;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(value &lt; <span class="number">0</span>) j++;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    res.<span class="built_in">push_back</span>(&#123;nums[i],nums[j],nums[k]&#125;);</span><br><span class="line">                    <span class="keyword">while</span> (j &lt; k &amp;&amp; nums[j] == nums[j + <span class="number">1</span>]) j++; </span><br><span class="line">                    j++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>数组系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>array</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记12——java多线程（更新中）</title>
    <url>/2022/02/03/f00e7866bf20/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1304521607217185</p>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>数组系列——连续子串问题</title>
    <url>/2022/02/02/0f0611fa7b0b/</url>
    <content><![CDATA[<h4 id="注意连续子串问题较为常见的两个技巧为滑动窗口法与前缀和滑动窗口法解相关子数组问题一般而言需要数组内元素都为正整数如果数组内元素存在负数的话滑动窗口是无法处理相关的负数样例的需要采用前缀和的技巧进行求解">注意：连续子串问题较为常见的两个技巧为：滑动窗口法与前缀和，滑动窗口法解相关子数组问题，一般而言需要数组内元素都为正整数，如果数组内元素存在负数的话，滑动窗口是无法处理相关的负数样例的，需要采用前缀和的技巧进行求解。</h4>
<h3 id="一剑指-offer-ii-008.-和大于等于-target-的最短子数组">一、<a href="https://leetcode-cn.com/problems/2VG8Kg/">剑指 Offer II 008. 和大于等于 target 的最短子数组</a></h3>
<p><strong>例题1描述：</strong></p>
<p>​ 给定一个含有 n 个正整数的数组和一个正整数 target 。</p>
<p>​ 找出该数组中满足其和 ≥ target 的长度最小的连续子数组 [numsl, numsl+1, ..., numsr-1, numsr] ，并返回其长度。如果不存在符合条件的子数组，返回 0 。</p>
<ul>
<li><p>示例 1：</p>
<ul>
<li>输入：target = 7, nums = [2,3,1,2,4,3]</li>
<li>输出：2</li>
<li>解释：子数组 [4,3] 是该条件下的长度最小的子数组。</li>
</ul></li>
<li><p>示例 2：</p>
<ul>
<li>输入：target = 4, nums = [1,4,4]</li>
<li>输出：1</li>
</ul></li>
<li><p>示例 3：</p>
<ul>
<li>输入：target = 11, nums = [1,1,1,1,1,1,1,1]</li>
<li>输出：0</li>
</ul></li>
<li><p>提示：</p>
<p>1 &lt;= target &lt;= 10^9 1 &lt;= nums.length &lt;= 10^5 1 &lt;= nums[i] &lt;= 10^5</p></li>
</ul>
<p><strong>例题1详解</strong>：</p>
<p>​ 本题在做的时候有三种解决方案:</p>
<p>​ 第一种就是最为简单的先计算前缀和，然后暴力开始从len = 1 到 len = nums.length 进行搜索，找到符合条件的len即返回.</p>
<p>​ 第二种,在第一种的基础上进行改进,将暴力搜索改为二分索,left=1,right=nums.length, len=(left + right)/2,时间复杂度能大大降低。</p>
<p>​ 第三种就是本文着重记录的<strong>滑动窗口</strong>解决方案：</p>
<p>​ 可以使用滑窗的题目一般题目中都会有明确的“<strong>连续子数组</strong>”、“<strong>连续子串</strong>”等关键字，另外可能会附带<strong>最大</strong>、<strong>最小</strong>的限定词进行补充。</p>
<p>​ 那么遇到此类题目，往往可以分为以下几步进行求解：</p>
<ul>
<li>初始化窗口左边界为0，右边界可以为0，也可以根据题意固定大小。</li>
<li>我们需要初始化一个ret的返回值，默认为0或者根据题意默认为最大值。</li>
<li>窗口的大小需要根据题目条件进行调整
<ul>
<li>最大连续...尽量扩张右边界，直到不满足题意再收缩左边界</li>
<li>最小连续...尽量缩小左边界，直到不满足题意再扩大右边界</li>
</ul></li>
<li>在执行3操作的过程中，不断与ret进行比较</li>
<li>最终返回ret结果即可。</li>
</ul>
<p>根据上述指南，我们可以书写代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">minSubArrayLen</span><span class="params">(<span class="keyword">int</span> target, vector&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> len = <span class="number">1e7</span>;</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> right = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> total = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(;right&lt;nums.<span class="built_in">size</span>();right++)&#123;</span><br><span class="line">            total += nums[right];</span><br><span class="line">            <span class="keyword">while</span>(total &gt;= target)&#123;</span><br><span class="line">                <span class="keyword">if</span>(right - left + <span class="number">1</span> &lt; len) len = right - left + <span class="number">1</span>;</span><br><span class="line">                total-= nums[left++];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(len == <span class="number">1e7</span>) len = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> len;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="二剑指-offer-ii-009-乘积小于-k-的子数组">二、<a href="https://leetcode-cn.com/problems/ZVAVXX/">剑指 Offer II 009 乘积小于 K 的子数组</a></h3>
<p><strong>例题2描述：</strong></p>
<p>​ 给定一个<strong>正整数数组 <code>nums</code></strong>和整数 <code>k</code> ，请找出该数组内乘积小于 <code>k</code> 的连续的子数组的个数。</p>
<ul>
<li><p>示例 1:</p>
<ul>
<li>输入: nums = [10,5,2,6], k = 100</li>
<li>输出: 8</li>
<li>解释: 8 个乘积小于 100 的子数组分别为: [10], [5], [2], [6], [10,5], [5,2], [2,6], [5,2,6]。需要注意的是 [10,5,2] 并不是乘积小于100的子数组。</li>
</ul></li>
<li><p>示例 2:</p>
<ul>
<li>输入: nums = [1,2,3], k = 0</li>
<li>输出: 0</li>
</ul></li>
<li><p>提示:</p>
<p>1 &lt;= nums.length &lt;= 3 * 10^4 1 &lt;= nums[i] &lt;= 1000 0 &lt;= k &lt;= 10^6</p></li>
</ul>
<p><strong>例题2解析</strong>：</p>
<p>​ 按照上述例题1的思想，简单来向，我们发现此题目求解的不是某个长度最小或长度最大的值，而是所有的连续子数组的个数，乍一看无法按照先前的内容进行求解，但其实我们可以发现：</p>
<p>​ 窗口每次移动后，ret都可以增加 <strong>right - left + 1</strong>个子数组。具体而言是什么意思呢？</p>
<p>​ 比如某次遍历符合题意的子数组为 ABCX，那么在该条件下符合条件的有X，CX，BCX，ABCX共四个（可以进行多个例子，发现个数符合right-left+1） ​ 我们可能会有疑问：AB，BC也算，为什么不算进去？ ​ 记住一点<strong>我们是以最右边的X为必要条件，进行计算符合条件的子数组，否则会出现重复的！</strong> ​ 比如在X为右侧边界时（ABCX），我们把BC算进去了，可是我们在C为最右侧时（ABC），BC已经出现过，我们重复加了BC这个子数组两次！</p>
<p>具体的代码应当如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">numSubarrayProductLessThanK</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> right = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> product = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(;right&lt;nums.<span class="built_in">size</span>();right++)&#123;</span><br><span class="line">            product = product * nums[right];</span><br><span class="line">            <span class="comment">//下面加了一个条件：left&lt;=right是因为，如果不加这个条件，当k=0的时候，会一直陷入该死循环中无法出循环。</span></span><br><span class="line">            <span class="keyword">while</span>(left &lt;= right &amp;&amp; product &gt;= k)&#123;</span><br><span class="line">                product = product / nums[left];</span><br><span class="line">                left++;</span><br><span class="line">            &#125;</span><br><span class="line">            count += right - left + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="三剑指-offer-ii-010.-和为-k-的子数组">三、<a href="https://leetcode-cn.com/problems/ZVAVXX/">剑指 Offer II 010. 和为 k 的子数组</a></h3>
<p><strong>例题3描述：</strong></p>
<p>​ 给定一个<strong>整数数组</strong>和一个整数 <code>k</code> <strong>，</strong>请找到该数组中和为 <code>k</code> 的连续子数组的个数。</p>
<ul>
<li><p>示例 1:</p>
<ul>
<li>``` 输入:nums = [1,1,1], k = 2 输出: 2 解释: 此题 [1,1] 与 [1,1] 为两种不同的情况 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- 示例 2:</span><br><span class="line"></span><br><span class="line">  - ```</span><br><span class="line">    输入:nums = [1,2,3], k = 3</span><br><span class="line">    输出: 2</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><p>提示:</p>
<ul>
<li><code>1 &lt;= nums.length &lt;= 2 * 104</code></li>
<li><code>-1000 &lt;= nums[i] &lt;= 1000</code></li>
<li><code>-107 &lt;= k &lt;= 107</code></li>
</ul></li>
</ul>
<p><strong>例题3解析</strong>：</p>
<p>​ 非常需要注意的是：此题中给出的条件是整数数组，而非正整数，故而滑动窗口没法使用，因为滑动窗口是需要你能保证，当右边界扩充时，和必增大，左边界收缩时和必减小，但是如果数组中存在负数，那么我们无法保证。此时需要应用前缀和。</p>
<p>​ <strong>以前我使用前缀和，都是通过先把所有的前缀和计算得到，然后存在Vector<int>中，然后再去根据前缀和，遍历处理问题，但这样人工遍历其复杂度为N^2</strong>，就会导致较高的时间复杂度，并且容易重复计算。那么应当如何去进行处理会比较好呢？</p>
<p>​ 我们<strong>一般可以采用Hash表来存储前缀和，</strong>在C++中可以使用速度较快的unordered_map，其底层就是用hash表进行实现。&lt;key,value&gt;，其存储的key代表前缀和的值，value代表该前缀和出现的次数。<strong>（只有在数组内存在负数的时候，才会有前缀和出现多次的情况）</strong></p>
<p>​ 然后，在上述例题中，应当在计算前缀和的每一步中，就去计算，到该元素为止，以该元素为结尾的子序列，有没有符合和为k 这一条件的，不然容易重复计算。</p>
<p>​ 同时，我们需要注意，要在开始时就往hash表中，插入(0,1)这一对元素，以处理边界条件。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">subarraySum</span><span class="params">(vector&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//利用哈希表存储 计算前缀和</span></span><br><span class="line">        unordered_map&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; sums;</span><br><span class="line">        sums[<span class="number">0</span>] = <span class="number">1</span>;  <span class="comment">// sum = 0 , 出现了1次</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            sum = sum + nums[i];</span><br><span class="line">            <span class="comment">//判断以该元素为结尾的子序列，有没有符合和为k 这一条件的</span></span><br><span class="line">            <span class="keyword">if</span>(sums.<span class="built_in">find</span>(sum-k) != sums.<span class="built_in">end</span>()) count+= sums[sum-k];</span><br><span class="line">			<span class="comment">//将该位置的前缀和也存入hash表中，以供后续计算参考</span></span><br><span class="line">            <span class="keyword">if</span>(sums.<span class="built_in">find</span>(sum) != sums.<span class="built_in">end</span>()) sums[sum]++;</span><br><span class="line">            <span class="keyword">else</span> sums[sum] = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓷ 算法类笔记</category>
        <category>数组系列</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>array</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记11——java正则表达式</title>
    <url>/2022/02/02/ab0718cbf72a/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1304066130968610</p>
<h3 id="一什么是正则表达式">一、什么是正则表达式：</h3>
<p>​ 正则表达式可以用字符串来描述规则，并用来匹配字符串。例如，判断手机号，我们用正则表达式<code>\d&#123;11&#125;</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">isValidMobileNumber</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> s.matches(<span class="string">&quot;\\d&#123;11&#125;&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 使用正则表达式的好处有哪些？一个正则表达式就是一个描述规则的字符串，所以，只需要编写正确的规则，我们就可以让正则表达式引擎去判断目标字符串是否符合规则。</p>
<p>​ 正则表达式是用字符串描述的一个匹配规则，使用正则表达式可以快速判断给定的字符串是否符合匹配规则。<strong>Java标准库<code>java.util.regex</code>内建了正则表达式引擎。</strong></p>
<h3 id="二匹配规则">二、匹配规则：</h3>
<p>正则表达式的匹配规则是从左到右按规则匹配。</p>
<h4 id="精确匹配">1、精确匹配：</h4>
<p>​ 对于正则表达式<code>abc</code>来说，它只能精确地匹配字符串<code>"abc"</code>，不能匹配<code>"ab"</code>，<code>"Abc"</code>，<code>"abcd"</code>等其他任何字符串。</p>
<p>​ 如果正则表达式有特殊字符，那就需要用<code>\</code>转义。例如，正则表达式<code>a\&amp;c</code>，其中<code>\&amp;</code>是用来匹配特殊字符<code>&amp;</code>的，它能精确匹配字符串<code>"a&amp;c"</code>，但不能匹配<code>"ac"</code>、<code>"a-c"</code>、<code>"a&amp;&amp;c"</code>等。</p>
<p>​ 如果想匹配非ASCII字符，例如中文，那就用<code>\u####</code>的十六进制表示，例如：<code>a\u548cc</code>匹配字符串<code>"a和c"</code>，中文字符<code>和</code>的Unicode编码是<code>548c</code>。</p>
<h4 id="模糊匹配.">2、模糊匹配：(.)</h4>
<p>​ 正则表达式<code>a.c</code>中间的<code>.</code>可以匹配一个任意字符</p>
<p>​ <code>.</code>匹配一个字符且仅限一个字符</p>
<h4 id="匹配数字">3、匹配数字：（</h4>
<p>​ 如果我们只想匹配<code>0</code>~<code>9</code>这样的数字，可以用<code>\d</code>匹配。例如，正则表达式<code>00\d</code>可以匹配：</p>
<ul>
<li><code>"007"</code>，因为<code>\d</code>可以匹配字符<code>7</code>；</li>
<li><code>"008"</code>，因为<code>\d</code>可以匹配字符<code>8</code>。</li>
</ul>
<p>​ 它不能匹配<code>"00A"</code>，<code>"0077"</code>，因为<code>\d</code>仅限单个数字字符。</p>
<h4 id="匹配常用字符">4、匹配常用字符：()</h4>
<p>用<code>\w</code>可以匹配一个字母、数字或下划线，w的意思是word。例如，<code>java\w</code>可以匹配：</p>
<ul>
<li><code>"javac"</code>，因为<code>\w</code>可以匹配英文字符<code>c</code>；</li>
<li><code>"java9"</code>，因为<code>\w</code>可以匹配数字字符<code>9</code>；。</li>
<li><code>"java_"</code>，因为<code>\w</code>可以匹配下划线<code>_</code>。</li>
</ul>
<p>因为<code>\w</code>不能匹配<code>#</code>、空格等字符。</p>
<h4 id="匹配空格字符">5、 匹配空格字符()</h4>
<p>用<code>\s</code>可以匹配一个空格字符，注意空格字符不但包括空格`<code>，还包括tab字符（在Java中用</code>表示）。例如，<code>a\sc</code>可以匹配：</p>
<ul>
<li><code>"a c"</code>，因为<code>\s</code>可以匹配空格字符``；</li>
<li><code>"a c"</code>，因为<code>\s</code>可以匹配tab字符<code>\t</code>。</li>
</ul>
<p>它不能匹配<code>"ac"</code>，<code>"abc"</code>等。</p>
<h4 id="匹配非数字">6、匹配非数字：（）</h4>
<p>​ <code>\D</code>匹配一个非数字</p>
<p>​ 类似的，<code>\W</code>可以匹配<code>\w</code>不能匹配的字符，<code>\S</code>可以匹配<code>\s</code>不能匹配的字符，这几个正好是反着来的。</p>
<h4 id="重复匹配">7、重复匹配：</h4>
<ul>
<li><p>修饰符<code>*</code>可以匹配任意个字符，包括0个字符。我们用<code>A\d*</code>可以匹配：</p>
<ul>
<li><p><code>A</code>：因为<code>\d*</code>可以匹配0个数字；</p></li>
<li><p><code>A0</code>：因为<code>\d*</code>可以匹配1个数字<code>0</code>；</p></li>
<li><p><code>A380</code>：因为<code>\d*</code>可以匹配多个数字<code>380</code>。</p></li>
</ul></li>
<li><p>修饰符<code>+</code>可以匹配至少一个字符。我们用<code>A\d+</code>可以匹配：</p>
<ul>
<li><code>A0</code>：因为<code>\d+</code>可以匹配1个数字<code>0</code>；</li>
<li><code>A380</code>：因为<code>\d+</code>可以匹配多个数字<code>380</code>。</li>
</ul></li>
<li><p>修饰符<code>?</code>可以匹配0个或一个字符。我们用<code>A\d?</code>可以匹配：</p>
<ul>
<li><code>A</code>：因为<code>\d?</code>可以匹配0个数字；</li>
<li><code>A0</code>：因为<code>\d?</code>可以匹配1个数字<code>0</code>。</li>
</ul></li>
<li><p>用修饰符<code>&#123;n&#125;</code>精确指定n个字符,<code>A\d&#123;3&#125;</code>可以精确匹配：</p>
<ul>
<li><code>A380</code>：因为<code>\d&#123;3&#125;</code>可以匹配3个数字<code>380</code>。</li>
</ul></li>
<li><p>用修饰符<code>&#123;n,m&#125;</code>指定匹配n~m个字符, <code>A\d&#123;3,5&#125;</code>可以精确匹配：</p>
<ul>
<li><code>A380</code>：因为<code>\d&#123;3,5&#125;</code>可以匹配3个数字<code>380</code>；</li>
<li><code>A3800</code>：因为<code>\d&#123;3,5&#125;</code>可以匹配4个数字<code>3800</code>；</li>
<li><code>A38000</code>：因为<code>\d&#123;3,5&#125;</code>可以匹配5个数字<code>38000</code>。</li>
</ul></li>
<li><p>如果没有上限，那么修饰符<code>&#123;n,&#125;</code>就可以匹配至少n个字符。</p></li>
</ul>
<h4 id="匹配规则快速查找">8、匹配规则快速查找：</h4>
<p>单个字符的匹配规则如下：</p>
<table>
<thead>
<tr class="header">
<th>正则表达式</th>
<th>规则</th>
<th>可以匹配</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>A</code></td>
<td>指定字符</td>
<td><code>A</code></td>
</tr>
<tr class="even">
<td><code>\u548c</code></td>
<td>指定Unicode字符</td>
<td><code>和</code></td>
</tr>
<tr class="odd">
<td><code>.</code></td>
<td>任意字符</td>
<td><code>a</code>，<code>b</code>，<code>&amp;</code>，<code>0</code></td>
</tr>
<tr class="even">
<td><code>\d</code></td>
<td>数字0~9</td>
<td><code>0</code>~<code>9</code></td>
</tr>
<tr class="odd">
<td><code>\w</code></td>
<td>大小写字母，数字和下划线</td>
<td><code>a</code><sub><code>z</code>，<code>A</code></sub><code>Z</code>，<code>0</code>~<code>9</code>，<code>_</code></td>
</tr>
<tr class="even">
<td><code>\s</code></td>
<td>空格、Tab键</td>
<td>空格，Tab</td>
</tr>
<tr class="odd">
<td><code>\D</code></td>
<td>非数字</td>
<td><code>a</code>，<code>A</code>，<code>&amp;</code>，<code>_</code>，……</td>
</tr>
<tr class="even">
<td><code>\W</code></td>
<td>非</td>
<td><code>&amp;</code>，<code>@</code>，<code>中</code>，……</td>
</tr>
<tr class="odd">
<td><code>\S</code></td>
<td>非</td>
<td><code>a</code>，<code>A</code>，<code>&amp;</code>，<code>_</code>，……</td>
</tr>
</tbody>
</table>
<p>多个字符的匹配规则如下：</p>
<table>
<thead>
<tr class="header">
<th>正则表达式</th>
<th>规则</th>
<th>可以匹配</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>A*</code></td>
<td>任意个数字符</td>
<td>空，<code>A</code>，<code>AA</code>，<code>AAA</code>，……</td>
</tr>
<tr class="even">
<td><code>A+</code></td>
<td>至少1个字符</td>
<td><code>A</code>，<code>AA</code>，<code>AAA</code>，……</td>
</tr>
<tr class="odd">
<td><code>A?</code></td>
<td>0个或1个字符</td>
<td>空，<code>A</code></td>
</tr>
<tr class="even">
<td><code>A&#123;3&#125;</code></td>
<td>指定个数字符</td>
<td><code>AAA</code></td>
</tr>
<tr class="odd">
<td><code>A&#123;2,3&#125;</code></td>
<td>指定范围个数字符</td>
<td><code>AA</code>，<code>AAA</code></td>
</tr>
<tr class="even">
<td><code>A&#123;2,&#125;</code></td>
<td>至少n个字符</td>
<td><code>AA</code>，<code>AAA</code>，<code>AAAA</code>，……</td>
</tr>
<tr class="odd">
<td><code>A&#123;0,3&#125;</code></td>
<td>最多n个字符</td>
<td>空，<code>A</code>，<code>AA</code>，<code>AAA</code></td>
</tr>
</tbody>
</table>
<h3 id="三复杂匹配规则">三、复杂匹配规则：</h3>
<h4 id="匹配开头结尾">1、匹配开头结尾：</h4>
<p>​ 进行多行匹配时，用<code>^</code>表示开头，<code>$</code>表示结尾。例如，<code>^A\d&#123;3&#125;$</code>，可以匹配<code>"A001"</code>、<code>"A380"</code>。</p>
<h4 id="匹配指定范围">2、匹配指定范围：</h4>
<p>​ <strong>使用<code>[...]</code>可以匹配范围内的字符</strong>，例如，<code>[123456789]</code>可以匹配<code>1</code>~<code>9</code>，这样就可以写出上述电话号码的规则：<code>[123456789]\d&#123;6,7&#125;</code>。</p>
<p>​ 把所有字符全列出来太麻烦，<code>[...]</code>还有一种写法，直接写<code>[1-9]</code>就可以。</p>
<p>​ <strong>要匹配大小写不限的十六进制数，比如<code>1A2b3c</code>，我们可以这样写：<code>[0-9a-fA-F]</code>，它表示一共可以匹配以下任意范围的字符：</strong></p>
<ul>
<li><code>0-9</code>：字符<code>0</code>~<code>9</code>；</li>
<li><code>a-f</code>：字符<code>a</code>~<code>f</code>；</li>
<li><code>A-F</code>：字符<code>A</code>~<code>F</code>。</li>
</ul>
<p>​ <strong><code>[...]</code>还有一种排除法，即不包含指定范围的字符。假设我们要匹配任意字符，但不包括数字，可以写<code>[^1-9]&#123;3&#125;</code>：</strong></p>
<ul>
<li>可以匹配<code>"ABC"</code>，因为不包含字符<code>1</code>~<code>9</code>；</li>
<li>可以匹配<code>"A00"</code>，因为不包含字符<code>1</code>~<code>9</code>；</li>
<li>不能匹配<code>"A01"</code>，因为包含字符<code>1</code>；</li>
<li>不能匹配<code>"A05"</code>，因为包含字符<code>5</code>。</li>
</ul>
<h4 id="或规则匹配">3、或规则匹配：</h4>
<p>​ 用<code>|</code>连接的两个正则规则是<em>或</em>规则，例如，<code>AB|CD</code>表示可以匹配<code>AB</code>或<code>CD</code>。</p>
<h4 id="使用括号">4、使用括号:</h4>
<p>​ 现在我们想要匹配字符串<code>learn java</code>、<code>learn php</code>和<code>learn go</code>怎么办？一个最简单的规则是<code>learn\sjava|learn\sphp|learn\sgo</code>，但是这个规则太复杂了，可以把公共部分提出来，然后用<code>(...)</code>把子规则括起来表示成<code>learn\\s(java|php|go)</code>。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String re = <span class="string">&quot;learn\\s(java|php|go)&quot;</span>;</span><br></pre></td></tr></table></figure>
<h4 id="规则总结">5、规则总结：</h4>
<p>复杂匹配规则主要有：</p>
<table>
<thead>
<tr class="header">
<th>正则表达式</th>
<th>规则</th>
<th>可以匹配</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>^</td>
<td>开头</td>
<td>字符串开头</td>
</tr>
<tr class="even">
<td>$</td>
<td>结尾</td>
<td>字符串结束</td>
</tr>
<tr class="odd">
<td>[ABC]</td>
<td>[…]内任意字符</td>
<td>A，B，C</td>
</tr>
<tr class="even">
<td>[A-F0-9xy]</td>
<td>指定范围的字符</td>
<td><code>A</code>，……，<code>F</code>，<code>0</code>，……，<code>9</code>，<code>x</code>，<code>y</code></td>
</tr>
<tr class="odd">
<td>[^A-F]</td>
<td>指定范围外的任意字符</td>
<td>非<code>A</code>~<code>F</code></td>
</tr>
<tr class="even">
<td>AB|CD|EF</td>
<td>AB或CD或EF</td>
<td><code>AB</code>，<code>CD</code>，<code>EF</code></td>
</tr>
</tbody>
</table>
<h3 id="四分组匹配-提取子串">四、分组匹配 + 提取子串：</h3>
<p>​ <code>(...)</code>还有一个重要作用，就是分组匹配。</p>
<p>​ 我们来看一下如何用正则匹配<code>区号-电话号</code>码这个规则。利用前面讲到的匹配规则，写出来很容易：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\d&#123;3,4&#125;\-\d&#123;6,8&#125;</span><br></pre></td></tr></table></figure>
<p>​ 虽然这个正则匹配规则很简单，但是往往匹配成功后，下一步是提取区号和电话号码，分别存入数据库。于是问题来了：<strong>如何提取匹配的子串</strong>？</p>
<p>​ 当然可以用<code>String</code>提供的<code>indexOf()</code>和<code>substring()</code>这些方法，但它们从正则匹配的字符串中提取子串没有通用性，下一次要提取<code>learn\s(java|php)</code>还得改代码。</p>
<p>​ <strong>正确的方法是用<code>(...)</code>先把要提取的规则分组，把上述正则表达式变为<code>(\d&#123;3,4&#125;)\-(\d&#123;6,8&#125;)</code></strong>。然后引入<code>java.util.regex</code>包，用<code>Pattern</code>对象匹配，匹配后获得一个<code>Matcher</code>对象，如果匹配成功，就可以直接从<code>Matcher.group(index)</code>返回子串：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Pattern p = Pattern.compile(<span class="string">&quot;(\\d&#123;3,4&#125;)\\-(\\d&#123;7,8&#125;)&quot;</span>);</span><br><span class="line">        Matcher m = p.matcher(<span class="string">&quot;010-12345678&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (m.matches()) &#123;</span><br><span class="line">            String g1 = m.group(<span class="number">1</span>);</span><br><span class="line">            String g2 = m.group(<span class="number">2</span>);</span><br><span class="line">            System.out.println(g1);</span><br><span class="line">            System.out.println(g2);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;匹配失败!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行上述代码，会得到两个匹配上的子串<code>010</code>和<code>12345678</code>。</p>
<p>​ 要特别注意，<code>Matcher.group(index)</code>方法的参数用1表示第一个子串，2表示第二个子串。如果我们传入0会得到什么呢？答案是<code>010-12345678</code>，即整个正则匹配到的字符串。</p>
<p>​ 我们在前面的代码中用到的正则表达式代码是<code>String.matches()</code>方法，而我们在分组提取的代码中用的是<code>java.util.regex</code>包里面的<code>Pattern</code>类和<code>Matcher</code>类。实际上这两种代码本质上是一样的，因为<code>String.matches()</code>方法内部调用的就是<code>Pattern</code>和<code>Matcher</code>类的方法。</p>
<p>​ 但是反复使用<code>String.matches()</code>对同一个正则表达式进行多次匹配效率较低，因为每次都会创建出一样的<code>Pattern</code>对象。完全可以先创建出一个<code>Pattern</code>对象，然后反复使用，就可以实现编译一次，多次匹配：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Pattern pattern = Pattern.compile(<span class="string">&quot;(\\d&#123;3,4&#125;)\\-(\\d&#123;7,8&#125;)&quot;</span>);</span><br><span class="line">        pattern.matcher(<span class="string">&quot;010-12345678&quot;</span>).matches(); <span class="comment">// true</span></span><br><span class="line">        pattern.matcher(<span class="string">&quot;021-123456&quot;</span>).matches(); <span class="comment">// false</span></span><br><span class="line">        pattern.matcher(<span class="string">&quot;022#1234567&quot;</span>).matches(); <span class="comment">// false</span></span><br><span class="line">        <span class="comment">// 获得Matcher对象:</span></span><br><span class="line">        Matcher matcher = pattern.matcher(<span class="string">&quot;010-12345678&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (matcher.matches()) &#123;</span><br><span class="line">            String whole = matcher.group(<span class="number">0</span>); <span class="comment">// &quot;010-12345678&quot;, 0表示匹配的整个字符串</span></span><br><span class="line">            String area = matcher.group(<span class="number">1</span>); <span class="comment">// &quot;010&quot;, 1表示匹配的第1个子串</span></span><br><span class="line">            String tel = matcher.group(<span class="number">2</span>); <span class="comment">// &quot;12345678&quot;, 2表示匹配的第2个子串</span></span><br><span class="line">            System.out.println(area);</span><br><span class="line">            System.out.println(tel);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 使用<code>Matcher</code>时，必须首先调用<code>matches()</code>判断是否匹配成功，匹配成功后，才能调用<code>group()</code>提取子串。</p>
<p>​ 利用提取子串的功能，我们轻松获得了区号和号码两部分。</p>
<h3 id="五非贪婪匹配">五、非贪婪匹配：</h3>
<p>先看一个简单的问题：</p>
<p>给定一个字符串表示的数字，判断该数字末尾<code>0</code>的个数。例如：</p>
<ul>
<li><code>"123000"</code>：3个<code>0</code></li>
<li><code>"10100"</code>：2个<code>0</code></li>
<li><code>"1001"</code>：0个<code>0</code></li>
</ul>
<p>可以很容易地写出该正则表达式：<code>(\d+)(0*)</code>，Java代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Pattern pattern = Pattern.compile(<span class="string">&quot;(\\d+)(0*)&quot;</span>);</span><br><span class="line">        Matcher matcher = pattern.matcher(<span class="string">&quot;1230000&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (matcher.matches()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;group1=&quot;</span> + matcher.group(<span class="number">1</span>)); <span class="comment">// &quot;1230000&quot;</span></span><br><span class="line">            System.out.println(<span class="string">&quot;group2=&quot;</span> + matcher.group(<span class="number">2</span>)); <span class="comment">// &quot;&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>然而打印的第二个子串是空字符串<code>""</code>。</p>
<p>实际上，我们期望分组匹配结果是：</p>
<table>
<thead>
<tr class="header">
<th>input</th>
<th><code>\d+</code></th>
<th><code>0*</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>123000</td>
<td>"123"</td>
<td>"000"</td>
</tr>
<tr class="even">
<td>10100</td>
<td>"101"</td>
<td>"00"</td>
</tr>
<tr class="odd">
<td>1001</td>
<td>"1001"</td>
<td>""</td>
</tr>
</tbody>
</table>
<p>但实际的分组匹配结果是这样的：</p>
<table>
<thead>
<tr class="header">
<th>input</th>
<th><code>\d+</code></th>
<th><code>0*</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>123000</td>
<td>"123000"</td>
<td>""</td>
</tr>
<tr class="even">
<td>10100</td>
<td>"10100"</td>
<td>""</td>
</tr>
<tr class="odd">
<td>1001</td>
<td>"1001"</td>
<td>""</td>
</tr>
</tbody>
</table>
<p>​ 仔细观察上述实际匹配结果，实际上它是完全合理的，因为<code>\d+</code>确实可以匹配后面任意个<code>0</code>。</p>
<p>​ <strong>这是因为正则表达式默认使用贪婪匹配：任何一个规则，它总是尽可能多地向后匹配，因此，<code>\d+</code>总是会把后面的<code>0</code>包含进来。</strong></p>
<p>​ <strong>要让<code>\d+</code>尽量少匹配，让<code>0*</code>尽量多匹配，我们就必须让<code>\d+</code>使用非贪婪匹配。在规则<code>\d+</code>后面加个<code>?</code>即可表示非贪婪匹配。我们改写正则表达式如下：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Pattern pattern = Pattern.compile(<span class="string">&quot;(\\d+?)(0*)&quot;</span>);</span><br><span class="line">        Matcher matcher = pattern.matcher(<span class="string">&quot;1230000&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (matcher.matches()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;group1=&quot;</span> + matcher.group(<span class="number">1</span>)); <span class="comment">// &quot;123&quot;</span></span><br><span class="line">            System.out.println(<span class="string">&quot;group2=&quot;</span> + matcher.group(<span class="number">2</span>)); <span class="comment">// &quot;0000&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ <strong>因此，给定一个匹配规则，加上<code>?</code>后就变成了非贪婪匹配。</strong></p>
<p>​ <strong>我们再来看这个正则表达式<code>(\d??)(9*)</code>，注意<code>\d?</code>表示匹配0个或1个数字，后面第二个<code>?</code>表示非贪婪匹配，因此，给定字符串<code>"9999"</code>，匹配到的两个子串分别是<code>""</code>和<code>"9999"</code>，因为对于<code>\d?</code>来说，可以匹配1个<code>9</code>，也可以匹配0个<code>9</code>，但是因为后面的<code>?</code>表示非贪婪匹配，它就会尽可能少的匹配，结果是匹配了0个<code>9</code>。</strong></p>
<h3 id="六搜索和替换">六、搜索和替换：</h3>
<h4 id="分割字符串">1、分割字符串：</h4>
<p>​ 使用正则表达式分割字符串可以实现更加灵活的功能。<code>String.split()</code>方法传入的正是正则表达式。我们来看下面的代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;a b c&quot;.split(&quot;\\s&quot;); // &#123; &quot;a&quot;, &quot;b&quot;, &quot;c&quot; &#125;</span><br><span class="line">&quot;a b  c&quot;.split(&quot;\\s&quot;); // &#123; &quot;a&quot;, &quot;b&quot;, &quot;&quot;, &quot;c&quot; &#125;</span><br><span class="line">&quot;a, b ;; c&quot;.split(&quot;[\\,\\;\\s]+&quot;); // &#123; &quot;a&quot;, &quot;b&quot;, &quot;c&quot; &#125;</span><br></pre></td></tr></table></figure>
<p>​ 如果我们想让用户输入一组标签，然后把标签提取出来，因为用户的输入往往是不规范的，这时，使用合适的正则表达式，就可以消除多个空格、混合<code>,</code>和<code>;</code>这些不规范的输入，直接提取出规范的字符串。</p>
<h4 id="搜索字符串">2、搜索字符串：</h4>
<p>​ 使用正则表达式还可以搜索字符串，我们来看例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String s = <span class="string">&quot;the quick brown fox jumps over the lazy dog.&quot;</span>;</span><br><span class="line">        Pattern p = Pattern.compile(<span class="string">&quot;\\wo\\w&quot;</span>);</span><br><span class="line">        Matcher m = p.matcher(s);</span><br><span class="line">        <span class="keyword">while</span> (m.find()) &#123;</span><br><span class="line">            String sub = s.substring(m.start(), m.end());</span><br><span class="line">            System.out.println(sub);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 我们获取到<code>Matcher</code>对象后，不需要调用<code>matches()</code>方法（因为匹配整个串肯定返回false），而是反复调用<code>find()</code>方法，在整个串中搜索能匹配上<code>\\wo\\w</code>规则的子串，并打印出来。<strong>这种方式比<code>String.indexOf()</code>要灵活得多，因为我们搜索的规则是3个字符：中间必须是<code>o</code>，前后两个必须是字符<code>[A-Za-z0-9_]</code>。</strong></p>
<h4 id="替换字符串">3、替换字符串：</h4>
<p>​ 使用正则表达式替换字符串可以直接调用<code>String.replaceAll()</code>，它的第一个参数是正则表达式，第二个参数是待替换的字符串。我们还是来看例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String s = <span class="string">&quot;The     quick\t\t brown   fox  jumps   over the  lazy dog.&quot;</span>;</span><br><span class="line">        String r = s.replaceAll(<span class="string">&quot;\\s+&quot;</span>, <span class="string">&quot; &quot;</span>);</span><br><span class="line">        System.out.println(r); <span class="comment">// &quot;The quick brown fox jumps over the lazy dog.&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记10——java单元测试JUnit</title>
    <url>/2022/02/02/97842fd619f0/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1304048154181666</p>
<h3 id="一编写junit测试">一、编写JUnit测试：</h3>
<h4 id="什么是测试驱动开发">1、什么是测试驱动开发？</h4>
<p>​ 所谓测试驱动开发，是指先编写接口，紧接着编写测试。编写完测试后，我们才开始真正编写实现代码。在编写实现代码的过程中，一边写，一边测，什么时候测试全部通过了，那就表示编写的实现完成了：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    编写接口</span><br><span class="line">     │</span><br><span class="line">     ▼</span><br><span class="line">    编写测试</span><br><span class="line">     │</span><br><span class="line">     ▼</span><br><span class="line">┌─&gt; 编写实现</span><br><span class="line">│    │</span><br><span class="line">│ N  ▼</span><br><span class="line">└── 运行测试</span><br><span class="line">     │ Y</span><br><span class="line">     ▼</span><br><span class="line">    任务完成</span><br></pre></td></tr></table></figure>
<h4 id="junit测试框架">2、JUnit测试框架：</h4>
<p>​ JUnit是一个开源的Java语言的单元测试框架，专门针对Java设计，使用最广泛。JUnit是事实上的单元测试的标准框架，任何Java开发者都应当学习并使用JUnit编写单元测试</p>
<p>​ 使用JUnit编写单元测试的好处在于，我们可以非常简单地组织测试代码，并随时运行它们，JUnit就会给出成功的测试和失败的测试，还可以生成测试报告，不仅包含测试的成功率，还可以统计测试的代码覆盖率，即被测试的代码本身有多少经过了测试。对于高质量的代码来说，测试覆盖率应该在80%以上。</p>
<h4 id="intellij中如何开启单元测试">3、IntelliJ中如何开启单元测试？</h4>
<p>​ 教程：https://blog.csdn.net/qq754772661/article/details/107790362</p>
<h4 id="单元测试文件怎么编写">4、单元测试文件怎么编写？</h4>
<p>​ 核心测试方法<code>testFact()</code>加上了<code>@Test</code>注解，这是JUnit要求的，它会把带有<code>@Test</code>的方法识别为测试方法。在测试方法内部，我们用<code>assertEquals(1, Factorial.fact(1))</code>表示，期望<code>Factorial.fact(1)</code>返回<code>1</code>。<code>assertEquals(expected, actual)</code>是最常用的测试方法，它在<code>Assertion</code>类中定义。<code>Assertion</code>还定义了其他断言方法，例如：</p>
<ul>
<li><code>assertTrue()</code>: 期待结果为<code>true</code></li>
<li><code>assertFalse()</code>: 期待结果为<code>false</code></li>
<li><code>assertNotNull()</code>: 期待结果为非<code>null</code></li>
<li><code>assertArrayEquals()</code>: 期待结果为数组并与期望数组每个元素的值均相等</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.itranswarp.learnjava;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.jupiter.api.Assertions.*;</span><br><span class="line"><span class="keyword">import</span> org.junit.jupiter.api.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FactorialTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">testFact</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        assertEquals(<span class="number">1</span>, Factorial.fact(<span class="number">1</span>));</span><br><span class="line">        assertEquals(<span class="number">2</span>, Factorial.fact(<span class="number">2</span>));</span><br><span class="line">        assertEquals(<span class="number">6</span>, Factorial.fact(<span class="number">3</span>));</span><br><span class="line">        assertEquals(<span class="number">3628800</span>, Factorial.fact(<span class="number">10</span>));</span><br><span class="line">        assertEquals(<span class="number">2432902008176640000L</span>, Factorial.fact(<span class="number">20</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编写完成后，在编译器内直接选择运行该文件即可。</p>
<h4 id="单元测试的结果">5、单元测试的结果：</h4>
<ul>
<li>如果全部通过测试：</li>
</ul>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_02_10_13_50_410.png" alt="屏幕捕获_2022_02_02_10_13_50_410" /><figcaption aria-hidden="true">屏幕捕获_2022_02_02_10_13_50_410</figcaption>
</figure>
<ul>
<li>如果有案例通不过测试：</li>
</ul>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_02_10_14_11_224.png" alt="屏幕捕获_2022_02_02_10_14_11_224" /><figcaption aria-hidden="true">屏幕捕获_2022_02_02_10_14_11_224</figcaption>
</figure>
<h4 id="单元测试的好处">6、单元测试的好处：</h4>
<p>​ 单元测试可以确保单个方法按照正确预期运行，如果修改了某个方法的代码，只需确保其对应的单元测试通过，即可认为改动正确。此外，测试代码本身就可以作为示例代码，用来演示如何调用该方法。</p>
<p>​ 使用JUnit进行单元测试，我们可以使用断言（<code>Assertion</code>）来测试期望结果，可以方便地组织和运行测试，并方便地查看测试结果。此外，<strong>JUnit既可以直接在IDE中运行，也可以方便地集成到Maven这些自动化工具中运行。</strong></p>
<p>在编写单元测试的时候，我们要遵循一定的规范：</p>
<p>​ 一是单元测试代码本身必须非常简单，能一下看明白，决不能再为测试代码编写测试；</p>
<p>​ 二是每个单元测试应当互相独立，不依赖运行的顺序；</p>
<p>​ <strong>三是测试时不但要覆盖常用测试用例，还要特别注意测试边界条件，例如输入为<code>0</code>，<code>null</code>，空字符串<code>""</code>等情况。</strong></p>
<h3 id="二使用fixture">二、使用Fixture</h3>
<p>​ 在一个单元测试中，我们经常编写多个<code>@Test</code>方法，来分组、分类对目标代码进行测试。在测试的时候，我们经常遇到一个对象需要初始化，测试完可能还需要清理的情况。如果每个<code>@Test</code>方法都写一遍这样的重复代码，显然比较麻烦。</p>
<p>​ <strong>JUnit提供了编写测试前准备、测试后清理的固定代码，我们称之为Fixture。</strong></p>
<ul>
<li>以下为要测试的代码：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Calculator</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> n = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">add</span><span class="params">(<span class="keyword">long</span> x)</span> </span>&#123;</span><br><span class="line">        n = n + x;</span><br><span class="line">        <span class="keyword">return</span> n;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">sub</span><span class="params">(<span class="keyword">long</span> x)</span> </span>&#123;</span><br><span class="line">        n = n - x;</span><br><span class="line">        <span class="keyword">return</span> n;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 这个类的功能很简单，但是测试的时候，我们要先初始化对象，我们不必在每个测试方法中都写上初始化代码，而是<strong>通过<code>@BeforeEach</code>来初始化，通过<code>@AfterEach</code>来清理资源：</strong>如下所示</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CalculatorTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Calculator calculator;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@BeforeEach</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.calculator = <span class="keyword">new</span> Calculator();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@AfterEach</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">tearDown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.calculator = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">testAdd</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        assertEquals(<span class="number">100</span>, <span class="keyword">this</span>.calculator.add(<span class="number">100</span>));</span><br><span class="line">        assertEquals(<span class="number">150</span>, <span class="keyword">this</span>.calculator.add(<span class="number">50</span>));</span><br><span class="line">        assertEquals(<span class="number">130</span>, <span class="keyword">this</span>.calculator.add(-<span class="number">20</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">testSub</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        assertEquals(-<span class="number">100</span>, <span class="keyword">this</span>.calculator.sub(<span class="number">100</span>));</span><br><span class="line">        assertEquals(-<span class="number">150</span>, <span class="keyword">this</span>.calculator.sub(<span class="number">50</span>));</span><br><span class="line">        assertEquals(-<span class="number">130</span>, <span class="keyword">this</span>.calculator.sub(-<span class="number">20</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 还有一些资源初始化和清理可能更加繁琐，而且会耗费较长的时间，例如初始化数据库。**JUnit还提供了<code>@BeforeAll</code>和<code>@AfterAll</code>，它们在运行所有@Test前后运行。</p>
<p>​ 因为<code>@BeforeAll</code>和<code>@AfterAll</code>在所有<code>@Test</code>方法运行前后仅运行一次，因此，它们只能初始化静态变量。</p>
<p><strong>事实上，<code>@BeforeAll</code>和<code>@AfterAll</code>也只能标注在静态方法上。</strong></p>
<p><strong>因此，我们总结出编写Fixture的套路如下：</strong></p>
<ol type="1">
<li>对于实例变量，在<code>@BeforeEach</code>中初始化，在<code>@AfterEach</code>中清理，它们在各个<code>@Test</code>方法中互不影响，因为是不同的实例；</li>
<li>对于静态变量，在<code>@BeforeAll</code>中初始化，在<code>@AfterAll</code>中清理，它们在各个<code>@Test</code>方法中均是唯一实例，会影响各个<code>@Test</code>方法。</li>
</ol>
<p>​ 大多数情况下，使用<code>@BeforeEach</code>和<code>@AfterEach</code>就足够了。只有某些测试资源初始化耗费时间太长，以至于我们不得不尽量“复用”时才会用到<code>@BeforeAll</code>和<code>@AfterAll</code>。</p>
<p>​ <strong>最后，注意到每次运行一个<code>@Test</code>方法前，JUnit首先创建一个<code>XxxTest</code>实例，因此，每个<code>@Test</code>方法内部的成员变量都是独立的，不能也无法把成员变量的状态从一个<code>@Test</code>方法带到另一个<code>@Test</code>方法。</strong></p>
<h3 id="三异常测试">三、异常测试：</h3>
<p>​ 对于可能抛出的异常进行测试，本身就是测试的重要环节。在编写JUnit测试的时候，除了正常的输入输出，我们还要特别针对可能导致异常的情况进行测试。示例如下：</p>
<ul>
<li>被测试代码如下：在方法入口，我们增加了对参数<code>n</code>的检查，如果为负数，则直接抛出<code>IllegalArgumentException</code>。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Factorial</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">fact</span><span class="params">(<span class="keyword">long</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (n &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> r = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">long</span> i = <span class="number">1</span>; i &lt;= n; i++) &#123;</span><br><span class="line">            r = r * i;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> r;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>测试代码：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testNegative</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    assertThrows(IllegalArgumentException.class, () -&gt; &#123;</span><br><span class="line">        Factorial.fact(-<span class="number">1</span>);</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="四条件测试">四、条件测试：</h3>
<h4 id="disabled">1、<span class="citation" data-cites="Disabled">@Disabled</span></h4>
<p>​ 在运行测试的时候，有些时候，我们需要排出某些<code>@Test</code>方法，不要让它运行，这时，我们就可以给它标记一个<code>@Disabled</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Disabled</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testBug101</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 这个测试不会运行</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 为什么我们不直接注释掉<code>@Test</code>，而是要加一个<code>@Disabled</code>？这是因为注释掉<code>@Test</code>，JUnit就不知道这是个测试方法，而加上<code>@Disabled</code>，JUnit仍然识别出这是个测试方法，只是暂时不运行。它会在测试结果中显示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Tests run: 68, Failures: 2, Errors: 0, Skipped: 5</span><br></pre></td></tr></table></figure>
<p>​ 类似<code>@Disabled</code>这种注解就称为条件测试，JUnit根据不同的条件注解，决定是否运行当前的<code>@Test</code>方法。</p>
<h4 id="enabledonos">2、<span class="citation" data-cites="EnabledOnOs">@EnabledOnOs</span></h4>
<p>给两个测试方法分别加上条件如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="meta">@EnabledOnOs(OS.WINDOWS)</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testWindows</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    assertEquals(<span class="string">&quot;C:\\test.ini&quot;</span>, config.getConfigFile(<span class="string">&quot;test.ini&quot;</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="meta">@EnabledOnOs(&#123; OS.LINUX, OS.MAC &#125;)</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testLinuxAndMac</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    assertEquals(<span class="string">&quot;/usr/local/test.cfg&quot;</span>, config.getConfigFile(<span class="string">&quot;test.cfg&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>@EnableOnOs</code>就是一个条件测试判断。</p>
<p>在Windows平台执行的测试: <span class="citation" data-cites="EnabledOnOs">@EnabledOnOs</span>(OS.WINDOWS)</p>
<h4 id="其他条件测试">3、其他条件测试：</h4>
<p>只能在Java 9或更高版本执行的测试，可以加上<code>@DisabledOnJre(JRE.JAVA_8)</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="meta">@DisabledOnJre(JRE.JAVA_8)</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testOnJava9OrAbove</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> this test is disabled on java 8</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>只能在64位操作系统上执行的测试，可以用<code>@EnabledIfSystemProperty</code>判断：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="meta">@EnabledIfSystemProperty(named = &quot;os.arch&quot;, matches = &quot;.*64.*&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testOnlyOn64bitSystem</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> this test is only run on 64 bit system</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>需要传入环境变量<code>DEBUG=true</code>才能执行的测试，可以用<code>@EnabledIfEnvironmentVariable</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="meta">@EnabledIfEnvironmentVariable(named = &quot;DEBUG&quot;, matches = &quot;true&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testOnlyOnDebugMode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> this test is only run on DEBUG=true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="五参数化测试">五、参数化测试：</h3>
<p>如果待测试的输入和输出是一组数据： 可以把测试数据组织起来 用不同的测试数据调用相同的测试方法</p>
<p>参数化测试和普通测试稍微不同的地方在于，一个测试方法需要接收至少一个参数，然后，传入一组参数反复运行。</p>
<p>JUnit提供了一个<code>@ParameterizedTest</code>注解，用来进行参数化测试。</p>
<p>假设我们想对<code>Math.abs()</code>进行测试，先用一组正数进行测试：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ParameterizedTest</span></span><br><span class="line"><span class="meta">@ValueSource(ints = &#123; 0, 1, 5, 100 &#125;)</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testAbs</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">    assertEquals(x, Math.abs(x));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再用一组负数进行测试：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ParameterizedTest</span></span><br><span class="line"><span class="meta">@ValueSource(ints = &#123; -1, -5, -100 &#125;)</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testAbsNegative</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">    assertEquals(-x, Math.abs(x));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意到参数化测试的注解是<code>@ParameterizedTest</code>，而不是普通的<code>@Test</code>。</p>
<p>实际的测试场景往往没有这么简单。假设我们自己编写了一个<code>StringUtils.capitalize()</code>方法，它会把字符串的第一个字母变为大写，后续字母变为小写：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringUtils</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">capitalize</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (s.length() == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> s;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Character.toUpperCase(s.charAt(<span class="number">0</span>)) + s.substring(<span class="number">1</span>).toLowerCase();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>要用参数化测试的方法来测试，我们不但要给出输入，还要给出预期输出。因此，测试方法至少需要接收两个参数：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ParameterizedTest</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testCapitalize</span><span class="params">(String input, String result)</span> </span>&#123;</span><br><span class="line">    assertEquals(result, StringUtils.capitalize(input));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>现在问题来了：参数如何传入？</p>
<p>最简单的方法是通过<code>@MethodSource</code>注解，它允许我们编写一个同名的静态方法来提供测试参数：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ParameterizedTest</span></span><br><span class="line"><span class="meta">@MethodSource</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testCapitalize</span><span class="params">(String input, String result)</span> </span>&#123;</span><br><span class="line">    assertEquals(result, StringUtils.capitalize(input));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> List&lt;Arguments&gt; <span class="title">testCapitalize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> List.of( <span class="comment">// arguments:</span></span><br><span class="line">            Arguments.arguments(<span class="string">&quot;abc&quot;</span>, <span class="string">&quot;Abc&quot;</span>), <span class="comment">//</span></span><br><span class="line">            Arguments.arguments(<span class="string">&quot;APPLE&quot;</span>, <span class="string">&quot;Apple&quot;</span>), <span class="comment">//</span></span><br><span class="line">            Arguments.arguments(<span class="string">&quot;gooD&quot;</span>, <span class="string">&quot;Good&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码很容易理解：静态方法<code>testCapitalize()</code>返回了一组测试参数，每个参数都包含两个<code>String</code>，正好作为测试方法的两个参数传入。</p>
<p>如果静态方法和测试方法的名称不同，<span class="citation" data-cites="MethodSource也允许指定方法名">@MethodSource也允许指定方法名</span>。但使用默认同名方法最方便。</p>
<p>另一种传入测试参数的方法是使用<code>@CsvSource</code>，它的每一个字符串表示一行，一行包含的若干参数用<code>,</code>分隔，因此，上述测试又可以改写如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ParameterizedTest</span></span><br><span class="line"><span class="meta">@CsvSource(&#123; &quot;abc, Abc&quot;, &quot;APPLE, Apple&quot;, &quot;gooD, Good&quot; &#125;)</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testCapitalize</span><span class="params">(String input, String result)</span> </span>&#123;</span><br><span class="line">    assertEquals(result, StringUtils.capitalize(input));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果有成百上千的测试输入，那么，直接写<code>@CsvSource</code>就很不方便。这个时候，我们可以把测试数据提到一个独立的CSV文件中，然后标注上<code>@CsvFileSource</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ParameterizedTest</span></span><br><span class="line"><span class="meta">@CsvFileSource(resources = &#123; &quot;/test-capitalize.csv&quot; &#125;)</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">testCapitalizeUsingCsvFile</span><span class="params">(String input, String result)</span> </span>&#123;</span><br><span class="line">    assertEquals(result, StringUtils.capitalize(input));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>JUnit只在classpath中查找指定的CSV文件，因此，<code>test-capitalize.csv</code>这个文件要放到<code>test</code>目录下，内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apple, Apple</span><br><span class="line">HELLO, Hello</span><br><span class="line">JUnit, Junit</span><br><span class="line">reSource, Resource</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记9——java 日期与时间（更新中）</title>
    <url>/2022/02/01/b8491ebfdd3e/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1298613246361634</p>
<h3 id="一基本概念">一、基本概念：</h3>
<h4 id="本地时间">1、本地时间</h4>
<p>​ 不同的时区，在同一时刻，本地时间是不同的。全球一共分为24个时区，<strong>伦敦所在的时区称为标准时区，其他时区按东／西偏移的小时区分，北京所在的时区是东八区。</strong></p>
<h4 id="时区">2、时区</h4>
<p>​ 因为光靠本地时间还无法唯一确定一个准确的时刻，所以我们还需要给本地时间加上一个时区。时区有好几种表示方式。</p>
<p>​ 一种是以<code>GMT</code>或者<code>UTC</code>加时区偏移表示，例如：<code>GMT+08:00</code>或者<code>UTC+08:00</code>表示东八区。</p>
<p>​ <code>GMT</code>和<code>UTC</code>可以认为基本是等价的，只是<code>UTC</code>使用更精确的原子钟计时，每隔几年会有一个闰秒，我们在开发程序的时候可以忽略两者的误差，因为计算机的时钟在联网的时候会自动与时间服务器同步时间。</p>
<p>​ 另一种是缩写，例如，<code>CST</code>表示<code>China Standard Time</code>，也就是中国标准时间。但是<code>CST</code>也可以表示美国中部时间<code>Central Standard Time USA</code>，因此，缩写容易产生混淆，我们尽量不要使用缩写。</p>
<p>​ 最后一种是以洲／城市表示，例如，<code>Asia/Shanghai</code>，表示上海所在地的时区。特别注意城市名称不是任意的城市，而是由国际标准组织规定的城市。</p>
<p>​ 因为时区的存在，东八区的2019年11月20日早上8:15，和西五区的2019年11月19日晚上19:15，他们的时刻是相同的</p>
<h4 id="夏令时">3、夏令时</h4>
<p>​ 时区还不是最复杂的，更复杂的是夏令时。所谓夏令时，就是夏天开始的时候，把时间往后拨1小时，夏天结束的时候，再把时间往前拨1小时。</p>
<p>​ 因为涉及到夏令时，相同的时区，如果表示的方式不同，转换出的时间是不同的。我们举个栗子：</p>
<p>对于2019-11-20和2019-6-20两个日期来说，假设北京人在纽约：</p>
<ul>
<li>如果以<code>GMT</code>或者<code>UTC</code>作为时区，无论日期是多少，时间都是<code>19:00</code>；</li>
<li>如果以国家／城市表示，例如<code>America／NewYork</code>，虽然纽约也在西五区，但是，因为夏令时的存在，在不同的日期，<code>GMT</code>时间和纽约时间可能是不一样的：</li>
</ul>
<table>
<thead>
<tr class="header">
<th>时区</th>
<th>2019-11-20</th>
<th>2019-6-20</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>GMT-05:00</td>
<td>19:00</td>
<td>19:00</td>
</tr>
<tr class="even">
<td>UTC-05:00</td>
<td>19:00</td>
<td>19:00</td>
</tr>
<tr class="odd">
<td>America/New_York</td>
<td>19:00</td>
<td>20:00</td>
</tr>
</tbody>
</table>
<p>​ 实行夏令时的不同地区，进入和退出夏令时的时间很可能是不同的。同一个地区，根据历史上是否实行过夏令时，标准时间在不同年份换算成当地时间也是不同的。因此，计算夏令时，没有统一的公式，必须按照一组给定的规则来算，并且，该规则要定期更新。</p>
<h4 id="本地化">4、本地化</h4>
<p>​ 在计算机中，通常使用<code>Locale</code>表示一个国家或地区的日期、时间、数字、货币等格式。<code>Locale</code>由<code>语言_国家</code>的字母缩写构成，例如，<code>zh_CN</code>表示中文+中国，<code>en_US</code>表示英文+美国。语言使用小写，国家使用大写。</p>
<p>对于日期来说，不同的Locale，例如，中国和美国的表示方式如下：</p>
<ul>
<li>zh_CN：2016-11-30</li>
<li>en_US：11/30/2016</li>
</ul>
<p>​ 计算机用<code>Locale</code>在日期、时间、货币和字符串之间进行转换。一个电商网站会根据用户所在的<code>Locale</code>对用户显示如下：</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>中国用户</th>
<th>美国用户</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>购买价格</td>
<td>12000.00</td>
<td>12,000.00</td>
</tr>
<tr class="even">
<td>购买日期</td>
<td>2016-11-30</td>
<td>11/30/2016</td>
</tr>
</tbody>
</table>
<h3 id="二date和calendar">二、Date和Calendar</h3>
<p>​ 这个“同一个时刻”在计算机中存储的本质上只是一个整数，我们称它为<code>Epoch Time</code></p>
<p>​ <code>Epoch Time</code>是计算从1970年1月1日零点（格林威治时区／GMT+00:00）到现在所经历的秒数，例如：</p>
<p>​ <code>1574208900</code>表示从从1970年1月1日零点GMT时区到该时刻一共经历了1574208900秒，换算成伦敦、北京和纽约时间分别是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1574208900 = 北京时间2019-11-20 8:15:00</span><br><span class="line">           = 伦敦时间2019-11-20 0:15:00</span><br><span class="line">           = 纽约时间2019-11-19 19:15:00</span><br></pre></td></tr></table></figure>
<p><code>Epoch Time</code>又称为时间戳，在不同的编程语言中，会有几种存储方式：</p>
<ul>
<li>以秒为单位的整数：1574208900，缺点是精度只能到秒；</li>
<li>以毫秒为单位的整数：1574208900123，最后3位表示毫秒数；</li>
<li>以秒为单位的浮点数：1574208900.123，小数点后面表示零点几秒。</li>
</ul>
<p><strong>在Java程序中，时间戳通常是用<code>long</code>表示的毫秒数，即：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">long t = 1574208900123L;</span><br></pre></td></tr></table></figure>
<p><strong>转换成北京时间就是<code>2019-11-20T8:15:00.123</code>。要获取当前时间戳，可以使用<code>System.currentTimeMillis()</code>，这是Java程序获取时间戳最常用的方法。</strong></p>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记8——java IO模块（更新中）</title>
    <url>/2022/02/01/2bb58d7c96cc/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1255945227202752</p>
<h3 id="一简介">一、简介：</h3>
<p>​ 在Java中，<code>InputStream</code>代表输入字节流，<code>OuputStream</code>代表输出字节流，这是最基本的两种IO流。</p>
<p>​ 如果我们需要读写的是字符，并且字符不全是单字节表示的ASCII字符，那么，按照<code>char</code>来读写显然更方便，这种流称为<em>字符流</em>。</p>
<p>​ Java提供了<code>Reader</code>和<code>Writer</code>表示字符流，字符流传输的最小数据单位是<code>char</code>。</p>
<p>​ <code>Reader</code>和<code>Writer</code><strong>本质上是一个能自动编解码的<code>InputStream</code>和<code>OutputStream</code></strong>。</p>
<p>​ <strong>使用<code>Reader</code>，数据源虽然是字节，但我们读入的数据都是<code>char</code>类型的字符，原因是<code>Reader</code>内部把读入的<code>byte</code>做了解码，转换成了<code>char</code>。</strong></p>
<p>​ <strong>使用<code>InputStream</code>，我们读入的数据和原始二进制数据一模一样，是<code>byte[]</code>数组</strong>，但是我们可以自己把二进制<code>byte[]</code>数组按照某种编码转换为字符串。</p>
<h3 id="二file对象">二、File对象：</h3>
<h4 id="构造file对象">1、构造File对象</h4>
<p>​ Java的标准库<code>java.io</code>提供了<code>File</code>对象来操作文件和目录。</p>
<p>​ 要构造一个<code>File</code>对象，需要传入文件路径：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        File f = <span class="keyword">new</span> File(<span class="string">&quot;C:\\Windows\\notepad.exe&quot;</span>);</span><br><span class="line">        System.out.println(f);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="file对象有3种形式表示的路径">2、File对象有3种形式表示的路径</h4>
<ul>
<li><code>getPath()</code>，返回构造方法传入的路径</li>
<li><code>getAbsolutePath()</code>，返回绝对路径</li>
<li><code>getCanonicalPath</code>，它和绝对路径类似，但是返回的是规范路径。</li>
</ul>
<p><strong>什么是规范路径？</strong></p>
<p>​ 绝对路径可以表示成<code>C:\Windows\System32\..\notepad.exe</code>，而<strong>规范路径就是把<code>.</code>和<code>..</code>转换成标准的绝对路径后的路径</strong>：<code>C:\Windows\notepad.exe</code>。</p>
<h4 id="文件和目录">3、文件和目录：</h4>
<p>​ <code>File</code>对象既可以表示文件，也可以表示目录。特别要注意的是，<strong>构造一个<code>File</code>对象，即使传入的文件或目录不存在，代码也不会出错</strong>，因为构造一个<code>File</code>对象，并不会导致任何磁盘操作。<strong>只有当我们调用<code>File</code>对象的某些方法的时候，才真正进行磁盘操作</strong>。</p>
<ul>
<li><code>isFile()</code>，判断该<code>File</code>对象是否是一个已存在的文件</li>
<li><code>isDirectory()</code>，判断该<code>File</code>对象是否是一个已存在的目录：</li>
</ul>
<p><strong>用<code>File</code>对象获取到一个文件时，还可以进一步判断文件的权限和大小：</strong></p>
<ul>
<li><code>boolean canRead()</code>：是否可读；</li>
<li><code>boolean canWrite()</code>：是否可写；</li>
<li><code>boolean canExecute()</code>：是否可执行；</li>
<li><code>long length()</code>：文件字节大小。</li>
</ul>
<p>对目录而言，是否可执行表示能否列出它包含的文件和子目录。</p>
<h4 id="创建和删除文件">4、创建和删除文件：</h4>
<p>​ 当File对象表示一个文件时，可以通过<code>createNewFile()</code>创建一个新文件，用<code>delete()</code>删除该文件：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">File file = <span class="keyword">new</span> File(<span class="string">&quot;/path/to/file&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (file.createNewFile()) &#123;</span><br><span class="line">    <span class="comment">// 文件创建成功:</span></span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span></span></span><br><span class="line">    <span class="keyword">if</span> (file.delete()) &#123;</span><br><span class="line">        <span class="comment">// 删除文件成功:</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 有些时候，程序需要读写一些临时文件，<strong>File对象提供了<code>createTempFile()</code>来创建一个临时文件</strong>，以及<code>deleteOnExit()</code>在JVM退出时自动删除该文件。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        File f = File.createTempFile(<span class="string">&quot;tmp-&quot;</span>, <span class="string">&quot;.txt&quot;</span>); <span class="comment">// 提供临时文件的前缀和后缀</span></span><br><span class="line">        f.deleteOnExit(); <span class="comment">// JVM退出时自动删除</span></span><br><span class="line">        System.out.println(f.isFile());</span><br><span class="line">        System.out.println(f.getAbsolutePath());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="遍历文件和目录">5、遍历文件和目录：</h4>
<p>​ 当File对象表示一个目录时，可以使用<code>list()</code>和<code>listFiles()</code>列出目录下的文件和子目录名。<code>listFiles()</code>提供了一系列重载方法，可以过滤不想要的文件和目录：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        File f = <span class="keyword">new</span> File(<span class="string">&quot;C:\\Windows&quot;</span>);</span><br><span class="line">        File[] fs1 = f.listFiles(); <span class="comment">// 列出所有文件和子目录</span></span><br><span class="line">        printFiles(fs1);</span><br><span class="line">        File[] fs2 = f.listFiles(<span class="keyword">new</span> FilenameFilter() &#123; <span class="comment">// 仅列出.exe文件</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">accept</span><span class="params">(File dir, String name)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> name.endsWith(<span class="string">&quot;.exe&quot;</span>); <span class="comment">// 返回true表示接受该文件</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        printFiles(fs2);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">printFiles</span><span class="params">(File[] files)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;==========&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (files != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (File f : files) &#123;</span><br><span class="line">                System.out.println(f);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;==========&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>和文件操作类似，File对象如果表示一个目录，可以通过以下方法创建和删除目录：</p>
<ul>
<li><code>boolean mkdir()</code>：创建当前File对象表示的目录；</li>
<li><code>boolean mkdirs()</code>：创建当前File对象表示的目录，并在必要时将不存在的父目录也创建出来；</li>
<li><code>boolean delete()</code>：删除当前File对象表示的目录，当前目录必须为空才能删除成功。</li>
</ul>
<h4 id="path对象">6、path对象：</h4>
<p>​ Java标准库还提供了一个<code>Path</code>对象，它位于<code>java.nio.file</code>包。<code>Path</code>对象和<code>File</code>对象类似，但操作更加简单：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        Path p1 = Paths.get(<span class="string">&quot;.&quot;</span>, <span class="string">&quot;project&quot;</span>, <span class="string">&quot;study&quot;</span>); <span class="comment">// 构造一个Path对象</span></span><br><span class="line">        System.out.println(p1);</span><br><span class="line">        Path p2 = p1.toAbsolutePath(); <span class="comment">// 转换为绝对路径</span></span><br><span class="line">        System.out.println(p2);</span><br><span class="line">        Path p3 = p2.normalize(); <span class="comment">// 转换为规范路径</span></span><br><span class="line">        System.out.println(p3);</span><br><span class="line">        File f = p3.toFile(); <span class="comment">// 转换为File对象</span></span><br><span class="line">        System.out.println(f);</span><br><span class="line">        <span class="keyword">for</span> (Path p : Paths.get(<span class="string">&quot;..&quot;</span>).toAbsolutePath()) &#123; <span class="comment">// 可以直接遍历Path</span></span><br><span class="line">            System.out.println(<span class="string">&quot;  &quot;</span> + p);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="三inputstream-和-outputstream">三、InputStream 和 OutputStream</h3>
<h4 id="inputstream">1、InputStream</h4>
<p>​ <code>InputStream</code>就是Java标准库提供的最基本的输入流。它位于<code>java.io</code>这个包里。<code>java.io</code>包提供了所有同步IO的功能。</p>
<p>​ <code>InputStream</code>并不是一个接口，而是一个抽象类，它是所有输入流的超类。这个抽象类定义的一个最重要的方法就是<code>int read()</code>，签名如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public abstract int read() throws IOException;</span><br></pre></td></tr></table></figure>
<p>​ 这个方法会读取输入流的下一个字节，并返回字节表示的<code>int</code>值（0~255）。如果已读到末尾，返回<code>-1</code>表示不能继续读取了。</p>
<h4 id="fileinputstream">2、FileInputStream</h4>
<p>​ <code>FileInputStream</code>是<code>InputStream</code>的一个子类。顾名思义，<code>FileInputStream</code>就是从文件流中读取数据。下面的代码演示了如何完整地读取一个<code>FileInputStream</code>的所有字节</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 创建一个FileInputStream对象:</span></span><br><span class="line">    InputStream input = <span class="keyword">new</span> FileInputStream(<span class="string">&quot;src/readme.txt&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">int</span> n = input.read(); <span class="comment">// 反复调用read()方法，直到返回-1</span></span><br><span class="line">        <span class="keyword">if</span> (n == -<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(n); <span class="comment">// 打印byte的值</span></span><br><span class="line">    &#125;</span><br><span class="line">    input.close(); <span class="comment">// 关闭流, InputStream和OutputStream都是通过close()方法来关闭流。关闭流就会释放对应的底层资源。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 我们还要注意到在读取或写入IO流的过程中，可能会发生错误，例如，文件不存在导致无法读取，没有写权限导致写入失败，等等，这些底层错误由Java虚拟机自动封装成<code>IOException</code>异常并抛出。因此，所有与IO操作相关的代码都必须正确处理<code>IOException</code>。</p>
<p>​ <strong>我们可以利用Java 7引入的新的<code>try(resource)</code>的语法</strong>，只需要编写<code>try</code>语句，让编译器自动为我们关闭资源。推荐的写法如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> (InputStream input = <span class="keyword">new</span> FileInputStream(<span class="string">&quot;src/readme.txt&quot;</span>)) &#123;</span><br><span class="line">        <span class="keyword">int</span> n;</span><br><span class="line">        <span class="keyword">while</span> ((n = input.read()) != -<span class="number">1</span>) &#123;</span><br><span class="line">            System.out.println(n);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="comment">// 编译器在此自动为我们写入finally并调用close()</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 实际上，编译器并不会特别地为<code>InputStream</code>加上自动关闭。<strong>编译器只看<code>try(resource = ...)</code>中的对象是否实现了<code>java.lang.AutoCloseable</code>接口</strong>，如果实现了，就自动加上<code>finally</code>语句并调用<code>close()</code>方法。<code>InputStream</code>和<code>OutputStream</code>都实现了这个接口，因此，都可以用在<code>try(resource)</code>中。</p>
<h4 id="缓冲区读取数据">3、缓冲区读取数据</h4>
<p>​ 在读取流的时候，一次读取一个字节并不是最高效的方法。很多流支持一次性读取多个字节到缓冲区，对于文件和网络流来说，利用缓冲区一次性读取多个字节效率往往要高很多。<code>InputStream</code>提供了两个重载方法来支持读取多个字节：</p>
<ul>
<li><code>int read(byte[] b)</code>：读取若干字节并填充到<code>byte[]</code>数组，返回读取的字节数</li>
<li><code>int read(byte[] b, int off, int len)</code>：指定<code>byte[]</code>数组的偏移量和最大填充数</li>
</ul>
<p>​ 利用上述方法一次读取多个字节时，需要先定义一个<code>byte[]</code>数组作为缓冲区，<code>read()</code>方法会尽可能多地读取字节到缓冲区， 但不会超过缓冲区的大小。<code>read()</code>方法的返回值不再是字节的<code>int</code>值，而是返回实际读取了多少个字节。如果返回<code>-1</code>，表示没有更多的数据了。</p>
<p>利用缓冲区一次读取多个字节的代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> (InputStream input = <span class="keyword">new</span> FileInputStream(<span class="string">&quot;src/readme.txt&quot;</span>)) &#123;</span><br><span class="line">        <span class="comment">// 定义1000个字节大小的缓冲区:</span></span><br><span class="line">        <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1000</span>];</span><br><span class="line">        <span class="keyword">int</span> n;</span><br><span class="line">        <span class="keyword">while</span> ((n = input.read(buffer)) != -<span class="number">1</span>) &#123; <span class="comment">// 读取到缓冲区</span></span><br><span class="line">            System.out.println(<span class="string">&quot;read &quot;</span> + n + <span class="string">&quot; bytes.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="阻塞">4、阻塞</h4>
<p>​ 在调用<code>InputStream</code>的<code>read()</code>方法读取数据时，我们说<code>read()</code>方法是阻塞（Blocking）的。它的意思是，对于下面的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> n;</span><br><span class="line">n = input.read(); <span class="comment">// 必须等待read()方法返回才能执行下一行代码</span></span><br><span class="line"><span class="keyword">int</span> m = n;</span><br></pre></td></tr></table></figure>
<p>​ 执行到第二行代码时，必须等<code>read()</code>方法返回后才能继续。因为读取IO流相比执行普通代码，速度会慢很多，因此，无法确定<code>read()</code>方法调用到底要花费多长时间。</p>
<h3 id="四outputstream">四、OutputStream</h3>
<h4 id="介绍">1、介绍</h4>
<p>​ 和<code>InputStream</code>类似，<code>OutputStream</code>也是抽象类，它是所有输出流的超类。这个抽象类定义的一个最重要的方法就是<code>void write(int b)</code>，签名如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">int</span> b)</span> <span class="keyword">throws</span> IOException</span>;</span><br></pre></td></tr></table></figure>
<p>​ 这个方法会<strong>写入一个字节到输出流</strong>。要注意的是，虽然传入的是<code>int</code>参数，但只会写入一个字节，即只写入<code>int</code>最低8位表示字节的部分（相当于<code>b &amp; 0xff</code>）。</p>
<h4 id="flush方法">2、Flush方法</h4>
<p>​ 要特别注意：<code>OutputStream</code>还提供了一个<code>flush()</code>方法，它的目的是将缓冲区的内容真正输出到目的地。</p>
<p>​ 为什么要有<code>flush()</code>？因为向磁盘、网络写入数据的时候，出于效率的考虑，操作系统并不是输出一个字节就立刻写入到文件或者发送到网络，而是把输出的字节先放到内存的一个缓冲区里（本质上就是一个<code>byte[]</code>数组），等到缓冲区写满了，再一次性写入文件或者网络。对于很多IO设备来说，一次写一个字节和一次写1000个字节，花费的时间几乎是完全一样的，所以<code>OutputStream</code>有个<code>flush()</code>方法，能强制把缓冲区内容输出。</p>
<p>​ 通常情况下，我们不需要调用这个<code>flush()</code>方法，因为缓冲区写满了<code>OutputStream</code>会自动调用它，并且，在调用<code>close()</code>方法关闭<code>OutputStream</code>之前，也会自动调用<code>flush()</code>方法。</p>
<p>​ <strong>但是，在某些情况下，我们必须手动调用<code>flush()</code>方法。举个栗子：</strong></p>
<p>​ 小明正在开发一款在线聊天软件，当用户输入一句话后，就通过<code>OutputStream</code>的<code>write()</code>方法写入网络流。小明测试的时候发现，发送方输入后，接收方根本收不到任何信息，怎么肥四？</p>
<p>​ 原因就在于写入网络流是先写入内存缓冲区，等缓冲区满了才会一次性发送到网络。如果缓冲区大小是4K，则发送方要敲几千个字符后，操作系统才会把缓冲区的内容发送出去，这个时候，接收方会一次性收到大量消息。</p>
<p>​ 解决办法就是每输入一句话后，立刻调用<code>flush()</code>，不管当前缓冲区是否已满，强迫操作系统把缓冲区的内容立刻发送出去。</p>
<h4 id="将若干个字节写入文件流-示例">3、将若干个字节写入文件流 示例：</h4>
<p>​ 我们以<code>FileOutputStream</code>为例，演示如何将若干个字节写入文件流：</p>
<p>​ 每次写入一个字节非常麻烦，更常见的方法是一次性写入若干字节。这时，可以用<code>OutputStream</code>提供的重载方法<code>void write(byte[])</code>来实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    OutputStream output = <span class="keyword">new</span> FileOutputStream(<span class="string">&quot;out/readme.txt&quot;</span>);</span><br><span class="line">    output.write(<span class="string">&quot;Hello&quot;</span>.getBytes(<span class="string">&quot;UTF-8&quot;</span>)); <span class="comment">// Hello</span></span><br><span class="line">    output.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 和<code>InputStream</code>一样，上述代码没有考虑到在发生异常的情况下如何正确地关闭资源。写入过程也会经常发生IO错误，例如，磁盘已满，无权限写入等等。我们需要用<code>try(resource)</code>来保证<code>OutputStream</code>在无论是否发生IO错误的时候都能够正确地关闭：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeFile</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> (OutputStream output = <span class="keyword">new</span> FileOutputStream(<span class="string">&quot;out/readme.txt&quot;</span>)) &#123;</span><br><span class="line">        output.write(<span class="string">&quot;Hello&quot;</span>.getBytes(<span class="string">&quot;UTF-8&quot;</span>)); <span class="comment">// Hello</span></span><br><span class="line">    &#125; <span class="comment">// 编译器在此自动为我们写入finally并调用close()</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="四阻塞">四、阻塞</h4>
<p>和<code>InputStream</code>一样，<code>OutputStream</code>的<code>write()</code>方法也是阻塞的。</p>
<h3 id="五filter模式">五、Filter模式</h3>
<h3 id="六操作zip">六、操作Zip</h3>
<p><code>ZipInputStream</code>是一种<code>FilterInputStream</code>，它可以直接读取zip包的内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">┌───────────────────┐</span><br><span class="line">│    InputStream    │</span><br><span class="line">└───────────────────┘</span><br><span class="line">          ▲</span><br><span class="line">          │</span><br><span class="line">┌───────────────────┐</span><br><span class="line">│ FilterInputStream │</span><br><span class="line">└───────────────────┘</span><br><span class="line">          ▲</span><br><span class="line">          │</span><br><span class="line">┌───────────────────┐</span><br><span class="line">│InflaterInputStream│</span><br><span class="line">└───────────────────┘</span><br><span class="line">          ▲</span><br><span class="line">          │</span><br><span class="line">┌───────────────────┐</span><br><span class="line">│  ZipInputStream   │</span><br><span class="line">└───────────────────┘</span><br><span class="line">          ▲</span><br><span class="line">          │</span><br><span class="line">┌───────────────────┐</span><br><span class="line">│  JarInputStream   │</span><br><span class="line">└───────────────────┘</span><br></pre></td></tr></table></figure>
<h4 id="读取zip包">1、读取Zip包：</h4>
<p>​ 我们要创建一个<code>ZipInputStream</code>，通常是传入一个<code>FileInputStream</code>作为数据源，然后，循环调用<code>getNextEntry()</code>，直到返回<code>null</code>，表示zip流结束。</p>
<p>​ 一个<code>ZipEntry</code>表示一个压缩文件或目录，如果是压缩文件，我们就用<code>read()</code>方法不断读取，直到返回<code>-1</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> (ZipInputStream zip = <span class="keyword">new</span> ZipInputStream(<span class="keyword">new</span> FileInputStream(...))) &#123;</span><br><span class="line">    ZipEntry entry = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">while</span> ((entry = zip.getNextEntry()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">        String name = entry.getName();</span><br><span class="line">        <span class="keyword">if</span> (!entry.isDirectory()) &#123;</span><br><span class="line">            <span class="keyword">int</span> n;</span><br><span class="line">            <span class="keyword">while</span> ((n = zip.read()) != -<span class="number">1</span>) &#123;</span><br><span class="line">                ...</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="写入zip包">2、写入Zip包：</h4>
<p><code>ZipOutputStream</code>是一种<code>FilterOutputStream</code>，它可以直接写入内容到zip包。我们要先创建一个<code>ZipOutputStream</code>，通常是包装一个<code>FileOutputStream</code>，然后，每写入一个文件前，先调用<code>putNextEntry()</code>，然后用<code>write()</code>写入<code>byte[]</code>数据，写入完毕后调用<code>closeEntry()</code>结束这个文件的打包。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> (ZipOutputStream zip = <span class="keyword">new</span> ZipOutputStream(<span class="keyword">new</span> FileOutputStream(...))) &#123;</span><br><span class="line">    File[] files = ...</span><br><span class="line">    <span class="keyword">for</span> (File file : files) &#123;</span><br><span class="line">        zip.putNextEntry(<span class="keyword">new</span> ZipEntry(file.getName()));</span><br><span class="line">        zip.write(getFileDataAsBytes(file));</span><br><span class="line">        zip.closeEntry();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码没有考虑文件的目录结构。如果要实现目录层次结构，<code>new ZipEntry(name)</code>传入的<code>name</code>要用相对路径。</p>
<h3 id="七读取classpath资源">七、读取classpath资源：</h3>
<h3 id="八序列化">八、序列化</h3>
<h3 id="九reader">九、Reader</h3>
<h3 id="十writer">十、Writer</h3>
<h3 id="十一printstream和printwriter">十一、PrintStream和PrintWriter</h3>
<h3 id="十二使用files">十二、使用Files</h3>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记7——java泛型（更新中）</title>
    <url>/2022/02/01/8b002b9e2dc6/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1264799402020448</p>
<h3 id="一泛型定义简介">一、泛型定义简介</h3>
<p>​ 泛型是一种“代码模板”，可以用一套代码套用各种类型。</p>
<p>​ 我们可以把<code>ArrayList</code>变成一种模板：<code>ArrayList&lt;T&gt;</code>，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ArrayList</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> T[] array;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> size;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(T e)</span> </span>&#123;...&#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;...&#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">get</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;...&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>T</code>可以是任何class。这样一来，我们就实现了：<strong>编写一次模版，可以创建任意类型的<code>ArrayList</code>：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建可以存储String的ArrayList:</span></span><br><span class="line">ArrayList&lt;String&gt; strList = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line"><span class="comment">// 创建可以存储Float的ArrayList:</span></span><br><span class="line">ArrayList&lt;Float&gt; floatList = <span class="keyword">new</span> ArrayList&lt;Float&gt;();</span><br><span class="line"><span class="comment">// 创建可以存储Person的ArrayList:</span></span><br><span class="line">ArrayList&lt;Person&gt; personList = <span class="keyword">new</span> ArrayList&lt;Person&gt;();</span><br></pre></td></tr></table></figure>
<p>​ 因此，<strong>泛型就是定义一种模板，例如<code>ArrayList&lt;T&gt;</code>，然后在代码中为用到的类创建对应的<code>ArrayList&lt;类型&gt;</code>：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ArrayList&lt;String&gt; strList = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>：注意泛型的继承关系：可以把<code>ArrayList&lt;Integer&gt;</code>向上转型为<code>List&lt;Integer&gt;</code>（<code>T</code>不能变！），但不能把<code>ArrayList&lt;Integer&gt;</code>向上转型为<code>ArrayList&lt;Number&gt;</code>（<code>T</code>不能变成父类）。</p>
<h3 id="二使用泛型">二、使用泛型</h3>
<h4 id="简写泛型">1、简写泛型：</h4>
<p>当我们定义泛型类型<code>&lt;Number&gt;</code>后，<code>List&lt;T&gt;</code>的泛型接口变为强类型<code>List&lt;Number&gt;</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Number&gt; list = <span class="keyword">new</span> ArrayList&lt;Number&gt;();</span><br><span class="line">list.add(<span class="keyword">new</span> Integer(<span class="number">123</span>));</span><br><span class="line">list.add(<span class="keyword">new</span> Double(<span class="number">12.34</span>));</span><br><span class="line">Number first = list.get(<span class="number">0</span>);</span><br><span class="line">Number second = list.get(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<p><strong>编译器如果能自动推断出泛型类型，就可以省略后面的泛型类型</strong>。例如，对于下面的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Number&gt; list = <span class="keyword">new</span> ArrayList&lt;Number&gt;();</span><br></pre></td></tr></table></figure>
<p>编译器看到泛型类型<code>List&lt;Number&gt;</code>就可以自动推断出后面的<code>ArrayList&lt;T&gt;</code>的泛型类型必须是<code>ArrayList&lt;Number&gt;</code>，因此，可以把代码简写为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 可以省略后面的Number，编译器可以自动推断泛型类型：</span></span><br><span class="line">List&lt;Number&gt; list = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br></pre></td></tr></table></figure>
<h4 id="使用泛型接口">2、使用泛型接口：</h4>
<p>​ 除了<code>ArrayList&lt;T&gt;</code>使用了泛型，还可以在接口中使用泛型。例如， <code>Arrays.sort(Object[])</code>可以对任意数组进行排序，但待排序的元素必须实现<code>Comparable&lt;T&gt;</code>这个泛型接口：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public interface Comparable&lt;T&gt; &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 返回负数: 当前实例比参数o小</span><br><span class="line">     * 返回0: 当前实例与参数o相等</span><br><span class="line">     * 返回正数: 当前实例比参数o大</span><br><span class="line">     */</span><br><span class="line">    int compareTo(T o);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 如下示例所示：实现对我们的自定义类Person的元素排序：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Person[] ps = <span class="keyword">new</span> Person[] &#123;</span><br><span class="line">            <span class="keyword">new</span> Person(<span class="string">&quot;Bob&quot;</span>, <span class="number">61</span>),</span><br><span class="line">            <span class="keyword">new</span> Person(<span class="string">&quot;Alice&quot;</span>, <span class="number">88</span>),</span><br><span class="line">            <span class="keyword">new</span> Person(<span class="string">&quot;Lily&quot;</span>, <span class="number">75</span>),</span><br><span class="line">        &#125;;</span><br><span class="line">        Arrays.sort(ps);</span><br><span class="line">        System.out.println(Arrays.toString(ps));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">Person</span>&gt; </span>&#123;</span><br><span class="line">    String name;</span><br><span class="line">    <span class="keyword">int</span> score;</span><br><span class="line">    Person(String name, <span class="keyword">int</span> score) &#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.score = score;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(Person other)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.name.compareTo(other.name);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.name + <span class="string">&quot;,&quot;</span> + <span class="keyword">this</span>.score;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 运行上述代码，可以正确实现按name进行排序。</span></span><br></pre></td></tr></table></figure>
<h3 id="三编写泛型">三、编写泛型</h3>
<h4 id="一般方法">1、一般方法：</h4>
<ul>
<li><p>首先，按照某种类型，例如：<code>String</code>，来编写类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Pair</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String first;</span><br><span class="line">    <span class="keyword">private</span> String last;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Pair</span><span class="params">(String first, String last)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.first = first;</span><br><span class="line">        <span class="keyword">this</span>.last = last;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getFirst</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> first;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getLast</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> last;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>然后，标记所有的特定类型，这里是<code>String</code>,并替换为T，并申明<code>&lt;T&gt;</code>：</p></li>
<li><p>``` public class Pair<T> { private T first; private T last; public Pair(T first, T last) { this.first = first; this.last = last; } public T getFirst() { return first; } public T getLast() { return last; } } <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- 熟练后即可直接从`T`开始编写。</span><br><span class="line"></span><br><span class="line">#### 2、静态方法：</span><br><span class="line"></span><br><span class="line">​	泛型类型`&lt;T&gt;`不能用于静态方法。</span><br><span class="line"></span><br><span class="line">​	对于静态方法，我们可以单独改写为“泛型”方法，只需要使用另一个类型即可。对于上面的`create()`静态方法，我们应该把它改为另一种泛型类型，例如，`&lt;K&gt;`：</span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line">public class Pair&lt;T&gt; &#123;</span><br><span class="line">    private T first;</span><br><span class="line">    private T last;</span><br><span class="line">    public Pair(T first, T last) &#123;</span><br><span class="line">        this.first = first;</span><br><span class="line">        this.last = last;</span><br><span class="line">    &#125;</span><br><span class="line">    public T getFirst() &#123; ... &#125;</span><br><span class="line">    public T getLast() &#123; ... &#125;</span><br><span class="line"></span><br><span class="line">    // 静态泛型方法应该使用其他类型区分:</span><br><span class="line">    public static &lt;K&gt; Pair&lt;K&gt; create(K first, K last) &#123;</span><br><span class="line">        return new Pair&lt;K&gt;(first, last);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<p>这样才能清楚地将静态方法的泛型类型和实例类型的泛型类型区分开。</p>
<h4 id="多个泛型的类型">3、多个泛型的类型：</h4>
<p>​ 泛型还可以定义多种类型。例如，我们希望<code>Pair</code>不总是存储两个类型一样的对象，就可以使用类型<code>&lt;T, K&gt;</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Pair</span>&lt;<span class="title">T</span>, <span class="title">K</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> T first;</span><br><span class="line">    <span class="keyword">private</span> K last;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Pair</span><span class="params">(T first, K last)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.first = first;</span><br><span class="line">        <span class="keyword">this</span>.last = last;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">getFirst</span><span class="params">()</span> </span>&#123; ... &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> K <span class="title">getLast</span><span class="params">()</span> </span>&#123; ... &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用的时候，需要指出两种类型：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pair&lt;String, Integer&gt; p = <span class="keyword">new</span> Pair&lt;&gt;(<span class="string">&quot;test&quot;</span>, <span class="number">123</span>);</span><br></pre></td></tr></table></figure>
<p>​ <strong>Java标准库的<code>Map&lt;K, V&gt;</code>就是使用两种泛型类型的例子。它对Key使用一种类型，对Value使用另一种类型。</strong></p>
<h3 id="四擦拭法java语言的泛型实现方法">四、擦拭法（java语言的泛型实现方法）：</h3>
<h4 id="擦拭法的基本含义">1、擦拭法的基本含义</h4>
<p>​ 擦拭法是指，<strong>虚拟机对泛型其实一无所知，所有的工作都是编译器做的。</strong></p>
<p>​ 例如，我们编写了一个泛型类<code>Pair&lt;T&gt;</code>，这是编译器看到的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Pair</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> T first;</span><br><span class="line">    <span class="keyword">private</span> T last;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Pair</span><span class="params">(T first, T last)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.first = first;</span><br><span class="line">        <span class="keyword">this</span>.last = last;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>而虚拟机根本不知道泛型。这是虚拟机执行的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Pair</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Object first;</span><br><span class="line">    <span class="keyword">private</span> Object last;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Pair</span><span class="params">(Object first, Object last)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.first = first;</span><br><span class="line">        <span class="keyword">this</span>.last = last;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因此，java使用擦拭法实现泛型，导致了：</p>
<ul>
<li><strong>编译器把类型<code>&lt;T&gt;</code>视为<code>Object</code>；</strong></li>
<li><strong>编译器根据<code>&lt;T&gt;</code>实现安全的强制转型。</strong></li>
</ul>
<p>使用泛型的时候，我们编写的代码也是编译器看到的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pair&lt;String&gt; p = <span class="keyword">new</span> Pair&lt;&gt;(<span class="string">&quot;Hello&quot;</span>, <span class="string">&quot;world&quot;</span>);</span><br><span class="line">String first = p.getFirst();</span><br><span class="line">String last = p.getLast();</span><br></pre></td></tr></table></figure>
<p>而虚拟机执行的代码并没有泛型：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pair p = <span class="keyword">new</span> Pair(<span class="string">&quot;Hello&quot;</span>, <span class="string">&quot;world&quot;</span>);</span><br><span class="line">String first = (String) p.getFirst();</span><br><span class="line">String last = (String) p.getLast();</span><br></pre></td></tr></table></figure>
<p><strong>Java的泛型是由编译器在编译时实行的，编译器内部永远把所有类型<code>T</code>视为<code>Object</code>处理，但是，在需要转型的时候，编译器会根据<code>T</code>的类型自动为我们实行安全地强制转型。</strong></p>
<h4 id="java泛型的局限">2、java泛型的局限：</h4>
<ul>
<li><p>1） <code>&lt;T&gt;</code>不能是基本类型，例如<code>int</code>，因为实际类型是<code>Object</code>，<code>Object</code>类型无法持有基本类型：</p></li>
<li><p>2） 所有泛型实例，无论<code>T</code>的类型是什么，<code>getClass()</code>返回同一个<code>Class</code>实例，因为编译后它们全部都是<code>Pair&lt;Object&gt;</code>。示例如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pair&lt;String&gt; p1 = <span class="keyword">new</span> Pair&lt;&gt;(<span class="string">&quot;Hello&quot;</span>, <span class="string">&quot;world&quot;</span>);</span><br><span class="line">Pair&lt;Integer&gt; p2 = <span class="keyword">new</span> Pair&lt;&gt;(<span class="number">123</span>, <span class="number">456</span>);</span><br><span class="line">Class c1 = p1.getClass();</span><br><span class="line">Class c2 = p2.getClass();</span><br><span class="line">System.out.println(c1==c2); <span class="comment">// true</span></span><br><span class="line">System.out.println(c1==Pair.class); <span class="comment">// true</span></span><br></pre></td></tr></table></figure></li>
<li><p>3）无法判断带泛型的类型，原因和前面一样，并不存在<code>Pair&lt;String&gt;.class</code>，而是只有唯一的<code>Pair.class</code>。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pair&lt;Integer&gt; p = <span class="keyword">new</span> Pair&lt;&gt;(<span class="number">123</span>, <span class="number">456</span>);</span><br><span class="line"><span class="comment">// Compile error:</span></span><br><span class="line"><span class="keyword">if</span> (p <span class="keyword">instanceof</span> Pair&lt;String&gt;) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>4）不能实例化<code>T</code>类型</p></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Pair</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> T first;</span><br><span class="line">    <span class="keyword">private</span> T last;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Pair</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// Compile error:</span></span><br><span class="line">        first = <span class="keyword">new</span> T();</span><br><span class="line">        last = <span class="keyword">new</span> T();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述代码无法通过编译，因为构造方法的两行语句：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">first = <span class="keyword">new</span> T();</span><br><span class="line">last = <span class="keyword">new</span> T();</span><br></pre></td></tr></table></figure>
<p>擦拭后实际上变成了：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">first = <span class="keyword">new</span> Object();</span><br><span class="line">last = <span class="keyword">new</span> Object();</span><br></pre></td></tr></table></figure>
<p>这样一来，创建<code>new Pair&lt;String&gt;()</code>和创建<code>new Pair&lt;Integer&gt;()</code>就全部成了<code>Object</code>，显然编译器要阻止这种类型不对的代码。</p>
<p>要实例化<code>T</code>类型，我们必须借助额外的<code>Class&lt;T&gt;</code>参数：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Pair</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> T first;</span><br><span class="line">    <span class="keyword">private</span> T last;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Pair</span><span class="params">(Class&lt;T&gt; clazz)</span> </span>&#123;</span><br><span class="line">        first = clazz.newInstance();</span><br><span class="line">        last = clazz.newInstance();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述代码借助<code>Class&lt;T&gt;</code>参数并通过反射来实例化<code>T</code>类型，使用的时候，也必须传入<code>Class&lt;T&gt;</code>。例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Pair&lt;String&gt; pair = <span class="keyword">new</span> Pair&lt;&gt;(String.class);</span><br></pre></td></tr></table></figure>
<p>因为传入了<code>Class&lt;String&gt;</code>的实例，所以我们借助<code>String.class</code>就可以实例化<code>String</code>类型。</p>
<h4 id="不恰当的覆写方法">3、不恰当的覆写方法</h4>
<p>有些时候，一个看似正确定义的方法会无法通过编译。例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Pair</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(T t)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span> == t;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这是因为，定义的<code>equals(T t)</code>方法实际上会被擦拭成<code>equals(Object t)</code>，而这个方法是继承自<code>Object</code>的，编译器会阻止一个实际上会变成覆写的泛型方法定义。</p>
<p>换个方法名，避开与<code>Object.equals(Object)</code>的冲突就可以成功编译：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Pair</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">same</span><span class="params">(T t)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span> == t;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="泛型继承待补充">4、泛型继承（待补充</h4>
<h3 id="五extends通配符">五、Extends通配符</h3>
<h3 id="六super通配符">六、Super通配符</h3>
<h3 id="七泛型和反射">七、泛型和反射</h3>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记6——java注解</title>
    <url>/2022/01/31/df1f1fae1854/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1264799402020448</p>
<h3 id="一注解是什么">一、注解是什么？</h3>
<p>​ 注解是放在Java源码的类、方法、字段、参数前的一种特殊“注释”：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// this is a component:</span></span><br><span class="line"><span class="meta">@Resource(&quot;hello&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Hello</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Inject</span></span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">hello</span><span class="params">(<span class="meta">@Param</span> String name)</span> </span>&#123;</span><br><span class="line">        System.out.println(name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ <strong>注释会被编译器直接忽略，注解则可以被编译器打包进入class文件</strong>，因此，注解是一种用作标注的“元数据”。</p>
<h3 id="二注解的作用">二、注解的作用：</h3>
<p>​ 从JVM的角度看，注解本身对代码逻辑没有任何影响，如何使用注解完全由工具决定。</p>
<p>​ Java的注解可以分为三类：</p>
<ul>
<li>1、<strong>由编译器使用的注解:</strong>( 这类注解不会被编译进入<code>.class</code>文件，它们在编译后就被编译器扔掉了 )
<ul>
<li><code>@Override</code>：让编译器检查该方法是否正确地实现了覆写；</li>
<li><code>@SuppressWarnings</code>：告诉编译器忽略此处代码产生的警告。</li>
</ul></li>
<li>2、<strong>由工具处理<code>.class</code>文件使用的注解</strong>:
<ul>
<li>比如有些工具会在加载class的时候，对class做动态修改，实现一些特殊的功能。<strong>这类注解会被编译进入<code>.class</code>文件，但加载结束后并不会存在于内存中</strong>。这类注解只被一些底层库使用，一般我们不必自己处理。</li>
</ul></li>
<li>3、<strong>在程序运行期能够读取的注解</strong>：
<ul>
<li>它们<strong>在加载后一直存在于JVM中</strong>，这也是最常用的注解。例如，一个配置了<code>@PostConstruct</code>的方法会在调用构造方法后自动被调用（这是Java代码读取该注解实现的功能，JVM并不会识别该注解）</li>
</ul></li>
</ul>
<h3 id="三注解的配置参数">三、注解的配置参数：</h3>
<p>定义一个注解时，还可以定义<strong>配置参数</strong>。配置参数可以包括：</p>
<ul>
<li>所有基本类型；</li>
<li>String；</li>
<li>枚举类型；</li>
<li>基本类型、String、Class以及枚举的数组。</li>
</ul>
<p>因为<strong>配置参数必须是常量</strong>，所以，上述限制保证了注解在定义时就已经确定了每个参数的值。</p>
<p><strong>注解的配置参数可以有默认值，缺少某个配置参数时将使用默认值。</strong></p>
<p>此外，大部分注解会有一个名为<code>value</code>的配置参数，对此参数赋值，可以只写常量，相当于省略了value参数。如果只写注解，相当于全部使用默认值。</p>
<p>举个栗子，对以下代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Hello</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Check(min=0, max=100, value=55)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> n;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Check(value=99)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> p;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Check(99)</span> <span class="comment">// @Check(value=99)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> x;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Check</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>@Check</code>就是一个注解。第一个<code>@Check(min=0, max=100, value=55)</code>明确定义了三个参数，第二个<code>@Check(value=99)</code>只定义了一个<code>value</code>参数，它实际上和<code>@Check(99)</code>是完全一样的。最后一个<code>@Check</code>表示所有参数都使用默认值。</p>
<h3 id="四定义注解">四、定义注解：</h3>
<h4 id="如何定义一个注解">1、如何定义一个注解？</h4>
<p>java语言使用<code>@interface</code>语法来定义注解（<code>Annotation</code>），它的格式如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> Report &#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">type</span><span class="params">()</span> <span class="keyword">default</span> 0</span>;</span><br><span class="line">    <span class="function">String <span class="title">level</span><span class="params">()</span> <span class="keyword">default</span> &quot;info&quot;</span>;</span><br><span class="line">    <span class="function">String <span class="title">value</span><span class="params">()</span> <span class="keyword">default</span> &quot;&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 注解的参数类似无参数方法，可以用<code>default</code>设定一个默认值（强烈推荐）。最常用的参数应当命名为<code>value</code>。</p>
<h4 id="元注解">2、元注解：</h4>
<p>​ 有一些注解可以修饰其他注解，这些注解就称为元注解（meta annotation）。Java标准库已经定义了一些元注解，我们只需要使用元注解，通常不需要自己去编写元注解。</p>
<ul>
<li><p><span class="citation" data-cites="Target">@Target</span>：</p>
<ul>
<li><p>使用<code>@Target</code>可以定义<code>Annotation</code>能够被应用于源码的哪些位置</p>
<ul>
<li>类或接口：<code>ElementType.TYPE</code>；</li>
<li>字段：<code>ElementType.FIELD</code>；</li>
<li>方法：<code>ElementType.METHOD</code>；</li>
<li>构造方法：<code>ElementType.CONSTRUCTOR</code>；</li>
<li>方法参数：<code>ElementType.PARAMETER</code>。</li>
</ul></li>
<li><p>例如，定义注解<code>@Report</code>可用在方法上，我们必须添加一个<code>@Target(ElementType.METHOD)</code></p>
<ul>
<li>```java <span class="citation" data-cites="Target">@Target</span>(ElementType.METHOD) public <span class="citation" data-cites="interface">@interface</span> Report { int type() default 0; String level() default "info"; String value() default ""; } <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- 定义注解`@Report`可用在方法或字段上，可以把`@Target`注解参数变为数组`&#123; ElementType.METHOD, ElementType.FIELD &#125;`：</span><br><span class="line"></span><br><span class="line">  - ```java</span><br><span class="line">    @Target(&#123;</span><br><span class="line">        ElementType.METHOD,</span><br><span class="line">        ElementType.FIELD</span><br><span class="line">    &#125;)</span><br><span class="line">    public @interface Report &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li>
</ul></li>
</ul></li>
<li><p><span class="citation" data-cites="Retention">@Retention</span>:</p>
<ul>
<li><p><code>@Retention</code>定义了<code>Annotation</code>的生命周期</p>
<ul>
<li>仅编译期：<code>RetentionPolicy.SOURCE</code>；</li>
<li>仅class文件：<code>RetentionPolicy.CLASS</code>；</li>
<li>运行期：<code>RetentionPolicy.RUNTIME</code>。</li>
</ul></li>
<li><p>如果<code>@Retention</code>不存在，则该<code>Annotation</code>默认为<code>CLASS</code>。因为通常我们自定义的<code>Annotation</code>都是<code>RUNTIME</code>，所以，务必要加上<code>@Retention(RetentionPolicy.RUNTIME)</code>这个元注解：</p>
<ul>
<li></li>
<li>```java <span class="citation" data-cites="Retention">@Retention</span>(RetentionPolicy.RUNTIME) public <span class="citation" data-cites="interface">@interface</span> Report { int type() default 0; String level() default "info"; String value() default ""; } <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- @Repeatable</span><br><span class="line"></span><br><span class="line">  - `@Repeatable`这个元注解可以定义`Annotation`是否可重复。</span><br><span class="line"></span><br><span class="line">    - ```</span><br><span class="line">      @Repeatable(Reports.class)</span><br><span class="line">      @Target(ElementType.TYPE)</span><br><span class="line">      public @interface Report &#123;</span><br><span class="line">          int type() default 0;</span><br><span class="line">          String level() default &quot;info&quot;;</span><br><span class="line">          String value() default &quot;&quot;;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      @Target(ElementType.TYPE)</span><br><span class="line">      public @interface Reports &#123;</span><br><span class="line">          Report[] value();</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><p>经过<code>@Repeatable</code>修饰后，在某个类型声明处，就可以添加多个<code>@Report</code>注解：</p>
<ul>
<li>```java <span class="citation" data-cites="Report">@Report</span>(type=1, level="debug") <span class="citation" data-cites="Report">@Report</span>(type=2, level="warning") public class Hello { } <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- @Inherited</span><br><span class="line"></span><br><span class="line">  - 使用`@Inherited`定义子类是否可继承父类定义的`Annotation`</span><br><span class="line"></span><br><span class="line">  - `@Inherited`仅针对`@Target(ElementType.TYPE)`类型的`annotation`有效，**并且仅针对`class`的继承，对`interface`的继承无效**</span><br><span class="line"></span><br><span class="line">    - ```java</span><br><span class="line">      @Inherited</span><br><span class="line">      @Target(ElementType.TYPE)</span><br><span class="line">      public @interface Report &#123;</span><br><span class="line">          int type() default 0;</span><br><span class="line">          String level() default &quot;info&quot;;</span><br><span class="line">          String value() default &quot;&quot;;</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><p>在使用的时候，如果一个类用到了<code>@Report</code>,则它的子类默认也定义了该注解：</p>
<ul>
<li>```java <span class="citation" data-cites="Report">@Report</span>(type=1) public class Person { } <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- ```java</span><br><span class="line">  public class Student extends Person &#123;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li>
</ul></li>
</ul></li>
</ul>
<h4 id="总结定义annotation的步骤">3、总结定义Annotation的步骤：</h4>
<h5 id="用interface定义注解">1）用<code>@interface</code>定义注解：</h5>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> Report &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="添加参数默认值把最常用的参数定义为value推荐所有参数都尽量设置默认值">2) 添加参数、默认值：(把最常用的参数定义为<code>value()</code>，推荐所有参数都尽量设置默认值。)</h5>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> Report &#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">type</span><span class="params">()</span> <span class="keyword">default</span> 0</span>;</span><br><span class="line">    <span class="function">String <span class="title">level</span><span class="params">()</span> <span class="keyword">default</span> &quot;info&quot;</span>;</span><br><span class="line">    <span class="function">String <span class="title">value</span><span class="params">()</span> <span class="keyword">default</span> &quot;&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="第三步用元注解配置注解">3) 第三步，用元注解配置注解：</h5>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Target(ElementType.TYPE)</span></span><br><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> Report &#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">type</span><span class="params">()</span> <span class="keyword">default</span> 0</span>;</span><br><span class="line">    <span class="function">String <span class="title">level</span><span class="params">()</span> <span class="keyword">default</span> &quot;info&quot;</span>;</span><br><span class="line">    <span class="function">String <span class="title">value</span><span class="params">()</span> <span class="keyword">default</span> &quot;&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 必须设置<code>@Target</code>和<code>@Retention</code>，<code>@Retention</code>一般设置为<code>RUNTIME</code>，因为我们自定义的注解通常要求在运行期读取。一般情况下，不必写<code>@Inherited</code>和<code>@Repeatable</code>。</p>
<h3 id="五处理注解">五、处理注解：</h3>
<p>​ Java的注解本身对代码逻辑没有任何影响。根据<code>@Retention</code>的配置：</p>
<ul>
<li><code>SOURCE</code>类型的注解在编译期就被丢掉了；</li>
<li><code>CLASS</code>类型的注解仅保存在class文件中，它们不会被加载进JVM；</li>
<li><code>RUNTIME</code>类型的注解会被加载进JVM，并且在运行期可以被程序读取。</li>
</ul>
<p>​ 如何使用注解完全由工具决定。<code>SOURCE</code>类型的注解主要由编译器使用，因此我们一般只使用，不编写。<code>CLASS</code>类型的注解主要由底层工具库使用，涉及到class的加载，一般我们很少用到。<strong>只有<code>RUNTIME</code>类型的注解不但要使用，还经常需要编写。</strong></p>
<p>​ 因为注解定义后也是一种<code>class</code>，所有的注解都继承自<code>java.lang.annotation.Annotation</code>，因此，读取注解，需要使用反射API。</p>
<p>​ Java提供的使用反射API读取<code>Annotation</code>的方法包括：</p>
<p>判断某个注解是否存在于<code>Class</code>、<code>Field</code>、<code>Method</code>或<code>Constructor</code>：</p>
<ul>
<li><code>Class.isAnnotationPresent(Class)</code></li>
<li><code>Field.isAnnotationPresent(Class)</code></li>
<li><code>Method.isAnnotationPresent(Class)</code></li>
<li><code>Constructor.isAnnotationPresent(Class)</code></li>
</ul>
<p>例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 判断@Report是否存在于Person类:</span></span><br><span class="line">Person.class.isAnnotationPresent(Report.class);</span><br></pre></td></tr></table></figure>
<p>使用反射API读取Annotation：</p>
<ul>
<li><code>Class.getAnnotation(Class)</code></li>
<li><code>Field.getAnnotation(Class)</code></li>
<li><code>Method.getAnnotation(Class)</code></li>
<li><code>Constructor.getAnnotation(Class)</code></li>
</ul>
<p>例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取Person定义的@Report注解:</span></span><br><span class="line">Report report = Person.class.getAnnotation(Report.class);</span><br><span class="line"><span class="keyword">int</span> type = report.type();</span><br><span class="line">String level = report.level();</span><br></pre></td></tr></table></figure>
<p>使用反射API读取<code>Annotation</code>有两种方法。方法一是先判断<code>Annotation</code>是否存在，如果存在，就直接读取：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Class cls = Person.class;</span><br><span class="line"><span class="keyword">if</span> (cls.isAnnotationPresent(Report.class)) &#123;</span><br><span class="line">    Report report = cls.getAnnotation(Report.class);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第二种方法是直接读取<code>Annotation</code>，如果<code>Annotation</code>不存在，将返回<code>null</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Class cls = Person.class;</span><br><span class="line">Report report = cls.getAnnotation(Report.class);</span><br><span class="line"><span class="keyword">if</span> (report != <span class="keyword">null</span>) &#123;</span><br><span class="line">   ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>读取方法、字段和构造方法的<code>Annotation</code>和Class类似。但要读取方法参数的<code>Annotation</code>就比较麻烦一点，因为方法参数本身可以看成一个数组，而每个参数又可以定义多个注解，所以，一次获取方法参数的所有注解就必须用一个二维数组来表示。例如，对于以下方法定义的注解：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">hello</span><span class="params">(<span class="meta">@NotNull</span> <span class="meta">@Range(max=5)</span> String name, <span class="meta">@NotNull</span> String prefix)</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>要读取方法参数的注解，我们先用反射获取<code>Method</code>实例，然后读取方法参数的所有注解：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 获取Method实例:</span></span><br><span class="line">Method m = ...</span><br><span class="line"><span class="comment">// 获取所有参数的Annotation:</span></span><br><span class="line">Annotation[][] annos = m.getParameterAnnotations();</span><br><span class="line"><span class="comment">// 第一个参数（索引为0）的所有Annotation:</span></span><br><span class="line">Annotation[] annosOfName = annos[<span class="number">0</span>];</span><br><span class="line"><span class="keyword">for</span> (Annotation anno : annosOfName) &#123;</span><br><span class="line">    <span class="keyword">if</span> (anno <span class="keyword">instanceof</span> Range) &#123; <span class="comment">// @Range注解</span></span><br><span class="line">        Range r = (Range) anno;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (anno <span class="keyword">instanceof</span> NotNull) &#123; <span class="comment">// @NotNull注解</span></span><br><span class="line">        NotNull n = (NotNull) anno;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="六使用注解">六、使用注解</h3>
<p>​ 注解如何使用，完全由程序自己决定。例如，JUnit是一个测试框架，它会自动运行所有标记为<code>@Test</code>的方法。</p>
<p>​ 我们来看一个<code>@Range</code>注解，我们希望用它来定义一个<code>String</code>字段的规则：字段长度满足<code>@Range</code>的参数定义：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="meta">@Target(ElementType.FIELD)</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> Range &#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">min</span><span class="params">()</span> <span class="keyword">default</span> 0</span>;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">max</span><span class="params">()</span> <span class="keyword">default</span> 255</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 在某个JavaBean中，我们可以使用该注解：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Range(min=1, max=20)</span></span><br><span class="line">    <span class="keyword">public</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Range(max=10)</span></span><br><span class="line">    <span class="keyword">public</span> String city;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 但是，定义了注解，本身对程序逻辑没有任何影响。我们必须自己编写代码来使用注解。这里，我们编写一个<code>Person</code>实例的检查方法，它可以检查<code>Person</code>实例的<code>String</code>字段长度是否满足<code>@Range</code>的定义：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">check</span><span class="params">(Person person)</span> <span class="keyword">throws</span> IllegalArgumentException, ReflectiveOperationException </span>&#123;</span><br><span class="line">    <span class="comment">// 遍历所有Field:</span></span><br><span class="line">    <span class="keyword">for</span> (Field field : person.getClass().getFields()) &#123;</span><br><span class="line">        <span class="comment">// 获取Field定义的@Range:</span></span><br><span class="line">        Range range = field.getAnnotation(Range.class);</span><br><span class="line">        <span class="comment">// 如果@Range存在:</span></span><br><span class="line">        <span class="keyword">if</span> (range != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 获取Field的值:</span></span><br><span class="line">            Object value = field.get(person);</span><br><span class="line">            <span class="comment">// 如果值是String:</span></span><br><span class="line">            <span class="keyword">if</span> (value <span class="keyword">instanceof</span> String) &#123;</span><br><span class="line">                String s = (String) value;</span><br><span class="line">                <span class="comment">// 判断值是否满足@Range的min/max:</span></span><br><span class="line">                <span class="keyword">if</span> (s.length() &lt; range.min() || s.length() &gt; range.max()) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;Invalid field: &quot;</span> + field.getName());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 这样一来，我们通过<code>@Range</code>注解，配合<code>check()</code>方法，就可以完成<code>Person</code>实例的检查。注意检查逻辑完全是我们自己编写的，JVM不会自动给注解添加任何额外的逻辑。</p>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>annotation</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记5——java反射机制</title>
    <url>/2022/01/30/5ea85635a06d/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1255945147512512</p>
<h3 id="一反射简介">一、反射简介</h3>
<p>Java的反射是指程序在运行期可以拿到一个对象的所有信息。</p>
<p>​ 反射是为了解决在运行期，对某个实例一无所知的情况下，如何调用其方法。正常情况下，如果我们要调用一个对象的方法，或者访问一个对象的字段，通常会传入对象实例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Main.java</span></span><br><span class="line"><span class="keyword">import</span> com.itranswarp.learnjava.Person;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function">String <span class="title">getFullName</span><span class="params">(Person p)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> p.getFirstName() + <span class="string">&quot; &quot;</span> + p.getLastName();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但是，如果不能获得<code>Person</code>类，只有一个<code>Object</code>实例，比如这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">String <span class="title">getFullName</span><span class="params">(Object obj)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> ???</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>怎么办？可能有人说：强制转型啊！</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">String <span class="title">getFullName</span><span class="params">(Object obj)</span> </span>&#123;</span><br><span class="line">    Person p = (Person) obj;</span><br><span class="line">    <span class="keyword">return</span> p.getFirstName() + <span class="string">&quot; &quot;</span> + p.getLastName();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 强制转型的时候，你会发现一个问题：编译上面的代码，仍然需要引用<code>Person</code>类。不然，去掉<code>import</code>语句，你看能不能编译通过？</p>
<p>​ <strong>所以，反射是为了解决在运行期，对某个实例一无所知的情况下，如何调用其方法。</strong></p>
<h3 id="二class类">二、Class类</h3>
<p>​ 查看此节前，需要注意：我们平时所说的类都是指“class”(小写)，本节要介绍的是一个叫做<strong>"Class"</strong>的类。</p>
<h4 id="简介">1、简介</h4>
<p>​ 我们平常定义的各个类都是<strong>由JVM在执行过程中动态加载的</strong>。JVM在第一次读取到一个不同的类时，就会将其加载入内存。每加载一种类，JVM就会为其创建一个<strong>"Class"</strong>类型的类的实例，并进行关联。这个叫做<strong>“Class”</strong>的类定义如下所示：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Class</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Class</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 以<code>String</code>类为例，当JVM加载<code>String</code>类时，它首先读取<code>String.class</code>文件到内存，然后，为<code>String</code>类创建一个<strong>“Class”</strong>类的实例并关联起来：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Class cls = <span class="keyword">new</span> Class(String);</span><br></pre></td></tr></table></figure>
<p>​ 这个<strong>“Class”</strong>类的实例实例是JVM内部创建的，如果我们查看JDK源码，可以发现<strong>"Class"</strong>类的构造方法是<code>private</code>，只有JVM能创建<strong>"Class"</strong>类的实例，我们自己的Java程序是无法创建<strong>"Class"</strong>实例的。</p>
<p>​ 所以，JVM持有的每个<strong>"Class"</strong>实例都指向一个数据类型（<code>class</code>或<code>interface</code>），如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">┌───────────────────────────┐</span><br><span class="line">│      Class Instance       │──────&gt; String</span><br><span class="line">├───────────────────────────┤</span><br><span class="line">│name = &quot;java.lang.String&quot;  │</span><br><span class="line">└───────────────────────────┘</span><br><span class="line">┌───────────────────────────┐</span><br><span class="line">│      Class Instance       │──────&gt; Random</span><br><span class="line">├───────────────────────────┤</span><br><span class="line">│name = &quot;java.util.Random&quot;  │</span><br><span class="line">└───────────────────────────┘</span><br><span class="line">┌───────────────────────────┐</span><br><span class="line">│      Class Instance       │──────&gt; Runnable</span><br><span class="line">├───────────────────────────┤</span><br><span class="line">│name = &quot;java.lang.Runnable&quot;│</span><br><span class="line">└───────────────────────────┘</span><br></pre></td></tr></table></figure>
<p>一个<strong>"Class"</strong>实例包含了其对应的类的所有完整信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">┌───────────────────────────┐</span><br><span class="line">│      Class Instance       │──────&gt; String</span><br><span class="line">├───────────────────────────┤</span><br><span class="line">│name = &quot;java.lang.String&quot;  │</span><br><span class="line">├───────────────────────────┤</span><br><span class="line">│package = &quot;java.lang&quot;      │</span><br><span class="line">├───────────────────────────┤</span><br><span class="line">│super = &quot;java.lang.Object&quot; │</span><br><span class="line">├───────────────────────────┤</span><br><span class="line">│interface = CharSequence...│</span><br><span class="line">├───────────────────────────┤</span><br><span class="line">│field = value[],hash,...   │</span><br><span class="line">├───────────────────────────┤</span><br><span class="line">│method = indexOf()...      │</span><br><span class="line">└───────────────────────────┘</span><br></pre></td></tr></table></figure>
<p>​ 由于JVM为每个加载的类创建了对应的<strong>"Class"</strong>实例，并在实例中保存了该类的所有信息，包括类名、包名、父类、实现的接口、所有方法、字段等，因此，如果获取了某个<strong>"Class"</strong>实例，我们就可以通过这个<strong>"Class"</strong>实例获取到该实例对应的类的所有信息。</p>
<p>​ 这种通过<strong>"Class"</strong>的实例获取类的信息的方法称为<strong>反射（Reflection）</strong>。</p>
<h4 id="如何获取一个类的class实例">2、如何获取一个类的<strong>"Class"</strong>实例</h4>
<ul>
<li>方法1：直接通过一个类的静态变量<code>class</code>获取：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Class cls = String.class;</span><br></pre></td></tr></table></figure>
<ul>
<li>方法二：如果我们有一个实例变量，可以通过该实例变量提供的<code>getClass()</code>方法获取：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s = <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line">Class cls = s.getClass();</span><br></pre></td></tr></table></figure>
<ul>
<li>方法三：如果知道一个类的完整类名，可以通过静态方法<code>Class.forName()</code>获取：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Class cls = Class.forName(<span class="string">&quot;java.lang.String&quot;</span>);</span><br></pre></td></tr></table></figure>
<h4 id="比较class实例">3、比较”Class“实例</h4>
<p>​ 因为<strong>"Class"</strong>实例在JVM中是唯一的，所以，上述方法获取的<strong>"Class"</strong>实例是同一个实例。可以用<code>==</code>比较两个<strong>"Class"</strong>实例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Class cls1 = String.class;</span><br><span class="line"></span><br><span class="line">String s = <span class="string">&quot;Hello&quot;</span>;</span><br><span class="line">Class cls2 = s.getClass();</span><br><span class="line"></span><br><span class="line"><span class="keyword">boolean</span> sameClass = cls1 == cls2; <span class="comment">// true</span></span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>：<strong>"Class"</strong>实例比较和<strong>instanceof</strong>的差别：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer n = <span class="keyword">new</span> Integer(<span class="number">123</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">boolean</span> b1 = n <span class="keyword">instanceof</span> Integer; <span class="comment">// true，因为n是Integer类型</span></span><br><span class="line"><span class="keyword">boolean</span> b2 = n <span class="keyword">instanceof</span> Number; <span class="comment">// true，因为n是Number类型的子类</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">boolean</span> b3 = n.getClass() == Integer.class; <span class="comment">// true，因为n.getClass()返回Integer.class</span></span><br><span class="line"><span class="keyword">boolean</span> b4 = n.getClass() == Number.class; <span class="comment">// false，因为Integer.class!=Number.class</span></span><br></pre></td></tr></table></figure>
<p>​ 用<code>instanceof</code>不但匹配指定类型，还匹配指定类型的子类。而用<code>==</code>判断<code>class</code>实例可以精确地判断数据类型，但不能作子类型比较。</p>
<p>​ 通常情况下，我们应该用<code>instanceof</code>判断数据类型，因为面向抽象编程的时候，我们不关心具体的子类型。只有在需要精确判断一个类型是不是某个<code>class</code>的时候，我们才使用<code>==</code>判断<code>class</code>实例。</p>
<h4 id="如何从class实例获取基本信息">4、如何从Class实例获取基本信息</h4>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printObjectInfo</span><span class="params">(Object obj)</span> </span>&#123;</span><br><span class="line">    Class cls = obj.getClass();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">printClassInfo</span><span class="params">(Class cls)</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;Class name: &quot;</span> + cls.getName());</span><br><span class="line">    System.out.println(<span class="string">&quot;Simple name: &quot;</span> + cls.getSimpleName());</span><br><span class="line">    <span class="keyword">if</span> (cls.getPackage() != <span class="keyword">null</span>) &#123;</span><br><span class="line">    	System.out.println(<span class="string">&quot;Package name: &quot;</span> + cls.getPackage().getName());</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(<span class="string">&quot;is interface: &quot;</span> + cls.isInterface());</span><br><span class="line">    System.out.println(<span class="string">&quot;is enum: &quot;</span> + cls.isEnum());</span><br><span class="line">    System.out.println(<span class="string">&quot;is array: &quot;</span> + cls.isArray());</span><br><span class="line">    System.out.println(<span class="string">&quot;is primitive: &quot;</span> + cls.isPrimitive());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="动态加载">5、动态加载：</h4>
<p>​ JVM在执行Java程序的时候，<strong>并不是一次性把所有用到的class全部加载到内存，而是第一次需要用到class时才加载</strong>。例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Main.java</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (args.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            create(args[<span class="number">0</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">create</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        Person p = <span class="keyword">new</span> Person(name);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 当执行<code>Main.java</code>时，由于用到了<code>Main</code>，因此，JVM首先会把<code>Main.class</code>加载到内存。然而，并不会加载<code>Person.class</code>，除非程序执行到<code>create()</code>方法，JVM发现需要加载<code>Person</code>类时，才会首次加载<code>Person.class</code>。如果没有执行<code>create()</code>方法，那么<code>Person.class</code>根本就不会被加载。</p>
<p>​ 这就是<strong>JVM动态加载<code>class</code>的特性</strong>。</p>
<p>​ <strong>备注</strong>：动态加载类的特性对于Java程序非常重要。利用JVM动态加载类的特性，我们才能在运行期根据条件加载不同的实现类。例如，Commons Logging总是优先使用Log4j，只有当Log4j不存在时，才使用JDK的logging。利用JVM动态加载特性，大致的实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Commons Logging优先使用Log4j:</span></span><br><span class="line">LogFactory factory = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">if</span> (isClassPresent(<span class="string">&quot;org.apache.logging.log4j.Logger&quot;</span>)) &#123;</span><br><span class="line">    factory = createLog4j();</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    factory = createJdkLog();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">isClassPresent</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Class.forName(name);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 这就是为什么我们只需要把Log4j的jar包放到classpath中，Commons Logging就会自动使用Log4j的原因。</p>
<h3 id="三通过class实例访问字段">三、通过Class实例访问字段：</h3>
<h4 id="获取字段信息">1、获取字段信息</h4>
<p>​ 对任意的一个<code>Object</code>实例，只要我们获取了它的<strong>"Class"</strong>，就可以获取它的一切信息。</p>
<p>​ <strong>"Class"</strong>类提供了以下几个方法来获取字段Field：</p>
<ul>
<li>Field getField(name)：根据字段名获取某个public的field（包括父类）</li>
<li>Field getDeclaredField(name)：根据字段名获取当前类的某个field（不包括父类）</li>
<li>Field[] getFields()：获取所有public的field（包括父类）</li>
<li>Field[] getDeclaredFields()：获取当前类的所有field（不包括父类）</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Class stdClass = Student.class;</span><br><span class="line">        <span class="comment">// 获取public字段&quot;score&quot;:</span></span><br><span class="line">        System.out.println(stdClass.getField(<span class="string">&quot;score&quot;</span>));</span><br><span class="line">        <span class="comment">// 获取继承的public字段&quot;name&quot;:</span></span><br><span class="line">        System.out.println(stdClass.getField(<span class="string">&quot;name&quot;</span>));</span><br><span class="line">        <span class="comment">// 获取private字段&quot;grade&quot;:</span></span><br><span class="line">        System.out.println(stdClass.getDeclaredField(<span class="string">&quot;grade&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span> <span class="keyword">extends</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> score;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> grade;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> String name;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/** 上述输出 </span></span><br><span class="line"><span class="comment">public int Student.score</span></span><br><span class="line"><span class="comment">public java.lang.String Person.name</span></span><br><span class="line"><span class="comment">private int Student.grade</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<p>一个<code>Field</code>对象包含了一个字段的所有信息：</p>
<ul>
<li><code>getName()</code>：返回字段名称，例如，<code>"name"</code>；</li>
<li><code>getType()</code>：返回字段类型，也是一个<code>Class</code>实例，例如，<code>String.class</code>；</li>
<li><code>getModifiers()</code>：返回字段的修饰符，它是一个<code>int</code>，不同的bit表示不同的含义。</li>
</ul>
<h4 id="获取字段值">2、获取字段值：</h4>
<p>​ 利用反射拿到字段的一个<code>Field</code>实例只是第一步，我们还可以拿到一个实例对应的该字段的值。</p>
<p>​ 例如，对于一个<code>Person</code>实例，我们可以先拿到<code>name</code>字段对应的<code>Field</code>，再获取这个实例的<code>name</code>字段的值：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang.reflect.Field;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Object p = <span class="keyword">new</span> Person(<span class="string">&quot;Xiao Ming&quot;</span>);</span><br><span class="line">        Class c = p.getClass();</span><br><span class="line">        Field f = c.getDeclaredField(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        Object value = f.get(p);</span><br><span class="line">        System.out.println(value); <span class="comment">// &quot;Xiao Ming&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 上述代码先获取<code>Class</code>实例，再获取<code>Field</code>实例，然后，用<code>Field.get(Object)</code>获取指定实例的指定字段的值。</p>
<p>​ 运行代码，如果不出意外，会得到一个<code>IllegalAccessException</code>，这是因为<code>name</code>被定义为一个<code>private</code>字段，正常情况下，<code>Main</code>类无法访问<code>Person</code>类的<code>private</code>字段。要修复错误，可以将<code>private</code>改为<code>public</code>，或者，在调用<code>Object value = f.get(p);</code>前，先写一句：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">f.setAccessible(<span class="keyword">true</span>);</span><br></pre></td></tr></table></figure>
<p>调用<code>Field.setAccessible(true)</code>的意思是，别管这个字段是不是<code>public</code>，一律允许访问。</p>
<h4 id="设置字段值">3、设置字段值：</h4>
<p>​ 通过Field实例既然可以获取到指定实例的字段值，自然也可以设置字段的值。</p>
<p>​ 设置字段值是通过<code>Field.set(Object, Object)</code>实现的，其中第一个<code>Object</code>参数是指定的实例，第二个<code>Object</code>参数是待修改的值。示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang.reflect.Field;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Person p = <span class="keyword">new</span> Person(<span class="string">&quot;Xiao Ming&quot;</span>);</span><br><span class="line">        System.out.println(p.getName()); <span class="comment">// &quot;Xiao Ming&quot;</span></span><br><span class="line">        Class c = p.getClass();</span><br><span class="line">        Field f = c.getDeclaredField(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        f.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">        f.set(p, <span class="string">&quot;Xiao Hong&quot;</span>);</span><br><span class="line">        System.out.println(p.getName()); <span class="comment">// &quot;Xiao Hong&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同样的，修改非<code>public</code>字段，需要首先调用<code>setAccessible(true)</code>。</p>
<h3 id="四调用方法">四、调用方法：</h3>
<h4 id="简介-1">1、简介</h4>
<p>可以通过<code>Class</code>实例获取所有<code>Method</code>信息。<code>Class</code>类提供了以下几个方法来获取<code>Method</code>：</p>
<ul>
<li><code>Method getMethod(name, Class...)</code>：获取某个<code>public</code>的<code>Method</code>（包括父类）</li>
<li><code>Method getDeclaredMethod(name, Class...)</code>：获取当前类的某个<code>Method</code>（不包括父类）</li>
<li><code>Method[] getMethods()</code>：获取所有<code>public</code>的<code>Method</code>（包括父类）</li>
<li><code>Method[] getDeclaredMethods()</code>：获取当前类的所有<code>Method</code>（不包括父类）</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Class stdClass = Student.class;</span><br><span class="line">        <span class="comment">// 获取public方法getScore，参数为String:</span></span><br><span class="line">        System.out.println(stdClass.getMethod(<span class="string">&quot;getScore&quot;</span>, String.class));</span><br><span class="line">        <span class="comment">// 获取继承的public方法getName，无参数:</span></span><br><span class="line">        System.out.println(stdClass.getMethod(<span class="string">&quot;getName&quot;</span>));</span><br><span class="line">        <span class="comment">// 获取private方法getGrade，参数为int:</span></span><br><span class="line">        System.out.println(stdClass.getDeclaredMethod(<span class="string">&quot;getGrade&quot;</span>, <span class="keyword">int</span>.class));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span> <span class="keyword">extends</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getScore</span><span class="params">(String type)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">99</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">getGrade</span><span class="params">(<span class="keyword">int</span> year)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Person&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">public int Student.getScore(java.lang.String)</span></span><br><span class="line"><span class="comment">public java.lang.String Person.getName()</span></span><br><span class="line"><span class="comment">private int Student.getGrade(int)</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<p>一个<code>Method</code>对象包含一个方法的所有信息：</p>
<ul>
<li><code>getName()</code>：返回方法名称，例如：<code>"getScore"</code>；</li>
<li><code>getReturnType()</code>：返回方法返回值类型，也是一个Class实例，例如：<code>String.class</code>；</li>
<li><code>getParameterTypes()</code>：返回方法的参数类型，是一个Class数组，例如：<code>&#123;String.class, int.class&#125;</code>；</li>
<li><code>getModifiers()</code>：返回方法的修饰符，它是一个<code>int</code>，不同的bit表示不同的含义。</li>
</ul>
<h4 id="调用方法">2、调用方法：</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">String s = &quot;Hello world&quot;;</span><br><span class="line">String r = s.substring(6); // &quot;world&quot;</span><br></pre></td></tr></table></figure>
<p>​ 如果用反射来用<code>substring</code>方法，需要以下代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang.reflect.Method;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// String对象:</span></span><br><span class="line">        String s = <span class="string">&quot;Hello world&quot;</span>;</span><br><span class="line">        <span class="comment">// 获取String substring(int)方法，参数为int:</span></span><br><span class="line">        Method m = String.class.getMethod(<span class="string">&quot;substring&quot;</span>, <span class="keyword">int</span>.class);</span><br><span class="line">        <span class="comment">// 在s对象上调用该方法并获取结果:</span></span><br><span class="line">        String r = (String) m.invoke(s, <span class="number">6</span>);</span><br><span class="line">        <span class="comment">// 打印调用结果:</span></span><br><span class="line">        System.out.println(r);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 对<code>Method</code>实例调用<code>invoke</code>就相当于调用该方法，<code>invoke</code>的第一个参数是对象实例，即在哪个实例上调用该方法，后面的可变参数要与方法参数一致，否则将报错。</p>
<h4 id="调用静态方法">3、调用静态方法：</h4>
<p>​ 如果获取到的Method表示一个静态方法，调用静态方法时，由于无需指定实例对象，所以<code>invoke</code>方法传入的第一个参数永远为<code>null</code>。我们以<code>Integer.parseInt(String)</code>为例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 获取Integer.parseInt(String)方法，参数为String:</span></span><br><span class="line">        Method m = Integer.class.getMethod(<span class="string">&quot;parseInt&quot;</span>, String.class);</span><br><span class="line">        <span class="comment">// 调用该静态方法并获取结果:</span></span><br><span class="line">        Integer n = (Integer) m.invoke(<span class="keyword">null</span>, <span class="string">&quot;12345&quot;</span>);</span><br><span class="line">        <span class="comment">// 打印调用结果:</span></span><br><span class="line">        System.out.println(n);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="调用非public方法">4、调用非public方法：</h4>
<p>为了调用非public方法，我们通过<code>Method.setAccessible(true)</code>允许其调用：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Person p = <span class="keyword">new</span> Person();</span><br><span class="line">        Method m = p.getClass().getDeclaredMethod(<span class="string">&quot;setName&quot;</span>, String.class);</span><br><span class="line">        m.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">        m.invoke(p, <span class="string">&quot;Bob&quot;</span>);</span><br><span class="line">        System.out.println(p.name);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    String name;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="五调用构造方法">五、调用构造方法：</h3>
<p>我们通常使用<code>new</code>操作符创建新的实例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Person p = new Person();</span><br></pre></td></tr></table></figure>
<p>如果通过反射来创建新的实例，可以调用Class提供的newInstance()方法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Person p = Person.class.newInstance();</span><br></pre></td></tr></table></figure>
<p>​ 调用Class.newInstance()的局限是，<strong>它只能调用该类的public无参数构造方法</strong>。如果构造方法带有参数，或者不是public，就无法直接通过Class.newInstance()来调用。</p>
<p>​ 为了调用任意的构造方法，Java的<strong>反射API提供了Constructor对象</strong>，它包含一个构造方法的所有信息，可以创建一个实例。Constructor对象和Method非常类似，不同之处仅在于它是一个构造方法，并且，调用结果总是返回实例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 获取构造方法Integer(int):</span></span><br><span class="line">        Constructor cons1 = Integer.class.getConstructor(<span class="keyword">int</span>.class);</span><br><span class="line">        <span class="comment">// 调用构造方法:</span></span><br><span class="line">        Integer n1 = (Integer) cons1.newInstance(<span class="number">123</span>);</span><br><span class="line">        System.out.println(n1);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取构造方法Integer(String)</span></span><br><span class="line">        Constructor cons2 = Integer.class.getConstructor(String.class);</span><br><span class="line">        Integer n2 = (Integer) cons2.newInstance(<span class="string">&quot;456&quot;</span>);</span><br><span class="line">        System.out.println(n2);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过Class实例获取Constructor的方法如下：</p>
<ul>
<li><code>getConstructor(Class...)</code>：获取某个<code>public</code>的<code>Constructor</code>；</li>
<li><code>getDeclaredConstructor(Class...)</code>：获取某个<code>Constructor</code>；</li>
<li><code>getConstructors()</code>：获取所有<code>public</code>的<code>Constructor</code>；</li>
<li><code>getDeclaredConstructors()</code>：获取所有<code>Constructor</code>。</li>
</ul>
<p>​ 注意<code>Constructor</code>总是当前类定义的构造方法，和父类无关，因此不存在多态的问题。</p>
<p>​ 调用非<code>public</code>的<code>Constructor</code>时，必须首先通过<code>setAccessible(true)</code>设置允许访问。<code>setAccessible(true)</code>可能会失败。</p>
<h3 id="六获取继承关系">六、获取继承关系：</h3>
<h4 id="获取父类的class">1、获取父类的Class</h4>
<p>​ 有了某个类的<code>Class</code>实例，我们还可以获取它的父类的<code>Class</code>：如下，<code>Integer</code>的父类类型是<code>Number</code>，<code>Number</code>的父类是<code>Object</code>，<code>Object</code>的父类是<code>null</code>。除<code>Object</code>外，其他任何非<code>interface</code>的<code>Class</code>都必定存在一个父类类型。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Class i = Integer.class;</span><br><span class="line">        Class n = i.getSuperclass();</span><br><span class="line">        System.out.println(n);</span><br><span class="line">        Class o = n.getSuperclass();</span><br><span class="line">        System.out.println(o);</span><br><span class="line">        System.out.println(o.getSuperclass());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">class java.lang.Number</span></span><br><span class="line"><span class="comment">class java.lang.Object</span></span><br><span class="line"><span class="comment">null </span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<h4 id="获取interface">2、获取Interface</h4>
<p>​ 由于一个类可能实现一个或多个接口，通过<code>Class</code>我们就可以查询到实现的接口类型。例如，查询<code>Integer</code>实现的接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Class s = Integer.class;</span><br><span class="line">        Class[] is = s.getInterfaces();</span><br><span class="line">        <span class="keyword">for</span> (Class i : is) &#123;</span><br><span class="line">            System.out.println(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">interface java.lang.Comparable</span></span><br><span class="line"><span class="comment">interface java.lang.constant.Constable</span></span><br><span class="line"><span class="comment">interface java.lang.constant.ConstantDesc </span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<p>运行上述代码可知，<code>Integer</code>实现的接口有：</p>
<ul>
<li>java.lang.Comparable</li>
<li>java.lang.constant.Constable</li>
<li>java.lang.constant.ConstantDesc</li>
</ul>
<p>要特别注意：</p>
<ul>
<li><p><code>getInterfaces()</code>只返回当前类直接实现的接口类型，并不包括其父类实现的接口类型：</p></li>
<li><p>对所有<code>interface</code>的<code>Class</code>调用<code>getSuperclass()</code>返回的是<code>null</code></p></li>
<li><p>如果一个类没有实现任何<code>interface</code>，那么<code>getInterfaces()</code>返回空数组。</p></li>
</ul>
<h4 id="继承关系">3、继承关系</h4>
<ul>
<li>当我们判断一个实例是否是某个类型时，正常情况下，使用<code>instanceof</code>操作符：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Object n = Integer.valueOf(<span class="number">123</span>);</span><br><span class="line"><span class="keyword">boolean</span> isDouble = n <span class="keyword">instanceof</span> Double; <span class="comment">// false</span></span><br><span class="line"><span class="keyword">boolean</span> isInteger = n <span class="keyword">instanceof</span> Integer; <span class="comment">// true</span></span><br><span class="line"><span class="keyword">boolean</span> isNumber = n <span class="keyword">instanceof</span> Number; <span class="comment">// true</span></span><br><span class="line"><span class="keyword">boolean</span> isSerializable = n <span class="keyword">instanceof</span> java.io.Serializable; <span class="comment">// true</span></span><br></pre></td></tr></table></figure>
<ul>
<li>如果是两个<code>Class</code>实例，要判断一个向上转型是否成立，可以调用<code>isAssignableFrom()</code>：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Integer i = ?</span></span><br><span class="line">Integer.class.isAssignableFrom(Integer.class); <span class="comment">// true，因为Integer可以赋值给Integer</span></span><br><span class="line"><span class="comment">// Number n = ?</span></span><br><span class="line">Number.class.isAssignableFrom(Integer.class); <span class="comment">// true，因为Integer可以赋值给Number</span></span><br><span class="line"><span class="comment">// Object o = ?</span></span><br><span class="line">Object.class.isAssignableFrom(Integer.class); <span class="comment">// true，因为Integer可以赋值给Object</span></span><br><span class="line"><span class="comment">// Integer i = ?</span></span><br><span class="line">Integer.class.isAssignableFrom(Number.class); <span class="comment">// false，因为Number不能赋值给Integer</span></span><br></pre></td></tr></table></figure>
<h3 id="七动态代理">七、动态代理：</h3>
<p>​ ? 未完待续</p>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>reflection</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记4——java异常处理</title>
    <url>/2022/01/30/f51e40b9c407/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1264734349295520</p>
<h3 id="一java异常简介">一、Java异常简介：</h3>
<h4 id="异常介绍与分类">1、异常介绍与分类</h4>
<p>所以，一个健壮的程序必须处理各种各样的错误。</p>
<p>调用方如何获知调用失败的信息？有两种方法：</p>
<ul>
<li>方法1：约定返回错误码，常见于C</li>
<li>方法2：在语言层面上提供异常处理机制：（较为常用）</li>
</ul>
<p><strong>异常是一种<code>class</code>，因此它本身带有类型信息。异常可以在任何地方抛出，但只需要在上层捕获，这样就和方法调用分离了</strong></p>
<p>Java的异常是<code>class</code>，它的继承关系如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">                     ┌───────────┐</span><br><span class="line">                     │  Object   │</span><br><span class="line">                     └───────────┘</span><br><span class="line">                           ▲</span><br><span class="line">                           │</span><br><span class="line">                     ┌───────────┐</span><br><span class="line">                     │ Throwable │</span><br><span class="line">                     └───────────┘</span><br><span class="line">                           ▲</span><br><span class="line">                 ┌─────────┴─────────┐</span><br><span class="line">                 │                   │</span><br><span class="line">           ┌───────────┐       ┌───────────┐</span><br><span class="line">           │   Error   │       │ Exception │</span><br><span class="line">           └───────────┘       └───────────┘</span><br><span class="line">                 ▲                   ▲</span><br><span class="line">         ┌───────┘              ┌────┴──────────┐</span><br><span class="line">         │                      │               │</span><br><span class="line">┌─────────────────┐    ┌─────────────────┐┌───────────┐</span><br><span class="line">│OutOfMemoryError │... │RuntimeException ││IOException│...</span><br><span class="line">└─────────────────┘    └─────────────────┘└───────────┘</span><br><span class="line">                                ▲</span><br><span class="line">                    ┌───────────┴─────────────┐</span><br><span class="line">                    │                         │</span><br><span class="line">         ┌─────────────────────┐ ┌─────────────────────────┐</span><br><span class="line">         │NullPointerException │ │IllegalArgumentException │...</span><br><span class="line">         └─────────────────────┘ └─────────────────────────┘</span><br></pre></td></tr></table></figure>
<p>从上图继承关系可知：<code>Throwable</code>是异常体系的根，它继承自<code>Object</code>。<code>Throwable</code>有两个体系：<code>Error</code>和<code>Exception</code>，<code>Error</code>表示严重的错误，程序对此一般无能为力，例如：</p>
<ul>
<li><code>OutOfMemoryError</code>：内存耗尽</li>
<li><code>NoClassDefFoundError</code>：无法加载某个Class</li>
<li><code>StackOverflowError</code>：栈溢出</li>
</ul>
<p>而<code>Exception</code>则是运行时的错误，它可以被捕获并处理。</p>
<ul>
<li><p>某些异常是应用程序逻辑处理的一部分，应该捕获并处理。例如：</p>
<ul>
<li><p><code>NumberFormatException</code>：数值类型的格式错误</p></li>
<li><p><code>FileNotFoundException</code>：未找到文件</p></li>
<li><p><code>SocketException</code>：读取网络失败</p></li>
</ul></li>
<li><p>还有一些异常是程序逻辑编写不对造成的，应该修复程序本身。例如：</p>
<ul>
<li><p><code>NullPointerException</code>：对某个<code>null</code>的对象调用方法或字段</p></li>
<li><p><code>IndexOutOfBoundsException</code>：数组索引越界</p></li>
</ul></li>
</ul>
<p><code>Exception</code>又分为两大类：</p>
<ol type="1">
<li><code>RuntimeException</code>以及它的子类；</li>
<li>非<code>RuntimeException</code>（包括<code>IOException</code>、<code>ReflectiveOperationException</code>等等）</li>
</ol>
<p><strong>Java规定</strong>：</p>
<ul>
<li>必须捕获的异常，包括<code>Exception</code>及其子类，但不包括<code>RuntimeException</code>及其子类，这种类型的异常称为<strong>Checked Exception</strong>。</li>
<li>不需要捕获的异常，包括<code>Error</code>及其子类，<code>RuntimeException</code>及其子类。</li>
</ul>
<h3 id="二捕获异常">二、捕获异常：</h3>
<h4 id="普通的捕获异常">1、普通的捕获异常：</h4>
<p>​ 捕获异常使用<code>try...catch</code>语句，把可能发生异常的代码放到<code>try &#123;...&#125;</code>中，然后使用<code>catch</code>捕获对应的<code>Exception</code>及其子类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.UnsupportedEncodingException;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">byte</span>[] bs = toGBK(<span class="string">&quot;中文&quot;</span>);</span><br><span class="line">        System.out.println(Arrays.toString(bs));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">byte</span>[] toGBK(String s) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 用指定编码转换String为byte[]:</span></span><br><span class="line">            <span class="keyword">return</span> s.getBytes(<span class="string">&quot;GBK&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">            <span class="comment">// 如果系统不支持GBK编码，会捕获到UnsupportedEncodingException:</span></span><br><span class="line">            System.out.println(e); <span class="comment">// 打印异常信息</span></span><br><span class="line">            <span class="keyword">return</span> s.getBytes(); <span class="comment">// 尝试使用用默认编码</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​ 如果我们不捕获<code>UnsupportedEncodingException</code>，会出现编译失败的问题：编译器会报错，错误信息类似：unreported exception UnsupportedEncodingException; must be caught or declared to be thrown，并且准确地指出需要捕获的语句是<code>return s.getBytes("GBK");</code>。意思是说，像<code>UnsupportedEncodingException</code>这样的Checked Exception，必须被捕获。</p>
<p>​ <strong>这是因为<code>String.getBytes(String)</code>方法定义是：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] getBytes(String charsetName) <span class="keyword">throws</span> UnsupportedEncodingException &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ <strong>在方法定义的时候，使用<code>throws Xxx</code>表示该方法可能抛出的异常类型</strong>。调用方在调用的时候，必须强制捕获这些异常，否则编译器会报错。</p>
<p>​ <strong>注意</strong>：只要是方法声明的Checked Exception，不在调用层捕获，也必须在更高的调用层捕获。所有未捕获的异常，最终也必须在<code>main()</code>方法中捕获，不会出现漏写<code>try</code>的情况。这是由编译器保证的。<code>main()</code>方法也是最后捕获<code>Exception</code>的机会。</p>
<p>​ <strong>注意</strong>：所有异常都可以调用<code>printStackTrace()</code>方法打印异常栈，这是一个简单有用的快速打印异常的方法。</p>
<h4 id="多个catch语句">2、多个catch语句：</h4>
<p>​ 可以使用多个<code>catch</code>语句，每个<code>catch</code>分别捕获对应的<code>Exception</code>及其子类。JVM在捕获到异常后，会从上到下匹配<code>catch</code>语句，匹配到某个<code>catch</code>后，执行<code>catch</code>代码块，然后不再继续匹配。</p>
<p>​ <strong>存在多个<code>catch</code>的时候，<code>catch</code>的顺序非常重要：</strong>子类必须写在前面。例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        process1();</span><br><span class="line">        process2();</span><br><span class="line">        process3();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;IO error&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123; <span class="comment">// 永远捕获不到</span></span><br><span class="line">        System.out.println(<span class="string">&quot;Bad encoding&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ <strong>对于上面的代码，<code>UnsupportedEncodingException</code>异常是永远捕获不到的</strong>，因为它是<code>IOException</code>的子类。当抛出<code>UnsupportedEncodingException</code>异常时，会被<code>catch (IOException e) &#123; ... &#125;</code>捕获并执行。</p>
<h4 id="finally语句">3、finally语句：</h4>
<p>无论是否有异常发生，如果我们都希望执行一些语句</p>
<p>Java的<code>try ... catch</code>机制还提供了<code>finally</code>语句，<code>finally</code>语句块保证有无错误都会执行。上述代码可以改写如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        process1();</span><br><span class="line">        process2();</span><br><span class="line">        process3();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (UnsupportedEncodingException e) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Bad encoding&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;IO error&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;END&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意<code>finally</code>有几个特点：</p>
<ol type="1">
<li><code>finally</code>语句不是必须的，可写可不写；</li>
<li><code>finally</code>总是最后执行。</li>
</ol>
<p>​ 如果没有发生异常，就正常执行<code>try &#123; ... &#125;</code>语句块，然后执行<code>finally</code>。如果发生了异常，就中断执行<code>try &#123; ... &#125;</code>语句块，然后跳转执行匹配的<code>catch</code>语句块，最后执行<code>finally</code>。</p>
<h4 id="捕获多种异常">4、捕获多种异常：</h4>
<p>可以把两个处理逻辑一样的异常用<code>|</code>合并到一起</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        process1();</span><br><span class="line">        process2();</span><br><span class="line">        process3();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException | NumberFormatException e) &#123; <span class="comment">// IOException或NumberFormatException</span></span><br><span class="line">        System.out.println(<span class="string">&quot;Bad input&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Unknown error&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="三抛出异常">三、抛出异常：</h3>
<h4 id="抛出异常链条">1、抛出异常链条：</h4>
<p>​ 当某个方法抛出了异常时，如果当前方法没有捕获异常，异常就会被抛到上层调用方法，直到遇到某个<code>try ... catch</code>被捕获为止</p>
<p>​ 通过<code>printStackTrace()</code>可以打印出方法的调用栈，类似：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java.lang.NumberFormatException: <span class="keyword">null</span></span><br><span class="line">    at java.base/java.lang.Integer.parseInt(Integer.java:<span class="number">614</span>)</span><br><span class="line">    at java.base/java.lang.Integer.parseInt(Integer.java:<span class="number">770</span>)</span><br><span class="line">    at Main.process2(Main.java:<span class="number">16</span>)</span><br><span class="line">    at Main.process1(Main.java:<span class="number">12</span>)</span><br><span class="line">    at Main.main(Main.java:<span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p><code>printStackTrace()</code>对于调试错误非常有用，上述信息表示：<code>NumberFormatException</code>是在<code>java.lang.Integer.parseInt</code>方法中被抛出的，从下往上看，调用层次依次是：</p>
<ol type="1">
<li><code>main()</code>调用<code>process1()</code>；</li>
<li><code>process1()</code>调用<code>process2()</code>；</li>
<li><code>process2()</code>调用<code>Integer.parseInt(String)</code>；</li>
<li><code>Integer.parseInt(String)</code>调用<code>Integer.parseInt(String, int)</code>。</li>
</ol>
<h4 id="如何抛出异常">2、如何抛出异常：</h4>
<p>抛出异常分两步：</p>
<ol type="1">
<li>创建某个<code>Exception</code>的实例；</li>
<li>用<code>throw</code>语句抛出。</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process2</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (s==<span class="keyword">null</span>) &#123;</span><br><span class="line">        NullPointerException e = <span class="keyword">new</span> NullPointerException();</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>或写成一行：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process2</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (s==<span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="异常捕获后再次抛出">3、异常捕获后再次抛出：</h4>
<p>​ 如果一个方法捕获了某个异常后，又在<code>catch</code>子句中抛出新的异常，就相当于把抛出的异常类型“转换”了：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process1</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        process2();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (NullPointerException e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">process2</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (s==<span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>打印出的异常栈类似：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java.lang.IllegalArgumentException</span><br><span class="line">    at Main.process1(Main.java:15)</span><br><span class="line">    at Main.main(Main.java:5)</span><br></pre></td></tr></table></figure>
<p>​ 这说明<strong>新的异常丢失了原始异常信息</strong>，我们已经看不到原始异常<code>NullPointerException</code>的信息了。</p>
<p>​ <strong>为了能追踪到完整的异常栈，在构造异常的时候，把原始的<code>Exception</code>实例传进去，新的<code>Exception</code>就可以持有原始<code>Exception</code>信息。</strong>对上述代码改进如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            process1();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">process1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            process2();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (NullPointerException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">process2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>运行上述代码，打印出的异常栈类似：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java.lang.IllegalArgumentException: java.lang.NullPointerException</span><br><span class="line">    at Main.process1(Main.java:15)</span><br><span class="line">    at Main.main(Main.java:5)</span><br><span class="line">Caused by: java.lang.NullPointerException</span><br><span class="line">    at Main.process2(Main.java:20)</span><br><span class="line">    at Main.process1(Main.java:13)</span><br></pre></td></tr></table></figure>
<p>​ 注意到<code>Caused by: Xxx</code>，说明捕获的<code>IllegalArgumentException</code>并不是造成问题的根源，根源在于<code>NullPointerException</code>，是在<code>Main.process2()</code>方法抛出的。</p>
<p>​ 在代码中<strong>获取原始异常可以使用<code>Throwable.getCause()</code>方法。如果返回<code>null</code>，说明已经是“根异常”了。</strong></p>
<h4 id="在try或catch种抛出异常finally语句会先执行然后再抛出异常">4、在try或catch种抛出异常，finally语句会先执行，然后再抛出异常</h4>
<h4 id="异常屏蔽">5、异常屏蔽：</h4>
<p>​ 如果在执行<code>finally</code>语句时抛出异常，那么，<code>catch</code>语句的异常还能否继续抛出？例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Integer.parseInt(<span class="string">&quot;abc&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;catched&quot;</span>);</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;finally&quot;</span>);</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行上述代码，发现异常信息如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">catched</span><br><span class="line">finally</span><br><span class="line">Exception in thread &quot;main&quot; java.lang.IllegalArgumentException</span><br><span class="line">    at Main.main(Main.java:11)</span><br></pre></td></tr></table></figure>
<p>​ 这说明<strong><code>finally</code>抛出异常后，原来在<code>catch</code>中准备抛出的异常就“消失”了，因为只能抛出一个异常。没有被抛出的异常称为“被屏蔽”的异常</strong>（Suppressed Exception）。</p>
<p>​ <strong>绝大多数情况下，在<code>finally</code>中不要抛出异常</strong>。因此，我们通常不需要关心<code>Suppressed Exception</code>。</p>
<h3 id="四自定义异常">四、自定义异常</h3>
<p>Java标准库定义的常用异常包括：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Exception</span><br><span class="line">│</span><br><span class="line">├─ RuntimeException</span><br><span class="line">│  │</span><br><span class="line">│  ├─ NullPointerException</span><br><span class="line">│  │</span><br><span class="line">│  ├─ IndexOutOfBoundsException</span><br><span class="line">│  │</span><br><span class="line">│  ├─ SecurityException</span><br><span class="line">│  │</span><br><span class="line">│  └─ IllegalArgumentException 参数检查不合法</span><br><span class="line">│     │</span><br><span class="line">│     └─ NumberFormatException</span><br><span class="line">│</span><br><span class="line">├─ IOException</span><br><span class="line">│  │</span><br><span class="line">│  ├─ UnsupportedCharsetException</span><br><span class="line">│  │</span><br><span class="line">│  ├─ FileNotFoundException</span><br><span class="line">│  │</span><br><span class="line">│  └─ SocketException</span><br><span class="line">│</span><br><span class="line">├─ ParseException</span><br><span class="line">│</span><br><span class="line">├─ GeneralSecurityException</span><br><span class="line">│</span><br><span class="line">├─ SQLException</span><br><span class="line">│</span><br><span class="line">└─ TimeoutException</span><br></pre></td></tr></table></figure>
<p><strong>当我们在代码中需要抛出异常时，尽量使用JDK已定义的异常类型</strong></p>
<p>在一个大型项目中，可以自定义新的异常类型，但是，保持一个合理的异常继承体系是非常重要的。</p>
<p><strong>一个常见的做法是自定义一个<code>BaseException</code>作为“根异常”，然后，派生出各种业务类型的异常。</strong></p>
<p><code>BaseException</code>需要从一个适合的<code>Exception</code>派生，通常建议从<code>RuntimeException</code>派生：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BaseException</span> <span class="keyword">extends</span> <span class="title">RuntimeException</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其他业务类型的异常就可以从<code>BaseException</code>派生：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserNotFoundException</span> <span class="keyword">extends</span> <span class="title">BaseException</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginFailedException</span> <span class="keyword">extends</span> <span class="title">BaseException</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>自定义的<code>BaseException</code>应该提供多个构造方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BaseException</span> <span class="keyword">extends</span> <span class="title">RuntimeException</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">BaseException</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">BaseException</span><span class="params">(String message, Throwable cause)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(message, cause);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">BaseException</span><span class="params">(String message)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(message);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">BaseException</span><span class="params">(Throwable cause)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(cause);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 上述构造方法实际上都是原样照抄<code>RuntimeException</code>。这样，抛出异常的时候，就可以选择合适的构造方法。通过IDE可以根据父类快速生成子类的构造方法。</p>
<h3 id="五nullpointerexception">五、NullPointerException</h3>
<p>​ <code>NullPointerException</code>即空指针异常，俗称NPE。如果一个对象为<code>null</code>，调用其方法或访问其字段就会产生`NullPointerException</p>
<h4 id="如何处理nullpointerexception">1、如何处理NullPointerException</h4>
<p>​ 遇到<code>NullPointerException</code>，遵循原则是早暴露，早修复，严禁使用<code>catch</code>来隐藏这种编码错误，一些好的编码习惯：如下</p>
<ul>
<li>成员变量在定义时初始化：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name = <span class="string">&quot;&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>使用空字符串<code>""</code>而不是默认的<code>null</code>可避免很多<code>NullPointerException</code>，编写业务逻辑时，用空字符串<code>""</code>表示未填写比<code>null</code>安全得多。</p></li>
<li><p>返回空字符串<code>""</code>、空数组而不是<code>null</code>,这样可以使得调用方无需检查结果是否为<code>null</code>。</p></li>
<li><p>如果调用方一定要根据<code>null</code>判断，比如返回<code>null</code>表示文件不存在，那么考虑返回<code>Optional&lt;T&gt;</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Optional&lt;String&gt; <span class="title">readFromFile</span><span class="params">(String file)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!fileExist(file)) &#123;</span><br><span class="line">        <span class="keyword">return</span> Optional.empty();</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样调用方必须通过<code>Optional.isPresent()</code>判断是否有结果。</p></li>
</ul>
<h4 id="如何定位nullpointerexception">2、如何定位NullPointerException</h4>
<p>​ 如果产生了<code>NullPointerException</code>，例如，调用<code>a.b.c.x()</code>时产生了<code>NullPointerException</code>，原因可能是：</p>
<ul>
<li><code>a</code>是<code>null</code>；</li>
<li><code>a.b</code>是<code>null</code>；</li>
<li><code>a.b.c</code>是<code>null</code>；</li>
</ul>
<p>​ 从Java 14开始，如果产生了<code>NullPointerException</code>，JVM可以给出详细的信息告诉我们<code>null</code>对象到底是谁。我们来看例子：</p>
<p>​ 可以在<code>NullPointerException</code>的详细信息中看到类似<code>... because "&lt;local1&gt;.address.city" is null</code>，意思是<code>city</code>字段为<code>null</code>，这样我们就能快速定位问题所在。</p>
<p>​ 这种增强的<code>NullPointerException</code>详细信息是Java 14新增的功能，但默认是关闭的，我们可以给JVM添加一个<code>-XX:+ShowCodeDetailsInExceptionMessages</code>参数启用它：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java -XX:+ShowCodeDetailsInExceptionMessages Main.java</span><br></pre></td></tr></table></figure>
<h3 id="六使用断言">六、使用断言</h3>
<p>​ 断言（Assertion）是一种<strong>调试程序的方式</strong>。在Java中，使用<code>assert</code>关键字来实现断言。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> x = Math.abs(-<span class="number">123.45</span>);</span><br><span class="line">    <span class="keyword">assert</span> x &gt;= <span class="number">0</span> : <span class="string">&quot;x must &gt;= 0&quot;</span>;</span><br><span class="line">    System.out.println(x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 语句<code>assert x &gt;= 0;</code>即为断言，断言条件<code>x &gt;= 0</code>预期为<code>true</code>。如果计算结果为<code>false</code>，则断言失败，抛出<code>AssertionError</code>。": "x must &gt;= 0" " 为可选的断言消息：</p>
<p>​ 这样，断言失败的时候，<code>AssertionError</code>会带上消息<code>x must &gt;= 0</code>，更加便于调试。</p>
<p>​ <strong>Java断言的特点是：断言失败时会抛出<code>AssertionError</code>，导致程序结束退出。因此，断言不能用于可恢复的程序错误，只应该用于开发和测试阶段。</strong></p>
<p><strong>注意</strong>：这JVM默认关闭断言指令，即遇到<code>assert</code>语句就自动忽略了，不执行。要执行<code>assert</code>语句，必须给Java虚拟机传递<code>-enableassertions</code>（可简写为<code>-ea</code>）参数启用断言。所以，上述程序必须在命令行下运行才有效果：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ java -ea Main.java</span><br><span class="line">Exception <span class="keyword">in</span> thread <span class="string">&quot;main&quot;</span> java.lang.AssertionError</span><br><span class="line">	at Main.main(Main.java:5)</span><br></pre></td></tr></table></figure>
<p>​ 断言很少被使用，更好的方法是编写单元测试。</p>
<h3 id="七使用jdk-logging">七、使用JDK Logging</h3>
<h4 id="使用日志的目的">1、使用日志的目的？</h4>
<p>日志就是Logging，它的目的是为了取代<code>System.out.println()</code>。</p>
<p>输出日志，而不是用<code>System.out.println()</code>，有以下几个好处：</p>
<ol type="1">
<li>可以设置输出样式，避免自己每次都写<code>"ERROR: " + var</code>；</li>
<li>可以设置输出级别，禁止某些级别输出。例如，只输出错误日志；</li>
<li>可以被重定向到文件，这样可以在程序运行结束后查看日志；</li>
<li>可以按包名控制日志级别，只输出某些包打的日志；</li>
</ol>
<h4 id="如何使用日志">2、如何使用日志？</h4>
<p>Java标准库内置了日志包<code>java.util.logging</code>，我们可以直接用</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.logging.Level;</span><br><span class="line"><span class="keyword">import</span> java.util.logging.Logger;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Hello</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Logger logger = Logger.getGlobal();</span><br><span class="line">        logger.info(<span class="string">&quot;start process...&quot;</span>);</span><br><span class="line">        logger.warning(<span class="string">&quot;memory is running out...&quot;</span>);</span><br><span class="line">        logger.fine(<span class="string">&quot;ignored.&quot;</span>);</span><br><span class="line">        logger.severe(<span class="string">&quot;process will be terminated...&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>运行上述代码，得到类似如下的输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Mar 02, 2019 6:32:13 PM Hello main</span><br><span class="line">INFO: start process...</span><br><span class="line">Mar 02, 2019 6:32:13 PM Hello main</span><br><span class="line">WARNING: memory is running out...</span><br><span class="line">Mar 02, 2019 6:32:13 PM Hello main</span><br><span class="line">SEVERE: process will be terminated...</span><br></pre></td></tr></table></figure>
<p>对比可见，使用日志最大的好处是，它自动打印了时间、调用类、调用方法等很多有用的信息。</p>
<h4 id="日志的输出级别">3、日志的输出级别：</h4>
<p>再仔细观察发现上述输出，4条日志，只打印了3条，<code>logger.fine()</code>没有打印。这是因为，日志的输出可以设定级别。JDK的Logging定义了7个日志级别，从严重到普通：</p>
<ul>
<li>SEVERE</li>
<li>WARNING</li>
<li>INFO</li>
<li>CONFIG</li>
<li>FINE</li>
<li>FINER</li>
<li>FINEST</li>
</ul>
<p>​ 因为<strong>默认级别是INFO，因此，INFO级别以下的日志，不会被打印出来。</strong>使用日志级别的好处在于，<strong>调整级别，就可以屏蔽掉很多调试相关的日志输出。</strong></p>
<p>使用Java标准库内置的Logging有以下局限：</p>
<ul>
<li><p>Logging系统在JVM启动时读取配置文件并完成初始化，一旦开始运行<code>main()</code>方法，就无法修改配置；</p></li>
<li><p>配置不太方便，需要在JVM启动时传递参数<code>-Djava.util.logging.config.file=&lt;config-file-name&gt;</code>。</p></li>
</ul>
<p>​ <strong>因此，Java标准库内置的Logging使用并不是非常广泛，更广泛的是下一个模块中所说的Commons Logging 或 Log4j 或</strong></p>
<h3 id="八使用commons-logging">八、使用Commons Logging</h3>
<h4 id="简单介绍">1、简单介绍</h4>
<p>​ <strong>Commons Logging是一个第三方日志库，它是由Apache创建的日志模块</strong></p>
<p>​ Commons Logging的特色是，<strong>它可以挂接不同的日志系统，并通过配置文件指定挂接的日志系统。</strong>默认情况下，<strong>Commons Logging自动搜索并使用Log4j</strong>（Log4j是另一个流行的日志系统），如果没有找到Log4j，再使用JDK Logging。</p>
<h4 id="如何使用">2、如何使用：</h4>
<p>第一步，通过<code>LogFactory</code>获取<code>Log</code>类的实例；</p>
<p>第二步，使用<code>Log</code>实例的方法打日志。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.commons.logging.Log;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.logging.LogFactory;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Log log = LogFactory.getLog(Main.class);</span><br><span class="line">        log.info(<span class="string">&quot;start...&quot;</span>);</span><br><span class="line">        log.warn(<span class="string">&quot;end.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="日志级别">3、日志级别：</h4>
<p>Commons Logging定义了6个日志级别：</p>
<ul>
<li>FATAL</li>
<li>ERROR</li>
<li>WARNING</li>
<li>INFO</li>
<li>DEBUG</li>
<li>TRACE</li>
</ul>
<p>默认级别是<code>INFO</code>。</p>
<h4 id="通常使用指南">4、通常使用指南</h4>
<ul>
<li>使用Commons Logging时，如果在静态方法中引用<code>Log</code>，通常直接定义一个静态类型变量：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在静态方法中引用Log:</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> Log log = LogFactory.getLog(Main.class);</span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;foo&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>在实例方法中引用<code>Log</code>，通常定义一个实例变量：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在实例方法中引用Log:</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">final</span> Log log = LogFactory.getLog(getClass());</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;foo&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ <strong>注意到实例变量log的获取方式是<code>LogFactory.getLog(getClass())</code>，虽然也可以用<code>LogFactory.getLog(Person.class)</code>，但是前一种方式有个非常大的好处，就是子类可以直接使用该<code>log</code>实例。例如：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在子类中使用父类实例化的log:</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Student</span> <span class="keyword">extends</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;bar&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 由于Java类的动态特性，子类获取的<code>log</code>字段实际上相当于<code>LogFactory.getLog(Student.class)</code>，但却是从父类继承而来，并且无需改动代码。</p>
<h4 id="记录异常">5、记录异常：</h4>
<p>​ 此外，Commons Logging的日志方法，例如<code>info()</code>，除了标准的<code>info(String)</code>外，还提供了一个非常有用的重载方法：<code>info(String, Throwable)</code>，这使得记录异常更加简单：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    log.error(<span class="string">&quot;got exception!&quot;</span>, e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="九使用log4j">九、使用Log4j</h3>
<h4 id="框架简介">1、框架简介：</h4>
<p>​ 上述介绍了Commons Logging，可以作为“日志接口”来使用。而真正的“日志实现”可以使用Log4j。</p>
<p>​ Log4j是一种非常流行的日志框架，最新版本是2.x。</p>
<p>​ Log4j是一个组件化设计的日志系统，它的架构大致如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">log.info(&quot;User signed in.&quot;);</span><br><span class="line"> │</span><br><span class="line"> │   ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐</span><br><span class="line"> ├──&gt;│ Appender │───&gt;│  Filter  │───&gt;│  Layout  │───&gt;│ Console  │</span><br><span class="line"> │   └──────────┘    └──────────┘    └──────────┘    └──────────┘</span><br><span class="line"> │</span><br><span class="line"> │   ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐</span><br><span class="line"> ├──&gt;│ Appender │───&gt;│  Filter  │───&gt;│  Layout  │───&gt;│   File   │</span><br><span class="line"> │   └──────────┘    └──────────┘    └──────────┘    └──────────┘</span><br><span class="line"> │</span><br><span class="line"> │   ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐</span><br><span class="line"> └──&gt;│ Appender │───&gt;│  Filter  │───&gt;│  Layout  │───&gt;│  Socket  │</span><br><span class="line">     └──────────┘    └──────────┘    └──────────┘    └──────────┘</span><br></pre></td></tr></table></figure>
<p>​ 当我们使用Log4j输出一条日志时，Log4j自动通过不同的Appender把同一条日志输出到不同的目的地。例如：</p>
<ul>
<li>console：输出到屏幕；</li>
<li>file：输出到文件；</li>
<li>socket：通过网络输出到远程计算机；</li>
<li>jdbc：输出到数据库</li>
</ul>
<p>​ <strong>在输出日志的过程中，通过Filter来过滤哪些log需要被输出，哪些log不需要被输出。例如，仅输出<code>ERROR</code>级别的日志。</strong></p>
<p>最后，通过Layout来格式化日志信息，例如，自动添加日期、时间、方法名称等信息。</p>
<p><strong>上述结构虽然复杂，但我们在实际使用的时候，并不需要关心Log4j的API，而是通过配置文件来配置它。</strong></p>
<h4 id="如何使用-1">2、如何使用：</h4>
<p>以XML配置为例，使用Log4j的时候，我们把一个<code>log4j2.xml</code>的文件放到<code>classpath</code>下就可以让Log4j读取配置文件并按照我们的配置来输出日志。下面是一个配置文件的例子：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">Configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">Properties</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 定义日志格式 --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Property</span> <span class="attr">name</span>=<span class="string">&quot;log.pattern&quot;</span>&gt;</span>%d&#123;MM-dd HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125;%n%msg%n%n<span class="tag">&lt;/<span class="name">Property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 定义文件名变量 --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Property</span> <span class="attr">name</span>=<span class="string">&quot;file.err.filename&quot;</span>&gt;</span>log/err.log<span class="tag">&lt;/<span class="name">Property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Property</span> <span class="attr">name</span>=<span class="string">&quot;file.err.pattern&quot;</span>&gt;</span>log/err.%i.log.gz<span class="tag">&lt;/<span class="name">Property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">Properties</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 定义Appender，即目的地 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">Appenders</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 定义输出到屏幕 --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Console</span> <span class="attr">name</span>=<span class="string">&quot;console&quot;</span> <span class="attr">target</span>=<span class="string">&quot;SYSTEM_OUT&quot;</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 日志格式引用上面定义的log.pattern --&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">PatternLayout</span> <span class="attr">pattern</span>=<span class="string">&quot;$&#123;log.pattern&#125;&quot;</span> /&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">Console</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 定义输出到文件,文件名引用上面定义的file.err.filename --&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">RollingFile</span> <span class="attr">name</span>=<span class="string">&quot;err&quot;</span> <span class="attr">bufferedIO</span>=<span class="string">&quot;true&quot;</span> <span class="attr">fileName</span>=<span class="string">&quot;$&#123;file.err.filename&#125;&quot;</span> <span class="attr">filePattern</span>=<span class="string">&quot;$&#123;file.err.pattern&#125;&quot;</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">PatternLayout</span> <span class="attr">pattern</span>=<span class="string">&quot;$&#123;log.pattern&#125;&quot;</span> /&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">Policies</span>&gt;</span></span><br><span class="line">                <span class="comment">&lt;!-- 根据文件大小自动切割日志 --&gt;</span></span><br><span class="line">				<span class="tag">&lt;<span class="name">SizeBasedTriggeringPolicy</span> <span class="attr">size</span>=<span class="string">&quot;1 MB&quot;</span> /&gt;</span></span><br><span class="line">			<span class="tag">&lt;/<span class="name">Policies</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 保留最近10份 --&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">DefaultRolloverStrategy</span> <span class="attr">max</span>=<span class="string">&quot;10&quot;</span> /&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">RollingFile</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">Appenders</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">Loggers</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">Root</span> <span class="attr">level</span>=<span class="string">&quot;info&quot;</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 对info级别的日志，输出到console --&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">&quot;console&quot;</span> <span class="attr">level</span>=<span class="string">&quot;info&quot;</span> /&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 对error级别的日志，输出到err，即上面定义的RollingFile --&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">AppenderRef</span> <span class="attr">ref</span>=<span class="string">&quot;err&quot;</span> <span class="attr">level</span>=<span class="string">&quot;error&quot;</span> /&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">Root</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">Loggers</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">Configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>​ 虽然配置Log4j比较繁琐，但一旦配置完成，使用起来就非常方便。对上面的配置文件，凡是<code>INFO</code>级别的日志，会自动输出到屏幕，而<code>ERROR</code>级别的日志，不但会输出到屏幕，还会同时输出到文件。并且，一旦日志文件达到指定大小（1MB），Log4j就会自动切割新的日志文件，并最多保留10份。</p>
<p>​ 有了配置文件还不够，因为Log4j也是一个第三方库，我们需要从<a href="https://logging.apache.org/log4j/2.x/download.html">这里</a>下载Log4j，解压后，把以下3个jar包放到<code>classpath</code>中：</p>
<ul>
<li>log4j-api-2.x.jar</li>
<li>log4j-core-2.x.jar</li>
<li>log4j-jcl-2.x.jar</li>
</ul>
<p>​ 因为Commons Logging会自动发现并使用Log4j，所以，把上一节下载的<code>commons-logging-1.2.jar</code>也放到<code>classpath</code>中。</p>
<p>​ 要打印日志，只需要按Commons Logging的写法写，不需要改动任何代码，就可以得到Log4j的日志输出，类似：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">03-03 12:09:45.880 [main] INFO  com.itranswarp.learnjava.Main</span><br><span class="line">Start process...</span><br></pre></td></tr></table></figure>
<h4 id="最佳实践">3、最佳实践：</h4>
<p>​ 在开发阶段，始终使用Commons Logging接口来写入日志，并且开发阶段无需引入Log4j。如果需要把日志写入文件， 只需要把正确的配置文件和Log4j相关的jar包放入<code>classpath</code>，就可以自动把日志切换成使用Log4j写入，无需修改任何代码。</p>
<h3 id="十使用slf4j和logback">十、使用SLF4J和Logback</h3>
<p>​ SLF4J类似于Commons Logging，也是一个日志接口，而Logback类似于Log4j，是一个日志的实现。</p>
<p>​ SLF4J对Commons Logging的接口有何改进？在Commons Logging中，我们要打印日志，有时候得这么写：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> score = <span class="number">99</span>;</span><br><span class="line">p.setScore(score);</span><br><span class="line">log.info(<span class="string">&quot;Set score &quot;</span> + score + <span class="string">&quot; for Person &quot;</span> + p.getName() + <span class="string">&quot; ok.&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>拼字符串是一个非常麻烦的事情，所以SLF4J的日志接口改进成这样了：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> score = <span class="number">99</span>;</span><br><span class="line">p.setScore(score);</span><br><span class="line">logger.info(<span class="string">&quot;Set score &#123;&#125; for Person &#123;&#125; ok.&quot;</span>, score, p.getName());</span><br></pre></td></tr></table></figure>
<p>我们靠猜也能猜出来，SLF4J的日志接口传入的是一个带占位符的字符串，用后面的变量自动替换占位符，所以看起来更加自然。</p>
<p>具体可以参照更详细的官方网站的教程</p>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记3——java核心类</title>
    <url>/2022/01/30/08838c47e5bb/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1260469698963456</p>
<h3 id="一字符串和编码">一、字符串和编码</h3>
<p>​ Java字符串的一个重要特点就是字符串<strong>不可变</strong>。这种不可变性是通过内部的<code>private final char[]</code>字段，以及没有任何修改<code>char[]</code>的方法实现的。</p>
<h4 id="字符串比较">1、字符串比较</h4>
<p>​ 必须使用<code>equals()</code>方法而不能用<code>==</code></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String s1 = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">        String s2 = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">        System.out.println(s1 == s2);     <span class="comment">//true</span></span><br><span class="line">        System.out.println(s1.equals(s2));  <span class="comment">//true</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 从表面上看，两个字符串用<code>==</code>和<code>equals()</code>比较都为<code>true</code>，但<strong>实际上那只是Java编译器在编译期，会自动把所有相同的字符串当作一个对象放入常量池，自然<code>s1</code>和<code>s2</code>的引用就是相同的。</strong></p>
<p>​ 所以，这种<code>==</code>比较返回<code>true</code>纯属巧合。换一种写法，<code>==</code>比较就会失败：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String s1 = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">        String s2 = <span class="string">&quot;HELLO&quot;</span>.toLowerCase();</span><br><span class="line">        System.out.println(s1 == s2);</span><br><span class="line">        System.out.println(s1.equals(s2));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 要忽略大小写比较，使用<code>equalsIgnoreCase()</code>方法。</p>
<h4 id="搜索与提取子串">2、搜索与提取子串</h4>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;Hello&quot;</span>.contains(<span class="string">&quot;ll&quot;</span>); <span class="comment">// true</span></span><br><span class="line"><span class="string">&quot;Hello&quot;</span>.indexOf(<span class="string">&quot;l&quot;</span>); <span class="comment">// 2</span></span><br><span class="line"><span class="string">&quot;Hello&quot;</span>.lastIndexOf(<span class="string">&quot;l&quot;</span>); <span class="comment">// 3</span></span><br><span class="line"><span class="string">&quot;Hello&quot;</span>.startsWith(<span class="string">&quot;He&quot;</span>); <span class="comment">// true</span></span><br><span class="line"><span class="string">&quot;Hello&quot;</span>.endsWith(<span class="string">&quot;lo&quot;</span>); <span class="comment">// true</span></span><br><span class="line"><span class="string">&quot;Hello&quot;</span>.substring(<span class="number">2</span>); <span class="comment">// &quot;llo&quot;</span></span><br><span class="line"><span class="string">&quot;Hello&quot;</span>.substring(<span class="number">2</span>, <span class="number">4</span>); <span class="string">&quot;ll&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="去除首尾空白字符">3、去除首尾空白字符：</h4>
<ul>
<li><p>使用<code>trim()</code>方法可以移除字符串首尾空白字符。<strong>空白字符包括空格，<code>\t</code>，<code>\r</code>，<code>\n</code></strong></p></li>
<li><p>另一个<code>strip()</code>方法也可以移除字符串首尾空白字符。它和<code>trim()</code>不同的是，类似中文的空格字符<code>\u3000</code>也会被移除</p></li>
</ul>
<h4 id="判断是否为空">4、判断是否为空：</h4>
<p><code>String</code>还提供了<code>isEmpty()</code>和<code>isBlank()</code>来判断字符串是否为空 和 空白字符串</p>
<p>空白字符串 代表 只含 <strong>空白字符</strong>的字符串。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;</span>.isEmpty(); <span class="comment">// true，因为字符串长度为0</span></span><br><span class="line"><span class="string">&quot;  &quot;</span>.isEmpty(); <span class="comment">// false，因为字符串长度不为0</span></span><br><span class="line"><span class="string">&quot;  \n&quot;</span>.isBlank(); <span class="comment">// true，因为只包含空白字符</span></span><br><span class="line"><span class="string">&quot; Hello &quot;</span>.isBlank(); <span class="comment">// false，因为包含非空白字符</span></span><br></pre></td></tr></table></figure>
<h4 id="替换子串">5、替换子串</h4>
<ul>
<li>根据字符或字符串替换</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">s.replace(<span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;w&#x27;</span>); <span class="comment">// &quot;hewwo&quot;，所有字符&#x27;l&#x27;被替换为&#x27;w&#x27;</span></span><br><span class="line">s.replace(<span class="string">&quot;ll&quot;</span>, <span class="string">&quot;~~&quot;</span>); <span class="comment">// &quot;he~~o&quot;，所有子串&quot;ll&quot;被替换为&quot;~~&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>正则表达式替换</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s = <span class="string">&quot;A,,B;C ,D&quot;</span>;</span><br><span class="line">s.replaceAll(<span class="string">&quot;[\\,\\;\\s]+&quot;</span>, <span class="string">&quot;,&quot;</span>); <span class="comment">// &quot;A,B,C,D&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="分割拼接格式化字符串">6、分割、拼接、格式化字符串：</h4>
<ul>
<li>要分割字符串，使用<code>split()</code>方法，并且传入的也是正则表达式：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s = <span class="string">&quot;A,B,C,D&quot;</span>;</span><br><span class="line">String[] ss = s.split(<span class="string">&quot;\\,&quot;</span>); <span class="comment">// &#123;&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;&#125;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>拼接字符串使用静态方法<code>join()</code>，它用指定的字符串连接字符串数组：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String[] arr = &#123;<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>, <span class="string">&quot;C&quot;</span>&#125;;</span><br><span class="line">String s = String.join(<span class="string">&quot;***&quot;</span>, arr); <span class="comment">// &quot;A***B***C&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>字符串提供了<code>formatted()</code>方法和<code>format()</code>静态方法，可以传入其他参数，替换占位符，然后生成新的字符串：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String s = <span class="string">&quot;Hi %s, your score is %d!&quot;</span>;</span><br><span class="line">        System.out.println(s.formatted(<span class="string">&quot;Alice&quot;</span>, <span class="number">80</span>));</span><br><span class="line">        System.out.println(String.format(<span class="string">&quot;Hi %s, your score is %.2f!&quot;</span>, <span class="string">&quot;Bob&quot;</span>, <span class="number">59.5</span>));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h4 id="类型转换">7、类型转换：</h4>
<p>要把任意基本类型或引用类型转换为字符串，可以使用静态方法<code>valueOf()</code></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String.valueOf(<span class="number">123</span>); <span class="comment">// &quot;123&quot;</span></span><br><span class="line">String.valueOf(<span class="number">45.67</span>); <span class="comment">// &quot;45.67&quot;</span></span><br><span class="line">String.valueOf(<span class="keyword">true</span>); <span class="comment">// &quot;true&quot;</span></span><br><span class="line">String.valueOf(<span class="keyword">new</span> Object()); <span class="comment">// 类似java.lang.Object@636be97c</span></span><br></pre></td></tr></table></figure>
<p>把字符串转换为其他类型，就需要根据情况。例如，把字符串转换为<code>int</code>类型：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> n1 = Integer.parseInt(<span class="string">&quot;123&quot;</span>); <span class="comment">// 123</span></span><br><span class="line"><span class="keyword">int</span> n2 = Integer.parseInt(<span class="string">&quot;ff&quot;</span>, <span class="number">16</span>); <span class="comment">// 按十六进制转换，255</span></span><br></pre></td></tr></table></figure>
<p>把字符串转换为<code>boolean</code>类型：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">boolean</span> b1 = Boolean.parseBoolean(<span class="string">&quot;true&quot;</span>); <span class="comment">// true</span></span><br><span class="line"><span class="keyword">boolean</span> b2 = Boolean.parseBoolean(<span class="string">&quot;FALSE&quot;</span>); <span class="comment">// false</span></span><br></pre></td></tr></table></figure>
<p>要特别注意，<code>Integer</code>有个<code>getInteger(String)</code>方法，它不是将字符串转换为<code>int</code>，而是把该字符串对应的系统变量转换为<code>Integer</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer.getInteger(<span class="string">&quot;java.version&quot;</span>); <span class="comment">// 版本号，11</span></span><br></pre></td></tr></table></figure>
<p><code>String</code>和<code>char[]</code>类型可以互相转换，方法是：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span>[] cs = <span class="string">&quot;Hello&quot;</span>.toCharArray(); <span class="comment">// String -&gt; char[]</span></span><br><span class="line">String s = <span class="keyword">new</span> String(cs); <span class="comment">// char[] -&gt; String</span></span><br></pre></td></tr></table></figure>
<p>如果修改了<code>char[]</code>数组，<code>String</code>并不会改变：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">char</span>[] cs = <span class="string">&quot;Hello&quot;</span>.toCharArray();</span><br><span class="line">        String s = <span class="keyword">new</span> String(cs);</span><br><span class="line">        System.out.println(s);</span><br><span class="line">        cs[<span class="number">0</span>] = <span class="string">&#x27;X&#x27;</span>;</span><br><span class="line">        System.out.println(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 这是因为通过<code>new String(char[])</code>创建新的<code>String</code>实例时，它并不会直接引用传入的<code>char[]</code>数组，而是会复制一份，所以，修改外部的<code>char[]</code>数组不会影响<code>String</code>实例内部的<code>char[]</code>数组，因为这是两个不同的数组。</p>
<p><strong>设计注意</strong>：从<code>String</code>的不变性设计可以看出，如果传入的对象有可能改变，我们需要复制而不是直接引用。</p>
<h4 id="字符编码问题">8、字符编码问题：</h4>
<p>​ 为了统一全球所有语言的编码，全球统一码联盟发布了<code>Unicode</code>编码</p>
<p>​ <code>Unicode</code>编码需要两个或者更多字节表示</p>
<p>英文字符<code>'A'</code>的<code>ASCII</code>编码和<code>Unicode</code>编码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">         ┌────┐</span><br><span class="line">ASCII:   │ 41 │</span><br><span class="line">         └────┘</span><br><span class="line">         ┌────┬────┐</span><br><span class="line">Unicode: │ 00 │ 41 │</span><br><span class="line">         └────┴────┘</span><br></pre></td></tr></table></figure>
<p>英文字符的<code>Unicode</code>编码就是简单地在前面添加一个<code>00</code>字节。</p>
<p>中文字符<code>'中'</code>的<code>GB2312</code>编码和<code>Unicode</code>编码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">         ┌────┬────┐</span><br><span class="line">GB2312:  │ d6 │ d0 │</span><br><span class="line">         └────┴────┘</span><br><span class="line">         ┌────┬────┐</span><br><span class="line">Unicode: │ 4e │ 2d │</span><br><span class="line">         └────┴────┘</span><br></pre></td></tr></table></figure>
<p>​ 那我们经常使用的<code>UTF-8</code>又是什么编码呢？因为英文字符的<code>Unicode</code>编码高字节总是<code>00</code>，包含大量英文的文本会浪费空间，所以，出现了<code>UTF-8</code>编码，<strong>它是一种变长编码</strong>，<strong>用来把固定长度的<code>Unicode</code>编码变成1～4字节的变长编码</strong>。通过<code>UTF-8</code>编码，英文字符<code>'A'</code>的<code>UTF-8</code>编码变为<code>0x41</code>，正好和<code>ASCII</code>码一致，而中文<code>'中'</code>的<code>UTF-8</code>编码为3字节<code>0xe4b8ad</code>。</p>
<p>​ <strong><code>UTF-8</code>编码的另一个好处是容错能力强。</strong>如果传输过程中某些字符出错，不会影响后续字符，因为<code>UTF-8</code>编码依靠高字节位来确定一个字符究竟是几个字节，它经常用来作为传输编码。</p>
<p>​ 在Java中，<strong><code>char</code>类型实际上就是两个字节的<code>Unicode</code>编码</strong>。如果我们要手动把字符串转换成其他编码，可以这样做：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">byte</span>[] b1 = <span class="string">&quot;Hello&quot;</span>.getBytes(); <span class="comment">// 按系统默认编码转换，不推荐</span></span><br><span class="line"><span class="keyword">byte</span>[] b2 = <span class="string">&quot;Hello&quot;</span>.getBytes(<span class="string">&quot;UTF-8&quot;</span>); <span class="comment">// 按UTF-8编码转换</span></span><br><span class="line"><span class="keyword">byte</span>[] b2 = <span class="string">&quot;Hello&quot;</span>.getBytes(<span class="string">&quot;GBK&quot;</span>); <span class="comment">// 按GBK编码转换</span></span><br><span class="line"><span class="keyword">byte</span>[] b3 = <span class="string">&quot;Hello&quot;</span>.getBytes(StandardCharsets.UTF_8); <span class="comment">// 按UTF-8编码转换</span></span><br></pre></td></tr></table></figure>
<p><strong>注意：转换编码后，就不再是<code>char</code>类型，而是<code>byte</code>类型表示的数组。</strong></p>
<p>如果要把已知编码的<code>byte[]</code>转换为<code>String</code>，可以这样做：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">byte</span>[] b = ...</span><br><span class="line">String s1 = <span class="keyword">new</span> String(b, <span class="string">&quot;GBK&quot;</span>); <span class="comment">// 按GBK转换</span></span><br><span class="line">String s2 = <span class="keyword">new</span> String(b, StandardCharsets.UTF_8); <span class="comment">// 按UTF-8转换</span></span><br></pre></td></tr></table></figure>
<p><strong>始终牢记：Java的<code>String</code>和<code>char</code>在内存中总是以Unicode编码表示。</strong></p>
<h3 id="二stringbuilder">二、StringBuilder</h3>
<p>​ 在java的String类种，虽然我们可以直接拼接字符串，但是，在循环中，<strong>每次循环都会创建新的字符串对象，然后扔掉旧的字符串</strong>。这样，<strong>绝大部分字符串都是临时对象，不但浪费内存，还会影响GC效率</strong>。</p>
<p>​ 为了能高效拼接字符串，Java标准库提供了<code>StringBuilder</code>，它是一个可变对象，可以预分配缓冲区，这样，往<code>StringBuilder</code>中新增字符时，不会创建新的临时对象：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">StringBuilder sb = <span class="keyword">new</span> StringBuilder(<span class="number">1024</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">    sb.append(<span class="string">&#x27;,&#x27;</span>);</span><br><span class="line">    sb.append(i);</span><br><span class="line">&#125;</span><br><span class="line">String s = sb.toString();</span><br></pre></td></tr></table></figure>
<p><strong>链式操作</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> sb = <span class="keyword">new</span> StringBuilder(<span class="number">1024</span>);</span><br><span class="line">        sb.append(<span class="string">&quot;Mr &quot;</span>)</span><br><span class="line">          .append(<span class="string">&quot;Bob&quot;</span>)</span><br><span class="line">          .append(<span class="string">&quot;!&quot;</span>)</span><br><span class="line">          .insert(<span class="number">0</span>, <span class="string">&quot;Hello, &quot;</span>);</span><br><span class="line">        System.out.println(sb.toString());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ <strong>进行链式操作的关键是：定义的<code>append()</code>方法会返回<code>this</code>，这样，就可以不断调用自身的其他方法</strong></p>
<p><strong>注意</strong>：对于普通的字符串<code>+</code>操作，并不需要我们将其改写为<code>StringBuilder</code>，因为Java编译器在编译时就自动把多个连续的<code>+</code>操作编码为<code>StringConcatFactory</code>的操作。在运行期，<code>StringConcatFactory</code>会自动把字符串连接操作优化为数组复制或者<code>StringBuilder</code>操作。</p>
<h3 id="三stringjoiner">三、StringJoiner</h3>
<ul>
<li>Java标准库还提供了一个<code>StringJoiner</code>可以用于使用分隔符拼接数组。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String[] names = &#123;<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;Alice&quot;</span>, <span class="string">&quot;Grace&quot;</span>&#125;;</span><br><span class="line">        <span class="comment">// var sj = new StringJoiner(&quot;, &quot;);  //case1 指定分隔符 </span></span><br><span class="line">        <span class="keyword">var</span> sj = <span class="keyword">new</span> StringJoiner(<span class="string">&quot;, &quot;</span>, <span class="string">&quot;Hello &quot;</span>, <span class="string">&quot;!&quot;</span>); <span class="comment">//case2 指定开头和结尾字符</span></span><br><span class="line">        <span class="keyword">for</span> (String name : names) &#123;</span><br><span class="line">            sj.add(name);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sj.toString());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// case1 Bob, Alice, Grace </span></span><br><span class="line"><span class="comment">// case2 Hello Bob, Alice, Grace! </span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>String</code>还提供了一个静态方法<code>join()</code>，这个方法在内部使用了<code>StringJoiner</code>来拼接字符串，在不需要指定“开头”和“结尾”的时候，用<code>String.join()</code>更方便：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String[] names = &#123;<span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;Alice&quot;</span>, <span class="string">&quot;Grace&quot;</span>&#125;;</span><br><span class="line"><span class="keyword">var</span> s = String.join(<span class="string">&quot;, &quot;</span>, names);</span><br></pre></td></tr></table></figure>
<h3 id="四包装类型">四、包装类型</h3>
<h4 id="什么是包装类型">1、什么是包装类型？</h4>
<p>java的数据类型分两种：</p>
<ul>
<li>基本类型：<code>byte</code>，<code>short</code>，<code>int</code>，<code>long</code>，<code>boolean</code>，<code>float</code>，<code>double</code>，<code>char</code></li>
<li>引用类型：所有<code>class</code>和<code>interface</code>类型</li>
</ul>
<p><strong>引用类型可以赋值为<code>null</code>，表示空，但基本类型不能赋值为<code>null</code></strong></p>
<p>如何把一个基本类型视为对象（引用类型）？</p>
<p>​ 比如，想要把<code>int</code>基本类型变成一个引用类型，我们可以定义一个<code>Integer</code>类，它只包含一个实例字段<code>int</code>，这样，<strong><code>Integer</code>类就可以视为<code>int</code>的包装类（Wrapper Class）</strong></p>
<p>实际上，因为包装类型非常有用，Java核心库为每种基本类型都提供了对应的包装类型：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">基本类型</th>
<th style="text-align: left;">对应的引用类型</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">boolean</td>
<td style="text-align: left;">java.lang.Boolean</td>
</tr>
<tr class="even">
<td style="text-align: left;">byte</td>
<td style="text-align: left;">java.lang.Byte</td>
</tr>
<tr class="odd">
<td style="text-align: left;">short</td>
<td style="text-align: left;">java.lang.Short</td>
</tr>
<tr class="even">
<td style="text-align: left;">int</td>
<td style="text-align: left;">java.lang.Integer</td>
</tr>
<tr class="odd">
<td style="text-align: left;">long</td>
<td style="text-align: left;">java.lang.Long</td>
</tr>
<tr class="even">
<td style="text-align: left;">float</td>
<td style="text-align: left;">java.lang.Float</td>
</tr>
<tr class="odd">
<td style="text-align: left;">double</td>
<td style="text-align: left;">java.lang.Double</td>
</tr>
<tr class="even">
<td style="text-align: left;">char</td>
<td style="text-align: left;">java.lang.Character</td>
</tr>
</tbody>
</table>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">100</span>;</span><br><span class="line">        <span class="comment">// 通过new操作符创建Integer实例(不推荐使用,会有编译警告):</span></span><br><span class="line">        Integer n1 = <span class="keyword">new</span> Integer(i);</span><br><span class="line">        <span class="comment">// 通过静态方法valueOf(int)创建Integer实例:</span></span><br><span class="line">        Integer n2 = Integer.valueOf(i);</span><br><span class="line">        <span class="comment">// 通过静态方法valueOf(String)创建Integer实例:</span></span><br><span class="line">        Integer n3 = Integer.valueOf(<span class="string">&quot;100&quot;</span>);</span><br><span class="line">        System.out.println(n3.intValue());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="auto-boxing">2、Auto Boxing</h4>
<p>因为<code>int</code>和<code>Integer</code>可以互相转换：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">100</span>;</span><br><span class="line">Integer n = Integer.valueOf(i);</span><br><span class="line"><span class="keyword">int</span> x = n.intValue();</span><br></pre></td></tr></table></figure>
<p>所以，Java编译器可以帮助我们自动在<code>int</code>和<code>Integer</code>之间转型：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer n = <span class="number">100</span>; <span class="comment">// 编译器自动使用Integer.valueOf(int)</span></span><br><span class="line"><span class="keyword">int</span> x = n; <span class="comment">// 编译器自动使用Integer.intValue()</span></span><br></pre></td></tr></table></figure>
<p>​ <strong>这种直接把<code>int</code>变为<code>Integer</code>的赋值写法，称为自动装箱（Auto Boxing），反过来，把<code>Integer</code>变为<code>int</code>的赋值写法，称为自动拆箱（Auto Unboxing）。</strong></p>
<p>​ 注意：<strong>自动装箱和自动拆箱只发生在编译阶段，目的是为了少写代码</strong>。</p>
<p>装箱和拆箱会影响代码的执行效率，因为编译后的<code>class</code>代码是严格区分基本类型和引用类型的。并且，自动拆箱执行时可能会报<code>NullPointerException</code>：</p>
<h4 id="不变类">3、不变类</h4>
<p>​ 所有的包装类型都是不变类，因此，一旦创建了<code>Integer</code>对象，该对象就是不变的。</p>
<p>​ 对两个<code>Integer</code>实例进行比较要特别注意：绝对不能用<code>==</code>比较，因为<code>Integer</code>是引用类型，必须使用<code>equals()</code>比较：</p>
<h4 id="进制转换">4、进制转换：</h4>
<p><code>Integer</code>类本身还提供了大量方法，例如，最常用的静态方法<code>parseInt()</code>可以把字符串解析成一个整数：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> x1 = Integer.parseInt(<span class="string">&quot;100&quot;</span>); <span class="comment">// 100</span></span><br><span class="line"><span class="keyword">int</span> x2 = Integer.parseInt(<span class="string">&quot;100&quot;</span>, <span class="number">16</span>); <span class="comment">// 256,因为按16进制解析</span></span><br></pre></td></tr></table></figure>
<p><code>Integer</code>还可以把整数格式化为指定进制的字符串：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(Integer.toString(<span class="number">100</span>)); <span class="comment">// &quot;100&quot;,表示为10进制</span></span><br><span class="line">        System.out.println(Integer.toString(<span class="number">100</span>, <span class="number">36</span>)); <span class="comment">// &quot;2s&quot;,表示为36进制</span></span><br><span class="line">        System.out.println(Integer.toHexString(<span class="number">100</span>)); <span class="comment">// &quot;64&quot;,表示为16进制</span></span><br><span class="line">        System.out.println(Integer.toOctalString(<span class="number">100</span>)); <span class="comment">// &quot;144&quot;,表示为8进制</span></span><br><span class="line">        System.out.println(Integer.toBinaryString(<span class="number">100</span>)); <span class="comment">// &quot;1100100&quot;,表示为2进制</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="五javabean">五、JavaBean</h3>
<p>在Java中，有很多<code>class</code>的定义都符合这样的规范：</p>
<ul>
<li>若干<code>private</code>实例字段；</li>
<li>通过<code>public</code>方法来读写实例字段。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">this</span>.name; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123; <span class="keyword">this</span>.name = name; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getAge</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">this</span>.age; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAge</span><span class="params">(<span class="keyword">int</span> age)</span> </span>&#123; <span class="keyword">this</span>.age = age; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果读写方法符合以下这种命名规范, 那么这种<code>class</code>被称为<code>JavaBean</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 读方法:</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Type <span class="title">getXyz</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="comment">// 写方法:</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setXyz</span><span class="params">(Type value)</span></span></span><br></pre></td></tr></table></figure>
<p>​ 上面的字段是<code>xyz</code>，那么读写方法名分别以<code>get</code>和<code>set</code>开头，并且后接大写字母开头的字段名<code>Xyz</code>，因此两个读写方法名分别是<code>getXyz()</code>和<code>setXyz()</code>。</p>
<p><code>boolean</code>字段比较特殊，它的读方法一般命名为<code>isXyz()</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 读方法:</span><br><span class="line">public boolean isChild()</span><br><span class="line">// 写方法:</span><br><span class="line">public void setChild(boolean value)</span><br></pre></td></tr></table></figure>
<p>​ <strong>我们通常把一组对应的读方法（<code>getter</code>）和写方法（<code>setter</code>）称为属性（<code>property</code>）。例如，<code>name</code>属性</strong>：</p>
<ul>
<li>对应的读方法是<code>String getName()</code></li>
<li>对应的写方法是<code>setName(String)</code></li>
</ul>
<p><strong>只有<code>getter</code>的属性称为只读属性（read-only）</strong>，例如，定义一个age只读属性：</p>
<ul>
<li>对应的读方法是<code>int getAge()</code></li>
<li>无对应的写方法<code>setAge(int)</code></li>
</ul>
<p>类似的，只有<code>setter</code>的属性称为只写属性（write-only）。</p>
<h4 id="javabean-的作用">javabean 的作用：</h4>
<p>​ JavaBean主要用来传递数据，即把一组数据组合成一个JavaBean便于传输。此外，JavaBean可以方便地被IDE工具分析，生成读写属性的代码，主要用在图形界面的可视化设计中。</p>
<p>​ 通过IDE，可以快速生成<code>getter</code>和<code>setter</code></p>
<h4 id="如何枚举javabean的所有属性">如何枚举JavaBean的所有属性？</h4>
<p>要枚举一个JavaBean的所有属性，可以直接使用Java核心库提供的<code>Introspector</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        BeanInfo info = Introspector.getBeanInfo(Person.class);</span><br><span class="line">        <span class="keyword">for</span> (PropertyDescriptor pd : info.getPropertyDescriptors()) &#123;</span><br><span class="line">            System.out.println(pd.getName());</span><br><span class="line">            System.out.println(<span class="string">&quot;  &quot;</span> + pd.getReadMethod());</span><br><span class="line">            System.out.println(<span class="string">&quot;  &quot;</span> + pd.getWriteMethod());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getAge</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> age;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAge</span><span class="params">(<span class="keyword">int</span> age)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">age</span></span><br><span class="line"><span class="comment">  public int Person.getAge()</span></span><br><span class="line"><span class="comment">  public void Person.setAge(int)</span></span><br><span class="line"><span class="comment">class</span></span><br><span class="line"><span class="comment">  public final native java.lang.Class java.lang.Object.getClass()</span></span><br><span class="line"><span class="comment">  null</span></span><br><span class="line"><span class="comment">name</span></span><br><span class="line"><span class="comment">  public java.lang.String Person.getName()</span></span><br><span class="line"><span class="comment">  public void Person.setName(java.lang.String) </span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<h3 id="六枚举类">六、枚举类</h3>
<h4 id="为什么需要枚举类">1、为什么需要枚举类：</h4>
<p>​ 在Java中，我们可以通过<code>static final</code>来定义常量,但有一个严重的问题就是，编译器无法检查每个值的合理性。比如说：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Weekday</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> SUN = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MON = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TUE = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> WED = <span class="number">3</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> THU = <span class="number">4</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> FRI = <span class="number">5</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> SAT = <span class="number">6</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>注意到<code>Weekday</code>定义的常量范围是<code>0</code>~<code>6</code>，并不包含<code>7</code>，编译器无法检查不在枚举中的<code>int</code>值；</p></li>
<li><p>定义的常量仍可与其他变量比较，但其用途并非是枚举星期</p></li>
</ul>
<p>​ 为了让编译器能自动检查某个值在枚举的集合内，并且，不同用途的枚举需要不同的类型来标记，不能混用，我们可以使用<code>enum</code>来定义枚举类：</p>
<h4 id="如何定义枚举类">2、如何定义枚举类？</h4>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Weekday day = Weekday.SUN;</span><br><span class="line">        <span class="keyword">if</span> (day == Weekday.SAT || day == Weekday.SUN) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;Work at home!&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;Work at office!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">Weekday</span> </span>&#123;</span><br><span class="line">    SUN, MON, TUE, WED, THU, FRI, SAT;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>定义枚举类是通过关键字<code>enum</code>实现的，我们只需依次列出枚举的常量名。</p>
<p>使用<code>enum</code>定义枚举有如下好处：</p>
<ul>
<li><p>首先，<code>enum</code>常量本身带有类型信息，即<code>Weekday.SUN</code>类型是<code>Weekday</code>，编译器会自动检查出类型错误。</p></li>
<li><p>其次，不可能引用到非枚举的值，因为无法通过编译。</p></li>
<li><p>最后，不同类型的枚举不能互相比较或者赋值，因为类型不符。</p></li>
</ul>
<h4 id="enum的比较">3、enum的比较：</h4>
<p>​ <code>enum</code>类型的每个常量在JVM中只有一个唯一实例，所以可以直接用<code>==</code>比较</p>
<h4 id="enum类型">4、enum类型：</h4>
<p>通过<code>enum</code>定义的枚举类，和其他的<code>class</code>没有任何区别。</p>
<p><code>enum</code>定义的类型就是<code>class</code>，只不过它有以下几个特点：</p>
<ul>
<li><p>定义的<code>enum</code>类型总是继承自<code>java.lang.Enum</code>，且无法被继承；</p></li>
<li><p>只能定义出<code>enum</code>的实例，而无法通过<code>new</code>操作符创建<code>enum</code>的实例；</p></li>
<li><p>定义的每个实例都是引用类型的唯一实例；</p></li>
<li><p>可以将<code>enum</code>类型用于<code>switch</code>语句。</p>
<p>例如，我们定义的<code>Color</code>枚举类：</p></li>
</ul>
<h4 id="enum示例">5、Enum示例：</h4>
<p>如下所示定义的enum:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">Color</span> </span>&#123;</span><br><span class="line">    RED, GREEN, BLUE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么编译器编译出的<code>class</code>大概就像这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Color</span> <span class="keyword">extends</span> <span class="title">Enum</span> </span>&#123; <span class="comment">// 继承自Enum，标记为final class</span></span><br><span class="line">    <span class="comment">// 每个实例均为全局唯一:</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Color RED = <span class="keyword">new</span> Color();</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Color GREEN = <span class="keyword">new</span> Color();</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Color BLUE = <span class="keyword">new</span> Color();</span><br><span class="line">    <span class="comment">// private构造方法，确保外部无法调用new操作符:</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Color</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所以，编译后的<code>enum</code>类和普通<code>class</code>并没有任何区别。但是我们自己无法按定义普通<code>class</code>那样来定义<code>enum</code>，必须使用<code>enum</code>关键字，这是Java语法规定的。</p>
<p>因为<strong><code>enum</code>是一个<code>class</code>，每个枚举的值都是<code>class</code>实例</strong>，因此，这些实例有一些方法：</p>
<ul>
<li>name()</li>
</ul>
<p>返回常量名，例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s = Weekday.SUN.name(); <span class="comment">// &quot;SUN&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>ordinal()</li>
</ul>
<p>返回定义的常量的顺序，从0开始计数，例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> n = Weekday.MON.ordinal(); <span class="comment">// 1</span></span><br></pre></td></tr></table></figure>
<p>改变枚举常量定义的顺序就会导致<code>ordinal()</code>返回值发生变化。例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">Weekday</span> </span>&#123;</span><br><span class="line">    SUN, MON, TUE, WED, THU, FRI, SAT;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>和</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">Weekday</span> </span>&#123;</span><br><span class="line">    MON, TUE, WED, THU, FRI, SAT, SUN;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 的<code>ordinal</code>就是不同的。如果在代码中编写了类似<code>if(x.ordinal()==1)</code>这样的语句，就要保证<code>enum</code>的枚举顺序不能变。新增的常量必须放在最后。</p>
<h4 id="书写健壮的enum代码">6、书写健壮的Enum代码</h4>
<p><code>Weekday</code>的枚举常量如果要和<code>int</code>转换，使用<code>ordinal()</code>不是非常方便, 比如这样写：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String task = Weekday.MON.ordinal() + <span class="string">&quot;/ppt&quot;</span>;</span><br><span class="line">saveToFile(task);</span><br></pre></td></tr></table></figure>
<p>​ 但是，如果不小心修改了枚举的顺序，编译器是无法检查出这种逻辑错误的。<strong>要编写健壮的代码，就不要依靠<code>ordinal()</code>的返回值。</strong> <strong>因为<code>enum</code>本身是<code>class</code>，所以我们可以定义<code>private</code>的构造方法，并且，给每个枚举常量添加字段：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Weekday day = Weekday.SUN;</span><br><span class="line">        <span class="keyword">if</span> (day.dayValue == <span class="number">6</span> || day.dayValue == <span class="number">0</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;Work at home!&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;Work at office!&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">Weekday</span> </span>&#123;</span><br><span class="line">    MON(<span class="number">1</span>), TUE(<span class="number">2</span>), WED(<span class="number">3</span>), THU(<span class="number">4</span>), FRI(<span class="number">5</span>), SAT(<span class="number">6</span>), SUN(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> dayValue;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Weekday</span><span class="params">(<span class="keyword">int</span> dayValue)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.dayValue = dayValue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这样就无需担心顺序的变化，新增枚举常量时，也需要指定一个<code>int</code>值。</p>
<p>默认情况下，对枚举常量调用<code>toString()</code>会返回和<code>name()</code>一样的字符串。但是，<code>toString()</code>可以被覆写，而<code>name()</code>则不行。我们可以给<code>Weekday</code>添加<code>toString()</code>方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">Weekday</span> </span>&#123;</span><br><span class="line">    MON(<span class="number">1</span>, <span class="string">&quot;星期一&quot;</span>), TUE(<span class="number">2</span>, <span class="string">&quot;星期二&quot;</span>), WED(<span class="number">3</span>, <span class="string">&quot;星期三&quot;</span>), THU(<span class="number">4</span>, <span class="string">&quot;星期四&quot;</span>), FRI(<span class="number">5</span>, <span class="string">&quot;星期五&quot;</span>), SAT(<span class="number">6</span>, <span class="string">&quot;星期六&quot;</span>), SUN(<span class="number">0</span>, <span class="string">&quot;星期日&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> dayValue;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String chinese;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Weekday</span><span class="params">(<span class="keyword">int</span> dayValue, String chinese)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.dayValue = dayValue;</span><br><span class="line">        <span class="keyword">this</span>.chinese = chinese;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.chinese;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="enum适合用在switch语句中">7、<code>enum</code>适合用在<code>switch</code>语句中</h4>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Weekday day = Weekday.SUN;</span><br><span class="line">        <span class="keyword">switch</span>(day) &#123;</span><br><span class="line">        <span class="keyword">case</span> MON:</span><br><span class="line">        <span class="keyword">case</span> TUE:</span><br><span class="line">        <span class="keyword">case</span> WED:</span><br><span class="line">        <span class="keyword">case</span> THU:</span><br><span class="line">        <span class="keyword">case</span> FRI:</span><br><span class="line">            System.out.println(<span class="string">&quot;Today is &quot;</span> + day + <span class="string">&quot;. Work at office!&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> SAT:</span><br><span class="line">        <span class="keyword">case</span> SUN:</span><br><span class="line">            System.out.println(<span class="string">&quot;Today is &quot;</span> + day + <span class="string">&quot;. Work at home!&quot;</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;cannot process &quot;</span> + day);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">Weekday</span> </span>&#123;</span><br><span class="line">    MON, TUE, WED, THU, FRI, SAT, SUN;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="七记录类">七、记录类</h3>
<h4 id="以往类的繁琐之处">1、以往类的繁琐之处：</h4>
<p>使用<code>String</code>、<code>Integer</code>等类型的时候，这些类型都是不变类，一个不变类具有以下特点：</p>
<ol type="1">
<li>定义class时使用<code>final</code>，无法派生子类；</li>
<li>每个字段使用<code>final</code>，保证创建实例后无法修改任何字段。</li>
</ol>
<p>假设我们希望定义一个<code>Point</code>类，有<code>x</code>、<code>y</code>两个变量，同时它是一个不变类，可以这么写：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Point</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> x;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> y;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Point</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.x = x;</span><br><span class="line">        <span class="keyword">this</span>.y = y;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">x</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.x;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">y</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.y;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里演示<code>Point</code>不变类的写法目的是，这些代码写起来都非常简单，但是很繁琐。</p>
<h4 id="record-记录类">2、record 记录类:</h4>
<p>​ 从Java 14开始，引入了新的<code>Record</code>类。我们定义<code>Record</code>类时，使用关键字<code>record</code>。把上述<code>Point</code>类改写为<code>Record</code>类，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Point p = <span class="keyword">new</span> Point(<span class="number">123</span>, <span class="number">456</span>);</span><br><span class="line">        System.out.println(p.x());</span><br><span class="line">        System.out.println(p.y());</span><br><span class="line">        System.out.println(p);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> record <span class="title">Point</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure>
<p>如果要把上述定义，以class的形式改写代码的话，应当如下所示：（其实也就是编译器会帮我们编译成如下的代码）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public final class Point extends Record &#123;</span><br><span class="line">    private final int x;</span><br><span class="line">    private final int y;</span><br><span class="line"></span><br><span class="line">    public Point(int x, int y) &#123;</span><br><span class="line">        this.x = x;</span><br><span class="line">        this.y = y;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int x() &#123;</span><br><span class="line">        return this.x;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int y() &#123;</span><br><span class="line">        return this.y;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String toString() &#123;</span><br><span class="line">        return String.format(&quot;Point[x=%s, y=%s]&quot;, x, y);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public boolean equals(Object o) &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">    public int hashCode() &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 除了用<code>final</code>修饰class以及每个字段外，编译器还自动为我们创建了构造方法，和字段名同名的方法，以及覆写<code>toString()</code>、<code>equals()</code>和<code>hashCode()</code>方法。</p>
<p>​ <strong>换句话说，使用<code>record</code>关键字，可以一行写出一个不变类。</strong></p>
<p>​ <strong>和<code>enum</code>类似，我们自己不能直接从<code>Record</code>派生，只能通过<code>record</code>关键字由编译器实现继承。</strong></p>
<h4 id="构造方法">3、构造方法：</h4>
<p>​ 编译器默认按照<code>record</code>声明的变量顺序自动创建一个构造方法，并在方法内给字段赋值。那么问题来了，如果我们要检查参数，应该怎么办？</p>
<p>​ <strong>假设<code>Point</code>类的<code>x</code>、<code>y</code>不允许负数，我们就得给<code>Point</code>的构造方法加上检查逻辑：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> record <span class="title">Point</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> Point &#123;</span><br><span class="line">        <span class="keyword">if</span> (x &lt; <span class="number">0</span> || y &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 注意到方法<code>public Point &#123;...&#125;</code>被称为Compact Constructor，它的目的是让我们编写检查逻辑，<strong>编译器最终生成的构造方法如下：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Point</span> <span class="keyword">extends</span> <span class="title">Record</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Point</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 这是我们编写的Compact Constructor:</span></span><br><span class="line">        <span class="keyword">if</span> (x &lt; <span class="number">0</span> || y &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 这是编译器继续生成的赋值代码:</span></span><br><span class="line">        <span class="keyword">this</span>.x = x;</span><br><span class="line">        <span class="keyword">this</span>.y = y;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>作为<code>record</code>的<code>Point</code>仍然可以添加静态方法。一种常用的静态方法是<code>of()</code>方法，用来创建<code>Point</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> record <span class="title">Point</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Point <span class="title">of</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Point(<span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Point <span class="title">of</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Point(x, y);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样我们可以写出更简洁的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> z = Point.of();</span><br><span class="line"><span class="keyword">var</span> p = Point.of(<span class="number">123</span>, <span class="number">456</span>);</span><br></pre></td></tr></table></figure>
<h4 id="总结">4、总结：</h4>
<p>从Java 14开始，提供新的<code>record</code>关键字，可以非常方便地定义Data Class：</p>
<ul>
<li>使用<code>record</code>定义的是不变类；</li>
<li>可以编写Compact Constructor对参数进行验证；</li>
<li>可以定义静态方法。</li>
</ul>
<h3 id="八biginteger">八、BigInteger</h3>
<p>​ 在Java中，由CPU原生提供的整型最大范围是64位<code>long</code>型整数。<strong>使用<code>long</code>型整数可以直接通过CPU指令进行计算，速度非常快</strong></p>
<p>​ 如果我们使用的整数范围超过了<code>long</code>型，就只能用软件来模拟一个大整数。<code>java.math.BigInteger</code>就是用来表示任意大小的整数。<code>BigInteger</code>内部用一个<code>int[]</code>数组来模拟一个非常大的整数：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BigInteger bi = <span class="keyword">new</span> BigInteger(<span class="string">&quot;1234567890&quot;</span>);</span><br><span class="line">System.out.println(bi.pow(<span class="number">5</span>)); <span class="comment">// 2867971860299718107233761438093672048294900000</span></span><br></pre></td></tr></table></figure>
<p>对<code>BigInteger</code>做运算的时候，只能使用实例方法，例如，加法运算：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BigInteger i1 = <span class="keyword">new</span> BigInteger(<span class="string">&quot;1234567890&quot;</span>);</span><br><span class="line">BigInteger i2 = <span class="keyword">new</span> BigInteger(<span class="string">&quot;12345678901234567890&quot;</span>);</span><br><span class="line">BigInteger sum = i1.add(i2); <span class="comment">// 12345678902469135780</span></span><br></pre></td></tr></table></figure>
<p><code>BigInteger</code>和<code>Integer</code>、<code>Long</code>一样，也是不可变类，并且也继承自<code>Number</code>类。因为<code>Number</code>定义了转换为基本类型的几个方法：</p>
<ul>
<li>转换为<code>byte</code>：<code>byteValue()</code></li>
<li>转换为<code>short</code>：<code>shortValue()</code></li>
<li>转换为<code>int</code>：<code>intValue()</code></li>
<li>转换为<code>long</code>：<code>longValue()</code></li>
<li>转换为<code>float</code>：<code>floatValue()</code></li>
<li>转换为<code>double</code>：<code>doubleValue()</code></li>
</ul>
<p>​ 因此，通过上述方法，可以把<code>BigInteger</code>转换成基本类型。如果<code>BigInteger</code>表示的范围超过了基本类型的范围，转换时将丢失高位信息，即结果不一定是准确的。如果需要准确地转换成基本类型，可以使用<code>intValueExact()</code>、<code>longValueExact()</code>等方法，在转换时如果超出范围，将直接抛出<code>ArithmeticException</code>异常。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BigInteger i = <span class="keyword">new</span> BigInteger(<span class="string">&quot;123456789000&quot;</span>);</span><br><span class="line">System.out.println(i.longValue()); <span class="comment">// 123456789000</span></span><br><span class="line">System.out.println(i.multiply(i).longValueExact()); <span class="comment">// java.lang.ArithmeticException: BigInteger out of long range</span></span><br></pre></td></tr></table></figure>
<p>​ 使用<code>longValueExact()</code>方法时，如果超出了<code>long</code>型的范围，会抛出<code>ArithmeticException</code>。</p>
<h3 id="九bigdecimal">九、BigDecimal</h3>
<h4 id="bigdecimal简介">1、BigDecimal简介</h4>
<p>和<code>BigInteger</code>类似，<code>BigDecimal</code>可以表示<strong>一个任意大小且精度完全准确</strong>的浮点数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BigDecimal bd = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;123.4567&quot;</span>);</span><br><span class="line">System.out.println(bd.multiply(bd)); <span class="comment">// 15241.55677489</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>BigDecimal</code>用<code>scale()</code>输出小数位数，例如：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BigDecimal d1 = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;123.45&quot;</span>);</span><br><span class="line">BigDecimal d2 = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;123.4500&quot;</span>);</span><br><span class="line">BigDecimal d3 = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;1234500&quot;</span>);</span><br><span class="line">System.out.println(d1.scale()); <span class="comment">// 2,两位小数</span></span><br><span class="line">System.out.println(d2.scale()); <span class="comment">// 4</span></span><br><span class="line">System.out.println(d3.scale()); <span class="comment">// 0</span></span><br></pre></td></tr></table></figure>
<ul>
<li>通过<code>BigDecimal</code>的<code>stripTrailingZeros()</code>方法，可以将一个<code>BigDecimal</code>格式化为一个相等的，但去掉了末尾0的<code>BigDecimal</code>：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BigDecimal d1 = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;123.4500&quot;</span>);</span><br><span class="line">BigDecimal d2 = d1.stripTrailingZeros();</span><br><span class="line">System.out.println(d1.scale()); <span class="comment">// 4</span></span><br><span class="line">System.out.println(d2.scale()); <span class="comment">// 2,因为去掉了00</span></span><br><span class="line"></span><br><span class="line">BigDecimal d3 = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;1234500&quot;</span>);</span><br><span class="line">BigDecimal d4 = d3.stripTrailingZeros();</span><br><span class="line">System.out.println(d3.scale()); <span class="comment">// 0</span></span><br><span class="line">System.out.println(d4.scale()); <span class="comment">// -2</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>如果一个<code>BigDecimal</code>的<code>scale()</code>返回负数，例如，<code>-2</code>，表示这个数是个整数，并且末尾有2个0。</p></li>
<li><p>可以对一个<code>BigDecimal</code>设置它的<code>scale</code>，如果精度比原始值低，那么按照指定的方法进行四舍五入或者直接截断：</p></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        BigDecimal d1 = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;123.456789&quot;</span>);</span><br><span class="line">        BigDecimal d2 = d1.setScale(<span class="number">4</span>, RoundingMode.HALF_UP); <span class="comment">// 四舍五入，123.4568</span></span><br><span class="line">        BigDecimal d3 = d1.setScale(<span class="number">4</span>, RoundingMode.DOWN); <span class="comment">// 直接截断，123.4567</span></span><br><span class="line">        System.out.println(d2);</span><br><span class="line">        System.out.println(d3);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对<code>BigDecimal</code>做加、减、乘时，精度不会丢失，但是做除法时，存在无法除尽的情况，这时，就必须指定精度以及如何进行截断：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BigDecimal d1 = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;123.456&quot;</span>);</span><br><span class="line">BigDecimal d2 = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;23.456789&quot;</span>);</span><br><span class="line">BigDecimal d3 = d1.divide(d2, <span class="number">10</span>, RoundingMode.HALF_UP); <span class="comment">// 保留10位小数并四舍五入</span></span><br><span class="line">BigDecimal d4 = d1.divide(d2); <span class="comment">// 报错：ArithmeticException，因为除不尽</span></span><br></pre></td></tr></table></figure>
<p>还可以对<code>BigDecimal</code>做除法的同时求余数：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        BigDecimal n = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;12.345&quot;</span>);</span><br><span class="line">        BigDecimal m = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;0.12&quot;</span>);</span><br><span class="line">        BigDecimal[] dr = n.divideAndRemainder(m);</span><br><span class="line">        System.out.println(dr[<span class="number">0</span>]); <span class="comment">// 102</span></span><br><span class="line">        System.out.println(dr[<span class="number">1</span>]); <span class="comment">// 0.105</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用<code>divideAndRemainder()</code>方法时，返回的数组包含两个<code>BigDecimal</code>，分别是商和余数，其中商总是整数，余数不会大于除数。我们可以利用这个方法判断两个<code>BigDecimal</code>是否是整数倍数：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BigDecimal n = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;12.75&quot;</span>);</span><br><span class="line">BigDecimal m = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;0.15&quot;</span>);</span><br><span class="line">BigDecimal[] dr = n.divideAndRemainder(m);</span><br><span class="line"><span class="keyword">if</span> (dr[<span class="number">1</span>].signum() == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// n是m的整数倍</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="比较bigdecimal">2、比较BigDecimal</h4>
<p>在比较两个<code>BigDecimal</code>的值是否相等时，要特别注意，使用<code>equals()</code>方法不但要求两个<code>BigDecimal</code>的值相等，还要求它们的<code>scale()</code>相等：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">BigDecimal d1 = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;123.456&quot;</span>);</span><br><span class="line">BigDecimal d2 = <span class="keyword">new</span> BigDecimal(<span class="string">&quot;123.45600&quot;</span>);</span><br><span class="line">System.out.println(d1.equals(d2)); <span class="comment">// false,因为scale不同</span></span><br><span class="line">System.out.println(d1.equals(d2.stripTrailingZeros())); <span class="comment">// true,因为d2去除尾部0后scale变为2</span></span><br><span class="line">System.out.println(d1.compareTo(d2)); <span class="comment">// 0</span></span><br></pre></td></tr></table></figure>
<p>必须使用<code>compareTo()</code>方法来比较，它根据两个值的大小分别返回负数、正数和<code>0</code>，分别表示小于、大于和等于。</p>
<p>总是使用compareTo()比较两个BigDecimal的值，不要使用equals()！</p>
<p>如果查看<code>BigDecimal</code>的源码，可以发现，实际上一个<code>BigDecimal</code>是通过一个<code>BigInteger</code>和一个<code>scale</code>来表示的，即<code>BigInteger</code>表示一个完整的整数，而<code>scale</code>表示小数位数：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BigDecimal</span> <span class="keyword">extends</span> <span class="title">Number</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">BigDecimal</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> BigInteger intVal;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> scale;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>BigDecimal</code>也是从<code>Number</code>继承的，也是不可变对象。</p>
<h3 id="十常用工具类">十、常用工具类</h3>
<h4 id="math">1、Math</h4>
<ul>
<li>求绝对值：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Math.abs(-<span class="number">100</span>); <span class="comment">// 100</span></span><br><span class="line">Math.abs(-<span class="number">7.8</span>); <span class="comment">// 7.8</span></span><br></pre></td></tr></table></figure>
<ul>
<li>取最大或最小值:</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Math.max(<span class="number">100</span>, <span class="number">99</span>); <span class="comment">// 100</span></span><br><span class="line">Math.min(<span class="number">1.2</span>, <span class="number">2.3</span>); <span class="comment">// 1.2</span></span><br></pre></td></tr></table></figure>
<ul>
<li>计算<span class="math inline">\(x^y\)</span>次方：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Math.pow(<span class="number">2</span>, <span class="number">10</span>); <span class="comment">// 2的10次方=1024</span></span><br></pre></td></tr></table></figure>
<ul>
<li>计算√x：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Math.sqrt(<span class="number">2</span>); <span class="comment">// 1.414...</span></span><br></pre></td></tr></table></figure>
<ul>
<li>计算ex次方：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Math.exp(<span class="number">2</span>); <span class="comment">// 7.389...</span></span><br></pre></td></tr></table></figure>
<ul>
<li>计算以e为底的对数：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Math.log(<span class="number">4</span>); <span class="comment">// 1.386...</span></span><br></pre></td></tr></table></figure>
<ul>
<li>计算以10为底的对数：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Math.log10(<span class="number">100</span>); <span class="comment">// 2</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Math还提供了几个数学常量：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> pi = Math.PI; <span class="comment">// 3.14159...</span></span><br><span class="line"><span class="keyword">double</span> e = Math.E; <span class="comment">// 2.7182818...</span></span><br><span class="line">Math.sin(Math.PI / <span class="number">6</span>); <span class="comment">// sin(π/6) = 0.5</span></span><br></pre></td></tr></table></figure>
<ul>
<li>生成一个随机数x，x的范围是<code>0 &lt;= x &lt; 1</code>：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Math.random(); <span class="comment">// 0.53907... 每次都不一样</span></span><br></pre></td></tr></table></figure>
<h4 id="random">2、Random</h4>
<p><code>Random</code>用来创建伪随机数。所谓伪随机数，是指只要给定一个初始的种子，产生的随机数序列是完全一样的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Random r = <span class="keyword">new</span> Random();</span><br><span class="line">r.nextInt(); <span class="comment">// 2071575453,每次都不一样</span></span><br><span class="line">r.nextInt(<span class="number">10</span>); <span class="comment">// 5,生成一个[0,10)之间的int</span></span><br><span class="line">r.nextLong(); <span class="comment">// 8811649292570369305,每次都不一样</span></span><br><span class="line">r.nextFloat(); <span class="comment">// 0.54335...生成一个[0,1)之间的float</span></span><br><span class="line">r.nextDouble(); <span class="comment">// 0.3716...生成一个[0,1)之间的double</span></span><br></pre></td></tr></table></figure>
<p>这是因为我们创建<code>Random</code>实例时，如果不给定种子，就使用系统当前时间戳作为种子，因此每次运行时，种子不同，得到的伪随机数序列就不同。</p>
<p>如果我们在创建<code>Random</code>实例时指定一个种子，就会得到完全确定的随机数序列：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Random r = <span class="keyword">new</span> Random(<span class="number">12345</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            System.out.println(r.nextInt(<span class="number">100</span>));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 51, 80, 41, 28, 55...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="securerandom">3、SecureRandom</h4>
<p>​ 有伪随机数，就有真随机数。实际上真正的真随机数只能通过量子力学原理来获取，而我们想要的是一个不可预测的安全的随机数，<code>SecureRandom</code>就是用来创建安全的随机数的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">SecureRandom sr = <span class="keyword">new</span> SecureRandom();</span><br><span class="line">System.out.println(sr.nextInt(<span class="number">100</span>));</span><br></pre></td></tr></table></figure>
<p><code>SecureRandom</code>的安全性是通过操作系统提供的安全的随机种子来生成随机数。这个种子是通过CPU的热噪声、读写磁盘的字节、网络流量等各种随机事件产生的“熵”。</p>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>core class</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记2——java面向对象编程基础</title>
    <url>/2022/01/29/be2dd498a3c4/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1260467032946976</p>
<h3 id="一类的方法">一、类的方法</h3>
<h4 id="一个类通过定义public方法就可以给外部代码暴露一些操作的接口">1、一个类通过定义public方法，就可以给外部代码暴露一些操作的接口。</h4>
<p>一般而言内部的变量设置为private，对内部变量的操作由暴露的接口进行，这样内部能够自己保证逻辑一致性。</p>
<p>在public的方法内部，我们就有机会检查参数对不对。比如：<code>setName()</code>方法可以做检查，例如，不允许传入<code>null</code>和空字符串：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (name == <span class="keyword">null</span> || name.isBlank()) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;invalid name&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.name = name.strip(); <span class="comment">// 去掉首尾空格</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="在方法内部可以使用一个隐含的变量this它始终指向当前实例">2、在方法内部，可以使用一个隐含的变量<code>this</code>，它始终指向当前实例</h4>
<p>如果没有命名冲突，可以省略<code>this</code></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name; <span class="comment">// 相当于this.name</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="可变参数">3、可变参数：</h4>
<p>可变参数用<code>类型...</code>定义，可变参数相当于数组类型,可变参数可以保证无法传入<code>null</code></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Group</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String[] names;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setNames</span><span class="params">(String... names)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.names = names;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Group g = <span class="keyword">new</span> Group();</span><br><span class="line">g.setNames(<span class="string">&quot;Xiao Ming&quot;</span>, <span class="string">&quot;Xiao Hong&quot;</span>, <span class="string">&quot;Xiao Jun&quot;</span>); <span class="comment">// 传入3个String</span></span><br><span class="line">g.setNames(<span class="string">&quot;Xiao Ming&quot;</span>, <span class="string">&quot;Xiao Hong&quot;</span>); <span class="comment">// 传入2个String</span></span><br><span class="line">g.setNames(<span class="string">&quot;Xiao Ming&quot;</span>); <span class="comment">// 传入1个String</span></span><br><span class="line">g.setNames(); <span class="comment">// 传入0个String</span></span><br></pre></td></tr></table></figure>
<h4 id="参数传递">4、参数传递：</h4>
<p>引用类型参数的传递，调用方的变量，和接收方的参数变量，指向的是同一个对象。双方任意一方对这个对象的修改，都会影响对方（因为指向同一个对象嘛）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 一个陷阱题目</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Person p = <span class="keyword">new</span> Person();</span><br><span class="line">        String bob = <span class="string">&quot;Bob&quot;</span>;</span><br><span class="line">        p.setName(bob); <span class="comment">// 传入bob变量</span></span><br><span class="line">        System.out.println(p.getName()); <span class="comment">// &quot;Bob&quot;</span></span><br><span class="line">        bob = <span class="string">&quot;Alice&quot;</span>; <span class="comment">// bob改名为Alice</span></span><br><span class="line">        System.out.println(p.getName()); <span class="comment">// &quot;Bob&quot;还是&quot;Alice&quot;?</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//回答： 应该是Alice：</span></span><br><span class="line"><span class="comment">// String bob = &quot;Bob&quot;; 的时候，为其分配内存，然后bob 是一个指针，指向该内存，比如0x0011.</span></span><br><span class="line"><span class="comment">// bob = &quot;Alice&quot; 时发生了重新赋值</span></span><br><span class="line"><span class="comment">// 但在java中String类型是不可变的，当发生改变时，会重新分配内存，即生成一个新的内存地址，例如：0x0022,这个时候，现在的bob的内存指向&quot;Alice&quot;，也就是指向0x0022，而p.bob的内存指向仍为0x0011，也就是Bob，所以输出的依旧是Bob。</span></span><br></pre></td></tr></table></figure>
<h3 id="二构造方法">二、构造方法：</h3>
<h4 id="没有在构造方法中初始化字段时引用类型的字段默认是null数值类型的字段用默认值int类型默认值是0布尔类型默认值是false">1、没有在构造方法中初始化字段时，引用类型的字段默认是<code>null</code>，数值类型的字段用默认值，<code>int</code>类型默认值是<code>0</code>，布尔类型默认值是<code>false</code>：</h4>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name; <span class="comment">// 默认初始化为null</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age; <span class="comment">// 默认初始化为0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="可以定义多个构造方法">2、可以定义多个构造方法：</h4>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getAge</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.age;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="既对字段进行初始化又在构造方法中对字段进行初始化">3、既对字段进行初始化，又在构造方法中对字段进行初始化：</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Person &#123;</span><br><span class="line">    private String name = &quot;Unamed&quot;;</span><br><span class="line">    private int age = 10;</span><br><span class="line"></span><br><span class="line">    public Person(String name, int age) &#123;</span><br><span class="line">        this.name = name;</span><br><span class="line">        this.age = age;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当我们创建对象的时候，<code>new Person("Xiao Ming", 12)</code>得到的对象实例，字段的初始值是啥？</p>
<p>在Java中，创建对象实例的时候，按照如下顺序进行初始化：</p>
<ol type="1">
<li>先初始化字段，例如，<code>int age = 10;</code>表示字段初始化为<code>10</code>，<code>double salary;</code>表示字段默认初始化为<code>0</code>，<code>String name;</code>表示引用类型字段默认初始化为<code>null</code>；</li>
<li>执行构造方法的代码进行初始化。</li>
</ol>
<p>​ 因此，<strong>构造方法的代码由于后运行</strong>，所以，<code>new Person("Xiao Ming", 12)</code>的字段值最终由构造方法的代码确定。</p>
<h4 id="一个构造方法可以调用其他构造方法这样做的目的是便于代码复用调用其他构造方法的语法是this">4、一个构造方法可以调用其他构造方法，这样做的目的是便于代码复用。调用其他构造方法的语法是<code>this(…)</code>：</h4>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(name, <span class="number">18</span>); <span class="comment">// 调用另一个构造方法Person(String, int)</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(<span class="string">&quot;Unnamed&quot;</span>); <span class="comment">// 调用另一个构造方法Person(String)</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="三方法重载overload">三、方法重载Overload：</h3>
<ul>
<li><p>方法重载是指多个方法的方法名相同，但各自的参数不同；</p></li>
<li><p>重载方法应该完成类似的功能，参考<code>String</code>的<code>indexOf()</code>；</p></li>
<li><p><strong>重载方法返回值类型应该相同,各自的参数应当不同</strong></p></li>
</ul>
<h3 id="四继承">四、继承：</h3>
<h4 id="基础继承与protected关键字">1、基础继承与Protected关键字：</h4>
<ul>
<li><p>Java使用<code>extends</code>关键字来实现继承：</p></li>
<li><p>注意：子类自动获得了父类的所有字段，严禁定义与父类重名的字段！</p></li>
<li><p>Java只允许一个class继承自一个类，因此，一个类有且仅有一个父类。</p></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;...&#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;...&#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getAge</span><span class="params">()</span> </span>&#123;...&#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAge</span><span class="params">(<span class="keyword">int</span> age)</span> </span>&#123;...&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span> <span class="keyword">extends</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 不要重复name和age字段/方法,</span></span><br><span class="line">    <span class="comment">// 只需要定义新增score字段/方法:</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> score;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getScore</span><span class="params">()</span> </span>&#123; … &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setScore</span><span class="params">(<span class="keyword">int</span> score)</span> </span>&#123; … &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>子类无法访问父类的<code>private</code>字段或者<code>private</code>方法</li>
<li>父类中用<code>protected</code>修饰的字段可以被子类访问</li>
<li><code>protected</code>关键字可以把字段和方法的访问权限控制在继承树内部，一个<code>protected</code>字段和方法可以被其子类，以及子类的子类所访问</li>
</ul>
<h4 id="super关键字">2、Super关键字：</h4>
<ul>
<li><p><code>super</code>关键字表示父类（超类）。子类引用父类的字段时，可以用<code>super.fieldName</code>。</p></li>
<li><p>观察以下代码，为何会编译错误？</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Student s = <span class="keyword">new</span> Student(<span class="string">&quot;Xiao Ming&quot;</span>, <span class="number">12</span>, <span class="number">89</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> String name;</span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">int</span> age;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Person</span><span class="params">(String name, <span class="keyword">int</span> age)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span> <span class="keyword">extends</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">int</span> score;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Student</span><span class="params">(String name, <span class="keyword">int</span> age, <span class="keyword">int</span> score)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.score = score;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>在Java中，任何<code>class</code>的构造方法，第一行语句必须是调用父类的构造方法。如果没有明确地调用父类的构造方法，编译器会帮我们自动加一句<code>super();</code>，所以，<code>Student</code>类的构造方法实际上是这样：</p></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span> <span class="keyword">extends</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">int</span> score;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Student</span><span class="params">(String name, <span class="keyword">int</span> age, <span class="keyword">int</span> score)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(); <span class="comment">// 自动调用父类的构造方法</span></span><br><span class="line">        <span class="keyword">this</span>.score = score;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但是，<code>Person</code>类并没有无参数的构造方法，因此，编译失败。</p>
<p>解决方法是调用<code>Person</code>类存在的某个构造方法。例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span> <span class="keyword">extends</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">int</span> score;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Student</span><span class="params">(String name, <span class="keyword">int</span> age, <span class="keyword">int</span> score)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(name, age); <span class="comment">// 调用父类的构造方法Person(String, int)</span></span><br><span class="line">        <span class="keyword">this</span>.score = score;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>结论：如果父类没有默认的构造方法，子类就必须显式调用<code>super()</code>并给出参数以便让编译器定位到父类的一个合适的构造方法。且子类不会继承任何父类的构造方法。子类默认的构造方法是编译器自动生成的，不是继承的。</li>
</ul>
<h4 id="阻止继承">3、阻止继承：</h4>
<ul>
<li>正常情况下，只要某个class没有<code>final</code>修饰符，那么任何类都可以从该class继承。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> String name;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// compile error: 不允许继承自Person</span></span><br><span class="line">Student extends Person &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>从Java 15开始，允许使用<code>sealed</code>修饰class，并通过<code>permits</code>明确写出能够从该class继承的子类名称。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> sealed <span class="class"><span class="keyword">class</span> <span class="title">Shape</span> <span class="title">permits</span> <span class="title">Rect</span>, <span class="title">Circle</span>, <span class="title">Triangle</span> </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>注意：这种<code>sealed</code>类主要用于一些框架，防止继承被滥用。</li>
</ul>
<p><code>sealed</code>类在Java 15中目前是预览状态，要启用它，必须使用参数<code>--enable-preview</code>和<code>--source 15</code>。</p>
<h4 id="向上转型">4、向上转型：</h4>
<p>​ 把一个子类类型赋值给父类类型的变量，被称为向上转型（upcasting）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Student s = <span class="keyword">new</span> Student();</span><br><span class="line">Person p = s; <span class="comment">// upcasting, ok</span></span><br><span class="line">Object o1 = p; <span class="comment">// upcasting, ok</span></span><br><span class="line">Object o2 = s; <span class="comment">// upcasting, ok</span></span><br></pre></td></tr></table></figure>
<p>​ 注意到继承树是<code>Student &gt; Person &gt; Object</code>，所以，可以把<code>Student</code>类型转型为<code>Person</code>，或者更高层次的<code>Object</code>。</p>
<h4 id="向下转型">5、向下转型：</h4>
<p>​ 如果把一个父类类型强制转型为子类类型，就是向下转型（downcasting）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Person p1 = <span class="keyword">new</span> Student(); <span class="comment">// upcasting, ok</span></span><br><span class="line">Person p2 = <span class="keyword">new</span> Person();</span><br><span class="line">Student s1 = (Student) p1; <span class="comment">// ok</span></span><br><span class="line">Student s2 = (Student) p2; <span class="comment">// runtime error! ClassCastException!</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p><code>Person</code>类型<code>p1</code>实际指向<code>Student</code>实例，</p></li>
<li><p><code>Person</code>类型变量<code>p2</code>实际指向<code>Person</code>实例。</p></li>
</ul>
<p>在向下转型的时候：</p>
<ul>
<li><p>把<code>p1</code>转型为<code>Student</code>会成功，因为<code>p1</code>确实指向<code>Student</code>实例，</p></li>
<li><p>把<code>p2</code>转型为<code>Student</code>会失败，因为<code>p2</code>的实际类型是<code>Person</code>，不能把父类变为子类，因为子类功能比父类多，多的功能无法凭空变出来。</p></li>
</ul>
<p>因此，向下转型很可能会失败。失败的时候，Java虚拟机会报<code>ClassCastException</code>。</p>
<p>为了避免向下转型出错，Java提供了<code>instanceof</code>操作符，可以先判断一个实例究竟是不是某种类型：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Person p = <span class="keyword">new</span> Person();</span><br><span class="line">System.out.println(p <span class="keyword">instanceof</span> Person); <span class="comment">// true</span></span><br><span class="line">System.out.println(p <span class="keyword">instanceof</span> Student); <span class="comment">// false</span></span><br><span class="line"></span><br><span class="line">Student s = <span class="keyword">new</span> Student();</span><br><span class="line">System.out.println(s <span class="keyword">instanceof</span> Person); <span class="comment">// true</span></span><br><span class="line">System.out.println(s <span class="keyword">instanceof</span> Student); <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line">Student n = <span class="keyword">null</span>;</span><br><span class="line">System.out.println(n <span class="keyword">instanceof</span> Student); <span class="comment">// false</span></span><br></pre></td></tr></table></figure>
<p><code>instanceof</code>实际上判断一个变量所指向的实例是否是指定类型，或者这个类型的子类。如果一个引用变量为<code>null</code>，那么对任何<code>instanceof</code>的判断都为<code>false</code>。</p>
<p>利用<code>instanceof</code>，在向下转型前可以先判断：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Person p = <span class="keyword">new</span> Student();</span><br><span class="line"><span class="keyword">if</span> (p <span class="keyword">instanceof</span> Student) &#123;</span><br><span class="line">    <span class="comment">// 只有判断成功才会向下转型:</span></span><br><span class="line">    Student s = (Student) p; <span class="comment">// 一定会成功</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="五多态">五、多态：</h3>
<h4 id="覆写-override">1、覆写 Override</h4>
<p>在继承关系中，子类如果定义了一个与父类方法签名完全相同的方法，被称为覆写（Override）。</p>
<ul>
<li><p>OverRide传入参数与返回值都应该相同。</p></li>
<li><p>加上<code>@Override</code>可以让编译器帮助检查是否进行了正确的覆写。希望进行覆写，但是不小心写错了方法签名，编译器会报错。</p></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Student</span> <span class="keyword">extends</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span> <span class="comment">// Compile error!</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(String s)</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="多态">2、多态</h4>
<p>Java的实例方法调用是基于运行时的实际类型的动态调用，而非变量的声明类型。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Person p = <span class="keyword">new</span> Student();</span><br><span class="line">p.run(); <span class="comment">// 运行的时Student的run()方法</span></span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">runTwice</span><span class="params">(Person p)</span> </span>&#123;</span><br><span class="line">    p.run();</span><br><span class="line">    p.run(); <span class="comment">//它传入的参数类型是Person，我们是无法知道传入的参数实际类型究竟是Person，还是Student，还是Person的其他子类，因此，也无法确定调用的是不是Person类定义的run()方法。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ <strong>多态的特性就是，运行期才能动态决定调用的子类方法。对某个类型调用某个方法，执行的实际方法可能是某个子类的覆写方法。这种不确定性的方法调用，究竟有什么作用？</strong></p>
<p>​ 示例如下：</p>
<ul>
<li>假设我们定义一种收入，需要给它报税，那么先定义一个<code>Income</code>类</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Income</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">double</span> income;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getTax</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> income * <span class="number">0.1</span>; <span class="comment">// 税率10%</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于工资收入，可以减去一个基数，那么我们可以从<code>Income</code>派生出<code>Salary</code>，并覆写<code>getTax()</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Salary</span> <span class="keyword">extends</span> <span class="title">Income</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getTax</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (income &lt;= <span class="number">5000</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> (income - <span class="number">5000</span>) * <span class="number">0.2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果你享受国务院特殊津贴，那么按照规定，可以全部免税：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StateCouncilSpecialAllowance</span> <span class="keyword">extends</span> <span class="title">Income</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getTax</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>现在，我们要编写一个报税的财务软件，对于一个人的所有收入进行报税，可以这么写：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 给一个有普通收入、工资收入和享受国务院特殊津贴的小伙伴算税:</span></span><br><span class="line">        Income[] incomes = <span class="keyword">new</span> Income[] &#123;</span><br><span class="line">            <span class="keyword">new</span> Income(<span class="number">3000</span>),</span><br><span class="line">            <span class="keyword">new</span> Salary(<span class="number">7500</span>),</span><br><span class="line">            <span class="keyword">new</span> StateCouncilSpecialAllowance(<span class="number">15000</span>)</span><br><span class="line">        &#125;;</span><br><span class="line">        System.out.println(totalTax(incomes));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">totalTax</span><span class="params">(Income... incomes)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">double</span> total = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (Income income: incomes) &#123;</span><br><span class="line">            total = total + income.getTax();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> total;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>观察<code>totalTax()</code>方法：利用多态，<code>totalTax()</code>方法只需要和<code>Income</code>打交道，它完全不需要知道<code>Salary</code>和<code>StateCouncilSpecialAllowance</code>的存在，就可以正确计算出总的税。如果我们要新增一种稿费收入，只需要从<code>Income</code>派生，然后正确覆写<code>getTax()</code>方法就可以。把新的类型传入<code>totalTax()</code>，不需要修改任何代码。</strong></p>
<h4 id="覆写object类的方法">3、覆写Object类的方法：</h4>
<p>​ 因为所有的<code>class</code>最终都继承自<code>Object</code>，而<code>Object</code>定义了几个重要的方法：</p>
<ul>
<li><code>toString()</code>：把instance输出为<code>String</code>；</li>
<li><code>equals()</code>：判断两个instance是否逻辑相等；</li>
<li><code>hashCode()</code>：计算一个instance的哈希值。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 显示更有意义的字符串:</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Person:name=&quot;</span> + name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 比较是否相等:</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 当且仅当o为Person类型:</span></span><br><span class="line">        <span class="keyword">if</span> (o <span class="keyword">instanceof</span> Person) &#123;</span><br><span class="line">            Person p = (Person) o;</span><br><span class="line">            <span class="comment">// 并且name字段相同时，返回true:</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>.name.equals(p.name);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算hash:</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.name.hashCode();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="super调用">4、Super调用</h4>
<p>在子类的覆写方法中，如果要调用父类的被覆写的方法，可以通过<code>super</code>来调用。例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Student extends Person &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 调用父类的hello()方法:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">super</span>.hello() + <span class="string">&quot;!&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="final-字段">5、Final 字段</h4>
<ul>
<li>如果一个父类不允许子类对它的某个方法进行覆写，可以把该方法标记为<code>final</code>。用<code>final</code>修饰的方法不能被<code>Override</code>：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> String name;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> String <span class="title">hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Hello, &quot;</span> + name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>对于一个类的实例字段，同样可以用<code>final</code>修饰。用<code>final</code>修饰的字段在初始化后不能被修改。例如:</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> String name = <span class="string">&quot;Unamed&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="六抽象类">六、抽象类</h3>
<ul>
<li>如果父类的方法本身不需要实现任何功能，仅仅是为了定义方法签名，目的是让子类去覆写它，那么，可以把父类的方法声明为抽象方法：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//编译错误</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//编译成功</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>通过<code>abstract</code>定义的方法是抽象方法，它只有定义，没有实现。抽象方法定义了子类必须实现的接口规范；</p></li>
<li><p>定义了抽象方法的class必须被定义为抽象类，从抽象类继承的子类必须实现抽象方法；</p></li>
<li><p>如果不实现抽象方法，则该子类仍是一个抽象类；</p></li>
</ul>
<h3 id="七面向抽象编程">七、面向抽象编程：</h3>
<p>我们定义了抽象类<code>Person</code>，以及具体的<code>Student</code>、<code>Teacher</code>子类的时候，我们可以通过抽象类<code>Person</code>类型去引用具体的子类的实例：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Person s = <span class="keyword">new</span> Student();</span><br><span class="line">Person t = <span class="keyword">new</span> Teacher();</span><br></pre></td></tr></table></figure>
<p>这种引用抽象类的好处在于，我们对其进行方法调用，并不关心<code>Person</code>类型变量的具体子类型：</p>
<p>这种尽量引用高层类型，避免引用实际子类型的方式，称之为面向抽象编程。</p>
<p>面向抽象编程的本质就是：</p>
<ul>
<li>上层代码只定义规范（例如：<code>abstract class Person</code>）；</li>
<li>不需要子类就可以实现业务逻辑（正常编译）；</li>
<li>具体的业务逻辑由不同的子类实现，调用者并不关心。</li>
</ul>
<h3 id="八接口interface">八、接口Interface</h3>
<h4 id="基础知识">1、基础知识</h4>
<p>如果一个抽象类没有字段，所有方法全部都是抽象方法：就可以把该抽象类改写为接口：<code>interface</code>。</p>
<p>在Java中，使用<code>interface</code>可以声明一个接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">String <span class="title">getName</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所谓<code>interface</code>，就是比抽象类还要抽象的纯抽象接口，因为它连字段都不能有。因为接口定义的所有方法默认都是<code>public abstract</code>的，所以这两个修饰符不需要写出来（写不写效果都一样)</p>
<ul>
<li><p>当一个具体的<code>class</code>去实现一个<code>interface</code>时，需要使用<code>implements</code>关键字。</p></li>
<li><p>```java class Student implements Person { private String name;</p>
<pre><code>public Student(String name) &#123;
    this.name = name;
&#125;

@Override
public void run() &#123;
    System.out.println(this.name + &quot; run&quot;);
&#125;

@Override
public String getName() &#123;
    return this.name;
&#125;</code></pre>
<p>} <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- 一个类可以实现多个`interface`</span><br><span class="line"></span><br><span class="line">- ```</span><br><span class="line">  class Student implements Person, Hello &#123; // 实现了两个interface</span><br><span class="line">      ...</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h4 id="接口继承使用extends">2、接口继承：使用extends</h4>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Hello</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">hello</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Person</span> <span class="keyword">extends</span> <span class="title">Hello</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function">String <span class="title">getName</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="default方法">3、default方法：</h3>
<p>在接口中，可以定义<code>default</code>方法。</p>
<p><strong>实现类可以不必覆写<code>default</code>方法。</strong></p>
<p><code>default</code>方法的目的是，当我们需要给接口新增一个方法时，将会涉及到修改全部子类。</p>
<p>但如果新增的是<code>default</code>方法，那么子类就不必全部修改，只需要在需要覆写的地方去覆写新增方法。</p>
<h3 id="九静态字段和静态方法">九、静态字段和静态方法：</h3>
<h4 id="静态字段">1、静态字段：</h4>
<p>​ 所有实例共享一个静态字段。推荐用类名来访问静态字段。可以把静态字段理解为描述<code>class</code>本身的字段（非实例字段）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Person.number = <span class="number">99</span>;</span><br><span class="line">System.out.println(Person.number);</span><br></pre></td></tr></table></figure>
<h4 id="静态方法">2、静态方法：</h4>
<ul>
<li><p>调用实例方法必须通过一个实例变量，而调用静态方法则不需要实例变量，通过类名就可以调用</p></li>
<li><p>静态方法内部，无法访问<code>this</code>变量，也无法访问实例字段，它只能访问静态字段</p></li>
</ul>
<h4 id="接口的静态字段">3、接口的静态字段：</h4>
<ul>
<li>因为<code>interface</code>是一个纯抽象类，所以它不能定义实例字段。但是，<code>interface</code>是可以有静态字段的，并且静态字段必须为<code>final</code>类型：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MALE = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> FEMALE = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 实际上，因为<code>interface</code>的字段只能是<code>public static final</code>类型，所以我们可以把这些修饰符都去掉，上述代码可以简写为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 编译器会自动加上public statc final:</span></span><br><span class="line">    <span class="keyword">int</span> MALE = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> FEMALE = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="十包">十、包：</h3>
<h4 id="简介">1、简介：</h4>
<p>如果小军写了一个<code>Arrays</code>类，恰好JDK也自带了一个<code>Arrays</code>类，如何解决类名冲突？</p>
<p>在Java中，我们使用<code>package</code>来解决名字冲突。</p>
<p><strong>Java定义了一种名字空间，称之为包：<code>package</code>。一个类总是属于某个包，类名（比如<code>Person</code>）只是一个简写，真正的完整类名是<code>包名.类名</code>。</strong></p>
<p>例如：</p>
<ul>
<li><p>小明的<code>Person</code>类存放在包<code>ming</code>下面，因此，完整类名是<code>ming.Person</code>；</p></li>
<li><p>小红的<code>Person</code>类存放在包<code>hong</code>下面，因此，完整类名是<code>hong.Person</code>；</p></li>
<li><p>小军的<code>Arrays</code>类存放在包<code>mr.jun</code>下面，因此，完整类名是<code>mr.jun.Arrays</code>；</p></li>
</ul>
<h4 id="如何申明包">2、如何申明包：</h4>
<p>在定义<code>class</code>的时候，我们需要在第一行声明这个<code>class</code>属于哪个包。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> ming; <span class="comment">// 申明包名ming</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意：包没有父子关系。java.util和java.util.zip是不同的包，两者没有任何继承关系。</p>
<h4 id="组织java文件">3、组织java文件：</h4>
<p>我们还需要按照包结构把上面的Java文件组织起来。假设以<code>package_sample</code>作为根目录，<code>src</code>作为源码目录，那么所有文件结构就是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package_sample</span><br><span class="line">└─ src</span><br><span class="line">    ├─ hong</span><br><span class="line">    │  └─ Person.java</span><br><span class="line">    │  ming</span><br><span class="line">    │  └─ Person.java</span><br><span class="line">    └─ mr</span><br><span class="line">       └─ jun</span><br><span class="line">          └─ Arrays.java</span><br></pre></td></tr></table></figure>
<h4 id="包作用域">4、包作用域：</h4>
<p>​ 位于同一个包的类，可以访问包作用域的字段和方法。不用<code>public</code>、<code>protected</code>、<code>private</code>修饰的字段和方法就是包作用域。例如，<code>Person</code>类定义在<code>hello</code>包下面：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> hello;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 包作用域:</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Hello!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>Main</code>类也定义在<code>hello</code>包下面：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> hello;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Person p = <span class="keyword">new</span> Person();</span><br><span class="line">        p.hello(); <span class="comment">// 可以调用，因为Main和Person在同一个包</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="包的引入">5、包的引入：</h4>
<h4 id="在一个class中我们总会引用其他的class由3种方法">1、在一个<code>class</code>中，我们总会引用其他的<code>class</code>，由3种方法：</h4>
<ul>
<li>写完整类名：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Person.java</span></span><br><span class="line"><span class="keyword">package</span> ming;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        mr.jun.Arrays arrays = <span class="keyword">new</span> mr.jun.Arrays();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>用<code>import</code>语句，导入小军的<code>Arrays</code>，然后写简单类名：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Person.java</span></span><br><span class="line"><span class="keyword">package</span> ming;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 导入完整类名:</span></span><br><span class="line"><span class="keyword">import</span> mr.jun.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Arrays arrays = <span class="keyword">new</span> Arrays();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>在写<code>import</code>的时候，可以使用<code>*</code>，表示把这个包下面的所有<code>class</code>都导入进来（但不包括子包的<code>class</code>）：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Person.java</span></span><br><span class="line"><span class="keyword">package</span> ming;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 导入mr.jun包的所有class:</span></span><br><span class="line"><span class="keyword">import</span> mr.jun.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Arrays arrays = <span class="keyword">new</span> Arrays();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="java编译器如何查找">2、Java编译器如何查找？</h4>
<p>Java编译器最终编译出的<code>.class</code>文件只使用完整类名，因此，在代码中，当编译器遇到一个<code>class</code>名称时：</p>
<ul>
<li>如果是完整类名，就直接根据完整类名查找这个<code>class</code>；</li>
<li>如果是简单类名，按下面的顺序依次查找：
<ul>
<li>查找当前<code>package</code>是否存在这个<code>class</code>；</li>
<li>查找<code>import</code>的包是否包含这个<code>class</code>；</li>
<li>查找<code>java.lang</code>包是否包含这个<code>class</code>。</li>
</ul></li>
</ul>
<h4 id="最佳实践">3、最佳实践：</h4>
<p>为了避免名字冲突，我们需要确定唯一的包名。推荐的做法是使用倒置的作用域名来确保唯一性。例如：</p>
<ul>
<li>org.apache</li>
<li>org.apache.commons.log</li>
<li>com.liaoxuefeng.sample</li>
</ul>
<p>子包就可以根据功能自行命名。</p>
<h3 id="十一作用域">十一、作用域：</h3>
<h4 id="public">1、public</h4>
<ul>
<li><p>定义为<code>public</code>的<code>class</code>、<code>interface</code>可以被其他任何类访问</p></li>
<li><p>定义为<code>public</code>的<code>field</code>、<code>method</code>可以被其他类访问，前提是首先有访问<code>class</code>的权限：</p></li>
</ul>
<h4 id="private">2、private</h4>
<ul>
<li><p>定义为<code>private</code>的<code>field</code>、<code>method</code>无法被其他类访问</p></li>
<li><p><code>private</code>访问权限被限定在<code>class</code>的内部，而且与方法声明顺序<em>无关</em>。推荐把<code>private</code>方法放到后面，因为<code>public</code>方法定义了类对外提供的功能，阅读代码的时候，应该先关注<code>public</code>方法</p></li>
<li><p>Java支持嵌套类，如果一个类内部还定义了嵌套类，那么，嵌套类拥有访问<code>private</code>的权限：</p></li>
<li><p><strong>嵌套类</strong>：</p></li>
<li><p>定义在一个<code>class</code>内部的<code>class</code>称为嵌套类（<code>nested class</code>），Java支持好几种嵌套类。</p></li>
<li><p>``` public class Main { public static void main(String[] args) { Inner i = new Inner(); i.hi(); }</p>
<pre><code>// private方法:
private static void hello() &#123;
    System.out.println(&quot;private hello!&quot;);
&#125;

// 静态内部类:
static class Inner &#123;
    public void hi() &#123;
        Main.hello();
    &#125;
&#125;</code></pre>
<p>}</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#### 3、protected</span><br><span class="line"></span><br><span class="line">- `protected`作用于继承关系。定义为`protected`的字段和方法可以被子类访问，以及子类的子类</span><br><span class="line"></span><br><span class="line">#### 4、package：</span><br><span class="line"></span><br><span class="line">- 包作用域是指一个类允许访问同一个`package`的没有`public`、`private`修饰的`class`，以及没有`public`、`protected`、`private`修饰的字段和方法。</span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line">package abc;</span><br><span class="line">// package权限的类:</span><br><span class="line">class Hello &#123;</span><br><span class="line">    // package权限的方法:</span><br><span class="line">    void hi() &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>只要在同一个包，就可以访问<code>package</code>权限的<code>class</code>、<code>field</code>和<code>method</code>：</p></li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> abc;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 可以访问package权限的类:</span></span><br><span class="line">        Hello h = <span class="keyword">new</span> Hello();</span><br><span class="line">        <span class="comment">// 可以调用package权限的方法:</span></span><br><span class="line">        h.hi();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="final">5、final</h4>
<p><code>final</code>与访问权限不冲突，它有很多作用：</p>
<ul>
<li>用<code>final</code>修饰<code>class</code>可以阻止被继承：</li>
<li>用<code>final</code>修饰<code>method</code>可以阻止被子类覆写</li>
<li>用<code>final</code>修饰<code>field</code>可以阻止被重新赋值</li>
<li>用<code>final</code>修饰局部变量可以阻止被重新赋值</li>
</ul>
<h4 id="最佳实践-1">6、最佳实践：</h4>
<ul>
<li><p>如果不确定是否需要<code>public</code>，就不声明为<code>public</code>，即尽可能少地暴露对外的字段和方法。</p></li>
<li><p>把方法定义为<code>package</code>权限有助于测试，因为测试类和被测试类只要位于同一个<code>package</code>，测试代码就可以访问被测试类的<code>package</code>权限方法。</p></li>
<li><p><strong>一个<code>.java</code>文件只能包含一个<code>public</code>类，但可以包含多个非<code>public</code>类。如果有<code>public</code>类，文件名必须和<code>public</code>类的名字相同。</strong></p></li>
</ul>
<h3 id="十二内部类">十二、内部类：</h3>
<p>Java的内部类分为好几种，通常情况用得不多，但也需要了解它们是如何使用的</p>
<h4 id="inner-class">1、Inner Class</h4>
<p>如果一个类定义在另一个类的内部，这个类就是Inner Class：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Outer</span> </span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Inner</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 定义了一个Inner Class</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Inner Class的实例不能单独存在，必须依附于一个Outer Class的实例</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Outer outer = <span class="keyword">new</span> Outer(<span class="string">&quot;Nested&quot;</span>); <span class="comment">// 实例化一个Outer</span></span><br><span class="line">        Outer.Inner inner = outer.<span class="function">new <span class="title">Inner</span><span class="params">()</span></span>; <span class="comment">// 实例化一个Inner</span></span><br><span class="line">        inner.hello();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Outer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    Outer(String name) &#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Inner</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;Hello, &quot;</span> + Outer.<span class="keyword">this</span>.name);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Outer.Inner inner = outer.new Inner();</span><br></pre></td></tr></table></figure>
<ul>
<li><p>Inner Class和普通Class相比，除了能引用Outer实例外，还有一个额外的“特权”，<strong>就是可以修改Outer Class的<code>private</code>字段</strong>，因为Inner Class的作用域在Outer Class内部，所以能访问Outer Class的<code>private</code>字段和方法。</p></li>
<li><p>观察Java编译器编译后的<code>.class</code>文件可以发现，<code>Outer</code>类被编译为<code>Outer.class</code>，而<code>Inner</code>类被编译为<code>Outer$Inner.class</code>。</p></li>
</ul>
<h4 id="anonymous-class">2、Anonymous Class</h4>
<p>​ 有一种定义Inner Class的方法，它不需要在Outer Class中明确地定义这个Class，而是在方法内部，通过匿名类（Anonymous Class）来定义。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Outer outer = <span class="keyword">new</span> Outer(<span class="string">&quot;Nested&quot;</span>);</span><br><span class="line">        outer.asyncHello();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Outer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    Outer(String name) &#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">asyncHello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Runnable r = <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;Hello, &quot;</span> + Outer.<span class="keyword">this</span>.name);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="keyword">new</span> Thread(r).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 观察<code>asyncHello()</code>方法，我们在方法内部实例化了一个<code>Runnable</code>。<code>Runnable</code>本身是接口，接口是不能实例化的，所以这里实际上是定义了一个实现了<code>Runnable</code>接口的匿名类，并且通过<code>new</code>实例化该匿名类，然后转型为<code>Runnable</code>。在定义匿名类的时候就必须实例化它，定义匿名类的写法如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Runnable r = <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">    <span class="comment">// 实现必要的抽象方法...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>匿名类和Inner Class一样，可以访问Outer Class的<code>private</code>字段和方法。之所以我们要定义匿名类，是因为在这里我们通常不关心类名，比直接定义Inner Class可以少写很多代码。</p>
<h4 id="static-nested-class-静态内部类">3、Static Nested Class 静态内部类：</h4>
<p>最后一种内部类和Inner Class类似，但是使用<code>static</code>修饰，称为静态内部类（Static Nested Class）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Outer.StaticNested sn = <span class="keyword">new</span> Outer.StaticNested();</span><br><span class="line">        sn.hello();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Outer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String NAME = <span class="string">&quot;OUTER&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    Outer(String name) &#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">StaticNested</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;Hello, &quot;</span> + Outer.NAME);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ 用<code>static</code>修饰的内部类和Inner Class有很大的不同，它不再依附于<code>Outer</code>的实例，而是一个完全独立的类，因此无法引用<code>Outer.this</code>，但它可以访问<code>Outer</code>的<code>private</code>静态字段和静态方法。如果把<code>StaticNested</code>移到<code>Outer</code>之外，就失去了访问<code>private</code>的权限。</p>
<h4 id="总结">4、总结：</h4>
<p>Java的内部类可分为Inner Class、Anonymous Class和Static Nested Class三种：</p>
<ul>
<li>Inner Class和Anonymous Class本质上是相同的，都必须依附于Outer Class的实例，即隐含地持有<code>Outer.this</code>实例，并拥有Outer Class的<code>private</code>访问权限；</li>
<li>Static Nested Class是独立类，但拥有Outer Class的<code>private</code>访问权限。</li>
</ul>
<h3 id="十三classpath-和-jar">十三、classpath 和 jar</h3>
<h4 id="classpath是什么">1、classpath是什么？</h4>
<p>​ <code>classpath</code>是JVM用到的一个环境变量，它用来指示JVM如何搜索<code>class</code></p>
<p>​ 因为Java是编译型语言，源码文件是<code>.java</code>，而编译后的<code>.class</code>文件才是真正可以被JVM执行的字节码。因此，JVM需要知道，如果要加载一个<code>abc.xyz.Hello</code>的类，应该去哪搜索对应的<code>Hello.class</code>文件。</p>
<p>​ 所以，<code>classpath</code>就是一组目录的集合，它设置的搜索路径与操作系统相关。例如，在Windows系统上，用<code>;</code>分隔，带空格的目录用<code>""</code>括起来，可能长这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">C:\work\project1\bin;C:\shared;&quot;D:\My Documents\project1\bin&quot;</span><br></pre></td></tr></table></figure>
<p>​ 在Linux系统上，用<code>:</code>分隔，可能长这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/usr/shared:/usr/local/bin:/home/liaoxuefeng/bin</span><br></pre></td></tr></table></figure>
<p>​ 现在我们假设<code>classpath</code>是<code>.;C:\work\project1\bin;C:\shared</code>，当JVM在加载<code>abc.xyz.Hello</code>这个类时，会依次查找：</p>
<ul>
<li><当前目录>.class</li>
<li>C:.class</li>
<li>C:.class</li>
</ul>
<p>​ 注意到<code>.</code>代表当前目录。如果JVM在某个路径下找到了对应的<code>class</code>文件，就不再往后继续搜索。如果所有路径下都没有找到，就报错。</p>
<h4 id="如何设定classpath">2、如何设定classpath?</h4>
<p>​ 在启动JVM时设置<code>classpath</code>变量,实际上就是给<code>java</code>命令传入<code>-classpath</code>或<code>-cp</code>参数：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">java -classpath .;C:\work\project1\bin;C:\shared abc.xyz.Hello</span><br></pre></td></tr></table></figure>
<p>​ 没有设置系统环境变量，也没有传入<code>-cp</code>参数，那么JVM默认的<code>classpath</code>为<code>.</code>，即当前目录：</p>
<p>​ 在IDE中运行Java程序，IDE自动传入的<code>-cp</code>参数是当前工程的<code>bin</code>目录和引入的jar包</p>
<p><strong>注意：不要把任何Java核心库添加到classpath中！JVM根本不依赖classpath加载核心库！</strong></p>
<h4 id="jar包是什么">3、jar包是什么？：</h4>
<p>​ 如果有很多<code>.class</code>文件，散落在各层目录中，肯定不便于管理。如果能把目录打一个包，变成一个文件，就方便多了。</p>
<p>​ jar包就是用来干这个事的，它可以把<code>package</code>组织的目录层级，以及各个目录下的所有文件（包括<code>.class</code>文件和其他文件）都打成一个jar文件，这样一来，无论是备份，还是发给客户，就简单多了。</p>
<p>​ jar包实际上就是一个zip格式的压缩文件，而jar包相当于目录。如果我们要执行一个jar包的<code>class</code>，就可以把jar包放到<code>classpath</code>中：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ava -cp ./hello.jar abc.xyz.Hello</span><br></pre></td></tr></table></figure>
<p>​ 这样JVM会自动在<code>hello.jar</code>文件里去搜索某个类。</p>
<h4 id="如何创建jar包">4、如何创建jar包？</h4>
<p>​ 因为jar包就是zip包，所以，直接在资源管理器中，找到正确的目录，点击右键，在弹出的快捷菜单中选择“发送到”，“压缩(zipped)文件夹”，就制作了一个zip文件。然后，把后缀从<code>.zip</code>改为<code>.jar</code>，一个jar包就创建成功。</p>
<p>假设编译输出的目录结构是这样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package_sample</span><br><span class="line">└─ bin</span><br><span class="line">   ├─ hong</span><br><span class="line">   │  └─ Person.class</span><br><span class="line">   │  ming</span><br><span class="line">   │  └─ Person.class</span><br><span class="line">   └─ mr</span><br><span class="line">      └─ jun</span><br><span class="line">         └─ Arrays.class</span><br></pre></td></tr></table></figure>
<p>这里需要特别注意的是，jar包里的第一层目录，不能是<code>bin</code>，而应该是<code>hong</code>、<code>ming</code>、<code>mr</code>。应当如下所示：</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/pic.png" alt="pic" /><figcaption aria-hidden="true">pic</figcaption>
</figure>
<h4 id="特殊文件-manifest.mf">4、特殊文件 MANIFEST.MF：</h4>
<p>​ jar包还可以包含一个特殊的<code>/META-INF/MANIFEST.MF</code>文件，<code>MANIFEST.MF</code>是纯文本，可以指定<code>Main-Class</code>和其它信息。JVM会自动读取这个<code>MANIFEST.MF</code>文件，如果存在<code>Main-Class</code>，我们就不必在命令行指定启动的类名，而是用更方便的命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java -jar hello.jar</span><br></pre></td></tr></table></figure>
<p>​ jar包还可以包含其它jar包，这个时候，就需要在<code>MANIFEST.MF</code>文件里配置<code>classpath</code>了。</p>
<p>​ 在大型项目中，不可能手动编写<code>MANIFEST.MF</code>文件，再手动创建zip包。Java社区提供了大量的开源构建工具，例如<a href="https://www.liaoxuefeng.com/wiki/1252599548343744/1255945359327200">Maven</a>，可以非常方便地创建jar包。</p>
<h3 id="十四模块">十四、模块：</h3>
<h4 id="java9之前的程序打包运行">1、java9之前的程序打包运行：</h4>
<p>从Java 9开始，JDK又引入了模块（Module）</p>
<p><code>.class</code>文件是JVM看到的最小可执行文件，而一个大型程序需要编写很多Class，并生成一堆<code>.class</code>文件，很不便于管理，所以，<code>jar</code>文件就是<code>class</code>文件的容器。</p>
<p>在Java 9之前，一个大型Java程序会生成自己的jar文件，同时引用依赖的第三方jar文件，而JVM自带的Java标准库，实际上也是以jar文件形式存放的，这个文件叫<code>rt.jar</code>，一共有60多M。</p>
<p>如果是自己开发的程序，除了一个自己的<code>app.jar</code>以外，还需要一堆第三方的jar包，运行一个Java程序，一般来说，命令行写这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java -cp app.jar:a.jar:b.jar:c.jar com.liaoxuefeng.sample.Main</span><br></pre></td></tr></table></figure>
<p>如果漏写了某个运行时需要用到的jar，那么在运行期极有可能抛出<code>ClassNotFoundException</code>。</p>
<p>所以，jar只是用于存放class的容器，<strong>它并不关心class之间的依赖</strong>。</p>
<h4 id="java9之后引入的模块">2、java9之后引入的模块：</h4>
<p>​ 主要为了解决依赖的问题。</p>
<p>​ 如果<code>a.jar</code>必须依赖另一个<code>b.jar</code>才能运行，那我们应该给<code>a.jar</code>加点说明啥的，让程序在编译和运行的时候能自动定位到<code>b.jar</code>，这种自带“依赖关系”的class容器就是模块。</p>
<p>为了表明Java模块化的决心，从Java 9开始，原有的Java标准库已经由一个单一巨大的<code>rt.jar</code>分拆成了几十个模块，这些模块以<code>.jmod</code>扩展名标识，可以在<code>$JAVA_HOME/jmods</code>目录下找到它们：</p>
<ul>
<li>java.base.jmod</li>
<li>java.compiler.jmod</li>
<li>java.datatransfer.jmod</li>
<li>java.desktop.jmod</li>
<li>...</li>
</ul>
<p>​ 这些<code>.jmod</code>文件每一个都是一个模块，模块名就是文件名。例如：模块<code>java.base</code>对应的文件就是<code>java.base.jmod</code>。模块之间的依赖关系已经被写入到模块内的<code>module-info.class</code>文件了。所有的模块都直接或间接地依赖<code>java.base</code>模块，只有<code>java.base</code>模块不依赖任何模块，它可以被看作是“根模块”，好比所有的类都是从<code>Object</code>直接或间接继承而来。</p>
<p>​ 把一堆class封装为jar仅仅是一个打包的过程，而把一堆class封装为模块则不但需要打包，还需要写入依赖关系，并且还可以包含二进制代码（通常是JNI扩展）。此外，模块支持多版本，即在同一个模块中可以为不同的JVM提供不同的版本。</p>
<h4 id="如何编写模块">3、如何编写模块：</h4>
<p>​ 首先，创建模块和原有的创建Java项目是完全一样的，以<code>oop-module</code>工程为例，它的目录结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">oop-module</span><br><span class="line">├── bin</span><br><span class="line">├── build.sh</span><br><span class="line">└── src</span><br><span class="line">    ├── com</span><br><span class="line">    │   └── itranswarp</span><br><span class="line">    │       └── sample</span><br><span class="line">    │           ├── Greeting.java</span><br><span class="line">    │           └── Main.java</span><br><span class="line">    └── module-info.java</span><br></pre></td></tr></table></figure>
<p>其中，<code>bin</code>目录存放编译后的class文件，<code>src</code>目录存放源码，按包名的目录结构存放，仅仅在<code>src</code>目录下多了一个<code>module-info.java</code>这个文件，这就是模块的描述文件。在这个模块中，它长这样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">module</span> hello.world &#123;</span><br><span class="line">	<span class="keyword">requires</span> java.base; <span class="comment">// 可不写，任何模块都会自动引入java.base</span></span><br><span class="line">	<span class="keyword">requires</span> java.xml;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，<code>module</code>是关键字，后面的<code>hello.world</code>是模块的名称，它的命名规范与包一致。花括号的<code>requires xxx;</code>表示这个模块需要引用的其他模块名。除了<code>java.base</code>可以被自动引入外，这里我们引入了一个<code>java.xml</code>的模块。</p>
<p>当我们使用模块声明了依赖关系后，才能使用引入的模块。例如，<code>Main.java</code>代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.itranswarp.sample;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 必须引入java.xml模块后才能使用其中的类:</span></span><br><span class="line"><span class="keyword">import</span> javax.xml.XMLConstants;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		Greeting g = <span class="keyword">new</span> Greeting();</span><br><span class="line">		System.out.println(g.hello(XMLConstants.XML_NS_PREFIX));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果把<code>requires java.xml;</code>从<code>module-info.java</code>中去掉，编译将报错。可见，模块的重要作用就是声明依赖关系。</p>
<h4 id="命令行编译并创建模块">4、 命令行编译并创建模块：</h4>
<p>首先，我们把工作目录切换到<code>oop-module</code>，在当前目录下编译所有的<code>.java</code>文件，并存放到<code>bin</code>目录下，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ javac -d bin src/module-info.java src/com/itranswarp/sample/*.java</span><br></pre></td></tr></table></figure>
<p>如果编译成功，现在项目结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">oop-module</span><br><span class="line">├── bin</span><br><span class="line">│   ├── com</span><br><span class="line">│   │   └── itranswarp</span><br><span class="line">│   │       └── sample</span><br><span class="line">│   │           ├── Greeting.class</span><br><span class="line">│   │           └── Main.class</span><br><span class="line">│   └── module-info.class</span><br><span class="line">└── src</span><br><span class="line">    ├── com</span><br><span class="line">    │   └── itranswarp</span><br><span class="line">    │       └── sample</span><br><span class="line">    │           ├── Greeting.java</span><br><span class="line">    │           └── Main.java</span><br><span class="line">    └── module-info.java</span><br></pre></td></tr></table></figure>
<p>注意到<code>src</code>目录下的<code>module-info.java</code>被编译到<code>bin</code>目录下的<code>module-info.class</code>。</p>
<p>下一步，我们需要把bin目录下的所有class文件先打包成jar，在打包的时候，注意传入<code>--main-class</code>参数，让这个jar包能自己定位<code>main</code>方法所在的类：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ jar --create --file hello.jar --main-class com.itranswarp.sample.Main -C bin .</span><br></pre></td></tr></table></figure>
<p>现在我们就在当前目录下得到了<code>hello.jar</code>这个jar包，它和普通jar包并无区别，可以直接使用命令<code>java -jar hello.jar</code>来运行它。但是我们的目标是创建模块，所以，继续使用JDK自带的<code>jmod</code>命令把一个jar包转换成模块：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ jmod create --class-path hello.jar hello.jmod</span><br></pre></td></tr></table></figure>
<p>于是，在当前目录下我们又得到了<code>hello.jmod</code>这个模块文件，这就是最后打包出来的传说中的模块！</p>
<h4 id="运行模块">5、运行模块：</h4>
<p>要运行一个jar，我们使用<code>java -jar xxx.jar</code>命令。要运行一个模块，我们只需要指定模块名。试试：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ java --module-path hello.jmod --module hello.world</span><br></pre></td></tr></table></figure>
<p>结果是一个错误：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Error occurred during initialization of boot layer</span><br><span class="line">java.lang.module.FindException: JMOD format not supported at execution time: hello.jmod</span><br></pre></td></tr></table></figure>
<p>原因是<code>.jmod</code>不能被放入<code>--module-path</code>中。换成<code>.jar</code>就没问题了：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ java --module-path hello.jar --module hello.world</span><br><span class="line">Hello, xml!</span><br></pre></td></tr></table></figure>
<h4 id="打包jre">6、打包JRE</h4>
<p>我们可以利用创建的<code>hello.jmod</code>来打包JRE。</p>
<p>​ 为了支持模块化，Java 9首先带头把自己的一个巨大无比的<code>rt.jar</code>拆成了几十个<code>.jmod</code>模块，原因就是，运行Java程序的时候，实际上我们用到的JDK模块，并没有那么多。不需要的模块，完全可以删除。</p>
<p>​ 过去发布一个Java应用程序，要运行它，必须下载一个完整的JRE，再运行jar包。而完整的JRE块头很大，有100多M。怎么给JRE瘦身呢？</p>
<p>​ 现在，JRE自身的标准库已经分拆成了模块，只需要带上程序用到的模块，其他的模块就可以被裁剪掉。怎么裁剪JRE呢？并不是说把系统安装的JRE给删掉部分模块，而是“复制”一份JRE，但只带上用到的模块。为此，JDK提供了<code>jlink</code>命令来干这件事。命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ jlink --module-path hello.jmod --add-modules java.base,java.xml,hello.world --output jre/</span><br></pre></td></tr></table></figure>
<p>我们在<code>--module-path</code>参数指定了我们自己的模块<code>hello.jmod</code>，然后，在<code>--add-modules</code>参数中指定了我们用到的3个模块<code>java.base</code>、<code>java.xml</code>和<code>hello.world</code>，用<code>,</code>分隔。最后，在<code>--output</code>参数指定输出目录。</p>
<p>现在，在当前目录下，我们可以找到<code>jre</code>目录，这是一个完整的并且带有我们自己<code>hello.jmod</code>模块的JRE。试试直接运行这个JRE：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ jre/bin/java --module hello.world</span><br><span class="line">Hello, xml!</span><br></pre></td></tr></table></figure>
<p>要分发我们自己的Java应用程序，只需要把这个<code>jre</code>目录打个包给对方发过去，对方直接运行上述命令即可，既不用下载安装JDK，也不用知道如何配置我们自己的模块，极大地方便了分发和部署。</p>
<h4 id="访问权限">7、访问权限：</h4>
<p>Java的class访问权限分为public、protected、private和默认的包访问权限。</p>
<p>引入模块后，这些访问权限的规则就要稍微做些调整。</p>
<p>确切地说，<strong>class的这些访问权限只在一个模块内有效</strong>，模块和模块之间，例如，a模块要访问b模块的某个class，必要条件是b模块明确地导出了可以访问的包。</p>
<p>举个例子：我们编写的模块<code>hello.world</code>用到了模块<code>java.xml</code>的一个类<code>javax.xml.XMLConstants</code>，我们之所以能直接使用这个类，是因为模块<code>java.xml</code>的<code>module-info.java</code>中声明了若干导出：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">module</span> java.xml &#123;</span><br><span class="line">    <span class="keyword">exports</span> java.xml;</span><br><span class="line">    <span class="keyword">exports</span> javax.xml.catalog;</span><br><span class="line">    <span class="keyword">exports</span> javax.xml.datatype;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>只有它声明的导出的包，外部代码才被允许访问。换句话说，如果外部代码想要访问我们的<code>hello.world</code>模块中的<code>com.itranswarp.sample.Greeting</code>类，我们必须将其导出：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">module</span> hello.world &#123;</span><br><span class="line">    <span class="keyword">exports</span> com.itranswarp.sample;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">requires</span> java.base;</span><br><span class="line">	<span class="keyword">requires</span> java.xml;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因此，模块进一步隔离了代码的访问权限。</p>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>oop</tag>
      </tags>
  </entry>
  <entry>
    <title>java系列笔记1——java基础</title>
    <url>/2022/01/28/0c40d5b18a1b/</url>
    <content><![CDATA[<p>参考教程网址：https://www.liaoxuefeng.com/wiki/1252599548343744/1260467032946976</p>
<h3 id="一第一个java程序">一、第一个Java程序</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Hello</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Hello, world!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​ java规定，某个类定义的<code>public static void main(String[] args)</code>是java程序的固定入口方法，因此，java程序总是从<code>main</code>方法开始执行。</p>
<h3 id="二如何运行java程序">二、如何运行Java程序：</h3>
<p>1、用javac把Hello.java编译成字节码文件Hello.class，</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> javac Hello.java</span></span><br></pre></td></tr></table></figure>
<p>2、然后用java命令执行这个字节码文件。javac是编译器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> java Hello</span></span><br><span class="line">Hello, world!</span><br></pre></td></tr></table></figure>
<p>给虚拟机传递的参数<code>Hello</code>是我们定义的类名，虚拟机自动查找对应的class文件并执行</p>
<p><strong>注意</strong>：</p>
<p>一个Java源码只能定义一个<code>public</code>类型的class，并且class名称和文件名要完全一致；</p>
<p>使用<code>javac</code>可以将<code>.java</code>源码编译成<code>.class</code>字节码；</p>
<p>使用<code>java</code>可以运行一个已编译的Java程序，参数是类名。</p>
<h3 id="三程序基本结构">三、程序基本结构：</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 可以用来自动创建文档的注释</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Hello</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 向屏幕输出文本:</span></span><br><span class="line">        System.out.println(<span class="string">&quot;Hello, world!&quot;</span>);</span><br><span class="line">        <span class="comment">/* 多行注释开始</span></span><br><span class="line"><span class="comment">        注释内容</span></span><br><span class="line"><span class="comment">        注释结束 */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="comment">// class定义结束</span></span><br></pre></td></tr></table></figure>
<p><code>public</code>是访问修饰符，表示该<code>class</code>是公开的。不写<code>public</code>，也能正确编译，但是这个类将无法从命令行执行。</p>
<h3 id="四数据类型">四、数据类型</h3>
<p><strong>基本数据类型：</strong></p>
<ul>
<li>整数类型：byte，short，int，long</li>
<li>浮点数类型：float，double</li>
<li>字符类型：char</li>
<li>布尔类型：boolean</li>
</ul>
<p><strong>引用类型</strong>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s = <span class="string">&quot;hello&quot;</span>;</span><br></pre></td></tr></table></figure>
<p>引用类型的变量类似于C语言的指针，它内部存储一个“地址”，指向某个对象在内存的位置</p>
<p><strong>常量</strong>：</p>
<p>如果加上<code>final</code>修饰符，这个变量就变成了常量：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="keyword">double</span> PI = <span class="number">3.14</span>; <span class="comment">// PI是一个常量</span></span><br></pre></td></tr></table></figure>
<p><strong>var关键字:</strong></p>
<p>如果想省略变量类型，可以使用<code>var</code>关键字</p>
<h3 id="五浮点数运算">五、浮点数运算：</h3>
<p>​ 由于浮点数存在运算误差，所以比较两个浮点数是否相等常常会出现错误的结果。正确的比较方法是判断两个浮点数之差的绝对值是否小于一个很小的数：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> r = Math.abs(x - y);</span><br><span class="line"><span class="comment">// 再判断绝对值是否足够小:</span></span><br><span class="line"><span class="keyword">if</span> (r &lt; <span class="number">0.00001</span>) &#123;</span><br><span class="line">    <span class="comment">// 可以认为相等</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 不相等</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>整数运算在除数为<code>0</code>时会报错，而浮点数运算在除数为<code>0</code>时，不会报错，但会返回几个特殊值：</p>
<ul>
<li><code>NaN</code>表示Not a Number</li>
<li><code>Infinity</code>表示无穷大</li>
<li><code>-Infinity</code>表示负无穷大</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> d1 = <span class="number">0.0</span> / <span class="number">0</span>; <span class="comment">// NaN</span></span><br><span class="line"><span class="keyword">double</span> d2 = <span class="number">1.0</span> / <span class="number">0</span>; <span class="comment">// Infinity</span></span><br><span class="line"><span class="keyword">double</span> d3 = -<span class="number">1.0</span> / <span class="number">0</span>; <span class="comment">// -Infinity</span></span><br></pre></td></tr></table></figure>
<h3 id="六字符类型">六、字符类型：</h3>
<p>一个<code>char</code>保存一个Unicode字符：</p>
<p>因为Java在内存中总是使用Unicode表示字符，所以，一个英文字符和一个中文字符都用一个<code>char</code>类型表示，它们都占用两个字节。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int n1 = &#x27;A&#x27;; // 字母“A”的Unicodde编码是65</span><br><span class="line">int n2 = &#x27;中&#x27;; // 汉字“中”的Unicode编码是20013</span><br><span class="line">还可以直接用转义字符\u+Unicode编码来表示一个字符：</span><br><span class="line">// 注意是十六进制:</span><br><span class="line">char c3 = &#x27;\u0041&#x27;; // &#x27;A&#x27;，因为十六进制0041 = 十进制65</span><br><span class="line">char c4 = &#x27;\u4e2d&#x27;; // &#x27;中&#x27;，因为十六进制4e2d = 十进制20013</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>如果用<code>+</code>连接字符串和其他数据类型，会将其他数据类型先自动转型为字符串，再连接：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> age = <span class="number">25</span>;</span><br><span class="line">        String s = <span class="string">&quot;age is &quot;</span> + age;</span><br><span class="line">        System.out.println(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从Java 13开始，字符串可以用<code>"""..."""</code>表示多行字符串（Text Blocks）了。</p>
<p>多行字符串前面共同的空格会被去掉，即：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String s = <span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">                   SELECT * FROM</span></span><br><span class="line"><span class="string">                     users</span></span><br><span class="line"><span class="string">                   WHERE id &gt; 100</span></span><br><span class="line"><span class="string">                   ORDER BY name DESC</span></span><br><span class="line"><span class="string">                   &quot;</span><span class="string">&quot;&quot;</span>;</span><br><span class="line">        System.out.println(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>不可见特性：</strong></p>
<p>Java的字符串除了是一个引用类型外，还有个重要特点，就是字符串不可变。考察以下代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String s = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">        System.out.println(s); <span class="comment">// 显示 hello</span></span><br><span class="line">        s = <span class="string">&quot;world&quot;</span>;</span><br><span class="line">        System.out.println(s); <span class="comment">// 显示 world</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>观察执行结果，难道字符串<code>s</code>变了吗？其实变的不是字符串，而是变量<code>s</code>的“指向”。</p>
<p><strong>空值null:</strong></p>
<p>引用类型的变量可以指向一个空值<code>null</code>，它表示不存在，即该变量不指向任何对象。例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String s1 = <span class="keyword">null</span>; <span class="comment">// s1是null</span></span><br><span class="line">String s2; <span class="comment">// 没有赋初值值，s2也是null</span></span><br></pre></td></tr></table></figure>
<h3 id="七数组">七、数组：</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] ns = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">5</span>];</span><br><span class="line"><span class="keyword">int</span>[] ns = &#123; <span class="number">68</span>, <span class="number">79</span>, <span class="number">91</span>, <span class="number">85</span>, <span class="number">62</span> &#125;;</span><br><span class="line">System.out.println(ns.length); <span class="comment">// 5</span></span><br></pre></td></tr></table></figure>
<h3 id="八流程控制手段">八、流程控制手段</h3>
<h4 id="输出">1、输出</h4>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">System.out.print(<span class="string">&quot;A,&quot;</span>); <span class="comment">//输出后不换行</span></span><br><span class="line">System.out.println() <span class="comment">//输出后自动换行</span></span><br><span class="line">System.out.printf(<span class="string">&quot;%.2f\n&quot;</span>, d); <span class="comment">// 格式化输出，显示两位小数3.14</span></span><br></pre></td></tr></table></figure>
<h4 id="输入">2、输入：</h4>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Scanner scanner = <span class="keyword">new</span> Scanner(System.in); <span class="comment">// 创建Scanner对象</span></span><br><span class="line">        System.out.print(<span class="string">&quot;Input your name: &quot;</span>); <span class="comment">// 打印提示</span></span><br><span class="line">        String name = scanner.nextLine(); <span class="comment">// 读取一行输入并获取字符串</span></span><br><span class="line">        System.out.print(<span class="string">&quot;Input your age: &quot;</span>); <span class="comment">// 打印提示</span></span><br><span class="line">        <span class="keyword">int</span> age = scanner.nextInt(); <span class="comment">// 读取一行输入并获取整数</span></span><br><span class="line">        System.out.printf(<span class="string">&quot;Hi, %s, you are %d\n&quot;</span>, name, age); <span class="comment">// 格式化输出</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>通过<code>import</code>语句导入<code>java.util.Scanner</code></li>
<li>创建<code>Scanner</code>对象并传入<code>System.in</code></li>
<li>有了<code>Scanner</code>对象后，要读取用户输入的字符串，使用<code>scanner.nextLine()</code>，要读取用户输入的整数，使用<code>scanner.nextInt()</code>。<code>Scanner</code>会自动转换数据类型，因此不必手动转换。</li>
</ul>
<h3 id="九判断引用类型变量内容是否相等">九、判断引用类型变量内容是否相等：</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String s1 = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">        String s2 = <span class="string">&quot;HELLO&quot;</span>.toLowerCase();</span><br><span class="line">        System.out.println(s1);</span><br><span class="line">        System.out.println(s2);</span><br><span class="line">        <span class="keyword">if</span> (s1 == s2) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;s1 == s2&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;s1 != s2&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 输出结果是 s1 != s2</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>要判断引用类型的变量内容是否相等，必须使用<code>equals()</code>方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">s1.equals(s2)</span><br></pre></td></tr></table></figure>
<h3 id="十新switch表达式">十、新Switch表达式：</h3>
<p>​ 从Java 12开始，<code>switch</code>语句升级为更简洁的表达式语法，使用类似模式匹配（Pattern Matching）的方法，保证只有一种路径会被执行，并且不需要<code>break</code>语句</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String fruit = <span class="string">&quot;apple&quot;</span>;</span><br><span class="line"><span class="keyword">switch</span> (fruit) &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;apple&quot;</span> -&gt; System.out.println(<span class="string">&quot;Selected apple&quot;</span>);</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;pear&quot;</span> -&gt; System.out.println(<span class="string">&quot;Selected pear&quot;</span>);</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;mango&quot;</span> -&gt; &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Selected mango&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;Good choice!&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">default</span> -&gt; System.out.println(<span class="string">&quot;No fruit selected&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="十一switch中的yield返回值">十一、Switch中的Yield返回值：</h3>
<p>大多数时候，在<code>switch</code>表达式内部，我们会返回简单的值。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        String fruit = <span class="string">&quot;orange&quot;</span>;</span><br><span class="line">        <span class="keyword">int</span> opt = <span class="keyword">switch</span> (fruit) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;apple&quot;</span> -&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;pear&quot;</span>, <span class="string">&quot;mango&quot;</span> -&gt; <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">default</span> -&gt; &#123;</span><br><span class="line">                <span class="keyword">int</span> code = fruit.hashCode();</span><br><span class="line">                yield code; <span class="comment">// switch语句返回值</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        System.out.println(<span class="string">&quot;opt = &quot;</span> + opt);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="十二for-each-循环">十二、for each 循环</h3>
<p>和<code>for</code>循环相比，<code>for each</code>循环的变量n不再是计数器，而是直接对应到数组的每个元素。<code>for each</code>循环的写法也更简洁。但是，<code>for each</code>循环无法指定遍历顺序，也无法获取数组的索引。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] ns = &#123; <span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">25</span> &#125;;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> n : ns) &#123;</span><br><span class="line">            System.out.println(n);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="十三排序库arrays.sort">十三、排序库：Arrays.sort()</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] ns = &#123; <span class="number">28</span>, <span class="number">12</span>, <span class="number">89</span>, <span class="number">73</span>, <span class="number">65</span>, <span class="number">18</span>, <span class="number">96</span>, <span class="number">50</span>, <span class="number">8</span>, <span class="number">36</span> &#125;;</span><br><span class="line">        Arrays.sort(ns);</span><br><span class="line">        System.out.println(Arrays.toString(ns));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="十四多维数组">十四、多维数组：</h3>
<h4 id="二维数组">1) 二维数组</h4>
<p>二维数组的每个数组元素的长度并不要求相同</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] ns = &#123;</span><br><span class="line">            &#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span> &#125;,</span><br><span class="line">            &#123; <span class="number">5</span>, <span class="number">6</span> &#125;,</span><br><span class="line">            &#123; <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span> &#125;</span><br><span class="line">		&#125;;</span><br><span class="line">        System.out.println(ns.length); <span class="comment">// 3</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>打印多维数组可以使用<code>Arrays.deepToString()</code></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] ns = &#123;</span><br><span class="line">            &#123; <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span> &#125;,</span><br><span class="line">            &#123; <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span> &#125;,</span><br><span class="line">            &#123; <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span> &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        System.out.println(Arrays.deepToString(ns));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="十五命令行参数">十五、命令行参数：</h3>
<p>命令行参数类型是<code>String[]</code>数组； 命令行参数由JVM接收用户输入并传给<code>main</code>方法；如何解析命令行参数需要由程序自己实现。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (String arg : args) &#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="string">&quot;-version&quot;</span>.equals(arg)) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;v 1.0&quot;</span>);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>java系列笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>《UniFormer:Unifying Convolution and Self-attention for Visual Recognition》</title>
    <url>/2022/01/27/7d2ace115a28/</url>
    <content><![CDATA[<h4 id="论文名称uniformer-unifying-convolution-and-self-attention-for-visual-recognition">论文名称：《UniFormer: Unifying Convolution and Self-attention for Visual Recognition》</h4>
<h4 id="论文地址-httpsarxiv.orgpdf2201.09450.pdf">论文地址： https://arxiv.org/pdf/2201.09450.pdf</h4>
<h2 id="关键词">1、关键词：</h2>
<p>​ Visual Recognition、CNN、SelfAttention、Transformer</p>
<h2 id="领域背景visual-recognition">2、领域背景—Visual Recognition：</h2>
<p>​ 表征学习一直是视觉识别领域的比较基本的研究。主要在面临向图像以及视频数据的时候，会存在两个问题：</p>
<ul>
<li>1、局部区域（空间、时间、时空）中的视觉内容往往是相似的，也就意味着局部冗余会比较大，这会导致不必要的计算量</li>
<li>2、全局的依赖关系比较复杂，在不同区域的目标物体之间都会存在一些动态的关系。</li>
</ul>
<h2 id="先前工作描述与比较">3、先前工作描述与比较：</h2>
<p>​ 基于领域背景中的两个主要问题，主流的解决方案就是CNN和ViT，但是它们都只针对上述问题中的某一个做出了解决，而忽略了另一个。如下所示：</p>
<ul>
<li><p>CNN能够通过小范围的卷积，降低局部冗余，减小计算量，但在捕获全局依赖中很有限制。</p></li>
<li><p>ViT能够通过Self-Attention很有效的捕获长距离的依赖，但是盲目的去计算所有tokens之间的相似关系，会带来很大的计算冗余。其在浅层网络上很难有效的去编码局部的特征。</p>
<ul>
<li>本文的作者进行了一个实验：如下图所示，显示的是ViT网络的第三层的Attention图，我们发现虽然Attention机制计算了全局的token之间的关系，但最终在锚点（绿色方框）学习到的有效信息均来源于其很小的一个邻域范围（红色填充方框）。所以,ViT花费了非常大的计算复杂度，去编码了一个局部的视觉表示特征。</li>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220129104342853.png" /></li>
</ul></li>
</ul>
<h2 id="主要设计思想">4、主要设计思想：</h2>
<p>​ 基于上述的工作描述，作者提出了UniFormer，将3D卷积和时空自注意力机制结合在一个简洁的<a href="https://so.csdn.net/so/search?q=transformer&amp;spm=1001.2101.3001.7020">transformer</a>结构中，能够同时处理局部冗余和全局依赖，其主要包括三个模块：</p>
<ul>
<li>Dynamic Position Embedding( DPE )</li>
<li>Multi-Head Relation Aggregator ( MHRA ) <strong>【和CNN与ViT的主要不同所在】</strong></li>
<li>Feed-Forward Network ( FFN )</li>
</ul>
<p>UniFormer与其他transformer的区别主要在于MHRA模块：</p>
<ul>
<li><p>在浅层，aggregator利用一个小的learnable matrix学习局部的token之间的相似性关系，通过聚合小的3D邻域的token信息极大地减少计算量。在深层，aggregator学习全局token之间的相似性关系，可以灵活的建立远距离图像区域或视频帧的token之间的长程依赖关系。</p></li>
<li><p>最后，通过以分层方式逐步堆叠局部和全局 UniFormer 块，我们可以灵活地整合它们的协作能力来促进Representation Learning。 最后，我们为视觉识别提供了一个通用且强大的主干，并通过简单而精细的适应成功地解决了各种下游视觉任务。</p></li>
</ul>
<h2 id="具体方法与网络架构">5、具体方法与网络架构：</h2>
<h3 id="uniformer-block">1) UniFormer Block</h3>
<p>​ 下面图片就是UniFormer Block的整体架构，其中在标注维度的地方，所有标红的字符都是仅对于视频输入有效，代表了输入视频的帧数，如果输入是个图像，那么这些标红的值应该都 = 1.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220127163758510.png" /></p>
<ul>
<li><strong>概述</strong>：Uniformer Block 的整体架构如上所示，分割成了几个阶段，每个阶段中由三个核心的模块重复堆叠L次组成，下面就是单词堆叠中，所有的模块的大致介绍：
<ul>
<li>Dynamic Position Embedding( DPE )</li>
<li>Multi-Head Relation Aggregator ( MHRA )</li>
<li>Feed-Forward Network ( FFN )</li>
<li>我们首先引入 DPE 将位置信息动态集成到所有Tokens（等式1）。它支持任意输入分辨率，并充分利用Tokens的顺序以获得更好的视觉识别效果。 然后，我们使用 MHRA ，其利用每个Token的上下文token，通过关系学习的方式，来增强每个Token（等式 2）。 通过在浅层和深层灵活设计Token的相似性，我们的 MHRA 可以巧妙地统一卷积和自注意力机制，以减少局部冗余并学习全局依赖性。 最后，我们像传统的 ViTs 一样添加 FFN，它由两个线性层和一个非线性函数GELU组成（等式 3）。 通道数先扩大4倍再恢复，因此每个token会被单独增强.</li>
</ul></li>
<li><strong>输入</strong>：<span class="math inline">\(X_{in} \in R^{C \times T \times H \times W}\)</span>, T 为视频帧数，当输入为图像时，T = 1</li>
<li><strong>输出</strong>：<span class="math inline">\(Z\)</span>特征空间向量</li>
<li><strong>公式表达</strong>：
<ul>
<li><span class="math inline">\(X = DPE(X_{in}) + X_{in}\)</span></li>
<li><span class="math inline">\(Y = MHRA(Norm(X)) + X\)</span></li>
<li><span class="math inline">\(Z = FFN(Norm(Y)) + Y\)</span></li>
</ul></li>
</ul>
<h3 id="multi-head-relation-aggregator">2) Multi-Head Relation Aggregator</h3>
<ul>
<li><p><strong>概述</strong>：该模块可以巧妙地统一卷积和自注意力机制，以减少局部冗余并学习全局依赖性。MHRA使用multi-head机制来计算token间的关系，公式表达如下：</p></li>
<li><p><strong>公式表达</strong>：</p>
<ul>
<li><strong>MHRA模块的第n个head</strong>： <span class="math inline">\(R_n(X) = A_nV_n(X)\)</span>，输入向量<span class="math inline">\(X \in R^{C \times T \times H \times W}\)</span>，我们会将其首先Reshape成一个token的序列<span class="math inline">\(X \in R^{L \times C}\)</span>, 其中 <span class="math inline">\(L = T \times H \times W\)</span></li>
<li><strong>总体</strong>： <span class="math inline">\(MHRA(X) = Concat(R_1(X);R_2(X);...;R_N(X))U\)</span>，<span class="math inline">\(U \in R^{C \times C}\)</span>是一个可学习矩阵，用于聚合N个Head的内容</li>
</ul></li>
<li><p><strong>单个Head内部变换细节介绍</strong>：</p>
<ul>
<li>每个RA包含<strong>token context encoding </strong>和 <strong>token affinity learning</strong>两步</li>
<li>1、我们应用<strong>线性变换</strong>将<strong>原始标记</strong>编码为<strong>上下文标记</strong>：<span class="math inline">\(V_n(X) \in R^{L \times \frac{C}{N}}\)</span></li>
<li>2、An是 <strong>token相似度</strong>，RA可以在其指导下来概括上下文信息，进行总结</li>
</ul></li>
<li><p><strong>浅层网络中的Local MHRA</strong>:</p>
<ul>
<li><p><strong>概述：</strong>在先前的比较中，我们发现：在浅层网络计算全局Self-Attention最终学到的也只是局部的信息，所以我们在浅层网络中，现在只在局部区域内来进行计算。因此，在浅层网络中，我们将Local Affinity作为一个<strong>可学习参数的矩阵</strong>。</p></li>
<li><p><strong>具体而言：</strong>给定anchor token <span class="math inline">\(X_i\)</span> , 局部RA学习该token和一个小邻域<span class="math inline">\(\Omega_i^{t \times h \times w}\)</span>内的其他token的相似性。<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220129110111062.png" alt="image-20220129110111062" /></p>
<p><span class="math inline">\(a_n \in R^{t \times h \times w}\)</span> , <span class="math inline">\(X_j\)</span> 代表邻域内的任一一个token，<span class="math inline">\(i-j\)</span> 表示token i和j的相对位置关系</p></li>
<li><p><strong>注意</strong>：因为tokens的感受野很小，相邻token之间的视觉内容在浅层中会发生微妙的变化。在这种情况下，没有必要去让token相似度动态的进行变化，因此我们使用一个可学习的参数矩阵来描述局部的token相似度，token的相似度仅取决于两个token之间的相对位置关系。</p></li>
<li><p><strong>与CNN的比较</strong>：其可以视为是 PWConv-DWConv-PWConv的组合，但是该论文中的Uniformer块是基于一个通用的Transformer的格式进行设计的，也就是说除了MHRA之外，还带有DPE和FFN，这一简单的继承能够非常有效的加强token的表示能力。</p></li>
</ul></li>
<li><p><strong>深层网络中的Global MHRA</strong>:</p>
<ul>
<li><p><strong>概述</strong>：在深层网络中，在更广阔的空间中获取长距离依赖很重要。因此，我们通过在全局条件下比较内容来进行token相似度的计算。</p></li>
<li><p><strong>具体而言</strong>：给定anchor token <span class="math inline">\(X_i\)</span> , 局部RA学习该token和所有其他token 的相似性</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220129111415083.png" /></p>
<p><span class="math inline">\(X_j\)</span> 代表全局范围<span class="math inline">\(size = T \times H \times W\)</span>内的任意一个token，<span class="math inline">\(Q_n 和 K_n\)</span>是两个不同的线性变换。</p></li>
<li><p><strong>与Transformer的比较</strong>：</p>
<p>可以被实例化为一个时空self-attention，<span class="math inline">\(Q_n 、K_n、V_n\)</span>代表Query、Key、Value.但是，UniformerBlock又和传统的ViT块不同：</p>
<ul>
<li>1、以往的video tranformer在视频域中分割开了时间和空间的attention，为了减少在计算token相似度比较时候的计算量。但是这会不可避免地恶化token之间的时空关系。相比之下，我们的模块联合编码时空token关系以生成更具辨别力的视频表示以进行识别。因为我们在浅层的时候大大的节省了token比较的计算量，所以整体模型上还是能到达一个计算量-准确度比较好的一个平衡。</li>
<li>2、其次，我们在 UniFormer 中采用动态位置嵌入 (DPE) 代替绝对位置嵌入。它是卷积风格的（见下节），可以克服排列不变性，对不同输入长度的视觉tokens友好</li>
</ul></li>
</ul></li>
</ul>
<h3 id="dynamic-position-embedding">3) Dynamic Position Embedding</h3>
<ul>
<li><p><strong>概述：</strong>先前绝大多数的位置编码都采用<strong>绝对或相对位置嵌入</strong>，然而绝对位置嵌入必须通过微调对各种输入大小进行插值，而相对位置嵌入由于自注意力机制的修改容易无法很好地工作。最近，有人提出了卷积位置编码，具体而言，卷积位置编码CPE，可以隐式地将位置信息通过卷积操作进行编码，这样可以让Transformer去处理任意的输入大小，并且提高识别性能。鉴于其即插即用地性质，我们将其拿过来作为我们的DPE模块：</p></li>
<li><p><span class="math inline">\(DPE(X_{in})= DWConv(X_in)\)</span> , DWConv 代表 depth-wise 卷积，zero padding</p></li>
<li><p><strong>原因</strong>：</p>
<ul>
<li><p>1、depthwise 卷积对任意的输入大小很友好（使用其时空版本对视频中的 3D 位置信息进行编码很简单）</p></li>
<li><p>2、很轻量化，能够较好的平衡计算量与准确性的平衡。</p></li>
<li><p>3、增加Zero padding，它可以通过逐步查询它们的邻居来帮助token了解它们的绝对位置</p>
<p>（Finally, we add extra zero paddings, since it can help tokens be aware of their absolute positions by querying their neighbors progressively 论文3.3最后一句话 ）</p></li>
</ul>
<!-- Zero Padding ？ 如何逐步查询令居进而帮助token了解绝对位置？ --></li>
</ul>
<h2 id="衍生框架-framework">6、衍生框架 FrameWork</h2>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220129115021079.png" /></p>
<h3 id="图像分类框架">1) 图像分类框架：</h3>
<ul>
<li>Stage1 和 Stage2 用的是 Local Uniformer Blocks
<ul>
<li>使用 PWConv-DWConv-PWConv 进行实例化</li>
</ul></li>
<li>Stage3 和 Stage4 用的是 Global Uniformer Blocks
<ul>
<li>使用 multi-head self-attention 进行实例化，heads = 64</li>
</ul></li>
<li>DPE 都实例化成 DWConv， spatial size = 3 x 3</li>
<li>FFN 的 Expand Ratio = 4</li>
<li>卷积 用 BN， self-attention 用 LN</li>
<li>特征降维：
<ul>
<li>Stage1前： $ 4  ， stride = 4 $</li>
<li>其他Stage前： $ 2  ， stride = 2 $</li>
</ul></li>
</ul>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220127163758510.png" /></p>
<h3 id="视频分类-密集预测-等其他框架详见论文主体">2） 视频分类 &amp;&amp; 密集预测 等其他框架详见论文主体</h3>
]]></content>
      <categories>
        <category>⓶ 论文阅读笔记</category>
        <category>CV相关论文</category>
      </categories>
      <tags>
        <tag>CNN</tag>
        <tag>Transformer</tag>
        <tag>Visual Recognition</tag>
      </tags>
  </entry>
  <entry>
    <title>《HandWritting Transformers》(更新中)</title>
    <url>/2022/01/26/8f68bd6cb4f4/</url>
    <content><![CDATA[<h4 id="论文名称handwriting-transformers">论文名称：《<strong>Handwriting Transformers</strong>》</h4>
<h4 id="论文地址-httpsarxiv.orgabs2104.03964">论文地址： https://arxiv.org/abs/2104.03964</h4>
<h2 id="关键词">1、关键词：</h2>
<p>​ 手写字体生成（英文）、GAN、Transformer</p>
<h2 id="领域背景手写字体生成">2、领域背景—手写字体生成：</h2>
<p>​ 自动的手写文字生成对于一些书写障碍的人十分重要。通常使用的方法是利用GAN来进行离线的手写文字图像生成。</p>
<h2 id="先前工作描述与比较">3、先前工作描述与比较：</h2>
<p>​ 两类生成方法： 基于笔画的在线生成方法（需要记录时序数据） 和 基于图像的离线生成方法。</p>
<ul>
<li><p>GANwriting ：该方法利用在少量信息中提取样式特征和预定义固定长度的文本内容来进行文本生成。</p></li>
<li><p>我们的方法：与GANwritting相似，我们的方法也是在少量的风格样例中去提取风格特征，但又与 GANwriting 不同，我们的方法具有生成任意长度的风格化文本的灵活性。 我们能够同时捕获全局和局部的书写风格。</p></li>
</ul>
<h2 id="主要设计思想">4、主要设计思想：</h2>
<p>两个主要改进的Motivation:</p>
<p>1、除了字/行级别的样式-内容纠缠之外，字符级别的样式和内容之间的纠缠有助于模仿特定字符的写作风格以及泛化到词汇外的内容。</p>
<p>2、为了生成准确的风格文本图像，需要模仿全局的（例如墨水宽度、倾斜度等）和局部的（例如字符风格、连字等）风格特征。</p>
<h2 id="具体方法与网络架构">5、具体方法与网络架构：</h2>
<p><strong>问题公式化描述：</strong></p>
<ul>
<li><span class="math inline">\(i \in W\)</span>, <span class="math inline">\(W\)</span>包含M个作者，<span class="math inline">\(i\)</span>代表某一个作者</li>
<li>一个手写文字图像集合 P</li>
<li>输入的文本内容<span class="math inline">\(A = \{a_j\}_{j=1}^Q\)</span>，视为一个Word String的集合</li>
<li>每个WordString 包含长度不定的字符，字符来自于字符集C</li>
<li>字符集C包含 字母表、标点、数字</li>
<li><span class="math inline">\(\hat X_i^t\)</span>代表依据新的文本内容t，生成的作者<span class="math inline">\(i\)</span>的新图像</li>
</ul>
<h3 id="整体架构overall-pipeline">1) 整体架构（Overall Pipeline）</h3>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220127103226508.png" /></p>
<ul>
<li><strong>概述</strong>：先利用CNN，将风格图像变换至高维特征空间，然后进入Transformer Encoder中，生成特征潜在向量Z，输入到Transformer Decoder中，与Query Words进行结合，解码输出F，再通过CNN Decoder，最终生成图像，然后进入到不同的判别器中，基于不同的角度，定义了4个损失函数，进行函数的优化。</li>
<li>Query Words进入到Transformer Decoder中前，需要进行词嵌入编码，对每个字符，定义了一个可学习的词嵌入向量，<span class="math inline">\(q_c \in R^{512}\)</span>，这样一种基于字符的表示，以及基于transformer的序列处理方式，帮助模型能够生成任意长度的手写单词，并且能够更好的泛化到词汇表外的数据。
<ul>
<li><span class="math inline">\(G_\theta\)</span>生成器，用于合成手写文本图像</li>
<li><span class="math inline">\(D_\Psi\)</span>判别器，用于确保生成图像的 手写风格的真实性（即确保看上去是手写图像）</li>
<li><span class="math inline">\(R_\phi\)</span>识别器，用于保持文本内容正确</li>
<li><span class="math inline">\(S_\eta\)</span>风格分类器，用于确保迁移的手写风格正确性（即确保生成的风格与Style Example一致）</li>
</ul></li>
<li><strong>输入</strong>： <span class="math inline">\(a_j \in A\)</span> &amp;&amp; <span class="math inline">\(X_i^s\)</span>文本 + 风格图像示例</li>
<li><strong>输出</strong>： <span class="math inline">\(\hat X_i^t\)</span>新生成的风格化手写字符图像（文本内容为 t ）</li>
</ul>
<h3 id="encoder-network-tepsilon">2) Encoder Network <span class="math inline">\(T\epsilon\)</span></h3>
<ul>
<li><strong>概述</strong>：将风格手写示例图编码至风格特征空间向量</li>
<li><strong>输入</strong>：<span class="math inline">\(X_i^s\)</span>风格手写示例图</li>
<li><strong>输出</strong>：<span class="math inline">\(Z \in R^{N \times d}\)</span>风格特征空间向量</li>
<li><strong>网络结构</strong>：
<ul>
<li><strong>Part1 : CNN Encoder</strong>
<ul>
<li>采用<strong>ResNet18</strong>: 为每个style image生成低分辨率的激活图<span class="math inline">\(h_{ij} \in R^{h \times w \times d}\)</span></li>
<li>将<span class="math inline">\(h_{ij}\)</span>在空间维度上展平，得到一个Sequence, <span class="math inline">\(n \times d\)</span>，其中<span class="math inline">\(n = h \times w\)</span>, 这个序列可以被视为风格图像某区域的描述子</li>
<li>同时，因为总共我们会提供P张风格示例图像，将所有风格示例图像中提取出的Sequence进行拼接，得到一个Tensor，<span class="math inline">\(H_i \in R^{N \times d}\)</span>其中，<span class="math inline">\(N = n \times P\)</span></li>
</ul></li>
<li><strong>Part2: Transformer-Based Encoder</strong>
<ul>
<li>L层，每一层都由multihead-self-attention 和 MLP模块组成。重复L遍，很标准的Transformer Encoder（论文中没有细讲有无Residual）</li>
<li>为保留提供的输入序列的未知信息，采用固定位置编码</li>
</ul></li>
</ul></li>
<li><strong>意义</strong>：对局部的和全局的手写风格图像特征建模，例如倾斜、歪斜、字符形状、连字、墨水宽度等</li>
</ul>
<h3 id="decoder-network-t_d">3) Decoder Network <span class="math inline">\(T_d\)</span></h3>
<ul>
<li><strong>概述</strong>：结合输入的字符序列，生成风格化的手写字符图像</li>
<li><strong>输入</strong>：<span class="math inline">\(Z \in R^{N \times d}\)</span>风格特征空间向量 + <span class="math inline">\(A\)</span>输入的字符序列</li>
<li><strong>输出</strong>：<span class="math inline">\(\hat X_i^t\)</span>新生成的风格化手写字符图像（文本内容为 t ）</li>
<li><strong>网络结构</strong>：
<ul>
<li><strong>Part1: Query Words 处理</strong>
<ul>
<li>将Query Words 编码成 Query Embedding，其为可学习的位置编码参数，加入到之后Transformer-Based Decoder中。简单来讲，这一步的作用就是要让每一个Query Embedding都在提供的样式图像中，能够去查找感兴趣的区域，从而进一步推断所有查询字符的风格属性。</li>
<li>如下图所示，t对应的位置编码，需要去学习的就是在我们提供的样例风格图像中，寻找字符t相关的位置（感兴趣的区域）。</li>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220127112528447.png" /></li>
</ul></li>
<li><strong>Part2: Transformer Based Decoder:</strong>
<ul>
<li>注意1：和self-attention不同，其key &amp; value 来源于Encoder的输出， query向量来源于Decoder自己的层。</li>
<li>注意2：在所有的Transformer Based Decoder中，我们是并行的去处理每一个Query Embeddings的，每个Query Embedding就代表一个字符。</li>
<li>将上一步的Query Embeddings 经过连续的 Transformer Based Decoder以后，会累积一些风格信息，产生一个输出 <span class="math inline">\(F_{a_j} \in R^{m_j \times d}\)</span>. <span class="math inline">\(m_j\)</span>是某个单词的字符数</li>
<li>然后，我们会将<span class="math inline">\(N(0,1)\)</span>的噪音，加入到 <span class="math inline">\(F_{a_j}\)</span>中，来模拟自然情况下的外部干扰变化。</li>
<li><strong>举例而言</strong>：
<ul>
<li>一个m个字符的单词</li>
<li>我们会将m个Embeddings Vectors连接起来，然后再通过一个FC层，得到一个<span class="math inline">\(m_j \times 8192\)</span>的矩阵，我们将其Reshape成 <span class="math inline">\(512 \times 4 \times 4m_j\)</span>,然后输入到CNN Decoder中。</li>
</ul></li>
</ul></li>
<li><strong>Part3: CNN Decoder</strong>:
<ul>
<li>4 个残差模块 + tanh激活函数</li>
<li>获得最终的输出图像</li>
</ul></li>
</ul></li>
</ul>
<h3 id="training-loss-objectives">4) Training &amp; Loss Objectives</h3>
<ul>
<li><p><strong>概述</strong>：总共由4个Loss函数组成，每个Loss负责不同的部分，在网络结构概述中已经有所提及。</p>
<ul>
<li>1、<span class="math inline">\(D_\Psi\)</span>判别器，用于确保生成图像的 手写风格的真实性（即确保看上去是手写图像）</li>
</ul>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220127115520938.png" /></p>
<ul>
<li><p>2、<span class="math inline">\(R_\phi\)</span>手写文本识别器，用于保持文本内容正确，使用CRNN搭建，使用CTC Loss函数，比较query words和识别输出的差别。识别器 Rφ 仅针对真实的、标记的、手写样本进行优化训练，但它用于鼓励 Gθ 生成具有准确内容的可读文本。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220127115740239.png" /></p></li>
<li><p>3、<span class="math inline">\(S_\eta\)</span>风格分类器，用于确保迁移的手写风格正确性（即确保生成的风格与Style Example一致） ，其能够预测一个给定的手写图像的作者。使用Cross-Entropy来定义Loss函数：其只在真实的样例上利用如下损失函数进行训练：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220127115916996.png" /></p></li>
<li><p>4、利用Cycle Loss 来确保编码的style features由循环一致性。这个损失函数能够让decoder最大程度上在解码阶段保留风格信息，使得我们能够从生成的图像中重建出最开始的风格特征序列。给定生成的图像 <span class="math inline">\(\hat X_i^t\)</span>，我们使用 编码器<span class="math inline">\(T\epsilon\)</span>来重建风格特征向量<span class="math inline">\(\hat Z\)</span>。如下所示的循环损失<span class="math inline">\(L_c\)</span>用于最小化<span class="math inline">\(Z\)</span>和 <span class="math inline">\(\hat Z\)</span>之间的L1差距</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220127120112639.png" /></p>
<p>循环损失对解码器施加了正则化，以一致地模仿生成的样式文本图像中的写作风格。</p></li>
</ul></li>
<li><p>总的来说，我们以端到端的方式训练我们的 HWT 模型，损失目标如下</p></li>
</ul>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220127120324671.png" /></p>
<ul>
<li>同时，我们观察到平衡网络 Sη 和 Rφ 的梯度有助于使用我们的损失公式进行训练。根据 [3]，我们将 ∇Sη 和 ∇Rφ 归一化，使其具有与对抗性损失梯度相同的标准偏差 (σ)</li>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220127120433481.png" /></li>
<li><span class="math inline">\(\alpha\)</span>是一个超参数，在训练我们的模型的时候被固定为1</li>
</ul>
]]></content>
      <categories>
        <category>⓶ 论文阅读笔记</category>
        <category>CV相关论文</category>
      </categories>
      <tags>
        <tag>GAN</tag>
        <tag>Transformer</tag>
        <tag>HandWritting Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>Tmux常用命令</title>
    <url>/2022/01/26/dd1871cc8c9e/</url>
    <content><![CDATA[<h3 id="tmux常用命令">Tmux常用命令</h3>
<ul>
<li><p>创建并指定session名字 tmux new -s $session_name</p></li>
<li><p>删除session Ctrl+b :kill-session</p></li>
<li><p>临时退出session Ctrl+b d</p></li>
<li><p>列出session tmux ls</p></li>
<li><p>进入已存在的session tmux a -t $session_name</p></li>
<li><p>删除所有session Ctrl+b :kill-server</p></li>
<li><p>删除指定session tmux kill-session -t $session_name</p></li>
<li><p>开启光标</p></li>
</ul>
<p>​ ctrl + b 按下后松开 再立马按 [</p>
<ul>
<li>关闭光标</li>
</ul>
<p>​ ctrl + q 按下后松开 再立马按 [</p>
]]></content>
      <categories>
        <category>⓺ 工具使用类笔记</category>
      </categories>
      <tags>
        <tag>Tmux</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记14——ResNet详解及为什么能解决深度网络退化问题</title>
    <url>/2022/01/23/4be37de340a1/</url>
    <content><![CDATA[<h2 id="一深度网络退化背景">一、深度网络退化背景</h2>
<p>​ 对于卷积神经网络，深度是一个很重要的因素。深度卷积网络自然的整合了低中高不同层次的特征，特征的层次可以靠加深网络的层次来丰富。因此在构建卷积网络时，网络的深度越高，可抽取的特征层次就越丰富越抽象。所以一般我们会倾向于使用更深层次的网络结构，以便取得更高层次的特征。但是更深层的网络结构有的时候并不会带来更好的结果，层数一旦过多以后，就会导致表现明显下降，这就是深度网络的退化问题。</p>
<p>​ 深度网络的退化问题到底是由于什么导致的呢？过拟合？还是梯度消失？梯度爆炸？</p>
<p>​ 其实都不是。如下图论文中显示的所示，显然其在训练集上的误差也很大，就不可能是过拟合问题。而梯度消失或梯度爆炸，通过加入BN层，就能够通过规整数据分布来解决这个问题，所以应当也不是梯度消失或爆炸的问题。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/aHR0cHM6Ly9pbWdrci5jbi1iai51ZmlsZW9zLmNvbS82Y2M3OThjNC0wMTNmLTRkNjQtYmY5Yi0yZDg0YWExOTQzNzYucG5n.png" /></p>
<p>​ 那么根本原因是什么呢？</p>
<p>​ 在<strong>MobileNet V2</strong>的论文中提到，由于非线性激活函数Relu的存在，每次输入到输出的过程都几乎是不可逆的，这也造成了许多<strong>不可逆的信息损失</strong>。我们试想一下，一个特征的一些有用的信息损失了，那他的表现还能做到持平吗？显然不可能做到持平。随着网络层数的加深，造成了许多不可逆的信息损失，最终导致了深度网络的退化问题。</p>
<h2 id="二resnet提出初衷与详解">二、ResNet提出初衷与详解</h2>
<p>​ 我们选择加深网络的层数，是希望深层的网络的表现能比浅层好，或者是<strong>希望它的表现至少和浅层网络持平（相当于直接复制浅层网络的特征）</strong>，可实际的结果却让我们大吃一惊（深度网络退化），这是为什么呢？</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/aHR0cHM6Ly9pbWdrci5jbi1iai51ZmlsZW9zLmNvbS81OGU1NDU3Yy1lZWEwLTRmMjctOGVlMS04ZDJhMTk4YmJkOTcucG5n.png" /></p>
<p>​ 如图所示，这是一个直观的例子，我们把右边的网络理解为左边浅层网络加深了三层（框起来的部分），假如我们希望右边的深层网络与左边的浅层网络持平，即是希望框起来的三层跟没加一样，也就是加的三层的输入等于输出。我们假设这三层的输入为x，输出为H(x)，那么深层网络与浅层网络表现持平的直观理解即是H(x)=x，这种让输出等于输入的方式，就是ResNet论文中提到的<strong>恒等映射（identity mapping)</strong>。</p>
<p>​ 所以<strong>ResNet的初衷，就是让网络拥有这种恒等映射的能力，能够在加深网络的时候，至少能保证深层网络的表现至少和浅层网络持平</strong>。</p>
<p>​ 所以，现在我们知道，<strong>如果想要让深度神经网络不退化，根本的原因就是如何去做到恒等映射</strong>。然而现有的神经网络很难拟合潜在的恒等映射函数，H(x) = x，因为神经网络内部总会做一些参数的调整。但我们如果把恒等映射作为网络的一部分，将网络设计为H(x) = F(x) + x的形式，即如残差结构中所示那样，网络的输出是由x 和 F(x) 相加得到的，那么就可以把问题转化为 让中间多出来的那三层，去学习一个残差函数F(x) = H(x) - x。只要学习到的残差函数，能够使得F(x) = 0，那么就构成了一个恒等映射。最终网络的结果就不会比失去这几层要差。<strong>并且，让网络去拟合一个残差比拟合一个恒等映射容易得多（原因见后）</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/aHR0cHM6Ly9pbWdrci5jbi1iai51ZmlsZW9zLmNvbS9mNGI5ZjRjYi04NWE4LTRmNjQtYjc0Ny1lMzU0ZDdjNmM2YmUucG5n.png" /></p>
<p>​ ResNet中，<strong>shortcut connection</strong>，<strong>通过跳接在激活函数前，将上一层（或几层）的输出与本层输出相加，将求和的结果输入到激活函数作为本层的输出</strong></p>
<p>​</p>
<h2 id="三为什么resnet能解决深度网络退化问题">三、为什么ResNet能解决深度网络退化问题？</h2>
<p>1、加了残差结构后就是给了输入x多一个选择，在神经网络学习到这层的参数是冗余的时候它可以选择直接走这条“跳接”曲线，跳过这个冗余层，而不需要再去拟合参数使得输出H(x)等于x。</p>
<p>2、因为学习残差的计算量比学习恒等映射小。假设普通网络为A，残差网络为B，输入为2，输出为2（输入和输出一样是为了模拟冗余层需要恒等映射的情况），那么普通网络就是A (2) = 2，而残差网络就是B ( 2 ) = F ( 2 ) + 2 = 2，显然残差网络中的F ( 2 ) = 0 。我们知道网络中权重一般会初始化成0附近的数，那么我们就很容易理解，为什么让F(2)拟合0会比A (2) = 2 容易了</p>
<p>3、我们知道ReLU能够将负数激活为0，而正数输入等于输出。这相当于过滤了负数的线性变化，让F(x)=0变得更加容易。</p>
<p>4、我们知道残差网络可以表示成H ( x ) = F ( x ) + x ，这就说明了在求输出H ( x ) 对输入x 的倒数（梯度），也就是在反向传播的时候，H ′ ( x ) = F ′ ( x ) + 1，残差结构的这个常数1也能保证在求梯度的时候梯度不会消失。</p>
<h2 id="四一些细节问题">四、一些细节问题：</h2>
<p>​ 在ResNet中，残差连接的相加，指的是逐元素相加，在ReSNet的网络示意图中，有的Skip-Connection是实线，有的是虚线，<strong>虚线的代表这些模块前后的维度不一致，因为去掉残差结构的Plain网络还是和VGG一样，也就是每隔n层进行下采样但深度翻倍（VGG通过池化层下采样，ResNet通过卷积）</strong>：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/aHR0cHM6Ly9pbWdrci5jbi1iai51ZmlsZW9zLmNvbS81YjZhMTNiZi00ZTU1LTRlMzYtOWY1NC05YzAzYzhkMmVkY2EucG5n.png" /></p>
<ul>
<li><p>空间上不一致时，需要给输入的X做一个线性的映射：调整一下H*W维度</p></li>
<li><p>深度上不一致时，有两种解决方法，一种是在跳接过程中加一个1×1的卷积层进行升维，另一种则是直接补零（先做下采样）。</p></li>
<li><p>针对比较深的神经网络，作者也考虑到计算量，会先用1×1的卷积将输入的256维降到64维，然后通过1×1恢复。这样做的目的是减少参数量和计算量。</p></li>
</ul>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/aHR0cHM6Ly9pbWdrci5jbi1iai51ZmlsZW9zLmNvbS85M2RiMDgzYi05NTk3LTRjZmUtODJmZC04NzRlNTI2NjViNmIucG5n.png" /></p>
<p>引用：https://blog.csdn.net/cristiano20/article/details/104309948</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>ResNet</tag>
        <tag>Degradation</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记13——DropOut详解及为什么能够防止过拟合</title>
    <url>/2022/01/21/788645531548/</url>
    <content><![CDATA[<h2 id="一dropout是什么">一、DropOut是什么？</h2>
<p>​ 过拟合是Deep Neural Networks(DNN)网络存在的问题之一。过拟合的特点是模型对训练数据的拟合非常好，但对测试数据的拟合却非常差，具体表现为loss和在训练集上的错误率非常低，而在验证集或测试集上却都要高很多。针对解决过拟合问题设计出来的方法很多，dropout就是其中一种最简单，也是最有效的方法。</p>
<p>​ 在训练DNN网络的过程中，对于每一个神经元，以p的概率被随机的drop out，也就是将其值置零。这样，在该轮前传和反传的过程中，该神经元将失去作用，相当于不存在，如下图所示。DropOut整体来说，是在训练过程中以一定的概率的使神经元失活，即输出为0，以提高模型的泛化能力，减少过拟合。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/dropout.jpeg" /></p>
<h2 id="二dropout阶段在训练阶段和测试阶段的区别">二、DropOut阶段在训练阶段和测试阶段的区别：</h2>
<h3 id="训练阶段">1、训练阶段：</h3>
<p>​ 在前向传播时，假设有这一层n个神经元，则我们可以假设每个神经元的概率都是0~1(可以通过python得到随机的值)，然后小于p的就失活，即不参与训练。</p>
<p>​ 在反向传播时，也只对参与训练的神经元进行参数更新。</p>
<p>​ 每次训练的时候，又是n个神经元，重新进行dropout</p>
<p>​ <strong>Dropout 在训练时采用，是为了减少神经元对部分上层神经元的依赖，类似将多个不同网络结构的模型集成起来，减少过拟合的风险。</strong></p>
<h3 id="测试阶段">2、测试阶段：</h3>
<p>​ 在测试时，应该用整个训练好的模型，不需要进行dropout。</p>
<p>​ 参与学习的节点和那些被隐藏的节点需要以一定的概率p加权求和，综合计算得到网络的输出。</p>
<p>​ 即预测的时候，每一个单元的参数要预乘以p。为什么要预乘以p呢？</p>
<p>​ 因为我们训练的时候会随机的丢弃一些神经元，但是预测的时候就没办法随机丢弃了。<strong>如果丢弃一些神经元，这会带来结果不稳定的问题，也就是给定一个测试数据，有时候输出a有时候输出b，结果不稳定，这是实际系统不能接受的</strong>，用户可能认为模型预测不准。那么<strong>一种”补偿“的方案就是每个神经元的权重都乘以一个p，这样在“总体上”使得测试数据和训练数据是大致一样的</strong>。</p>
<p>​ <strong>比如一个神经元的输出是x，那么在训练的时候它有p的概率参与训练，(1-p)的概率丢弃，那么它输出的期望是<span class="math inline">\(p \times x+(1-p) \times 0 = p \times x\)</span>。因此测试的时候把这个神经元的权重乘以p可以得到同样的期望。</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220121204115930.png" /></p>
<h2 id="三dropout如何防止过拟合">三、DropOut如何防止过拟合？</h2>
<p><strong>（1）数据层面</strong></p>
<p>​ 对于每一个dropout后的网络，进行训练时，相当于做了Data Augmentation。比如，对于某一层，dropout一些单元后，形成的结果是(1.5，0，2.5，0，1，2，0)，其中0是被drop的单元，那么总能找到一个样本，使得结果也是如此。这样每一次dropout其实都相当于增加了样本。</p>
<p><strong>（2）模型层面</strong></p>
<ul>
<li><p><strong>在较大程度上减小了网络的大小：</strong>在这个“残缺”的网络中，让神经网络学习数据中的局部特征（即部分分布式特征），但这些特征也足以进行输出正确的结果。</p></li>
<li><p><strong>取平均的作用：</strong> 如果正常的模型（没有dropout），我们用相同的训练数据去训练5个不同的神经网络，一般会得到5个不同的结果，此时我们可以采用 “5个结果取均值”或者“多数取胜的投票策略”去决定最终结果。（例如 3个网络判断结果为数字9,那么很有可能真正的结果就是数字9，其它两个网络给出了错误结果）。<strong>这种“综合起来取平均”的策略通常可以有效防止过拟合问题。因为不同的网络可能产生不同的过拟合，取平均则有可能让一些“相反的”拟合互相抵消。每次训练随机dropout掉不同的隐藏神经元，网络结构已经不同，这就类似在训练不同的网络，整个dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。</strong></p></li>
<li><p><strong>减少神经元之间共适应关系：</strong> 因为dropout导致两个神经元不一定每次都在一个网络中出现，这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况， 迫使网络去学习更加鲁棒的特征。换句话说，假如神经网络是在做出某种预测，<strong>它不应该对一些特定的线索片段太过敏感</strong>，即使丢失特定的线索，它也应该可以从众多其它线索中学习一些共同的模式（鲁棒性）。</p></li>
</ul>
<p>引用：</p>
<p>https://zhuanlan.zhihu.com/p/175142160</p>
<p>https://www.zhihu.com/question/402485242/answer/1553947864</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>OverFitting</tag>
        <tag>DropOut</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记12——BatchNorm详解及为什么能防止过拟合</title>
    <url>/2022/01/21/22d362e1f563/</url>
    <content><![CDATA[<h2 id="一详解batchnorm原理">一、详解BatchNorm原理：</h2>
<p>​ BatchNorm是一种能够加速深度神经网络收敛，避免过拟合的方法，那么为什么呢？首先我们需要探讨一下这个问题，为什么深度神经网络<strong>随着网络深度加深，训练起来越困难，收敛越来越慢？</strong></p>
<p>在回答这个问题前需要首先了解两个概念：</p>
<p>​ <strong>1、独立同分布（IID）</strong>：即假设训练数据和测试数据是满足相同分布的。它是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障</p>
<p>​ <strong>2、Covariate shift</strong>：<strong>如果ML系统实例集合&lt;X,Y&gt;中的输入值X的分布老是变，这不符合IID假设</strong>，网络模型很难<strong>稳定的学规律</strong>。</p>
<p>​ 所以，之所以深度神经网络随着网络深度加深，训练越来越困难是因为，对于深度学习这种包含很多隐层的网络结构，在训练过程中，因为各层参数不停在变化，所以每个隐层都会面临covariate shift的问题，也就是<strong>在训练过程中，隐层的输入分布老是变来变去，这就是所谓的“Internal Covariate Shift（ICS）”，Internal指的是深层网络的隐层，是发生在网络内部的事情，而不是covariate shift问题只发生在输入层</strong></p>
<p>​ BatchNorm的基本思想就是能不能<strong>让每个隐层节点的激活输入分布固定下来呢</strong>？这样就避免了“Internal Covariate Shift”问题了。</p>
<p>​ 所以BN实质上就是在深度神经网络训练过程中使得每一层神经网络的输入保持相同分布的一种方法。</p>
<p>​ BN的基本思想其实相当直观：因为深层神经网络在做非线性变换前的<strong>激活输入值随着网络深度加深或者在训练过程中，其分布逐渐发生偏移或者变动，之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近</strong>（对于Sigmoid函数来说，意味着激活输入值WU+B是大的负值或正值），所以这<strong>导致反向传播时低层神经网络的梯度消失</strong>，这是训练深层神经网络收敛越来越慢的<strong>本质原因</strong>，<strong>而BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布</strong>，其实就是把越来越偏的分布强制拉回比较标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，意思是<strong>这样让梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。</strong></p>
<p>​ <strong>对于每个隐层神经元，把逐渐向非线性函数映射后向取值区间极限饱和区靠拢的输入分布强制拉回到均值为0方差为1的比较标准的正态分布，使得非线性变换函数的输入值落入对输入比较敏感的区域，以此避免梯度消失问题。</strong>因为梯度一直都能保持比较大的状态，所以很明显对神经网络的参数调整效率比较高，就是变动大，就是说向损失函数最优值迈动的步子大，也就是说收敛地快。BN说到底就是这么个机制，方法很简单，道理很深刻。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/aHR0cDovL3FsLm1hZ2ljLXNldmVuLnRvcC91cGxvYWQvMjAyMC8zL2ltYWdlLTVkMjU4MDQxNGI0YTRkNjhiODEzMDMxMDZlMzY5YzNiLnBuZw.png" style="zoom: 67%;" /></p>
<h2 id="二batchnorm在训练阶段和测试阶段的做法与意义">二、BatchNorm在训练阶段和测试阶段的做法与意义：</h2>
<h3 id="训练阶段">1、训练阶段：</h3>
<p>​ 首先计算均值和方差（每次训练给一个批量，计算批量的均值方差），然后归一化，然后缩放和平移，完事！</p>
<h3 id="测试阶段">2、测试阶段：</h3>
<p>​ 每次只输入一张图片，这怎么计算批量的均值和方差，于是，应该是这样子，在训练的时候实现计算好mean、 var，测试的时候直接拿来用就可以了，不用计算均值和方差。</p>
<ul>
<li><p>用训练集来估计总体均值 μ 和总体标准差 σ 。</p></li>
<li><p>较为简单的做法就是把每个mini-batch的均值和方差都保存下来，然后训练完了求均值的均值，方差的均值即可。</p></li>
<li><p>在测试阶段应用BatchNorm的含义，应该就是要让测试集的测试精度与整个训练网络保持一致。</p></li>
</ul>
<h2 id="三batchnorm的两个参数gamma和beta有什么作用">三、BatchNorm的两个参数<span class="math inline">\({\gamma}\)</span>和<span class="math inline">\(\beta\)</span>有什么作用？</h2>
<p><img src="https://www.zhihu.com/equation?tex=y%3D\frac%7Bx-\mathrm%7BE%7D%5Bx%5D%7D%7B\sqrt%7B\operatorname%7BVar%7D%5Bx%5D%2B\epsilon%7D%7D+*+\gamma%2B\beta+" /></p>
<h3 id="如果只做归一化为什么是学不到任何东西的">1、如果只做归一化，为什么是学不到任何东西的？</h3>
<p>​ 如果在每一层之后都归一化成0-1的高斯分布（减均值除方差）那么数据的分布一直都是高斯分布，数据分布都是固定的了，这样即使加更多层就没有意义了，<strong>深度网络就是想学习数据的分布发现规律性，BN就是不让学习的数据分布偏离太远</strong></p>
<h3 id="两个参数的作用">2、两个参数的作用</h3>
<p>​ 为了减小Internal Covariate Shift，对神经网络的每一层做归一化不就可以了，假设将每一层输出后的数据都归一化到0均值，1方差，满足正胎分布，但是，此时有一个问题，<strong>如果每一层的数据分布都是标准正态分布，导致其完全学习不到输入数据的特征，因为，费劲心思学习到的特征分布被归一化了，因此，直接对每一层做归一化显然是不合理的。</strong>但是如果稍作修改，加入可训练的参数做归一化，那就是BatchNorm 实现的了。</p>
<p>​ 接下来详细介绍一下这额外的两个参数，之前也说过如果直接做归一化不做其他处理，神经网络是学不到任何东西的，但是加入这两个参数后，事情就不一样了。先考虑特殊情况下，如果γ 和β 分别等于此batch的标准差和均值，那么<span class="math inline">\(y_i\)</span>就还原到归一化前的x了吗，也即是缩放平移到了归一化前的分布，相当于batch norm没有起作用，<span class="math inline">\(β\)</span>和γ 分别称之为 平移参数和缩放参数 。这样就<strong>保证了每一次数据经过归一化后还保留的有学习来的特征，同时又能完成归一化这个操作，加速训练</strong>。</p>
<p>引用：https://www.cnblogs.com/hoojjack/p/12350707.html</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>OverFitting</tag>
        <tag>Batch Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记11——Training Data、Validation Data、Testing Data含义及作用</title>
    <url>/2022/01/21/ff71970a89e2/</url>
    <content><![CDATA[<p>我们在进行一个机器学习的任务的时候，往往会将所有数据划分成三块——Training Data、Validation Data、Testing Data,它们各自在训练的过程中扮演何种角色呢？</p>
<h4 id="一trainvaltest的含义与作用">一、Train、Val、Test的含义与作用：</h4>
<p>顾名思义，三个数据集合它们的简单含义如下：</p>
<ul>
<li>训练集(train)：训练模型，用来拟合模型的数据集；</li>
<li>验证集(val)：评估模型，训练过程中提供相对于train的无偏估计的数据集，同时用来调整超参数和特征选择，实际参与训练</li>
<li>测试集(test)：最终模型训练好之后，用来提供相对于train+valid的无偏估计的数据集。</li>
</ul>
<p>​ 一般我们会将最开始划分的Training Set分割为Training Data和Validation Data两个集合，一般而言比例为9：1。我们使用划分后的Training Data进行训练，在每个Epoch结束后使用训练期间机器没有见到过的Validation进行验证，依据验证集得到的Loss值来进行模型好坏的衡量。</p>
<p>​ 话句话说，Validation Data　其实就是用来避免过拟合的，在训练过程中，我们通常用它来确定一些超参数（比如根据validation data上的accuracy来确定early stopping的epoch大小、根据validation data确定learning rate等等）。</p>
<p>​ 那为啥不直接在Testing data上做这些呢？因为如果在Testing data做这些，那么随着训练的进行，我们的网络实际上就是在一点一点地overfitting我们的Testing data，导致最后得到的Testing accuracy没有任何参考意义。因此，Training data的作用是计算梯度更新权重，Validation data在每个Epoch结束后进行验证，Testing data则给出一个accuracy以判断网络的好坏。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/20210202115236662.png" /></p>
<p><strong>如上所示的训练划分容易带来一些显而易见的问题：</strong></p>
<ul>
<li>如果样本数量太少，验证集和测试集更少，无法在统计学上代表数据</li>
<li>划分数据前时，进行不同的随机打乱则得到的模型性能差别可能很大，可能训练集中的数据都偏向于某一类，而验证集的数据偏向于另一类</li>
</ul>
<h4 id="二n-fold-cross-validation">二、N-Fold Cross Validation</h4>
<p>此时，就可以使用常见的叫做N-Fold Cross Validation，（K折交叉验证）：</p>
<p>​ 如下图所示,我们将Training Set分为N个集合(示例中为3个),其中N-1个集合用于训练,1个集合用于验证,然后每轮Epoch中,都执行N遍,每一遍都拿不同的集合用于训练与验证,然后计算一遍Loss值,最终选取平均Loss最小的那一组参数进行模型的更新.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114111918585.png" /></p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Training Set</tag>
        <tag>Validation Set</tag>
        <tag>Testing Set</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记10——L1、L2正则化以及为什么正则化能够防止过拟合</title>
    <url>/2022/01/21/d692eb11c4b5/</url>
    <content><![CDATA[<p>在训练数据不够多时，或者overtraining时，常常会导致overfitting（过拟合）。其直观的表现如下图所示，随着训练过程的进行，模型复杂度增加，在Training data上的error渐渐减小，但是在验证集上的error却反而渐渐增大——因为训练出来的网络过拟合了训练集，对训练集外的数据却不work。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/OhX9eFQ.jpg" /></p>
<p>​ 在ML2021课程系列笔记2中，提及了一些防止过拟合的内容，本篇用于详细解释其中正则化的部分：</p>
<h3 id="一什么是l1l2正则化">一、什么是L1、L2正则化？</h3>
<h4 id="l1-正则化">L1 正则化：</h4>
<p>​ 简单而言，L1正则化就是在Loss函数后面增加一个正则化项，L1正则化的公式如下,</p>
<p>​ <span class="math inline">\(C_0\)</span>为原来的损失函数，即所有权重w的绝对值的和. n是训练集的样本大小，λ 是正则项系数，C为加了正则化后的损失函数</p>
<p>​ <span class="math inline">\(C = C_0 + \frac{\lambda}{n} \sum_{w}|w|\)</span></p>
<h4 id="l2-正则化">L2 正则化：</h4>
<p>​ 简单而言，L2正则化也是在Loss函数后面增加一个正则化项，L2正则化的公式如下,与上含义类似。</p>
<p>​ <span class="math inline">\(C = C_0 + \frac{\lambda}{2n} \sum_w w^2\)</span></p>
<h3 id="二l1l2正则化如何避免overfitting">二、L1、L2正则化如何避免OverFitting？</h3>
<h4 id="l1l2正则化能降低权重值w">1、L1、L2正则化能降低权重值w</h4>
<p>​ 我们以L2正则化项为例，进行解释，首先我们让C对偏置项b和对权重系数w进行求导，得到如下：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/mebEC90.jpg" /></p>
<p>​ 我们发现，C对b求导与正则化项无关，C对w求导得到得结果与正则化项有关。</p>
<p>​ 最终所反映到梯度下降优化参数上，就是如下图所示得情况：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/qM83geg.jpg" /></p>
<p>​ <strong>如果没有正则化项，那么更新得w前得系数应当为1，而现在由于因为η、λ、n都是正的，所以 1−ηλ/n小于1，它的效果是减小w，这也就是权重衰减（weight decay）的由来</strong>。</p>
<p>​ <strong>到此为止，我们发现L2正则化项，其能够使得减小w。（其实这一点比较直观的也能看出来，因为Loss函数中加入了一项<span class="math inline">\(w^2\)</span>的求和，也就是说如果权重值w过大，Loss函数值会上升，这就意味着这一个正则化项惩罚了权值矩阵使其不能取太大值。）</strong></p>
<p>​ 那么，关键问题是，<strong>为什么权重矩阵w小，能够防止过拟合呢？</strong></p>
<h4 id="较高的权重w往往意味着过拟合的函数">2、较高的权重w往往意味着过拟合的函数：</h4>
<p>​ 我们会发现：<strong>过拟合的时候，拟合函数的系数往往非常大，为什么？如下图所示，过拟合，就是拟合函数需要顾忌每一个点，最终形成的拟合函数波动很大。在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大。</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/RsR5cOK.png" /></p>
<p>​</p>
<p>​ 更进一步的解释：当权重系数很小的时候，容易出现像左图一样，高偏差拟合能力很差的情况，随着权重系数逐渐增大，就会像右侧的图进行发展。如果权重系数很大，往往意味着在某些很小的区间中，函数值的变化会非常的剧烈，导致一些高方差的结果，也就是函数对于训练数据过度拟合了。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220121122935964.png" /></p>
<p>​</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>OverFitting</tag>
        <tag>Regularization</tag>
      </tags>
  </entry>
  <entry>
    <title>《DG-Font Deformable Generative Networks for Unsupervised Font Generation》</title>
    <url>/2022/01/20/4c71dd4cca5d/</url>
    <content><![CDATA[<h4 id="论文名称dg-font-deformable-generative-networks-for-unsupervised-font-generationcvpr2021">论文名称：《DG-Font: Deformable Generative Networks for Unsupervised Font Generation》CVPR2021</h4>
<h4 id="论文地址-httpsopenaccess.thecvf.comcontentcvpr2021htmlxie_dg-font_deformable_generative_networks_for_unsupervised_font_generation_cvpr_2021_paper.html">论文地址： https://openaccess.thecvf.com/content/CVPR2021/html/Xie_DG-Font_Deformable_Generative_Networks_for_Unsupervised_Font_Generation_CVPR_2021_paper.html</h4>
<h2 id="关键词">1、关键词：</h2>
<p>​ Font-Generation、Deformable Convolution Skip Connection、Unsupervised Learning</p>
<h2 id="领域背景">2、领域背景：</h2>
<p>​ 字体生成是一个具有挑战的任务，现存的大部分方法都是通过<strong>有监督学习</strong>的方法进行字体的生成，他们需要大量的<strong>paired data</strong>（例如对应风格的字符图像），然而大量的这些数据需要花费非常昂贵的代价去进行收集。</p>
<p>​ 字体生成目标是自动的能够生成某种特定字体的字符，并且创造一个字体字符集。</p>
<p>​ 在传统的字符集的创造方式中，严重依赖于专家设计者，独立的去绘制每一个字体的图像，这对于一些基于语标的语言（比如中文、日文、韩文）很不友好。专家们需要有大量的工作量去进行设计，字体生成领域就是为了解决这样一个问题，使用神经网络去学习从一种风格到另一种风格的映射关系，从而生成特定语言的某种风格的一个字符集。</p>
<p>​ 与字体生成最相关的<strong>图像生成领域 （Image-To-Image Translation）</strong>，在通常的image-to-image的转换模型中通常将<strong>style</strong>定义为<strong>纹理和颜色</strong>，而字体的<strong>style</strong>往往是指<strong>字体的格式几何形状、笔画粗细、笔尖和连笔书写的模式等内容。（geometric transformation, stroke thickness, tips, and joined-up writing pattern）</strong>，故而没法直接应用到字体的生成上。同时在图像中往往采用的<strong>AdaIN-based</strong>方法（这种方法是在统计学上对齐特征来迁移图像的纹理和颜色特征）对于字体这种变换局部的特征模式的任务是不合适的。</p>
<p>​ 同时，对于image-to-image的生成任务而言，一系列的<strong>无监督</strong>的方法，都是使用对抗<strong>训练结合Consistent Contrains</strong>来进行的。如果使用image-to-image的方法直接应用到字体生成任务中的话，即使Consistent Constraints会帮助我们<strong>保留一个字符图片内容的结构</strong>，但是他们仍然会导致<strong>诸如模糊、丢失笔画</strong>等问题。</p>
<h2 id="先前工作描述与比较">3、先前工作描述与比较：</h2>
<h4 id="image-to-image-translation">1) Image-To-Image Translation</h4>
<p>​ <strong>image-to-image迁移的任务，就是学习一个从source domain到target domain的映射关系。其可以用于艺术风格迁移、语义分割、图像动画等等。</strong></p>
<ul>
<li>Pix2Pix是基于Conditional GAN的第一个做Image-to-Image的迁移任务。</li>
<li>Cycle-GAN通过Cycle Consistency 做到了无监督学习。</li>
</ul>
<p>​ <strong>这类工作无法直接应用至Font-Generation中，原因在Part2的领域背景最后已经做了简略的描述</strong></p>
<h4 id="font-generation">2) Font-Generation</h4>
<p>​ <strong>字体生成目标是自动的能够生成某种特定字体的字符，并且创造一个字体字符集。</strong></p>
<p>​ <strong>一般而言，从前的方法有两大条路径：</strong></p>
<ul>
<li><strong>基于paired data进行训练</strong>
<ul>
<li>EMD和SAVAE设计的神经网络，分割开了字体的内容和风格（content &amp; style）的表示，可以生成新的风格的字符内容。</li>
<li>zi2zi和rewrite这两篇论文，通过上千对匹配的字符，基于GAN进行了有监督学习。其之后，很多文章基于zi2zi进行了生成质量的改进。</li>
</ul></li>
<li><strong>基于辅助标识（例如笔画、部首等内容）</strong>
<ul>
<li><strong>这类方法往往都依赖于先验知识，并且只能应用到特定的书写系统中去。 并且这些方法仍旧需要数千匹配的数据以及辅助注释</strong></li>
<li>《Scfont: Structure-guided chinese font generation via deep stacked networks.》给每个笔画打上标签，来通过书写轨迹的合成，生成字的图像</li>
<li>DM-FONT 提出解纠缠策略来解纠缠复杂的字形结构，这有助于在富文本设计中捕获局部细节</li>
<li>CalliGAN 进一步将字符分解为组件，并提供包括笔画顺序在内的低级结构信息来指导生成过程。</li>
<li>《RD-GAN: few/zero-shot chinese character styletransfer via radical decomposition and rendering》 使用对字符偏旁部首的分解，来达到字体的生成</li>
<li>其他一些的方法也通过提取字符的骨架和笔画的算法来进行生成</li>
</ul></li>
</ul>
<p>​ <strong>相比之下，该篇论文提出的DG-FONT不需要其他的辅助标识，并且是无监督的形式进行的</strong></p>
<h4 id="deformable-convolution">3) Deformable Convolution</h4>
<p>​ <strong>介绍链接：https://blog.slks.xyz/2022/01/07/basic5/</strong></p>
<p>​ <strong>可变形卷积Deformable Convolution</strong>，<strong>其加强了CNN的变换建模能力</strong>，它通过额外的偏移量增加了模块中的空间采样位置。 可变形卷积已被应用于解决几个高级视觉任务，例如对象检测、视频对象检测采样、语义分割和人体姿态估计。</p>
<p>​ 最近，一些方法尝试在图像生成任务中应用可变形卷积。 TDAN[48] 通过使用可变形卷积对齐两个连续帧并输出高分辨率帧来解决视频超分辨率任务。</p>
<p>​ <strong>在我们提出的 DG-Font 中，可变形卷积的偏移量是通过 learned latent style code来进行估计的。</strong>（具体内容见后细节）</p>
<h2 id="主要设计思想">4、主要设计思想：</h2>
<p>​ 作者提出了可变形生成网络（Deformable Generative Networks）来做<strong>非监督的字体生成</strong>。其利用提供的目标字体图像（<strong>style image input</strong>）来将一种字体的字符变形和转换为另一种字体。</p>
<p>​ DG-FONT 分离了字体的style和content，然后再将两个domain的表示进行融合，生成新的字体的字符。</p>
<p>​ 其核心模块为一个叫做<strong>FDSC（feature deformation skip connection）的东西</strong>，可以用来预测一个位移映射map然后使用位移映射map去对low-level的特征图做变形卷积。然后FDSC的输出被送入一个混合器，然后生成最终的结果。</p>
<p>​ FDSC模块将会<strong>对内容图像的低层级特征进行变换，其能够保留文字本身的模式</strong>，比如笔画和偏旁部首信息。因为对于内容相同的两种不同风格的字体，<strong>它们的每一笔画通常都是对应的</strong>（如下图所示）。利用字体的空间关系，利用FDSC进行空间变形，<strong>有效地保证了生成的字符具有完整的结构</strong>。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220116172624229.png" /></p>
<p>​</p>
<p>​ 同时，为了区分不同的风格，模型还使用了一个多任务标识符判别器Multi-Task Discriminator，以保证每个风格都可以被独立判定。</p>
<h2 id="具体方法与网络架构">5、具体方法与网络架构：</h2>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220116160758876.png" /></p>
<h3 id="整体架构overall-pipeline">1) 整体架构（Overall Pipeline）</h3>
<ul>
<li><p><strong>概述</strong>：如上图所示，整个网络包含一个 Style Encoder、一个Content Encoder、一个Mixer、和两个FDSC模块。</p>
<ul>
<li><p><strong>Style Encoder</strong> 从输入图像中学习Style Representation。具体而言，其将一个Style Image作为输入，将其映射至一个Style Latent Vector <span class="math inline">\(Z_S\)</span>。</p></li>
<li><p><strong>Content Encoder</strong> 提取Content Images的结构特征，将其 映射到一个空间特征图 <span class="math inline">\(Z_C\)</span></p></li>
<li><p><strong>Deformable Convolution</strong>能够使得<em>Content Encoder</em>去识别到相同内容的字中Style-Invariant的特征</p></li>
<li><p><strong>Mixer</strong> 通过混合<span class="math inline">\(Z_C\)</span>和<span class="math inline">\(Z_S\)</span>来生成输出字符。其使用<strong>AdaIN</strong>方法将style特征注入Mixer中。</p></li>
<li><p><strong>FDSC</strong> 模块能够将变形的<em>Low-Level</em>特征从<em>Content Encoder</em>中传输到Mixer中</p></li>
<li><p><strong>Multi-Task Discriminator</strong> ：当字符图像从生成网络生成后，该判别器用来对每个单独的 Style 同时执行判断任务。对于每一个style来说， Discriminator的输出是一个二元分类器， 判断其是真实图片还是生成图片。同时，因为在训练集中，有多种不同的字体风格，所以判别器的输出是一个数组，它的长度是所有风格的数量，数组里的每个元素是一个二元向量【例如，假设总共有5个风格，最终判别器输出的应当是如下的一个向量：</p>
<p>​ [ [ 1 0 ] , [ 0 0 ] , [ 0 0 ] , [ 0 0 ] , [ 0 0 ] ]</p>
<p>】</p></li>
</ul></li>
<li><p><strong>输入</strong>：<strong>Style Image</strong>【风格A，汉字1】、<strong>Content Image</strong>【风格B，汉字2】</p></li>
<li><p><strong>输出</strong>：<strong>Output Image</strong>【风格A，汉字2】</p></li>
</ul>
<h3 id="style-encoder">2) Style Encoder</h3>
<ul>
<li><strong>概述</strong>：从输入图像中学习 Style Representation。具体而言，其将一个Style Image作为输入，将其映射至一个Style Latent Vector <span class="math inline">\(Z_S\)</span>。</li>
<li><strong>输入</strong>：Style Image <span class="math inline">\(I_s \in R^{H*W}\)</span></li>
<li><strong>输出</strong>：Style Latent Vector <span class="math inline">\(Z_s \in R\)</span></li>
<li><strong>网络结构</strong>：如下所示
<ul>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220119151744473.png" /></li>
</ul></li>
<li><strong>公式表达</strong>：</li>
<li><strong>实现细节（官方代码）</strong>
<ul>
<li>其在源代码中，其为GuidingNet文件部分，可供选择的项有Vgg11，Vgg13，Vgg16，Vgg19等。这个StyleEncoder网络将输入的StyleImage进行特征的提取以后，得到特征向量，在Decoder中使用AdaIn融合之前，源代码中还经过了一个MLP模块。然后，利用MLP模块输出的内容，对AdaIN2d里面的weight和bias进行初始化，最终达到</li>
</ul></li>
</ul>
<h3 id="content-encoder">3) Content Encoder</h3>
<ul>
<li><p><strong>概述</strong>：提取Content Images的结构特征，将其 映射到一个空间特征图 <span class="math inline">\(Z_C\)</span></p></li>
<li><p><strong>输入</strong>：Content Image <span class="math inline">\(I_c \in R^{H*W}\)</span></p></li>
<li><p><strong>输出</strong>：Content Latent Vector <span class="math inline">\(Z_c \in R\)</span></p></li>
<li><p><strong>网络结构细节</strong>：</p>
<ul>
<li><p>in_channel = 3,out_channel=64,kernel_size=7 x 7,stride = 1,padding = 3 的变形卷积层 + IN(64) 归一化 + Activation(ReLu)</p></li>
<li><p>得到FDSC-1模块的输入 skip1 [32, 64, 80, 80]</p></li>
<li><p>in_channel = 64,out_channel=128,kernel_size =4 x 4,stride=2,padding=1 的变形卷积层 + IN(128) 归一化 + Activation(ReLu)</p></li>
<li><p>得到FDSC-2模块的输入 skip2 [30,128,40,40]</p></li>
<li><p>in_channel =128,out_channel=256,kernel_size =4 x 4,stride=2,padding=1 的变形卷积层 + IN(256) 归一化 + Activation(ReLu)</p></li>
<li><p>N个ResBlock</p>
<ul>
<li><p>每个ResBlock如下：</p></li>
<li><p>Input---&gt;Conv2D---&gt;Conv2D---&gt; + ---&gt; output</p>
<p><span class="math inline">\(\downarrow\)</span>-------------------------------------------<span class="math inline">\(\uparrow\)</span></p></li>
<li><p>Conv2D,in_dim=256,out_dim=256,kernel_size=3x3,stride=1,padding=1 普通卷积层</p></li>
</ul></li>
</ul></li>
<li><p><strong>举例</strong>：</p>
<ul>
<li>假设输入图像为 80 * 80 ，Batch_Size = 32 , 那么：skip1,skip2和最终的output <span class="math inline">\(Z_c\)</span>的大小分别如下：</li>
<li>skip1.shape: torch.Size([32, 64, 80, 80])</li>
<li>skip2.shape: torch.Size([32, 128, 40, 40])</li>
<li>ouput.shape: torch.Size([32, 256, 20, 20])</li>
</ul></li>
<li><p><strong>意义</strong>：提取Content Images的结构特征，应用变形卷积层能够保持字体笔画结构</p></li>
</ul>
<h3 id="feature-deformation-skip-connection-fdsc-module">4) Feature Deformation Skip Connection ( FDSC Module)</h3>
<ul>
<li><p><strong>概述</strong>：其由一个变形卷积层组成，具体的作用作者在书写时写在了Mixer的卷积层后的内容里</p></li>
<li><p><strong>实现细节</strong></p>
<ul>
<li><p>首先，其输入来自于Content Encoder，也就是文中提及的skip1和skip2，我们以skip1为例继续讲解：</p></li>
<li><p>其次，它会将Skip1和Mixer中经过了Conv以后的内容A，Concat一起，然后将这个Concat完的东西放入变形卷积模块中，得到一个新计算的Concat_Pre,最后将这个Concat_Pre和A再Concat到一起，得到最终的输出。</p></li>
<li><p>这就是为什么在论文的示意图中：这个FDSC模块有来回的箭头表示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_01_19_15_31_59_728.png" /></p></li>
</ul></li>
</ul>
<h3 id="mixer">5) Mixer</h3>
<ul>
<li><p><strong>概述</strong>：通过混合<span class="math inline">\(Z_C\)</span>和<span class="math inline">\(Z_S\)</span>来生成输出字符。其使用<strong>AdaIN</strong>方法将style特征注入Mixer中。</p></li>
<li><p><strong>输入</strong>： <span class="math inline">\(Z_c \in R\)</span>即ContentEncoder的输出，256通道的特征图 [32,256,20,20]</p></li>
<li><p><strong>输出</strong>：</p></li>
<li><p><strong>网络结构及细节</strong>：</p>
<ul>
<li>2个ResBlock，输出仍然为256通道的特征图 [32,256,20,20]</li>
<li>Upsample上采样 ，特征图大小变为 40 x 40</li>
<li>Conv2dBlock，in_channel = 256,out_channel=128,kernel_size =5 x 5,stride=1,padding=2 的卷积层 + AdIN(128) 归一化 + Activation(ReLu), 经过该层后，计算得到的大小应当为 [32,128,40,40]
<ul>
<li>然后，需要将此层输出的output和skip2在Channel通道Concat起来，得到deformable_concat [32,256,40,40]</li>
<li>然后将deformable_concat与skip2 输入 FDSC的变形卷积模块中，得到 concat_pre [32,128,40,40] 和 offset2 [32,18,40,40]</li>
<li>最后将cancat_pre和最开始的output Concat起来，得到该步的最终输出，大小为 [32，256，40，40]</li>
</ul></li>
<li>Upsample上采样，特征图大小变为80 x 80</li>
<li>Conv2dBlock，in_channel = 256,out_channel=64,kernel_size =5 x 5,stride=1,padding=2 的卷积层 + AdIN(64) 归一化 + Activation(ReLu), 经过该层后，计算得到的大小应当为 [32,64,80,80]
<ul>
<li>然后，需要将此层输出的output和skip1在Channel通道Concat起来，得到deformable_concat [32,128,80,80]</li>
<li>然后将deformable_concat与skip1 输入 变形卷积模块中，得到 Concat_pre [32,128,40,40] 和 offset2 [32,18,40,40]</li>
<li>最后将cancat_pre和最开始的outputConcat起来，得到该步的最终输出，大小为 [32，256，40，40]</li>
</ul></li>
<li>Conv2dBlock，in_channel = 128,out_channel=3,kernel_size =7 x 7,stride=1,padding=3 的卷积层 + Activation(Tanh), 经过该层后，计算得到的大小应当为 [32,3,80,80]</li>
</ul></li>
</ul>
<h3 id="multi-task-discriminator">6) Multi-Task Discriminator</h3>
<ul>
<li><p><strong>概述</strong>：当字符图像从生成网络生成后，该判别器用来对每个单独的 Style 同时执行判断任务。对于每一个style来说， Discriminator的输出是一个二元分类器， 判断其是真实图片还是生成图片。</p></li>
<li><p><strong>输入</strong>：</p>
<ul>
<li>- x: images of shape (batch, 3, image_size, image_size).，例如为 4个 3 * 64 * 64的图像</li>
<li>- y: domain indices of shape (batch). 例如 y_in 为 4个需要其判断的 domain的标号</li>
</ul></li>
<li><p><strong>输出</strong>：各个需要判断的得分情况</p></li>
<li><p><strong>示例</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">D = Discriminator(<span class="number">64</span>, <span class="number">4</span>)  <span class="comment"># 初始化判别器参数 64 为图像大小，4为该判别器需要判别区分的domain的数量</span></span><br><span class="line">x_in = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">64</span>)  <span class="comment"># x_in 为 2个 3*64*64的图像  y_in 为 2个需要其判断的 domain的标号</span></span><br><span class="line">y_in = torch.randint(<span class="number">0</span>, <span class="number">10</span>, size=(<span class="number">2</span>, )) <span class="comment"># 假设为[1,3] 就是要让D去判断，第一个图是否属于domain1，第二个图是否属于domain3……</span></span><br><span class="line">out, feat = D(x_in, y_in)</span><br><span class="line"><span class="built_in">print</span>(out, feat)    </span><br><span class="line"><span class="built_in">print</span>(out.shape, feat.shape)  <span class="comment"># out为Discriminator打的分数（内部简化过）,feat为没处理过的原始输出，差别见下示例</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">out。shape = 1 * 2 ,out的第一个值相当于取了feat中[1,1,1,1]因为是第一个图片，并且是判断是否属于domain1的值，即为1.7796</span></span><br><span class="line"><span class="string">out的第二个值相当于取了feat中[2,3,1,1]因为是第二个图片，并且是判断是否属于domain3的值，即为0.9986</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">out: [1.7796, 0.9986]    </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">feat。shape = 2 * 4 * 1 * 1 ，其有2张需要判断的图像，第一张图像有4个值，分别是根据domain0-domain3打的分数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">feat:tensor([[[[-0.8181]],  </span></span><br><span class="line"><span class="string">         [[ 1.7796]],</span></span><br><span class="line"><span class="string">         [[ 3.0122]],</span></span><br><span class="line"><span class="string">         [[ 0.9614]]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[[-0.5011]],</span></span><br><span class="line"><span class="string">         [[ 0.5076]],</span></span><br><span class="line"><span class="string">         [[ 3.4774]],</span></span><br><span class="line"><span class="string">         [[ 0.9986]]]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>网络细节（官方代码）</strong></p>
<ul>
<li>与论文附录一致：</li>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220119155654674.png" /></li>
</ul></li>
</ul>
<h2 id="dg-font网络的训练验证以及主函数见下一篇dg-font代码详解">6、DG-Font网络的训练、验证以及主函数（见下一篇DG-Font代码详解）：</h2>
<p><strong>注：此部分结合了官方源码的内容，讲述训练的整体过程</strong></p>
]]></content>
      <categories>
        <category>⓶ 论文阅读笔记</category>
        <category>CV相关论文</category>
      </categories>
      <tags>
        <tag>Font Generation</tag>
        <tag>Deformable Convolution Skip Connection</tag>
        <tag>Unsupervised Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch学习笔记10——PyTorch 中，nn与nn.functional有什么区别？（搬运）</title>
    <url>/2022/01/18/acaa679c551a/</url>
    <content><![CDATA[<h1 id="pytorch-中nn-与-nn.functional-有什么区别">PyTorch 中，nn 与 nn.functional 有什么区别？</h1>
<p>​ 注：在阅读代码以及Pytorch文档的时候发现，nn和nn.functional有很多相同的函数，文档中也有许多引用，故而搜索了一下有何区别，该文为搬运文，以下为引用说明，避免产生误会。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">作者：肥波喇齐</span><br><span class="line">链接：https://www.zhihu.com/question/66782101/answer/579393790</span><br><span class="line">来源：知乎</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure>
<h4 id="两者的相同之处">1、两者的相同之处：</h4>
<ul>
<li><code>nn.Xxx</code>和<code>nn.functional.xxx</code>的实际功能是相同的，即<code>nn.Conv2d</code>和<code>nn.functional.conv2d</code> 都是进行卷积，<code>nn.Dropout</code> 和<code>nn.functional.dropout</code>都是进行dropout,………………；</li>
<li>运行效率也是近乎相同。</li>
</ul>
<p>​ <code>nn.functional.xxx</code>是函数接口，而<code>nn.Xxx</code>是<code>nn.functional.xxx</code>的类封装，并且<strong><code>nn.Xxx</code>都继承于一个共同祖先<code>nn.Module</code>。</strong>这一点导致<code>nn.Xxx</code>除了具有<code>nn.functional.xxx</code>功能之外，内部附带了<code>nn.Module</code>相关的属性和方法，例如<code>train(), eval(),load_state_dict, state_dict</code>等。</p>
<h4 id="两者的差别之处">2、两者的差别之处：</h4>
<ul>
<li><strong>两者的调用方式不同。</strong></li>
</ul>
<p><code>nn.Xxx</code> 需要先实例化并传入参数，然后以函数调用的方式调用实例化的对象并传入输入数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">inputs = torch.rand(<span class="number">64</span>, <span class="number">3</span>, <span class="number">244</span>, <span class="number">244</span>)</span><br><span class="line">conv = nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">out = conv(inputs)</span><br></pre></td></tr></table></figure>
<p><code>nn.functional.xxx</code>同时传入输入数据和weight, bias等其他参数 。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">weight = torch.rand(<span class="number">64</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">bias = torch.rand(<span class="number">64</span>) </span><br><span class="line">out = nn.functional.conv2d(inputs, weight, bias, padding=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong><code>nn.Xxx</code>继承于<code>nn.Module</code>， 能够很好的与<code>nn.Sequential</code>结合使用， 而<code>nn.functional.xxx</code>无法与<code>nn.Sequential</code>结合使用。</strong></p></li>
<li><p><strong><code>nn.Xxx</code>不需要你自己定义和管理weight；而<code>nn.functional.xxx</code>需要你自己定义weight，每次调用的时候都需要手动传入weight, 不利于代码复用。</strong></p>
<p>例如：使用<code>nn.Xxx</code>定义一个CNN</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.cnn1 = nn.Conv2d(in_channels=<span class="number">1</span>,  out_channels=<span class="number">16</span>, kernel_size=<span class="number">5</span>,padding=<span class="number">0</span>)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.maxpool1 = nn.MaxPool2d(kernel_size=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        self.cnn2 = nn.Conv2d(in_channels=<span class="number">16</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">5</span>,  padding=<span class="number">0</span>)</span><br><span class="line">        self.relu2 = nn.ReLU()</span><br><span class="line">        self.maxpool2 = nn.MaxPool2d(kernel_size=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        self.linear1 = nn.Linear(<span class="number">4</span> * <span class="number">4</span> * <span class="number">32</span>, <span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        out = self.maxpool1(self.relu1(self.cnn1(x)))</span><br><span class="line">        out = self.maxpool2(self.relu2(self.cnn2(out)))</span><br><span class="line">        out = self.linear1(out.view(x.size(<span class="number">0</span>), -<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>使用<code>nn.function.xxx</code>定义一个与上面相同的CNN。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.cnn1_weight = nn.Parameter(torch.rand(<span class="number">16</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">        self.bias1_weight = nn.Parameter(torch.rand(<span class="number">16</span>))</span><br><span class="line">        </span><br><span class="line">        self.cnn2_weight = nn.Parameter(torch.rand(<span class="number">32</span>, <span class="number">16</span>, <span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">        self.bias2_weight = nn.Parameter(torch.rand(<span class="number">32</span>))</span><br><span class="line">        </span><br><span class="line">        self.linear1_weight = nn.Parameter(torch.rand(<span class="number">4</span> * <span class="number">4</span> * <span class="number">32</span>, <span class="number">10</span>))</span><br><span class="line">        self.bias3_weight = nn.Parameter(torch.rand(<span class="number">10</span>))</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        out = F.conv2d(x, self.cnn1_weight, self.bias1_weight)</span><br><span class="line">        out = F.relu(out)</span><br><span class="line">        out = F.max_pool2d(out)</span><br><span class="line">        </span><br><span class="line">        out = F.conv2d(x, self.cnn2_weight, self.bias2_weight)</span><br><span class="line">        out = F.relu(out)</span><br><span class="line">        out = F.max_pool2d(out)</span><br><span class="line">        </span><br><span class="line">        out = F.linear(x, self.linear1_weight, self.bias3_weight)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure></li>
</ul>
<p>​ 上面两种定义方式得到CNN功能都是相同的，但PyTorch官方推荐：具有学习参数的（例如，conv2d, linear, batch_norm)采用<code>nn.Xxx</code>方式，没有学习参数的（例如，maxpool, loss func, activation func）等根据个人选择使用<code>nn.functional.xxx</code>或者<code>nn.Xxx</code>方式。</p>
<p>​ 但关于<strong>dropout</strong>，个人强烈推荐使用<code>nn.Xxx</code>方式，因为一般情况下只有训练阶段才进行dropout，在eval阶段都不会进行dropout。使用<code>nn.Xxx</code>方式定义dropout，在调用<code>model.eval()</code>之后，model中所有的dropout layer都关闭，但以<code>nn.function.dropout</code>方式定义dropout，在调用<code>model.eval</code>之后并不能关闭dropout。</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Pytorch系列笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记9——归一化方法FRN(Filter Response Normalization)</title>
    <url>/2022/01/18/920f212c6758/</url>
    <content><![CDATA[<h4 id="一简介">一、简介</h4>
<p>​ <strong>在先前的文章中，链接：https://blog.slks.xyz/2022/01/16/basic7/，讲解了BN、LN、IN、CIN、GN等多种不同的Normalization，由于在DG-Font的阅读过程中，又发现了一个新的归一化方法叫做FRN，故而在此篇略做记录。</strong></p>
<p>​ <strong>FRN</strong>是谷歌提出的一种新的归一化方法，和GN一样不依赖batch，故而FRN层不仅消除了模型训练过程中对batch的依赖，而且当batch size较大时性能优于BN。</p>
<p>​ <strong>原论文名称：</strong>《Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks》</p>
<p>​ <strong>原论文地址：</strong>https://arxiv.org/abs/1911.09737</p>
<h4 id="二结构">二、结构：</h4>
<p>​ 如下所示，FRN层整体结构包括归一化层FRN（Filter Response Normalization）和激活层TLU（Thresholded Linear Unit）。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220118102128474.png" /></p>
<p>​ 整个结构并不复杂，就是通过一个公式计算，最后经过一个阈值限制输出</p>
<p>​ 其中FRN的操作是对每个样例的每个channel单独进行归一化的，这里<span class="math inline">\(x\)</span>就是一个N（=HxW）维度的向量，所以FRN没有BN层对batch依赖的问题。BN层采用归一化方法是减去均值然后除以标准差，而FRN却不同，这里没有减去均值操作，公式中的<span class="math inline">\(v^2\)</span>是<span class="math inline">\({x}\)</span>的二次范数的平均值。这种归一化方式类似BN可以用来消除中间操作（卷积和非线性激活）带来的尺度问题，有助于模型训练。 公式里的<span class="math inline">\({\epsilon}\)</span>是一个很小的正常量，一般为<span class="math inline">\(1^{-6}\)</span>以防止除0。</p>
<p>​ 一般情况下网络的特征图大小N(=HxW)较大，但是有时候可能会出现1x1的特征图的情况，比如InceptionV3和VGG网络，此时就<span class="math inline">\({\epsilon}\)</span>比较关键，</p>
<p>​ 归一化之后同样需要进行缩放和平移变换，这里的<span class="math inline">\(\gamma\)</span>和<span class="math inline">\(\beta\)</span>也是可学习的参数（参数为长度是C的向量, 即为特征数目，也就是通道数):</p>
<p>​ <span class="math display">\[{y = \gamma \hat{x} + \beta}\]</span></p>
<p>​ FRN缺少去均值的操作，这可能使得归一化的结果任意地偏移0，如果FRN之后是ReLU激活层，可能产生很多0值，这对于模型训练和性能是不利的。为了解决这个问题，FRN之后采用的阈值化的ReLU，即TLU：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_01_18_10_32_35_986.png" /></p>
<p>​ 这里的<span class="math inline">\(\tau\)</span>是一个可学习的参数。原论文中发现FRN之后采用TLU对于提升性能是至关重要的。</p>
<h4 id="三代码实现coding">三、代码实现Coding</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FRN</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_features, eps=<span class="number">1e-6</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(FRN, self).__init__()</span><br><span class="line">        self.tau = nn.Parameter(torch.zeros(<span class="number">1</span>, num_features, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.gamma = nn.Parameter(torch.ones(<span class="number">1</span>, num_features, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.beta = nn.Parameter(torch.zeros(<span class="number">1</span>, num_features, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.eps = eps</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment">## input x  shape [B,C,H,W] (batch_size , channel , height , width)</span></span><br><span class="line">        x1 = torch.mean(x**<span class="number">2</span>, dim=[<span class="number">2</span>, <span class="number">3</span>], keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment">## x1       shape [B,C,1,1] (batch_size , channel , 1 , 1)</span></span><br><span class="line">        x2 = x1 + self.eps</span><br><span class="line">        <span class="comment">## x2 	    shape [B,C,1,1] (batch_size , channel , 1 , 1),  【+ 为逐元素相加，不改变维度】</span></span><br><span class="line">        x3 = torch.rsqrt(x2)</span><br><span class="line">        <span class="comment">## x3       shape [B,C,1,1] (batch_size , channel , 1 , 1),  【sqrt 为逐元素操作，不改变为维度】</span></span><br><span class="line">        x4 = x * x3</span><br><span class="line">        <span class="comment">## x4       shape [B,C,H,W] (batch_size , channel , height , width)  </span></span><br><span class="line">        <span class="comment">##          广播机制,逐元素相乘  [B,C,H,W] * [B,C,1,1] = [B,C,H,W]</span></span><br><span class="line">        output = torch.<span class="built_in">max</span>(self.gamma * x4 + self.beta, self.tau)</span><br><span class="line">        <span class="comment">## output   shape [B,C,H,W] (batch_size , channel , height , width)  torch.max 逐元素操作</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="comment">## 相关注解：</span></span><br><span class="line"><span class="comment">## 输入的 x.shape = [B,C,H,W] ( Batch_Size \ Channel \ Height \ Width )</span></span><br><span class="line"><span class="comment">## torch.rsqrt()  对每个元素取平方根后再取倒数，并不会影响如维度等因素。</span></span><br><span class="line"><span class="comment">## torch.mean() 其中dim=[2,3] 代表按第2、3维求平均值, 即在单个实例、单个Channel上求平均</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title>Torch/Numpy的广播机制介绍</title>
    <url>/2022/01/18/52f2902757db/</url>
    <content><![CDATA[<p>Numpy以及Tensor的广播机制介绍（以Torch为例，两者一致）</p>
<h3 id="广播机制在何处会出现">1、广播机制在何处会出现？</h3>
<p>​ 广播针对的运算是element wise类型的运算，即元素对元素类型的运算</p>
<p>​ <strong>Element-wise的计算符号包括如下：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">算数运算：+, -, *, /, //, %, divmod(), ** or pow(), &lt;&lt;, &gt;&gt;, &amp;, ^, |</span><br><span class="line"></span><br><span class="line">比较运算：==, &lt;, &gt;, &lt;=, &gt;=, !=</span><br></pre></td></tr></table></figure>
<h3 id="广播机制的规则与出现的原因">2、广播机制的规则与出现的原因</h3>
<p>​ 正常来说，两个做Element wise类型运算的变量，其相应维度的长度要相等，如下所示：这种形式做Element-Wise的运算是非常简单且易理解的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">b = torch.rand(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">c = a * b</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">a:tensor([[0.9912, 0.3736],</span></span><br><span class="line"><span class="string">        [0.0708, 0.6939]])</span></span><br><span class="line"><span class="string">b:tensor([[0.5788, 0.6296],</span></span><br><span class="line"><span class="string">        [0.9746, 0.8540]])</span></span><br><span class="line"><span class="string">c:tensor([[0.5737, 0.2352],</span></span><br><span class="line"><span class="string">        [0.0690, 0.5925]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​ 那么当两个Tensor的对应维度不对齐的时候，<strong>为了避免用户使用代码for循环来操作填补数组，导致一些低效率的行为出现</strong>，所以其提供了一种广播机制，其实质就是一种处理规则，在不对齐的维度上，长度较短的自动做值复制来扩充长度，从而使得两个Tensor在该维度上一致。</p>
<h3 id="广播机制起效的情况">3、广播机制起效的情况</h3>
<p>​ 但是，实际上，并不是所有的不同维度的Tensor相乘时，都会触发广播机制。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">b = torch.rand(<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line">c = a * b</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	RuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 0</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>​ 那么，广播机制在何时才会起效呢？其只对如下情况起作用：</p>
<p>​ <strong>两个Tensor，它们如果在某一个维度上长度不同的话，必定有一个Tensor在这个维度上的长度为1，广播机制才会起效。即 1 vs M 的情况</strong></p>
<p>​ <strong>具体计算规则：</strong>长度为1的Tensor在维度上会复制该元素并扩充至长度为M，当这个维度完成对齐，接着重复检查上一层维度，如此反复，直至所有维度都检查完。</p>
<p>​ <strong>示例</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = torch.rand(<span class="number">1</span>,<span class="number">5</span>,<span class="number">3</span>)</span><br><span class="line">b = torch.rand(<span class="number">3</span>,<span class="number">5</span>,<span class="number">1</span>)</span><br><span class="line">c = a * b</span><br><span class="line"><span class="built_in">print</span>(c.shape)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	torch.Size([3, 5, 3])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>​ <strong>示意图</strong>：</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/20200308204131296.png" alt="20200308204131296" /><figcaption aria-hidden="true">20200308204131296</figcaption>
</figure>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>Python基础扩充笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>Auto BroadCasting</tag>
      </tags>
  </entry>
  <entry>
    <title>Python导入自定义模块（同目录、子目录、跨目录）</title>
    <url>/2022/01/18/a7c2f4fb23de/</url>
    <content><![CDATA[<h3 id="基本格式">1、基本格式：</h3>
<p>​ <strong>from 文件名 import 类名</strong></p>
<h3 id="分情形讨论引入方式">2、分情形讨论引入方式：</h3>
<p>​ 假设现有如下目录结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── model0.py</span><br><span class="line">├── main.py</span><br><span class="line">├── model1/</span><br><span class="line">│   └── model1_main.py</span><br><span class="line">└── model2/</span><br><span class="line">    └── model2_main.py</span><br></pre></td></tr></table></figure>
<h4 id="同级目录引入">1）同级目录引入</h4>
<p><strong>main.py</strong> 中需要导入 <strong>model0.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> model0</span><br><span class="line"><span class="comment"># 或</span></span><br><span class="line"><span class="keyword">from</span> model0 <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure>
<p>两者都是可以的，同级目录下引入十分简便，直接import即可</p>
<h4 id="子目录引入">2）子目录引入</h4>
<p><strong>main.py</strong> 中需要导入 <strong>model1_main.py</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">我们首先需要在model1/下建立__init__.py空文件，让编译器认为这是一个模块。</span><br></pre></td></tr></table></figure>
<p>建立后，<strong>目录结构应当如下所示：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── model0.py</span><br><span class="line">├── main.py</span><br><span class="line">├── model1/</span><br><span class="line">│   └── model1_main.py</span><br><span class="line">│   └── __init__.py</span><br><span class="line">└── model2/</span><br><span class="line">    └── model2_main.py</span><br></pre></td></tr></table></figure>
<p>然后进行引入：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> model1.model1_main</span><br><span class="line"><span class="comment"># 或</span></span><br><span class="line"><span class="keyword">from</span> model1.model1_main <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure>
<h4 id="跨目录引入">3）跨目录引入</h4>
<p><strong>model1_main.py</strong>导入<strong>model2/model2_main.py</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">同理我们首先需要在model2/下建立__init__.py空文件，让编译器认为这是一个模块。</span><br></pre></td></tr></table></figure>
<p>建立后，<strong>目录结构应当如下所示：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── model0.py</span><br><span class="line">├── main.py</span><br><span class="line">├── model1/</span><br><span class="line">│   └── model1_main.py</span><br><span class="line">│   └── __init__.py</span><br><span class="line">└── model2/</span><br><span class="line">│   └── model2_main.py</span><br><span class="line">│   └── __init__.py</span><br></pre></td></tr></table></figure>
<p>然后在model1_main文件中进行引入</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&quot;..&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> model2.model2_main</span><br></pre></td></tr></table></figure>
<h4 id="更为一般的介绍">4）更为一般的介绍：</h4>
<p>sys模块是python内置的，我们导入跨自定义模块的步骤一般如下：</p>
<p>​ 首先要确保被导入的模块文件夹内有 __init__.py文件，确保其被识别为一个模块，然后再执行下面步骤：</p>
<ol type="1">
<li><strong>先导入sys模块</strong></li>
<li>然后通过<code>sys.path.append(path)</code> 函数来导入自定义模块所在的目录</li>
<li><strong>导入自定义模块</strong>。</li>
</ol>
<p>​ 只不过在同级目录以及子目录下进行引入，不需要这么复杂，可以有更简单的方法，而在跨目录引入时，就需要采用这种方案。</p>
]]></content>
      <categories>
        <category>⓸ 编程语言类笔记</category>
        <category>Python基础扩充笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Module Import</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker部署与实践笔记</title>
    <url>/2022/01/17/52faafcaa31c/</url>
    <content><![CDATA[<h3 id="一docker优势功能">一、Docker优势功能</h3>
<p>1：持续交付和部署</p>
<p>​ 对开发和运维（<a href="https://zh.wikipedia.org/wiki/DevOps">DevOps</a>）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。</p>
<p>​ 使用 <code>Docker</code> 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 <a href="https://yeasy.gitbook.io/docker_practice/image/dockerfile">Dockerfile</a> 来进行镜像构建，并结合 <a href="https://en.wikipedia.org/wiki/Continuous_integration">持续集成(Continuous Integration)</a> 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 <a href="https://en.wikipedia.org/wiki/Continuous_delivery">持续部署(Continuous Delivery/Deployment)</a> 系统进行自动部署。</p>
<p>而且使用 <a href="https://yeasy.gitbook.io/docker_practice/image/build"><code>Dockerfile</code></a> 使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。</p>
<p>2、 开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 <code>Docker</code> 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 <em>「这段代码在我机器上没问题啊」</em> 这类问题</p>
<h3 id="二docker-基本概念">二、Docker 基本概念</h3>
<ul>
<li><strong>镜像</strong>（<code>Image</code>）</li>
<li><strong>容器</strong>（<code>Container</code>）</li>
<li><strong>仓库</strong>（<code>Repository</code>）</li>
</ul>
<p>1、镜像：<strong>Docker 镜像</strong>（<code>Image</code>），就相当于是一个 <code>root</code> 文件系统。比如官方镜像 <code>ubuntu:18.04</code> 就包含了完整的一套 Ubuntu 18.04 最小系统的 <code>root</code> 文件系统。</p>
<p>​ 使用分层存储技术，在 Docker 设计时，就充分利用 <a href="https://en.wikipedia.org/wiki/Union_mount">Union FS</a> 的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 <code>ISO</code> 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。</p>
<p>2、镜像（<code>Image</code>）和容器（<code>Container</code>）的关系，就像是面向对象程序设计中的 <code>类</code> 和 <code>实例</code> 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。</p>
<p>​ 每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为 <strong>容器存储层</strong>。</p>
<p>​ 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。</p>
<p>​ 按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 <a href="">数据卷（Volume）</a>、或者 <a href="">绑定宿主目录</a>，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。</p>
<p>​ 据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。</p>
<p>3、仓库</p>
<p>​ 镜像构建完成后，可以很容易的在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，<a href="">Docker Registry</a> 就是这样的服务。</p>
<p>​ 一个 <strong>Docker Registry</strong> 中可以包含多个 <strong>仓库</strong>（<code>Repository</code>）；每个仓库可以包含多个 <strong>标签</strong>（<code>Tag</code>）；每个标签对应一个镜像。</p>
<h3 id="三使用镜像">三、使用镜像：</h3>
<h4 id="获取镜像">1、 获取镜像：</h4>
<p>​ 从 Docker 镜像仓库获取镜像的命令是 <code>docker pull</code>。其命令格式为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签]</span><br></pre></td></tr></table></figure>
<p>Docker 镜像仓库地址：地址的格式一般是 <code>&lt;域名/IP&gt;[:端口号]</code>。默认地址是 Docker Hub(<code>docker.io</code>)。</p>
<p>仓库名：如之前所说，这里的仓库名是两段式名称，即 <code>&lt;用户名&gt;/&lt;软件名&gt;</code>。对于 Docker Hub，如果不给出用户名，则默认为 <code>library</code>，也就是官方镜像。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">示例： docker pull ubuntu:18.04</span><br></pre></td></tr></table></figure>
<p>​ 上面的命令中没有给出 Docker 镜像仓库地址，因此将会从 Docker Hub （<code>docker.io</code>）获取镜像。而镜像名称是 <code>ubuntu:18.04</code>，因此将会获取官方镜像 <code>library/ubuntu</code> 仓库中标签为 <code>18.04</code> 的镜像。<code>docker pull</code> 命令的输出结果最后一行给出了镜像的完整名称，即： <code>docker.io/library/ubuntu:18.04</code></p>
<h4 id="运行镜像">2、运行镜像：</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker run -it --rm ubuntu:18.04 bash</span><br></pre></td></tr></table></figure>
<p><code>docker run</code> 就是运行容器的命令，具体格式我们会在 <a href="">容器</a> 一节进行详细讲解，我们这里简要的说明一下上面用到的参数。</p>
<ul>
<li><code>-it</code>：这是两个参数，一个是 <code>-i</code>：交互式操作，一个是 <code>-t</code> 终端。我们这里打算进入 <code>bash</code> 执行一些命令并查看返回结果，因此我们需要交互式终端。</li>
<li><code>--rm</code>：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 <code>docker rm</code>。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 <code>--rm</code> 可以避免浪费空间。</li>
<li><code>ubuntu:18.04</code>：这是指用 <code>ubuntu:18.04</code> 镜像为基础来启动容器。</li>
<li><code>bash</code>：放在镜像名后的是 <strong>命令</strong>，这里我们希望有个交互式 Shell，因此用的是 <code>bash</code>。</li>
</ul>
<h4 id="想要列出已经下载的镜像">3、想要列出已经下载的镜像：</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker image ls</span><br></pre></td></tr></table></figure>
<p>列表包含了 <code>仓库名</code>、<code>标签</code>、<code>镜像 ID</code>、<code>创建时间</code> 以及 <code>所占用的空间</code>。</p>
<p>你可以通过 <code>docker system df</code> 命令来便捷的查看镜像、容器、数据卷所占用的空间。</p>
<h5 id="虚悬镜像-指无标签镜像">!! 虚悬镜像 : 指无标签镜像</h5>
<p>一般来说其已经失去了存在的价值，可以随意删除：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker image prune</span><br></pre></td></tr></table></figure>
<h5 id="中间层镜像为了加速镜像构建重复利用资源docker-会利用-中间层镜像所以在使用一段时间后可能会看到一些依赖的中间层镜像">!! 中间层镜像：为了加速镜像构建、重复利用资源，Docker 会利用 <strong>中间层镜像</strong>。所以在使用一段时间后，可能会看到一些依赖的中间层镜像。</h5>
<p>​ 默认的 <code>docker image ls</code> 列表中只会显示顶层镜像，如果希望显示包括中间层镜像在内的所有镜像的话，需要加 <code>-a</code> 参数。</p>
<p>​ 这样会看到很多无标签的镜像，与之前的虚悬镜像不同，这些无标签的镜像很多都是中间层镜像，是其它镜像所依赖的镜像。这些无标签镜像不应该删除，否则会导致上层镜像因为依赖丢失而出错。实际上，这些镜像也没必要删除，因为之前说过，相同的层只会存一遍，而这些镜像是别的镜像的依赖，因此并不会因为它们被列出来而多存了一份，无论如何你也会需要它们。只要删除那些依赖它们的镜像后，这些依赖的中间层镜像也会被连带删除。</p>
<h5 id="其余不常用命令见-httpsyeasy.gitbook.iodocker_practiceimagelist">其余不常用命令见： https://yeasy.gitbook.io/docker_practice/image/list</h5>
<h4 id="删除本地镜像">4、 删除本地镜像</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...]</span><br></pre></td></tr></table></figure>
<p>其中，<code>&lt;镜像&gt;</code> 可以是 <code>镜像短 ID</code>、<code>镜像长 ID</code>、<code>镜像名</code> 或者 <code>镜像摘要</code>。</p>
<p>例子：例如我们有以下镜像：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker image ls</span><br><span class="line">REPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">centos                      latest              0584b3d2cf6d        3 weeks ago         196.5 MB</span><br><span class="line">redis                       alpine              501ad78535f0        3 weeks ago         21.03 MB</span><br><span class="line">docker                      latest              cf693ec9b5c7        3 weeks ago         105.1 MB</span><br><span class="line">nginx                       latest              e43d811ce2f4        5 weeks ago     </span><br></pre></td></tr></table></figure>
<p>​ 我们可以用镜像的完整 ID，也称为 <code>长 ID</code>，来删除镜像。使用脚本的时候可能会用长 ID，但是人工输入就太累了，所以更多的时候是用 <code>短 ID</code> 来删除镜像。<code>docker image ls</code> 默认列出的就已经是短 ID 了，一般取前3个字符以上，只要足够区分于别的镜像就可以了。</p>
<p>比如这里，如果我们要删除 <code>redis:alpine</code> 镜像，可以执行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker image rm 501</span><br><span class="line">Untagged: redis:alpine</span><br><span class="line">Untagged: redis@sha256:f1ed3708f538b537eb9c2a7dd50dc90a706f7debd7e1196c9264edeea521a86d</span><br><span class="line">Deleted: sha256:501ad78535f015d88872e13fa87a828425117e3d28075d0c117932b05bf189b7</span><br><span class="line">Deleted: sha256:96167737e29ca8e9d74982ef2a0dda76ed7b430da55e321c071f0dbff8c2899b</span><br><span class="line">Deleted: sha256:32770d1dcf835f192cafd6b9263b7b597a1778a403a109e2cc2ee866f74adf23</span><br><span class="line">Deleted: sha256:127227698ad74a5846ff5153475e03439d96d4b1c7f2a449c7a826ef74a2d2fa</span><br><span class="line">Deleted: sha256:1333ecc582459bac54e1437335c0816bc17634e131ea0cc48daa27d32c75eab3</span><br></pre></td></tr></table></figure>
<p>我们也可以用<code>镜像名</code>，也就是 <code>&lt;仓库名&gt;:&lt;标签&gt;</code>，来删除镜像。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ docker image rm centos</span><br><span class="line">Untagged: centos:latest</span><br><span class="line">Untagged: centos@sha256:b2f9d1c0ff5f87a4743104d099a3d561002ac500db1b9bfa02a783a46e0d366c</span><br><span class="line">Deleted: sha256:0584b3d2cf6d235ee310cf14b54667d889887b838d3f3d3033acd70fc3c48b8a</span><br></pre></td></tr></table></figure>
<h5 id="untagged-和deleted">Untagged 和Deleted</h5>
<p>​ 删除行分两类，镜像的唯一标识是其 ID 和摘要，而一个镜像可以有多个标签。</p>
<p>​ 因此当我们使用上面命令删除镜像的时候，实际上是在要求删除某个标签的镜像。</p>
<p>​ 所以首先需要做的是将满足我们要求的所有镜像标签都取消，这就是我们看到的 <code>Untagged</code> 的信息。</p>
<p>​ 因为一个镜像可以对应多个标签，因此当我们删除了所指定的标签后，可能还有别的标签指向了这个镜像，如果是这种情况，那么 <code>Delete</code> 行为就不会发生。所以并非所有的 <code>docker image rm</code> 都会产生删除镜像的行为，有可能仅仅是取消了某个标签而已。</p>
<h3 id="四使用容器">四、使用容器：</h3>
<h4 id="启动容器">1、启动容器：</h4>
<h4 id="分两种1新创建一个容器并启动-2启动一个已经停止的容器">分两种：1、新创建一个容器并启动 2、启动一个已经停止的容器</h4>
<p>​ 容器是独立运行的一个或一组应用，以及它们的运行态环境。对应的，虚拟机可以理解为模拟运行的一整套操作系统（提供了运行态环境和其他系统环境）和跑在上面的应用</p>
<h4 id="新创建一个容器并启动">1）新创建一个容器并启动</h4>
<p>​ 当利用 <code>docker run</code> 来创建容器时，Docker 在后台运行的标准操作包括：</p>
<ul>
<li>检查本地是否存在指定的镜像，不存在就从 <a href="">registry</a> 下载</li>
<li>利用镜像创建并启动一个容器</li>
<li>分配一个文件系统，并在只读的镜像层外面挂载一层可读写层</li>
<li>从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去</li>
<li>从地址池配置一个 ip 地址给容器</li>
<li>执行用户指定的应用程序</li>
<li>执行完毕后容器被终止</li>
</ul>
<h4 id="启动一个已经停止的容器">2）启动一个已经停止的容器</h4>
<p>可以利用 <code>docker container start</code> 命令，直接将一个已经终止（<code>exited</code>）的容器启动运行。</p>
<p>容器的核心为所执行的应用程序，所需要的资源都是应用程序运行所必需的。除此之外，并没有其它的资源。可以在伪终端中利用 <code>ps</code> 或 <code>top</code> 来查看进程信息。</p>
<h4 id="守护态运行容器">2、守护态运行容器：</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d ubuntu:18.04</span><br></pre></td></tr></table></figure>
<p>！！利用-d参数在后台运行容器！！！</p>
<p>注意：容器是否会长久运行，是和 <code>docker run</code> 指定的命令有关，和 <code>-d</code> 参数无关！！！</p>
<p>使用 <code>-d</code> 参数启动后会返回一个唯一的 id，也可以通过 <code>docker container ls</code> 命令来查看容器信息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker container ls</span><br><span class="line">CONTAINER ID  IMAGE         COMMAND               CREATED        STATUS       PORTS NAMES</span><br><span class="line">77b2dc01fe0f  ubuntu:18.04  /bin/sh -c &#x27;while tr  2 minutes ago  Up 1 minute        agitated_wright</span><br></pre></td></tr></table></figure>
<p>要获取容器的输出信息，可以通过 <code>docker container logs</code> 命令。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker container logs [container ID or NAMES]</span><br><span class="line">hello world</span><br><span class="line">hello world</span><br><span class="line">hello world</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure>
<h4 id="终止容器">3、终止容器</h4>
<p>可以使用 <code>docker container stop</code> 来终止一个运行中的容器。</p>
<p>此外，当 Docker 容器中指定的应用终结时，容器也自动终止</p>
<p>处于终止状态的容器，可以通过 <code>docker container start</code> 命令来重新启动。</p>
<p>此外，<code>docker container restart</code> 命令会将一个运行态的容器终止，然后再重新启动它。</p>
<h4 id="进入容器">4、进入容器：</h4>
<p>docker exec 命令</p>
<p><code>docker exec</code> 后边可以跟多个参数，这里主要说明 <code>-i</code> <code>-t</code> 参数。</p>
<h4 id="导出容器">5、导出容器：</h4>
<p>如果要导出本地某个容器，可以使用 <code>docker export</code> 命令。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker container ls -a</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                    PORTS               NAMES</span><br><span class="line">7691a814370e        ubuntu:18.04        &quot;/bin/bash&quot;         36 hours ago        Exited (0) 21 hours ago                       test</span><br><span class="line">$ docker export 7691a814370e &gt; ubuntu.tar</span><br></pre></td></tr></table></figure>
<h4 id="导入容器">6、导入容器：</h4>
<p>可以使用 <code>docker import</code> 从容器快照文件中再导入为镜像</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cat ubuntu.tar | docker import - test/ubuntu:v1.0</span><br><span class="line">$ docker image ls</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED              VIRTUAL SIZE</span><br><span class="line">test/ubuntu         v1.0                9d37a6082e97        About a minute ago   171.3 MB</span><br></pre></td></tr></table></figure>
<p>​ 用户既可以使用 <code>docker load</code>来导入镜像存储文件到本地镜像库，也可以使用 <em><code>docker import</code></em> 来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入时可以重新指定标签等元数据信息。*</p>
<h4 id="删除容器或清理所有处于终止状态的容器">7、删除容器或清理所有处于终止状态的容器：</h4>
<p>​ 可以使用 <code>docker container rm</code> 来删除一个处于终止状态的容器。例如</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker container rm trusting_newton</span><br><span class="line">trusting_newton</span><br></pre></td></tr></table></figure>
<p>​ 用 <code>docker container ls -a</code> 命令可以查看所有已经创建的包括终止状态的容器，如果数量太多要一个个删除可能会很麻烦，用下面的命令可以清理掉所有处于终止状态的容器。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker container prune</span><br></pre></td></tr></table></figure>
<h2 id="五访问仓库">五、访问仓库</h2>
<p>​ 一个容易混淆的概念是注册服务器（<code>Registry</code>）。实际上注册服务器是管理仓库的具体服务器，每个服务器上可以有多个仓库，而每个仓库下面有多个镜像。从这方面来说，仓库可以被认为是一个具体的项目或目录。例如对于仓库地址 <code>docker.io/ubuntu</code> 来说，<code>docker.io</code> 是注册服务器地址，<code>ubuntu</code> 是仓库名。</p>
<h4 id="登录仓库">登录仓库</h4>
<p>！！可以通过执行 <code>docker login</code> 命令交互式的输入用户名及密码来完成在命令行界面登录 Docker Hub。</p>
<p>！！你可以通过 <code>docker logout</code> 退出登录。</p>
<h4 id="镜像查找">镜像查找</h4>
<p>你可以通过 <code>docker search</code> 命令来查找官方仓库中的镜像，并利用 <code>docker pull</code> 命令来将它下载到本地。</p>
<p>例如以 <code>centos</code> 为关键词进行搜索：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker search centos</span><br><span class="line">NAME                               DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED</span><br><span class="line">centos                             The official build of CentOS.                   6449      [OK]</span><br><span class="line">ansible/centos7-ansible            Ansible on Centos7                              132                  [OK]</span><br><span class="line">consol/centos-xfce-vnc             Centos container with &quot;headless&quot; VNC session…   126                  [OK]</span><br><span class="line">jdeathe/centos-ssh                 OpenSSH / Supervisor / EPEL/IUS/SCL Repos - …   117                  [OK]</span><br><span class="line">centos/systemd                     systemd enabled base container.                 96                   [OK]</span><br></pre></td></tr></table></figure>
<p>​ 可以看到返回了很多包含关键字的镜像，其中包括镜像名字、描述、收藏数（表示该镜像的受关注程度）、是否官方创建（<code>OFFICIAL</code>）、是否自动构建 （<code>AUTOMATED</code>）。</p>
<p>​ 根据是否是官方提供，可将镜像分为两类。</p>
<p>​ 一种是类似 <code>centos</code> 这样的镜像，被称为基础镜像或根镜像。这些基础镜像由 Docker 公司创建、验证、支持、提供。这样的镜像往往使用单个单词作为名字。</p>
<p>​ 还有一种类型，比如 <code>ansible/centos7-ansible</code> 镜像，它是由 Docker Hub 的注册用户创建并维护的，往往带有用户名称前缀。可以通过前缀 <code>username/</code> 来指定使用某个用户提供的镜像，比如 ansible 用户。</p>
<h4 id="推送镜像">推送镜像</h4>
<p>用户也可以在登录后通过 <code>docker push</code> 命令来将自己的镜像推送到 Docker Hub。</p>
<p>以下命令中的 <code>username</code> 请替换为你的 Docker 账号用户名</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker tag ubuntu:18.04 username/ubuntu:18.04</span><br><span class="line"></span><br><span class="line">$ docker image ls</span><br><span class="line"></span><br><span class="line">REPOSITORY                                               TAG                    IMAGE ID            CREATED             SIZE</span><br><span class="line">ubuntu                                                   18.04                  275d79972a86        6 days ago          94.6MB</span><br><span class="line">username/ubuntu                                          18.04                  275d79972a86        6 days ago          94.6MB</span><br><span class="line"></span><br><span class="line">$ docker push username/ubuntu:18.04</span><br></pre></td></tr></table></figure>
<h4 id="自动构建">自动构建</h4>
<p>自动构建（<code>Automated Builds</code>）功能对于需要经常升级镜像内程序来说，十分方便。</p>
<p>有时候，用户构建了镜像，安装了某个软件，当软件发布新版本则需要手动更新镜像。</p>
<p>而自动构建允许用户通过 Docker Hub 指定跟踪一个目标网站（支持 <a href="https://github.com/">GitHub</a> 或 <a href="https://bitbucket.org/">BitBucket</a>）上的项目，一旦项目发生新的提交 （<code>commit</code>）或者创建了新的标签（<code>tag</code>），Docker Hub 会自动构建镜像并推送到 Docker Hub 中。</p>
<p>要配置自动构建，包括如下的步骤：</p>
<ul>
<li>登录 Docker Hub；</li>
<li>在 Docker Hub 点击右上角头像，在账号设置（<code>Account Settings</code>）中关联（<code>Linked Accounts</code>）目标网站；</li>
<li>在 Docker Hub 中新建或选择已有的仓库，在 <code>Builds</code> 选项卡中选择 <code>Configure Automated Builds</code>；</li>
<li>选取一个目标网站中的项目（需要含 <code>Dockerfile</code>）和分支；</li>
<li>指定 <code>Dockerfile</code> 的位置，并保存。</li>
</ul>
<p>之后，可以在 Docker Hub 的仓库页面的 <code>Timeline</code> 选项卡中查看每次构建的状态</p>
<h2 id="六数据管理">六、数据管理</h2>
<h3 id="如何在-docker-内部以及容器之间管理数据">！！如何在 Docker 内部以及容器之间管理数据，</h3>
<h3 id="在容器中管理数据主要有两种方式">！！在容器中管理数据主要有两种方式：</h3>
<ul>
<li>数据卷（Volumes）</li>
<li>挂载主机目录 (Bind mounts)</li>
</ul>
<h4 id="数据卷">数据卷</h4>
<p><code>数据卷</code> 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性：</p>
<ul>
<li><code>数据卷</code> 可以在容器之间共享和重用</li>
<li>对 <code>数据卷</code> 的修改会立马生效</li>
<li>对 <code>数据卷</code> 的更新，不会影响镜像</li>
<li><code>数据卷</code> 默认会一直存在，即使容器被删除</li>
</ul>
<p>创建一个数据卷</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker volume create my-vol</span><br></pre></td></tr></table></figure>
<p>查看所有的 <code>数据卷</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker volume ls</span><br><span class="line"></span><br><span class="line">DRIVER              VOLUME NAME</span><br><span class="line">local               my-vol</span><br></pre></td></tr></table></figure>
<h4 id="启动一个挂载数据卷的容器">启动一个挂载数据卷的容器</h4>
<p>在用 <code>docker run</code> 命令的时候，使用 <code>--mount</code> 标记来将 <code>数据卷</code> 挂载到容器里。在一次 <code>docker run</code> 中可以挂载多个 <code>数据卷</code>。</p>
<p>下面创建一个名为 <code>web</code> 的容器，并加载一个 <code>数据卷</code> 到容器的 <code>/usr/share/nginx/html</code> 目录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker run -d -P \</span><br><span class="line">    --name web \</span><br><span class="line">    # -v my-vol:/usr/share/nginx/html \</span><br><span class="line">    --mount source=my-vol,target=/usr/share/nginx/html \</span><br><span class="line">    nginx:alpine</span><br></pre></td></tr></table></figure>
<p>查看数据卷的具体信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker inspect web</span><br></pre></td></tr></table></figure>
<p>!!!<code>数据卷</code> 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 <code>数据卷</code>，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的 <code>数据卷</code>。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 <code>docker rm -v</code> 这个命令</p>
<p>删除数据卷时请采用：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker volume rm my-vol</span><br></pre></td></tr></table></figure>
<h4 id="挂载主机目录">挂载主机目录</h4>
<p>使用 <code>--mount</code> 标记可以指定挂载一个本地主机的目录到容器中去。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker run -d -P \</span><br><span class="line">    --name web \</span><br><span class="line">    # -v /src/webapp:/usr/share/nginx/html \</span><br><span class="line">    --mount type=bind,source=/src/webapp,target=/usr/share/nginx/html \</span><br><span class="line">    nginx:alpine</span><br></pre></td></tr></table></figure>
<h2 id="七网络应用">七、网络应用</h2>
<p>​ 容器中可以运行一些网络应用，要让外部也可以访问这些应用，可以通过 <code>-P</code> 或 <code>-p</code> 参数来指定端口映射。</p>
<p>当使用 <code>-P</code> 标记时，Docker 会随机映射一个端口到内部容器开放的网络端口。</p>
<p>​ 使用 <code>docker container ls</code> 可以看到，本地主机的 32768 被映射到了容器的 80 端口。此时访问本机的 32768 端口即可访问容器内 NGINX 默认页面。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker run -d -P nginx:alpine</span><br><span class="line"></span><br><span class="line">$ docker container ls -l</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                   NAMES</span><br><span class="line"></span><br><span class="line">fae320d08268        nginx:alpine        &quot;/docker-entrypoint.…&quot;   24 seconds ago      Up 20 seconds       0.0.0.0:32768-&gt;80/tcp   bold_mcnulty</span><br></pre></td></tr></table></figure>
<p>​ <code>-p</code> 则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 <code>ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort</code>。</p>
<h4 id="查看映射端口配置">查看映射端口配置</h4>
<p>​ 使用 <code>docker port</code> 来查看当前映射的端口配置，也可以查看到绑定的地址</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker port fa 80</span><br><span class="line">0.0.0.0:32768</span><br></pre></td></tr></table></figure>
<h3 id="注意">注意：</h3>
<ul>
<li>容器有自己的内部网络和 ip 地址（使用 <code>docker inspect</code> 查看，Docker 还可以有一个可变的网络配置。）</li>
<li><code>-p</code> 标记可以多次使用来绑定多个端口</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ docker run -d \</span><br><span class="line">    -p 80:80 \</span><br><span class="line">    -p 443:443 \</span><br><span class="line">    nginx:alpine</span><br></pre></td></tr></table></figure>
<h4 id="八使用dockerfile定制镜像">八、使用DockerFIle定制镜像</h4>
<p>​ Dockerfile 是一个文本文件，其内包含了一条条的 <strong>指令(Instruction)</strong>，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。</p>
]]></content>
      <categories>
        <category>⓺ 工具使用类笔记</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记8——图像风格迁移方法AdaIN</title>
    <url>/2022/01/17/27fde64f6abc/</url>
    <content><![CDATA[<p><strong>AdaIN</strong>是一种经典的图片风格迁移算法，在 2017 年ICCV中提出。主要用于将一张图片(风格图) 中的风格、纹理迁移到另一张图片 (内容图)，同时要保留内容图的主体结构。如下所示：</p>
<p>​ <strong>论文名称：《Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization》</strong></p>
<p>​ <strong>论文链接：https://arxiv.org/abs/1703.06868</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/b219ebc4b74543a95e9180d3cb15748ab9011436.jpeg" /></p>
<h2 id="一adain简介">一、AdaIN简介</h2>
<p>​ 这篇论文的主要目标是实现<strong>实时的、任意风格的风格迁移（style transfer）</strong>，核心方法就是其提出的自适应实例标准化（<strong>Adaptive Instance Normalization，AdaIN</strong>），通过<strong>将内容图像（content image）特征的均值和方差对齐到风格图像（style image）的均值和方差</strong>来实现风格迁移。</p>
<p>​ 此外，这个方法还给用户非常多的控制权，包括如下：</p>
<ul>
<li>内容和风格的折中（trade off）
<ul>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220116183935766.png" /></li>
</ul></li>
<li>风格插值（混合风格迁移）
<ul>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220116183943127.png" /></li>
</ul></li>
<li>是否保留颜色
<ul>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220116183918123.png" /></li>
</ul></li>
<li>对图像的特定区域进行风格迁移
<ul>
<li><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220116183906461.png" /></li>
</ul></li>
</ul>
<h2 id="二前备知识">二、前备知识：</h2>
<p>​ 你需要熟悉Batch Normaliztion（BN）、Layer Norm（LN）、Instance Norm（IN）、Group Norm（GN）、Conditional Instance Norm（CIN）等概念。</p>
<p>​ 下图为特征图张量，可以直观看出BN，LN，IN，GN等规范化方法的区别。N为样本维度，C为通道维度，H为height，W即width，代表特征图的尺寸。</p>
<p><img src="https://img-blog.csdnimg.cn/2019061216413530.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNTU3Njg4MQ==,size_16,color_FFFFFF,t_70" /></p>
<p>​ 具体每种Normalization的方法介绍可以参见我的这一篇Blog：</p>
<p>​ https://blog.slks.xyz/2022/01/16/basic7/</p>
<p>​</p>
<h2 id="三adain具体介绍">三、AdaIN具体介绍</h2>
<h5 id="输入content-input-x-style-input-y">输入：Content Input x &amp;&amp; Style Input y</h5>
<p>​ AdaIN 简单地将 x 的通道均值和方差对齐以匹配 y 的均值和方差。 不像BN、IN或CIN，AdaIN没有需要从网络中进行学习的仿射变换参数，它能够自适应的从style input中计算得到仿射变换的参数。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220117103448955.png" /></p>
<p>​ 我们简单地用 σ(y) 缩放归一化的Content Input，并用 µ(y) 移动它。 与 IN 类似，这些统计数据是跨空间位置计算的。也就是说，其实对于单个实例的单个特征通道计算的均值和方差数据。</p>
<p>​ 直观地说，让我们考虑一个检测特定风格笔触的特征通道。</p>
<p>​ 具有这种风格的图像会对它的特征部分产生较高的平均激活。AdaIN 产生的输出将对该特征具有相同的高平均激活，同时其也保留内容图像的空间结构。 然后我们可以使用前馈解码器将风格特征转换回图像空间。同时，这个特征通道的方差可以编码更细微的风格信息，这些信息也传递到 AdaIN 输出和最终输出图像。</p>
<p>​ 简而言之，AdaIN 通过传输特征统计数据（特别是通道均值和方差）在特征空间中执行风格迁移。我们的 AdaIN 层就像一个 IN 层一样简单，几乎不增加计算成本。</p>
<h2 id="四网络结构">四、网络结构</h2>
<p>​ 在论文中，其使用VGG-19来编码内容和风格，在浅层空间将特征图通过AdaIN层，进行上述仿射变换，解码器根据变换后的特征图试图重建图像，通过反向传播训练解码器，使得解码器输出越来越真实的图像。整体架构如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/2019061217185282.png" /></p>
<p>​ 更为具体的代码可见以下链接地址：</p>
<p>​ https://github.com/xunhuang1995/AdaIN-style</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Style Transfer</tag>
        <tag>AdaIN</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记7——各种归一化Normalization方法（含BN、LN、IN、CIN、GN）</title>
    <url>/2022/01/16/8bf646a3f959/</url>
    <content><![CDATA[<p><strong>本文介绍了常见的几种 <a href="机器学习基础系列笔记2—数据表征与自动编码器.md">机器学习基础系列笔记2—数据表征与自动编码器.md</a> Normaliza <a href="机器学习基础系列笔记0—常见概念与函数（更新中）.md">机器学习基础系列笔记0—常见概念与函数（更新中）.md</a> tion方式，如BatchNorm、LayerNorm、InstanceNorm、Conditional Instance Norm、Group Norm。 各种Normalization在理论上都能够起到平滑损失函数平面的效果，加速函数的收敛效果，但是它们在机器学习的各个领域上，各有偏重与优势。</strong></p>
<h3 id="目录概述">目录概述：</h3>
<ul>
<li><strong>BatchNorm</strong>：batch方向做归一化，算N * H * W的均值, 常用于CNN等视觉识别领域，如果当Batch的尺寸比较小或是在一些动态网络中时不适用。</li>
<li><strong>LayerNorm</strong>：channel方向做归一化，算C * H * W的均值，LN不适用于CNN等视觉识别领域，但是可在BN无法使用的领域如RNN和Batch Size较小时进行使用。</li>
<li><strong>InstanceNorm</strong>：一个channel一个实例内做归一化，算H * W的均值，其适用于批量较小且单独考虑每个像素点的场景中，如GAN生成网络，但在MLP或RNN或Feature Map较小的时候不适用。</li>
<li><strong>GroupNorm</strong>：将channel方向分group，然后每个group内做归一化，算(C  G) * H * W的均值</li>
</ul>
<h3 id="batch-normbn">1、Batch Norm（BN）</h3>
<p>​ Ioffe 和 Szegedy 的开创性工作引入了批量归一化（BN）层，通过归一化特征统计显示简化了前馈网络的训练。 BN 层最初旨在加速判别网络的训练，但也被发现在生成图像建模中有效。</p>
<h5 id="输入"><strong>输入</strong>：</h5>
<p>​ <strong>An input batch</strong> <span class="math inline">\(x \in R^{N \times C \times H \times W}\)</span></p>
<h5 id="说明"><strong>说明</strong>：</h5>
<p>​ Batch Normalization就是对一个Batch中的数据进行标准化，就是每一个值减去batch的均值，除以batch的标准差，计算公式如下：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220116184553370.png" /></p>
<ul>
<li><p><span class="math inline">\(\gamma , \beta \in R^{C}\)</span>是从数据中训练得到的参数。</p></li>
<li><p><span class="math inline">\(\mu(x) , \sigma(x) \in R^{C}\)</span>是均值和方差，为每个特征通道（C）独立计算批量大小（N）和空间维度（H * W）</p></li>
<li><p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220116185246851.png" /></p></li>
</ul>
<h5 id="卷积网络中的bn"><strong>卷积网络中的BN</strong></h5>
<p>​ BN除了可以应用在MLP上，其在CNN网络中的表现也非常好，<strong>卷积网络和MLP的不同点是卷积网络中每个样本的隐层节点的输出是三维（宽度，高度，维度）的</strong>，而MLP是一维的。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_01_17_09_33_31_622.png" /></p>
<p>​ 在上图中，假设一个批量有 <span class="math inline">\(m\)</span>个样本，Feature Map的尺寸是 <span class="math inline">\({p \times q}\)</span>，通道数是<span class="math inline">\(d\)</span>。<strong>在卷积网络中，BN的操作是以Feature Map为单位的</strong>，因此一个BN要统计的数据个数为 <span class="math inline">\({m \times p \times q}\)</span>，每个Feature Map使用一组<span class="math inline">\(\gamma\)</span>和<span class="math inline">\({\beta}\)</span>.</p>
<h5 id="类比"><strong>类比</strong>：</h5>
<p>​ 如果把输入<span class="math inline">\(x \in R^{N \times C \times H \times W}\)</span>类比为一摞书，这摞书总共有 N 本，每本有 C 页，每页有 H 行，每行 W 个字符。BN 求均值时，相当于把这些书按页码一一对应地加起来（例如第1本书第36页，第2本书第36页......），再除以每个页码下的字符总数：N<strong>×</strong>H<strong>×</strong>W，因此可以把 <strong>BN 看成求“平均书”</strong>的操作（注意这个“平均书”每页只有一个字）。</p>
<h5 id="总结"><strong>总结：</strong></h5>
<p>​ BN是深度学习调参中非常好用的策略之一（另外一个可能就是Dropout），当你的模型发生<strong>梯度消失/爆炸或者损失值震荡比较严重</strong>的时候，在BN中加入网络往往能取得非常好的效果，因为BN能够起到平滑损失平面的作用。</p>
<p>​ BN也有一些不是非常适用的场景，在遇见这些场景时要谨慎的使用BN：</p>
<ul>
<li>受制于硬件限制，每个Batch的尺寸比较小，这时候谨慎使用BN；</li>
<li>在类似于RNN的<strong>动态网络</strong>中谨慎使用BN；</li>
<li>训练数据集和测试数据集方差较大的时候。</li>
</ul>
<h3 id="layer-normln">2、Layer Norm（LN）</h3>
<p>​ Layer Normalization（LN）的提出有效的解决了BN的这两个问题（一个是不适用于动态网络，一个是batch尺寸较小的时候）。LN和BN不同点是归一化的维度是互相垂直的。如下图所示。在图1中<span class="math inline">\(N\)</span>表示样本轴， <span class="math inline">\(C\)</span>表示通道轴， <span class="math inline">\(F\)</span>是每个通道的特征数量( W*H )。BN 如右侧所示，它是取不同样本的同一个通道的特征做归一化；LN则是如左侧所示，它取的是同一个样本的不同通道做归一化。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_01_17_09_33_37_355.png" /></p>
<h5 id="mlp中的ln"><strong>MLP中的LN</strong></h5>
<p>​ BN的两个缺点的产生原因均是因为<strong>计算归一化统计量时计算的样本数太少</strong>。LN是一个独立于batch size的算法，所以无论样本数多少都不会影响参与LN计算的数据量，从而解决BN的两个问题。</p>
<p>​ 先看MLP中的LN。设<span class="math inline">\(H\)</span>是一层中隐层节点的数量， <span class="math inline">\(l\)</span>是MLP的层数，我们可以计算LN的归一化统计量<span class="math inline">\(\mu\)</span>和<span class="math inline">\(\sigma\)</span>：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_01_17_09_24_28_295.png" /></p>
<p>​ 注意上面<strong>统计量的计算是和样本数量没有关系</strong>的，它的<strong>数量只取决于隐层节点的数量</strong>，所以只要隐层节点的数量足够多，我们就能保证LN的归一化统计量足够具有代表性。</p>
<p>​ 通过<span class="math inline">\(\mu ^{l}\)</span>和<span class="math inline">\(\sigma ^{l}\)</span>可以计算得到归一化后的值：<span class="math inline">\(\hat{a}^l\)</span></p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_01_17_09_26_22_177.png" /></p>
<p>​ BN的文章中介绍过几乎所有的归一化方法都能起到平滑损失平面的作用。<strong>所以从原理上讲，LN能加速收敛速度的。</strong>但我们发现，将LN添加到CNN后，实验结果表明LN破坏了卷积层学习到的特征，使得模型无法收敛，所以在CNN之后使用BN是一个较好的选择。</p>
<h5 id="类比-1"><strong>类比</strong>：</h5>
<p>​ LN 求均值时，相当于把每一本书的所有字加起来，再除以这本书的 字符总数：C<strong>×</strong>H<strong>×</strong>W，即求整本书的“平均字”，求标准差时也是同理。</p>
<h5 id="总结-1"><strong>总结</strong></h5>
<p>​ 总体而言，LN是和BN非常近似的一种归一化方法，不同的是<strong>BN取的是不同样本的同一个特征，而LN取的是同一个样本的不同特征</strong>。在BN和LN都能使用的场景中，<strong>BN的效果一般优于LN，原因是基于不同数据，同一特征得到的归一化特征更不容易损失信息。</strong></p>
<p>​ 但是有些场景是不能使用BN的，例如batchsize较小或者在RNN中，这时候可以选择使用LN，LN得到的模型更稳定且起到正则化的作用。RNN能应用到小批量和RNN中是因为LN的归一化统计量的计算是和batchsize没有关系的</p>
<h3 id="instance-normin">3、Instance Norm（IN）</h3>
<p>​ 对于图像风格迁移这类<strong>注重每个像素的任务</strong>来说，每个样本的每个像素点的信息都是非常重要的，于是像Batch Normlization这种每个批量的所有样本都做归一化的算法就不太适用了，因为BN计算归一化统计量时考虑了一个批量中所有图片的内容，从而<strong>造成了每个样本独特细节的丢失</strong>。同理对于LayerNormalization这类需要考虑一个样本所有通道的算法来说可能忽略了不同通道的差异，也不太适用于图像风格迁移这类应用。</p>
<p>​ 所以一篇论文提出了Instance Normalization（IN），一种更适合对单个像素有更高要求的场景的归一化算法（IST，GAN等）。IN的算法非常简单，<strong>计算归一化统计量时考虑单个样本，单个通道的所有元素</strong>。IN（右）和BN（中）以及LN（左）的不同从图1中可以非常明显的看出。<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_01_17_09_33_44_819.png" /></p>
<p>​ IN方法计算公式如下：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220117093553291.png" /></p>
<p>​ 不同于BN(x),这边的<span class="math inline">\(\mu(x) , \sigma(x) \in R^{C}\)</span>是均值和方差，是为每个实例的每个特征通道（C）独立计算的。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220117093715421.png" /></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220117093735940.png" /></p>
<p>​ IN在计算归一化统计量时并没有像BN那样跨样本、单通道，也没有像LN那样单样本、跨通道。它是取的单通道，单样本上的数据进行计算。所以对比BN的公式，它只需要它只需要去掉批量维的求和即可。</p>
<h5 id="类比-2"><strong>类比</strong>：</h5>
<p>​ IN 求均值时，相当于把一页书中所有字加起来，再除以该页的总字数：H<strong>×</strong>W，即求每页书的“平均字”，求标准差时也是同理。</p>
<h5 id="总结-2"><strong>总结</strong>：</h5>
<p>​ IN本身是一个非常简单的算法，<strong>尤其适用于批量较小且单独考虑每个像素点的场景中</strong>，因为其计算归一化统计量时没有混合批量和通道之间的数据，对于这种场景下的应用，我们可以考虑使用IN。</p>
<p>​ 另外需要注意的一点是在图像这类应用中，每个通道上的值是比较大的，因此也能够取得比较合适的归一化统计量。但是有两个场景建议不要使用IN:</p>
<ol type="1">
<li>MLP或者RNN中：因为在MLP或者RNN中，每个通道上只有一个数据，这时会自然不能使用IN；</li>
<li>Feature Map比较小时：因为此时IN的采样数据非常少，得到的归一化统计量将不再具有代表性。</li>
</ol>
<h3 id="group-normgn">4、Group Norm（GN）</h3>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/n6ck05dvpj.png" /></p>
<p>​ GN 把通道分为组，并计算每一组之内的均值和方差，以进行归一化。GN 的计算与批量大小无关，其精度也在各种批量大小下保持稳定。可以看到，GN和LN很像。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/1496926-9e0fd762d02d26c1.webp" /></p>
<h5 id="类比-3"><strong>类比</strong>：</h5>
<p>​ GN 相当于把一本 C 页的书平均分成 G 份，每份成为有 C/G 页的小册子，求每个小册子的“平均字”和字的“标准差”。</p>
<h5 id="总体"><strong>总体</strong>：</h5>
<p>​ <strong>LN 和 IN 在视觉识别上的成功率都是很有限的</strong>，对于<strong>训练序列模型（RNN/LSTM）或生成模型（GAN）</strong>很有效。所以，<strong>在视觉识别领域，BN用的比较多，GN就是为了改善BN的不足而来的。</strong></p>
<p>​ <strong>GN适用于占用显存比较大的任务，例如图像分割</strong>。对这类任务，可能 batchsize 只能是个位数，再大显存就不够用了。而当 batchsize 是个位数时，BN 的表现很差，因为没办法通过几个样本的数据量，来近似总体的均值和标准差。GN 是独立于 batch 的,所以可以适用。</p>
<h3 id="conditional-instance-normcin">5、Conditional Instance Norm（CIN）</h3>
<p>​ Dumoulin等人在进行风格迁移任务，使用IN的时候，用不同的<span class="math inline">\(\gamma\)</span>和 <span class="math inline">\(\beta\)</span>即可生成出风格不同的图像，于是提出了Conditional Instance Normalization(CIN)。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220117102111791.png" /></p>
<p>​ 其中s代表风格，<span class="math inline">\(\gamma ^s\)</span>和 <span class="math inline">\(\beta ^s\)</span>是学出来的，一组 <span class="math inline">\((\gamma ^s,\beta ^s)\)</span>对应一种风格。Dumoulin等人的方法迁移有限种的风格，想迁移新的的风格则需要训练新的模型。</p>
<p><strong>部分内容参考链接：</strong></p>
<p>https://zhuanlan.zhihu.com/p/54530247</p>
<p>https://zhuanlan.zhihu.com/p/56542480</p>
<p>https://www.jianshu.com/p/f15fcdf13438</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title>《Deep Residual Fourier Transformation for Single Image Deblurring》论文笔记</title>
    <url>/2022/01/14/92b79ab7b72b/</url>
    <content><![CDATA[<h4 id="论文名称deep-residual-fourier-transformation-for-single-image-deblurring">论文名称：《Deep Residual Fourier Transformation for Single Image Deblurring》</h4>
<h4 id="论文地址-httpsarxiv.orgabs2111.11745">论文地址： https://arxiv.org/abs/2111.11745</h4>
<h2 id="关键词">1、关键词：</h2>
<p>​ Image Deblurring、FFT、ResBlock</p>
<h2 id="领域背景">2、领域背景：</h2>
<p>​ Image Deblurring 图像去模糊，往往指由非常规相机或物体移动、光学虚焦等因素引起的一种现象，他们会导致看上去低质量的图像。</p>
<h2 id="先前工作描述与比较">3、先前工作描述与比较：</h2>
<p>​ 在先前，DeepDeblur使用CNN配合ResBlock，构建了多尺度的一个结构，使用Residual Block来聚焦学习模糊的图像和清晰的图像对之间的差距。并且取得了非常好的效果。但是，它也有一定的局限性：</p>
<ul>
<li><p>ResBlock通常在CNN中进行，其感知域容易受到限制（尤其是在比较前面的层），所以ResBlock的机制往往会无法对全局的信息进行建模（这些信息往往在从一个模糊图像重建一个清晰图像的时候较为有用）</p></li>
<li><p>先前的方法很少从频域的角度去关注模糊的图像和清晰的图像之间的关系，而我们发现，相较于模糊图像，清晰的图像往往包含更少的低频信息以及更多的高频信息。</p></li>
<li><p>CNN在捕获可见的特征的时候很厉害，但是对于频域的特征较弱，并且ResBlock 可能具备良好的高频信息的学习，但是对于低频信息的学习较弱一些。</p></li>
<li><p>论文贡献</p>
<ul>
<li>这篇论文提出的 <em>Residual Fast Fourier Transform with Convolution Block (Res FFT-Conv Block)</em>既能够捕获长距离信息，也能捕获短距离信息，同时也有能力考虑整个高频和低频的信息。通过使用这个Block还提出了一个框架，可以应用于图像去模糊领域 <em>Residual Fourier Transformation (DeepRFT) framework</em></li>
</ul></li>
</ul>
<h2 id="主要设计思想">4、主要设计思想：</h2>
<p>​ 提出了<strong>Residual Fast Fourier Transform with Convolution Block（Res FFT-Conv Block）</strong>模块，这是一个即插即用的模块。设计思想如下所示：</p>
<ul>
<li>Res FFT-Conv模块 将图像从空间域转至频域，然后使用<span class="math inline">\(1 \times 1\)</span>的卷积层进行卷积。由于FFT的特性，就能够使得在很early的层上卷积的感知域就能包含整个图像。其能更好的捕获模糊图像和清晰图像之间全局的差异。</li>
</ul>
<p>​ 提出了<strong>Deep Residual Fourier Transformation (DeepRFT) 框架</strong>，主要操作如下：</p>
<ul>
<li>DeepRFT框架通过将Res FFT-Conv模块插入进MIMO-UNet这个网络结构中，来进行图像去模糊的任务同时，使用DepthWise Over-parameterized Conolution以加速网络训练，达到很好的效果。</li>
</ul>
<h2 id="具体方法与网络架构">5、具体方法与网络架构：</h2>
<h3 id="resblocklook-back">1) ResBlock（Look Back）</h3>
<ul>
<li><p><strong>网络结构</strong>：包含两个<span class="math inline">\(3 \times 3\)</span>卷积层 以及 一个 RELU激活函数层</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114155111786.png" alt="image-20220114155111786" style="zoom: 50%;" /></p></li>
<li><p><strong>意义</strong>：能够训练更深的网络结构、拥有更大的感知域、加快训练时的收敛速度。卷积操作能够很好的学习到一些图像中的高频信息，因为其经常能够从图像的edges中捕获信息。</p></li>
<li><p><strong>缺陷</strong>：</p>
<ul>
<li>缺少对低频信息的建模能力</li>
<li>虽然我们能够通过堆叠模块来加大感知域，但是堆叠会带来巨大的计算复杂度。且在前几层网络中，感知域大小还是非常局部的，缺少全局的信息。</li>
</ul></li>
</ul>
<h3 id="residual-fast-fourier-transform-blockcurrent-substitute">2）Residual Fast Fourier Transform Block（Current Substitute）</h3>
<ul>
<li><p><strong>输入</strong>：<span class="math inline">\(Z \in R^{H \times W \times C}\)</span></p></li>
<li><p><strong>网络结构</strong>：两条残差流：</p>
<ul>
<li>与ResBlock一致的空间域信息残差流</li>
<li>基于Channel-Wise FFT的频域信息流，用于在频域中捕获图像的全局信息。</li>
</ul>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114155802644.png" alt="image-20220114155802644" style="zoom: 50%;" /></p></li>
<li><p><strong>核心实现-公式表达</strong>（最左侧的频域信息流）</p>
<ol type="1">
<li><span class="math inline">\(F(Z) \in C^{H \times W/2 \times C}\)</span>,对输入的特征Z，计算 2D real FFT ,由于傅立叶变换两侧对称，所以宽方向可以仅保留一半</li>
<li><span class="math inline">\(\widetilde{Z} = R(F(Z)) \odot_C I((F(Z))) \in R^{H \times W/2 \times 2C}\)</span>, 将傅立叶变换后的实数部分和虚数部分在Channel层面Concatenate起来</li>
<li>经过2个<span class="math inline">\(1 \times 1\)</span>的卷积层和1个ReLU激活函数层</li>
<li><span class="math inline">\(Y^{fft} = F^{-1}(f^{real} + jf^{img}) \in R^{H \times W \times C}\)</span>应用逆向2D real FFT来将 f <span class="math inline">\((f^{real} \odot_C f^{img} )\)</span>变换回空间域</li>
<li><span class="math inline">\(Y = Y^{fft} + Y^{res} + Z\)</span>，最终输出使用三个相加的形式得到。</li>
</ol></li>
</ul>
<h3 id="deep-residual-fourier-transform-framework">3） Deep Residual Fourier Transform Framework</h3>
<ul>
<li><p><strong>简介</strong>：基于MIMO-UNet进行的设计，MIMO-UNet是一个用于做多尺度图像去模糊的多输入多输出的U-Net架构。将MIMO-UNet中的所有ResBlocks用该论文提出的Res FFT-Conv Blocks进行替换。同时，我们额外将所有的<span class="math inline">\(1 \times 1\)</span>卷积层用我们提出的DO-Conv替换掉了。</p></li>
<li><p>MIMO-UNet 详细可以参见这篇论文：《Rethinking Coarse-to-Fine Approach in Single Image Deblurring》</p></li>
<li><p><strong>网络结构</strong>：</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114170635133.png" alt="image-20220114170635133" style="zoom:50%;" /></p></li>
</ul>
<h3 id="depthwise-over-parameterized-convolution">4）<strong>Depthwise over-parameterized convolution</strong></h3>
<ul>
<li><p><strong>简介</strong>：DO-Conv已经在许多高级别的视觉任务中显示出了它的潜力，它加速了训练并且通过使用深度卷积增强卷积层来获得更好的性能。DO-Conv 是两个相邻的线性运算，在操作时可以组合成传统的卷积运算。</p></li>
<li><p>具体可以参见这篇论文《DO-Conv: Depthwise Over-parameterized Convolutional》</p></li>
<li><p>论文链接：https://arxiv.org/pdf/2006.12030.pdf</p></li>
</ul>
<h3 id="loss-function">5） Loss Function</h3>
<ul>
<li><p><span class="math inline">\(Let\)</span><span class="math inline">\({k \in {0,……,K-1}}\)</span>为 DeepRFT的第k个层级</p></li>
<li><p><span class="math inline">\({\hat{S_k}}\)</span>为 <span class="math inline">\(k_{th}\)</span>重建图像</p></li>
<li><p><span class="math inline">\(S_k 为\)</span> <span class="math inline">\(k_{th}\)</span>GroundTruth清晰的图像</p></li>
<li><p>考虑3种，不同类型的Loss Function：</p>
<ul>
<li><p>Multi-Scale Charbonnier loss：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114171903475.png" alt="image-20220114171903475" style="zoom:50%;" /></p></li>
<li><p>Multi-Scale Edge loss：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114171944558.png" alt="image-20220114171944558" style="zoom:50%;" /></p></li>
<li><p>Multi-Scale Frequency Reconstruction (MSFR) 在频域计算，FT代表FFT操作</p></li>
</ul></li>
</ul>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114172909832.png" alt="image-20220114172909832" style="zoom: 50%;" /></p>
<ul>
<li>最终Loss函数：<span class="math inline">\(L = L_{msc} + \alpha_1L_{msed}+ \alpha_2L_{msfr}\)</span></li>
<li><span class="math inline">\(\alpha_1\)</span>、<span class="math inline">\(\alpha_2\)</span>为tradeoff参数，通常为0.05 和 0.01</li>
</ul>
]]></content>
      <categories>
        <category>⓶ 论文阅读笔记</category>
        <category>CV相关论文</category>
      </categories>
      <tags>
        <tag>FFT</tag>
        <tag>Image Deblurring</tag>
        <tag>Residual Block</tag>
      </tags>
  </entry>
  <entry>
    <title>《SwinIR- Image Restoration Using Swin Transformer》论文笔记</title>
    <url>/2022/01/13/45d8498aa8b8/</url>
    <content><![CDATA[<h3 id="论文名称swinir-image-restoration-using-swin-transformer">论文名称：《SwinIR: Image Restoration Using Swin Transformer》</h3>
<h3 id="论文链接httpsopenaccess.thecvf.comcontenticcv2021waimhtmlliang_swinir_image_restoration_using_swin_transformer_iccvw_2021_paper.html">论文链接：https://openaccess.thecvf.com/content/ICCV2021W/AIM/html/Liang_SwinIR_Image_Restoration_Using_Swin_Transformer_ICCVW_2021_paper.html</h3>
<h2 id="关键词">1、关键词：</h2>
<p>​ 图像修复（Image Restoration）、Transformer</p>
<h2 id="领域背景图像修复">2、领域背景—图像修复：</h2>
<p>​ 图像修复是一个经典问题，一般而言其目标为从低分辨率的图像中恢复出高分辨率的图像。通常可以用于超分辨率、图像去噪，以及JPEG压缩鬼影去除等应用。此篇文章将Swin Transformer应用于图像修复领域中。</p>
<h2 id="先前工作描述与比较">3、先前工作描述与比较：</h2>
<p>​ 和CNN比起来，Transformer设计了Self-Attention机制来捕获全局内容之间的信息交互，也在一系列的任务重得到了比较好的结果。但是ViT用于图像恢复的话，因为Vit要划分patch，所以就会不可避免的导致恢复的图像在patch和patch之间有边界感，同时每一个patch邻近边界的像素也会因为缺少信息而没法做出更好的恢复效果。</p>
<p>​ <strong>先前方法的问题</strong>：使用基于CNN的方法进行图像修复：会存在两个源于卷积层本身带来的基本的问题：</p>
<p>1、图像和卷积核之间是内容无关的，我们用同一个卷积核去修复不同的图像区域，可能并不是一个好的选择</p>
<p>2、由于CNN的local processing方案，卷积层是在局部邻域（ local neighborhood ）内建立像素关系，其长距离的依赖关系（long-range dependency）主要通过深度叠加卷积层来进行建模，有的时候可能并不是很有效</p>
<p>​ 而Swin Transformer，结合了两者的优势。既能够像CNN那样处理大尺度的图像，也能弥补CNN在long-range dependency上的不足（使用SW-MSA机制）</p>
<h2 id="主要设计思想">4、主要设计思想：</h2>
<p>​ SwinIR由三部分组成。首先浅层特征提取部分是由卷积层组成的，输出结果将直接传输到重建模块中，为了保持图像本身的低频信息，而深层特征提取模块主要由RSTB（Residual Swin Transformer blocks）组成。同时，其在每一个block的后面还加了一层卷积层，来做特征加强，以及使用残差网络来为特征聚合提供捷径。最终，浅层和深层特征被输送到重建模块，进行高质量的图像重建。总体流程概括如下：</p>
<ul>
<li>浅层特征提取：<strong>低质量图像</strong> <span class="math inline">\(\to\)</span><strong>浅层特征图</strong></li>
<li>深层特征提取：<strong>浅层特征图</strong><span class="math inline">\(\to\)</span><strong>深层特征图</strong></li>
<li>高质量图片生成：<strong>浅层特征图</strong>+<strong>深层特征图</strong><span class="math inline">\(\to\)</span><strong>高质量图像</strong></li>
</ul>
<h2 id="具体方法与网络架构">5、具体方法与网络架构：</h2>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/network_swinir.png" /></p>
<p>​ 首先，对于这一整个架构而言，分为3大块，分别是浅层特征提取、深层特征提取以及图像重建，<strong>对于不同的任务而言，我们使用相同的特征提取模块，但是会使用不同的图像重建模块</strong>。</p>
<h3 id="浅层特征提取shallow-feature-extraction">1）浅层特征提取(Shallow Feature Extraction)</h3>
<ul>
<li><strong>概述</strong>：使用卷积网络从<strong>低质量图像</strong>中提取<strong>浅层特征图</strong></li>
<li><strong>输入</strong>：<strong>低质量图像(LQ)</strong> <span class="math inline">\(I_{LQ}\in R^{H\times W\times C_{in}}\)</span></li>
<li><strong>输出</strong>：<strong>浅层特征图</strong> <span class="math inline">\(F_{0}\in R^{H\times W\times C_{embed}}\)</span>，<span class="math inline">\(C_{embed}\)</span>为特征通道数目</li>
<li><strong>网络结构</strong>：单层<span class="math inline">\(3\times3\)</span>卷积网络</li>
<li><strong>公式表达</strong>：<span class="math inline">\(F_{0}=H_{SF}(I_{LQ})\)</span>，其中<span class="math inline">\(H_{SF}\)</span>为卷积网络</li>
<li><strong>实现细节（官方代码）</strong>
<ul>
<li><span class="math inline">\(H_{SF}\)</span>为单层，输入图像通道<span class="math inline">\(C_{in}=3\)</span>，输出特征通道<span class="math inline">\(C=96\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络</li>
</ul></li>
<li><strong>意义</strong>：卷积层在前期的视觉处理中往往能起到较好的效果，能够导致一个较为稳定的结果，同时也提供了一个从图像空间映射到高维特征空间的手段。</li>
</ul>
<h3 id="深层特征提取deep-feature-extraction">2）深层特征提取(Deep Feature Extraction)：</h3>
<ul>
<li><p><strong>输入</strong>：<strong>浅层特征图</strong><span class="math inline">\(F_{0}\in R^{H\times W\times C_{embed}}\)</span></p></li>
<li><p><strong>输出</strong>：<strong>深层特征图</strong><span class="math inline">\(F_{DF}\in R^{H\times W\times C_{embed}}\)</span></p></li>
<li><p><strong>网络结构：</strong></p>
<ul>
<li><span class="math inline">\(K\)</span>个串联的Residual Swin Transformer Block（RSTB）和 <span class="math inline">\(1\)</span>个卷积层 构成</li>
<li>每个RSTB（Residual Swin Transformer Block）内部由<span class="math inline">\(L\)</span>个串联的 Swin Transformer Layer（STL）和 一个卷积层构成（如上图a）</li>
<li>STL（Swin Transformer Layer）结构为Layer Norm<span class="math inline">\(\to\)</span>MSA<span class="math inline">\(\to\)</span>Layer Norm<span class="math inline">\(\to\)</span>MLP 且 MSA和MLP后有残差连接（如上图b）</li>
</ul></li>
<li><p><strong>公式表达</strong>：</p>
<ul>
<li><strong>整体结构</strong>：
<ul>
<li><span class="math inline">\(F_i=H_{RSTB_i}(F_{i-1}),\ i=1,2,...,K\)</span></li>
<li><span class="math inline">\(F_{DF}=H_{CONV}(F_{K})\)</span></li>
</ul></li>
<li><strong>RSTB</strong>：
<ul>
<li><span class="math inline">\(F_{i,j}=H_{Swin_{i,j}}(F_{i,j-1}),\ j=1,2,...,L\)</span></li>
<li><span class="math inline">\(F_i=H_{CONV_i}(F_{i,L})\)</span></li>
</ul></li>
<li><strong>STL</strong>：
<ul>
<li><span class="math inline">\(H_{Swin_{i,j}}(X)=STL_2(STL_1(X))\)</span></li>
<li><span class="math inline">\(STL_1(X)=MSA(LN(X))+X\)</span></li>
<li><span class="math inline">\(STL_2(X)=MLP(LN(X))+X\)</span></li>
</ul></li>
</ul></li>
<li><p><strong>实现细节（官方代码）</strong></p>
<ul>
<li><p><strong>PatchEmbed和PatchUnEmbed操作</strong></p>
<ul>
<li>代码中使用PatchEmbed操作将<span class="math inline">\(224\times224\)</span>的特征图拆分为<span class="math inline">\(16\times16\)</span>的Patch，并且有可选的LayerNorm操作</li>
<li>对应的代码中使用PatchUnEmbed操作将<span class="math inline">\(16\times16\)</span>的Patch还原为<span class="math inline">\(224\times224\)</span>的特征图</li>
<li>PatchEmbed和PatchUnEmbed操作的执行逻辑如下
<ul>
<li>每一个RSTB的开头，执行PatchEmbed操作</li>
<li>每一个RSTB的卷积操作前，执行PatchUnEmbed操作</li>
<li>只在第一个RSTB开头的PatchEmbed操作中，使用LayerNorm</li>
</ul></li>
</ul></li>
<li><p><strong>RSTB的串联数量（<span class="math inline">\(K\)</span>的取值）</strong></p>
<ul>
<li>虽然论文图片中的RSTB有6个，但在代码中只有4个，即<span class="math inline">\(K=4\)</span></li>
</ul></li>
<li><p><strong>STL的串联数量（<span class="math inline">\(L\)</span>的取值）</strong></p>
<ul>
<li>代码中每个RSTB内部的STL的数目为6个，与论文图片中的一致，即<span class="math inline">\(L=6\)</span></li>
</ul></li>
<li><p><strong>配对的STL</strong></p>
<ul>
<li>如前述所说，每个RSTB中STL的数目为6个，其中每两个STL构成一组，第一个STL内的MSA为Swin中的W-MSA，第二个为Swin中的SW-MSA，这一操作与原版Swin中的一致</li>
</ul></li>
<li><p><strong>卷积操作</strong></p>
<ul>
<li>对于整个深层特征提取模块末尾和RSTB内部的卷积，代码根据任务不同分为两种
<ol type="1">
<li>对于小模型任务，如一般图片、轻量图片的SR、图片降噪和JPEG格式压缩图像修复，采用的是单层，输入输出维度为<span class="math inline">\(C_{embed}=96\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络</li>
<li>对于大模型任务，如真实世界图片SR，采用的是一个多层卷积网络
<ul>
<li>第一层为输入维度为<span class="math inline">\(C_{embed}=96\)</span>，输出维度为<span class="math inline">\(C_{embed}/4\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络，并对输出进行LeakyReLu</li>
<li>第二层为输入维度为<span class="math inline">\(C_{embed}/4\)</span>，输出维度为<span class="math inline">\(C_{embed}/4\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络，并对输出进行LeakyReLu</li>
<li>第三层为输入维度为<span class="math inline">\(C_{embed}/4\)</span>，输出维度为<span class="math inline">\(C_{embed}\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络</li>
</ul></li>
</ol></li>
</ul></li>
</ul></li>
<li><p><strong>意义</strong>：</p>
<ul>
<li>作者认为在所有RSTB后面，再加一层Conv层，能够将卷积操作的归纳偏置(inductive bias)带入这类基于Transformer骨架的网络中，为后续浅层和深层特征的融合打好基础。</li>
<li><!--具体的作用需要通过实验验证，这个Conv层是否是必要的。--></li>
<li>对于单个RSTB内部的卷积操作，论文认为卷积核在空间上的不变性可以增强提取出特征的平移不变性</li>
<li>残差连接为不同的RSTB模块提供了一个到后续图像重建模块的短连接，允许不同级别的特征在最后一个重建模块中更好的进行聚合。</li>
<li><!--同样，具体的作用需要通过实验验证，这个Conv层是否是必要的。--></li>
</ul></li>
</ul>
<h3 id="高质量图像修复-hq-image-reconstruction">3）高质量图像修复 (HQ Image Reconstruction)：</h3>
<ul>
<li><strong>概述</strong>：根据<strong>浅层与深层特征图</strong>生成<strong>高质量图像</strong>，浅层特征负责包含低频信息，深层特征聚焦于恢复丢失的高频信息。</li>
<li><strong>输入</strong>：<strong>浅层特征图</strong> <span class="math inline">\(F_{0}\in R^{H\times W\times C_{embed}}\)</span>和 <strong>深层特征图</strong> <span class="math inline">\(F_{DF}\in R^{H\times W\times C_{embed}}\)</span></li>
<li><strong>输出</strong>：<strong>高质量重建图像(RHQ)</strong> <span class="math inline">\(I_{RHQ}\in R^{H&#39;\times W&#39;\times C_{out}}\)</span></li>
<li><strong>网络结构</strong>：卷积网络</li>
<li><strong>公式表达</strong>：<span class="math inline">\(I_{RHQ}=H_{REC}(F_{0}+F_{DF})\)</span>，其中<span class="math inline">\(H_{REC}\)</span>为重建模块函数，其实在实现上就是一个卷积模块</li>
<li><strong>实现细节（官方代码）</strong>
<ul>
<li><span class="math inline">\(H_{REC}(F_{0}+F_{DF})\)</span>中的“+”号就是数学意义上的相加，本质上是残差连接</li>
<li><strong>卷积操作</strong>
<ul>
<li>根据任务不同分为四种卷积操作：
<ol type="1">
<li>对于图像去噪和JPEG格式压缩图像修复，采用的是单层，输入维度为<span class="math inline">\(C_{embed}=96\)</span>，输出维度为<span class="math inline">\(C_{out}=3\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络，同时卷积输出与输入使用残差连接，即<span class="math inline">\(H_{REC}(X)=H_{CONV}(X)+X\)</span></li>
<li>对于一般图像SR，卷积分为三层
<ul>
<li>第一层进行特征降维，为输入维度为<span class="math inline">\(C_{embed}=96\)</span>，输出维度为<span class="math inline">\(C_{feat}=64\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络，并对卷积输出进行LeakyReLU</li>
<li>第二层进行上采样，先通过输入维度为<span class="math inline">\(C_{feat}=64\)</span>，输出维度为<span class="math inline">\(4\times C_{feat}\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络，然后对卷积输出进行PixelShuffle</li>
<li>第三层为输入维度为<span class="math inline">\(C_{feat}=64\)</span>，输出维度为<span class="math inline">\(C_{out}=3\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络</li>
</ul></li>
<li>对于轻量图像SR，为了减少参数，采用的是单层，输入维度为<span class="math inline">\(C_{feat}=64\)</span>，输出维度为<span class="math inline">\(Scale^2\times C_{out}\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络，然后对卷积输出进行PixelShuffle</li>
<li>对于真实世界图像SR，使用多层卷积
<ul>
<li>第一层进行特征降维，为输入维度为<span class="math inline">\(C_{embed}=96\)</span>，输出维度为<span class="math inline">\(C_{feat}=64\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络，并对卷积输出进行LeakyReLu</li>
<li>第二、三层进行上采样，先使用torch.nn.functional.interpolate函数进行指定<span class="math inline">\(Scale\)</span>的最近邻上采样，然后通过输入输出维度为<span class="math inline">\(C_{feat}=64\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络，并对卷积输出进行LeakyReLU</li>
<li>第四层为输入输出维度为<span class="math inline">\(C_{feat}=64\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络，并对卷积输出进行LeakyReLU</li>
<li>第五层为输入维度为<span class="math inline">\(C_{feat}=64\)</span>，输出维度为<span class="math inline">\(C_{out}=3\)</span>，步长<span class="math inline">\(stride=1\)</span>，填充<span class="math inline">\(pading=1\)</span>的<span class="math inline">\(3\times3\)</span>卷积网络</li>
</ul></li>
</ol></li>
</ul></li>
</ul></li>
</ul>
<h3 id="其他细节">4） 其他细节：</h3>
<p>​ 上述总的结构中看到的<strong>Skip-Connection</strong>，是能够将浅层特征直接输入到重建模块中，让深层特征提取模块专注于高频信息的提取以及能够获得更稳定的训练。</p>
<h3 id="使用的损失函数根据任务情况略有不同">5） 使用的损失函数：（根据任务情况略有不同）</h3>
<ul>
<li><p>对于一般图像以及轻量图像SR，使用<strong>L1 Loss</strong>,<span class="math inline">\(I_{RHQ}\)</span>为重建的高质量图像，<span class="math inline">\(I_{HQ}\)</span>为Ground_Truth高质量图像</p>
<ul>
<li><span class="math inline">\(L = \sqrt{||I_{RHQ} - I_{HQ} ||_1}\)</span></li>
</ul></li>
<li><p>对于真实世界图像SR，会结合<strong>Pixel Loss</strong>和<strong>GAN Loss</strong>以及<strong>Percepture Loss</strong>来提升生成质量</p></li>
<li><p>对于去噪和JPEG压缩任务而言，我们使用<strong>Charbonnier Loss</strong>进行优化</p>
<ul>
<li><span class="math inline">\(\sqrt{||I_{RHQ}-I_{HQ}||^2 + \varepsilon^2 }\)</span>, <span class="math inline">\(\varepsilon\)</span>是个常数，通常被设置为<span class="math inline">\(10^{-3}\)</span></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>⓶ 论文阅读笔记</category>
        <category>CV相关论文</category>
      </categories>
      <tags>
        <tag>Swin Transformer</tag>
        <tag>Image Restoration</tag>
      </tags>
  </entry>
  <entry>
    <title>《Uformer A General U-Shaped Transformer for Image Restoration》论文笔记</title>
    <url>/2022/01/13/56f3e5f0e0f5/</url>
    <content><![CDATA[<h3 id="论文名称uformer-a-general-u-shaped-transformer-for-image-restoration">论文名称：《Uformer: A General U-Shaped Transformer for Image Restoration》</h3>
<h3 id="论文地址-httpsarxiv.orgabs2106.03106">论文地址： https://arxiv.org/abs/2106.03106</h3>
<h2 id="关键词">1、关键词：</h2>
<p>​ 图像修复（Image Restoration）、类UNet结构、Transformer</p>
<h2 id="领域背景图像修复">2、领域背景—图像修复：</h2>
<p>​ 图像修复是一个经典问题，一般而言其目标为从低分辨率的图像中恢复出高分辨率的图像。通常可以用于超分辨率、图像去噪，以及JPEG压缩鬼影去除等应用。此篇文章将Swin Transformer应用于图像修复领域中。</p>
<h2 id="先前工作描述与比较">3、先前工作描述与比较：</h2>
<p>​ 近年来图像修复很好结果的都是基于卷积的网络，但是卷积网络在long-range dependencies上依旧存在局限性。同时，最近也有很多文章使用transofmer对低分辨率的特征图进行处理（限于self-attention的计算复杂度）。</p>
<h2 id="主要设计思想">4、主要设计思想：</h2>
<p>​ 论文旨在 在多尺度分辨率下，去恢复更多的图像细节。Uformer基于UNet，只不过将所有的卷积层替换为了Encoder-Decoder结构，同时保留了整体的Encoder-Decoder架构以及skip-connections。总体来说就是使用TransformerBlock 构建了一个层次化的encoder-decoder网络。</p>
<p>​ <strong>2个核心设计</strong></p>
<p>​ 1、<strong>LeWin Transformer Block</strong>( locally-enhanced window Transformer block ),使用分块的self-attetiond代替全局的self-attention，在捕获高分辨率图像的局部特征时，减少了计算量。</p>
<p>​ 2、提出了<strong>可学习的多尺度恢复调制器</strong>，以多尺度 <strong>spatial bias</strong> 的形式去在decoder的不同层上调节特征。来处理不同的图像退化问题（比如说虚焦、运动模糊等。这个模块本身由一个多尺度的spatial bias组成，用来在decoder的不同层级上调整特征。更具体一点的话，就是一个可学习的基于窗口的tensor张量，和特征直接相加，从而来调整特征能够恢复更多的细节。整体而言，这个调制器对于恢复图像细节而言有非常强的能力，同时只带来了一点点额外的参数和计算代价。</p>
<h2 id="具体方法与网络架构">5、具体方法与网络架构：</h2>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220112112308268.png" /></p>
<h3 id="整体架构overall-pipeline">1) 整体架构（Overall Pipeline）</h3>
<ul>
<li><strong>概述</strong>：U型带Skip-Connection的Encoder-Decoder网络，基于UNet结构，但是将UNet中的所有卷积层都替换成了LeWinBlocks。</li>
<li><strong>输入</strong>：退化图像 <span class="math inline">\(I \in R^{3\times H\times W}\)</span></li>
<li><strong>输出</strong>：修复图像 <span class="math inline">\(I^{&#39;} \in R^{3\times H\times W}\)</span>
<ul>
<li><span class="math inline">\(Residual \in R^{3\times H\times W }\)</span></li>
<li><span class="math inline">\(I^{&#39;} = I + R e sidual\)</span></li>
</ul></li>
</ul>
<h3 id="input-projection">2) Input Projection</h3>
<ul>
<li><strong>概述</strong>：用于从退化图像中提取低层级信息</li>
<li><strong>输入</strong>：退化图像 <span class="math inline">\(I \in R^{3\times H\times W}\)</span></li>
<li><strong>输出</strong>：low-level 特征图 <span class="math inline">\(X_0\)</span></li>
<li><strong>网络结构</strong>：
<ul>
<li><span class="math inline">\(3\times 3\)</span>卷积层 + LeakyReLU激活函数</li>
</ul></li>
</ul>
<h3 id="encoder---one-stage-encoder中总共k个stage">3) Encoder - One Stage （ Encoder中总共K个Stage ）</h3>
<ul>
<li><strong>概述</strong>：用于从退化图像中提取低层级信息</li>
<li><strong>输入</strong>：特征图 <span class="math inline">\(X_{l-1}\)</span></li>
<li><strong>输出</strong>：第<span class="math inline">\(l\)</span>个阶段的输出特征图 <span class="math inline">\(X_l \in R^{2^lC \times \frac{H}{2^l} \times \frac{W}{2^l}}\)</span></li>
<li><strong>网络结构</strong>：
<ul>
<li><span class="math inline">\({N_l}\)</span>个 LeWinBlocks的叠加，以及一个下采样层（$4  $卷积 $stride$2）</li>
</ul></li>
<li><strong>实现细节（官方代码）</strong>
<ul>
<li>LeWinBlocks
<ul>
<li>将2D空间特征图先进行patch划分，然后展平，具体见后</li>
</ul></li>
<li>Down Sampling：（channel 翻倍，特征图宽高 减半）
<ul>
<li>Reshape 展平的特征 至 2D的空间特征图，然后使用 <span class="math inline">\(4 \times 4\)</span>卷积 $stride$2，对其进行卷积</li>
</ul></li>
</ul></li>
<li><strong>意义</strong>：在一遍遍的下采样与Lewin Transformer Blocks中提取特征信息，Lewin Transformer Block可以更好的提取远距离的相关性依赖信息，并且有效的降低计算复杂度</li>
</ul>
<h3 id="bottleneck-stage">4) BottleNeck Stage</h3>
<ul>
<li><strong>概述</strong>：用于提取更长距离的信息，甚至是全局的信息</li>
<li><strong>输入</strong>：特征图 <span class="math inline">\(X_{K}\)</span></li>
<li><strong>输出</strong>：序列向量 V</li>
<li><strong>网络结构</strong>：
<ul>
<li><span class="math inline">\({N_?}\)</span>个 LeWinBlocks的叠加</li>
</ul></li>
<li><strong>实现细节（官方代码）</strong>
<ul>
<li>LeWinBlocks
<ul>
<li>将2D空间特征图先进行patch划分，然后展平，具体见后</li>
</ul></li>
</ul></li>
<li><strong>意义</strong>：由于前面已经进行了许多次的特征提取以及下采样了，所以在此处再增加一个LeWinBlocks的模块，能够捕获到更长距离的信息，甚至是能够捕获全局的信息。</li>
</ul>
<p><!-- 但是这个模块难道不可以用Encoder阶段更大的K 来弥补吗？需要实验 --></p>
<h3 id="decoder---one-stage-decoder中总共k个stage与encoder一致">5）Decoder - One Stage （Decoder中总共K个Stage，与Encoder一致 ）</h3>
<ul>
<li><strong>概述</strong>：用于小尺寸的特征图中逐渐重建恢复特征信息</li>
<li><strong>输入</strong>：1维特征序列 <span class="math inline">\(V_{in}\)</span></li>
<li><strong>输出</strong>：1维特征输出序列 <span class="math inline">\(V_{out}\)</span></li>
<li><strong>网络结构</strong>：
<ul>
<li>一个上采样层（$2  $反卷积 $stride$2）以及 <span class="math inline">\({N_l}\)</span>个 LeWinBlocks的叠加</li>
</ul></li>
<li><strong>实现细节（官方代码）</strong>
<ul>
<li>Up Sampling：（channel 减半，特征图宽高 翻倍）
<ul>
<li>先将输入的特征序列 Reshape 成 2D特征图，然后进行上采样，得到新的2D特征图</li>
</ul></li>
<li>Residual Module：
<ul>
<li>Up Sampling 完以后得到的2D特征图需要和对应Encoder-Stage中 输出的2D特征图进行Concat，然后得到一个新的2D特征图。</li>
</ul></li>
<li>LeWinBlocks
<ul>
<li>将残差Concat得到的2D空间特征图先进行patch划分，然后展平，具体见后</li>
</ul></li>
</ul></li>
<li><strong>意义</strong>：在一遍遍的上采样与Lewin Transformer Blocks中重建特征信息。</li>
</ul>
<h3 id="output-projection">6) Output Projection</h3>
<ul>
<li><strong>概述</strong>：用于将输出的序列，变换成2D特征图后，再 映射至 3通道的残差图像，准备和原图像叠加。</li>
<li><strong>输入</strong>：1维特征输出序列 <span class="math inline">\(V_{out}\)</span></li>
<li><strong>输出</strong>：残差图像 <span class="math inline">\(Residual \in R^{3\times H\times W }\)</span></li>
<li><strong>网络结构</strong>：
<ul>
<li><span class="math inline">\(3\times 3\)</span>卷积层</li>
</ul></li>
<li><strong>实现细节（官方代码）</strong>：
<ul>
<li>先将 最后一个Decoder Stage输出的 序列 <span class="math inline">\(V_{out}\)</span>Reshape成2D的特征图，然后应用<span class="math inline">\(3 \times 3\)</span>的卷积层，来获得一个残差图像</li>
</ul></li>
</ul>
<h3 id="最终输出-loss函数">7）最终输出 &amp; Loss函数</h3>
<ul>
<li><strong>概述</strong>：将OutPut Projection 得到的Residual Image 和 原来的输入图像相加，得到 最终的修复图像。</li>
<li><strong>Loss</strong>：使用 <strong>Charbonnier Loss</strong>，<span class="math inline">\(I^{&#39;}\)</span>是 ground-truth 图像
<ul>
<li><span class="math display">\[l(I^{&#39;},\hat I) = \sqrt{||I^{&#39;} - \hat I||^2 + \varepsilon^2}\]</span></li>
</ul></li>
</ul>
<h3 id="lewin-transformer-block">8）LeWin Transformer Block</h3>
<ul>
<li><p><strong>概述</strong>：由W-MSA 以及LeFF两个模块组成</p></li>
<li><p><strong>输入</strong>：2D特征图</p></li>
<li><p><strong>输出</strong>：2D特征图</p></li>
<li><p><strong>网络结构</strong>：公式表达：</p>
<ul>
<li><span class="math inline">\(X_{l}^{&#39;} = W-MSA(LN(X_{l-1})) + X_{l-1}\)</span><strong>W-MSA 模块的输出</strong></li>
<li><span class="math inline">\(X_l = LeFF(LN(X_l^{&#39;})) + X_l^{&#39;}\)</span>**LeFF模块的输出*</li>
</ul></li>
<li><p><strong>实现细节（官方代码）</strong>：</p>
<ul>
<li><p>W-MSA 与 Vision Transformer中一致</p></li>
<li><p>作者论文中说尝试了移动窗口，但是带来的结果好坏增长微乎其微，说明：在图像修复领域，窗口与窗口之间的信息交互并不是很重要。图像修复领域比较注重局部的信息交互？</p></li>
<li><p>LeFF模块结构：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/截屏2022-01-12%20下午3.31.12.png" /></p>
<ul>
<li>1、对于每个Token，应用一个Linear Projection，增加特征channel</li>
<li>2、将tokens Reshape 成 2D 特征图，用 <span class="math inline">\(3 \times 3\)</span>depth-wise convolutional 捕获局部信息</li>
<li>3、再将2D特征图展平回tokens，再应用一个Linear Projection，缩减特征channel</li>
<li>在每一个Linear Projection / Convolution 后都会应用 GELU激活函数。</li>
</ul></li>
</ul></li>
<li><p><strong>意义</strong>：解决了如下两个问题 1）全局计算self-attention复杂度太高 2）在捕捉局部的依赖关系时有限制。</p></li>
</ul>
<h3 id="multi-scale-restoration-modulator">9）Multi-Scale Restoration Modulator</h3>
<ul>
<li><strong>概述</strong>：因为不同的图像有不同的混乱残差形式，比如模糊、噪音、下雨等等，为了更好的应对各种不同的修复任务，提出了这个light-weight multi-scale的恢复模块。来calibrate特征以及更好的修复细节。<br />
</li>
<li><strong>网络结构</strong>：
<ul>
<li>在每一个LeWin Transformer Block中，其为一个<span class="math inline">\(M \times M \times C\)</span>大小的张量，M为window_size，C为特征图通道数。</li>
<li>在一个LeWin Transformer Block中，对于所有其分割出来的windows，这个 调制器模块的参数都是共享的。</li>
</ul></li>
<li><strong>形式</strong>：在Self-Attention计算前，将其直接加到每一个窗口的像素值上。</li>
<li><strong>意义</strong>：在Image Deblurring 和 Image Denoising里面，作者证实了该模块的重要性，能够更好的修复细节。一种可能的解释是添加 在解码器的每个阶段的modulator可以对特征图进行更为灵活的调整，从而提高恢复的细节的性能表现。这个跟先前的StyleGAN的某个模块一致。</li>
</ul>
]]></content>
      <categories>
        <category>⓶ 论文阅读笔记</category>
        <category>CV相关论文</category>
      </categories>
      <tags>
        <tag>UNet</tag>
        <tag>Swin Transformer</tag>
        <tag>Image Restoration</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记6——全卷积网络FCN &amp; U-Net结构</title>
    <url>/2022/01/12/8c9b3da724b3/</url>
    <content><![CDATA[<p>本文讲解FCN与U-Net相关的知识，在此之前你需要了解CNN是什么</p>
<h3 id="一fcn全卷积网络">一、FCN全卷积网络</h3>
<p>​ 首先，我们还是要回顾一下CNN的整体网络架构与优势：CNN网络最后输出的是类别的概率值。CNN 的强大之处在于它的多层卷积结构能自动学习特征，并且可以学习到多个层次的特征：</p>
<p>​ 较浅的卷积层感知域较小，学习到一些局部区域的特征。</p>
<p>​ 而较深的卷积层具有较大的感知域，能够学习到更加抽象一些的特征。这些抽象特征对物体的大小、位置和方向等敏感性更低，从而有助于识别性能的提高。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114212245766.png" /></p>
<p>​ 而FCN相较于CNN来说，其将CNN最后几个用于输出概率的全连接层都改成了卷积层，从而使得模型网络中所有的层都是卷积层，最终输出一张已经label好的图像，故称为全卷积网络。全卷积神经网络主要使用了三种技术：</p>
<p>​ 1、卷积化（Convolutional）</p>
<p>​ 2、上采样（Upsample）</p>
<p>​ 3、跳跃结构（Skip Layer）</p>
<p>​ 整个FCN网络基本原理如图5（只是原理示意图）：</p>
<p>​ 1、image经过多个卷积和+一个max pooling变为pool1 feature，宽高变为1/2</p>
<p>​ 2、pool1 feature再经过多个conv+一个max pooling变为pool2 feature，宽高变为1/4</p>
<p>​ 3、pool2 feature再经过多个conv+一个max pooling变为pool3 feature，宽高变为1/8</p>
<p>​ 4、......</p>
<p>​ 5、直到pool5 feature，宽高变为1/32。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/dsawqeasd.png" /></p>
<p>那么，对于三种不同规格参数的FCN，后续还原操作也不太一样，如下所示：</p>
<p>​ 1、对于FCN-32s，直接对pool5 feature进行32倍上采样获得32x upsampled feature，再对32x upsampled feature每个点做softmax prediction获得32x upsampled feature prediction（即语义分割图）。</p>
<p>​ 2、对于FCN-16s，首先对pool5 feature进行2倍上采样获得2x upsampled feature，再把pool4 feature和2x upsampled feature逐点相加，然后对相加的feature进行16倍上采样，并softmax prediction，获得16x upsampled feature prediction。</p>
<p>​ 3、对于FCN-8s，首先进行pool4+2x upsampled feature逐点相加，然后又进行pool3+2x upsampled逐点相加，即进行更多次特征融合。具体过程与16s类似，不再赘述。</p>
<p>​ 在上述处理过程中，我们发现FCN-16s和FCN-8s都引入了skip connection，将pool3或是pool4 feature与pool5上采样后的feature逐像素相加，进行多次特征融合，这样处理的原因在于：</p>
<p>​ FCN模型虽然通过卷积和反卷积我们基本能定位到目标区域，但是，我们会发现模型前期是通过卷积、池化、非线性激活函数等作用输出了特征权重图像，我们经过反卷积等操作输出的<strong>图像实际是很粗糙的</strong>，毕竟丢了很多细节。因此我们需要找到一种方式填补丢失的细节数据，所以就有了跳跃结构。</p>
<p>​ 作者在原文种给出3种网络结果对比，明显可以看出效果：FCN-32s &lt; FCN-16s &lt; FCN-8s，即使用多层feature融合有利于提高分割准确性。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114212421618.png" /></p>
<h4 id="fcn优点">FCN优点：</h4>
<p>​ 与传统用CNN进行图像分割的方法相比，FCN有两大明显的优点：一是可以接受任意大小的输入图像，而不用要求所有的训练图像和测试图像具有同样的尺寸。二是更加高效，因为避免了由于使用像素块而带来的重复存储和计算卷积的问题。</p>
<h4 id="fcn缺点">FCN缺点：</h4>
<p>1、分割的结果不够精细。图像过于模糊或平滑，没有分割出目标图像的细节</p>
<p>2、因为模型是基于CNN改进而来，即便是用卷积替换了全连接，但是依然是独立像素进行分类，没有充分考虑像素与像素之间的关系</p>
<h2 id="二关于卷积网络中降采样与上采样以及特征提取阶段的理解">二、关于卷积网络中降采样与上采样以及特征提取阶段的理解：</h2>
<p>​ 1、降采样的理论意义是，它可以增加对输入图像的一些小扰动的鲁棒性，比如图像平移，旋转等，减少过拟合的风险，降低运算量，增加感受野的大小。</p>
<p>​ 2、上采样的最大的作用其实就是把抽象的特征再还原到原图的尺寸，最终得到分割结果。但很容易得到模糊或过于平滑的结果，无法还原细节部分。</p>
<p>​ 3、对于特征提取阶段，浅层结构可以抓取图像的一些简单的特征，比如边界，颜色，而深层结构因为感受野大了，而且经过的卷积操作多了，能抓取到图像的一些抽象特征。</p>
<h3 id="三unet网络">三、UNet网络</h3>
<p>​ UNet网络整体结构如下：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114212533302.png" /></p>
<p>​ 蓝色箭头代表3*3的卷积层+ReLU激活函数层</p>
<p>​ 红色箭头代表2*2的最大池化层</p>
<p>​ 绿色箭头代表2*2的上采样层（通常采用反卷积）</p>
<p>​ 浅蓝色箭头代表1*1的卷积层，在最后用于调整输出通道数目</p>
<p>​ 在整一个过程中，值得注意的是灰色箭头，我们会注意到灰色箭头代表的是“copy and crop”，即复制和剪切。我们以第一层的灰色箭头举例来看：其左侧大小为64 * 568 * 568，右侧大小为128 * 392 * 392。其中，右侧有64个通道的数据来源于左侧，64个通道的数据来源于上一层的上采样。那么灰色箭头应该就是把左侧的内容复制到了右侧，并且concat在了原先上采样后得到的64 * 392 * 392的数据上，形成了128 * 392 * 392的数据。</p>
<p>​ 但是问题在于，568 * 568和392 * 392还有较大的尺寸差别，这就需要利用crop来完成，由于在每个卷积中都会丢失边界像素，因此裁剪crop是必要的</p>
<p>​ 在上述网络形式中，最重要的结构就是其中的<strong>skip-connection</strong>。UNet中<strong>Concat</strong>形式的skip-connection的好处是，<strong>对于分割这个任务，空间域信息非常重要</strong>。而网络的encoder部分，通过各个pooling层已经把特征图分辨率降得非常小了，这一点不利于精确的分割mask生成，通过skip-connection可以把较浅的卷积层特征引过来，那些特征分辨率较高，且层数浅，会含有比较丰富的low-level信息，更利于生成分割mask。</p>
<p>​ 总体来说，就是把对应尺度上的特征信息引入到上采样或反卷积过程，为后期图像分割提供多尺度多层次的信息，由此可以得到更精细的分割效果，如U-Net论文描述的分割结果一样。这比单纯用编解码器框架要好，纯粹的编解码器框架，在编码过程中压缩和丢失了大量细节信息，而这些信息很可能会有助于后期的图像分割。</p>
<p>​ 同时，需要注意的一点是：此处的skip-connection与ResNet中直接相加形式的skip-connection不同，ResNet中的跳跃连接可以有效的减少梯度消失和网络退化问题，使训练更容易。直观上理解可以认为BP的时候，深层的梯度可以更容易的传回浅层，因为这种结构的存在，对神经网络层数的设定可以更随意一些。</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>FCN</tag>
        <tag>UNet</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记5——1x1卷积 &amp; 部分卷积 &amp; 空洞卷积 &amp; 可变形卷积</title>
    <url>/2022/01/07/3664afb64da5/</url>
    <content><![CDATA[<h3 id="一1-x-1-卷积">一、1 X 1 卷积</h3>
<h4 id="实现特征的升降维">1、实现特征的升降维</h4>
<p>​ 当1*1卷积出现时，在大多数情况下它作用是升/降特征的维度，这里的维度指的是通道数（厚度），而不改变图片的宽和高。</p>
<p>​ 因为1*1的卷积核，并不会改变图像的宽和高，但是其能够通过卷积核的数量，来调节输出的feature map的通道数。同时，其对不同通道上的像素点进行线性组合，有助于通道间信息的交互和整合过程</p>
<h4 id="减少模型参数量">2、减少模型参数量</h4>
<p>​ 这一想法最早在GoogleNet中被提出，比如说如下两个Inception模块：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114211201756.png" /></p>
<p>​ 从直观上来看，感觉像是只有3*3卷积的模块会拥有更少的训练数据，实则不然，我们可以计算一下训练数据个数：</p>
<p><strong>情况1:</strong></p>
<ol type="1">
<li><p>1 * 1卷积部分： 96 * 32 * 1 * 1= 3072个</p></li>
<li><p>3 * 3卷积部分： 32 * 48 * 3 * 3= 13824个</p>
<p>总计16896个训练参数</p></li>
</ol>
<p><strong>情况2:</strong> 总计 96*48*3*3 = 41472个训练参数</p>
<p>​ 从实际上来看，带1 * 1卷积的模型参数量更少，本质原因是因为1*1的卷积对数据的特征向量进行了降维的处理，使得特征通道数目先有了一定的减少。</p>
<p>​ 如下所示：在ResNet中的残差模块使用1*1的卷积核的意义也在于此：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114211323250.png" /></p>
<h3 id="二空洞卷积dilated-convolution">二、空洞卷积（Dilated Convolution）</h3>
<p>​ 顾名思义，其做法就是在卷积map中加入空洞的部分，以此增加感受域。如下图所示，</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114211417135.png" /></p>
<p>​ 右侧为普通卷积，左侧为空洞卷积。</p>
<p>​ 这个做法起源于最开始的语义分割领域，主要问题在于CNN本身可能存在一些致命性的缺陷，比如up-sampling和pooling layer的设计。问题主要在于：</p>
<p>​ 1、上采样和池化层是人为设计好的，是不可学习的。</p>
<p>​ 2、容易丢失内部数据结构与空间的层次化信息</p>
<p>​ 3、小物体的信息无法重建，假设有多个pooling layer，那么从理论上来讲在一定小的范围内的像素的物体是无法被重建的。</p>
<p>​ 所以有人提出了空洞卷积的思想。其本身避免了一部分上述讲到的2、3的问题，但是其也存在一些潜在问题，具体可以参考：<a href="https://www.zhihu.com/question/54149221">如何理解空洞卷积（dilated convolution）？</a></p>
<p>​ 最终，图森组提出了一个HDC的设计结构，来满足整个基于空洞卷积的设计。较为具体的内容也可以参考上述的文章。</p>
<h3 id="三部分卷积partial-convolution">三、部分卷积（Partial Convolution）</h3>
<p>​ 部分卷积在这篇论文中被提出，用于进行图像补全的任务，《Image Inpainting for Irregular Holes Using Partial Convolutions》</p>
<p>​ 在图像补全领域中，这篇论文前通常使用卷积层对有效像素和mask像素无差别的做卷积，容易导致颜色差异和伪影。而且先前的工作都是聚焦于一个图像中心的规则区域，并且都需要很昂贵的后处理机制。</p>
<p>​ 相比于人们以前使用的非神经网络的方法（PatchMatch等），使用神经网络的方法容易学习到语义的优点和有意义的隐藏表示信息，对于图像补全有很大的意义。但是这些网络使用卷积核的时候，使用一个固定的值将输入图像中被mask的地方代替，然后去卷积，这样就很容易导致孔洞区域内的纹理缺失，或者是边缘出现伪影。（就比如说使用经典卷积的U-Net架构。</p>
<p>​ 具体一点，如下图所示：先使用固定值m替换掉mask为0的区域，然后进行卷积。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114211456573.png" /></p>
<p>​ 而在这篇论文中提出了部分卷积的概念，只针对于有有效像素的部分进行卷积，并且能够自动的更新mask。</p>
<h4 id="部分卷积公式">1、部分卷积公式：</h4>
<p>​ 首先如下所示为部分卷积的公式：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114211521396.png" /></p>
<p>​ 仍然以如下所示为例：红色代表图像数据，蓝色代表mask数据，绿色代表卷积核。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114211532929.png" /></p>
<p>我们选择其中红色图像中的两个蓝色框起来的部分做卷积，作为示例：</p>
<p>首先公式中各个运算符号的含义如下英文描述所示，总体的步骤主要就是：</p>
<p>​ 1）将被卷积的区域先展开，形成X</p>
<p>​ 2）将mask对应的区域展开，形成M</p>
<p>​ 3）X和M做点对点乘积⊙，然后再乘上一个缩放因子，来调整有效输入的变化量。</p>
<p>​ 4）SUM(1)代表区域大小和卷积核一致，但值都是1的区域，所以在此处SUM(1)为9，而SUM(M)为7，因为该对应区域的mask中有7个1.</p>
<p>​ 5）最后再将卷积核展开形成W，两个向量相乘就完成了该区域的卷积。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/图片2.png" /></p>
<p>​ 另外一个区域，由于mask内的值都是0，所以最终输出的值直接为0.</p>
<h4 id="自动更新mask规则">2、自动更新Mask规则</h4>
<p>​ 具体更新规则描述如下：如果卷积能够根据至少一个有效输入值来计算输出输出，那么我们在下一步中，就把此像素点的mask标记为1.再讲的通俗一点，其实就是该范围的mask内只要有1，那就在下一层的卷积中，更新mask在此点的值至1.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114211755555.png" /></p>
<p>​ 具体的示例如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/图片3.png" /></p>
<p>​ 所以你会发现，在部分卷积的自动更新mask的过程中，只要部分卷积层叠加的足够多，最后任何mask都会逐渐变为所有都是1的形式，从而计算出需填补区域的内容。</p>
<p>​ 所以最终该论文在图像边界使用带有适当掩码的部分卷积来代替典型的填充。这确保了图像mask边缘处的修复内容不会受到图像外部无效值的影响。</p>
<h3 id="四可变形卷积deformable-convolution">四、可变形卷积（Deformable Convolution）</h3>
<p>​ 普通的卷积在应对一些物体复杂形变的场景的时候，往往无法得到好的结果。这个时候就有人提出了可变性卷积。</p>
<p>​ 简单而言，Deformable Conv 在感受野中引入了偏移量，而且这偏移量是可学习的，这样可以使得感受野不再是单一的方形，而是能够尽可能与物体的实际形状贴近，于是卷积区域便始终覆盖在物体形状周围，无论物体如何形变，加入可学习的偏移量后都可以搞定。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114211950684.png" alt="image-20220114211950684" style="zoom:150%;" /></p>
<p>​</p>
<p>​ 一个二维的卷积通常由两步组成，第一步是使用一个grid R去到输入的特征图上进行采样。第二步是根据卷积核的权重，对所有采样的点进行加权求和。比如说像下述这样一个就定义了一个3*3的方形的被卷积区域。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114212003778.png" /></p>
<p>​ 那么对于一个普通的卷积而言，可以用如下公式来进行表示，p0就是当前点，pn是R中的值。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114212010083.png" /></p>
<p>​ 在可变形卷积中，如下所示，R被加强了，还多了一个offset。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114212018393.png" /></p>
<p>​ 这样的话呢，采样就在一个不规则的并且带有偏移的位置上进行了。通常而言这个offset ∆pn 是小数，所以通常需要通过线性插值来计算像素的值，公式如下所示：其实就是x(p)的值要由其周围整数像素x(q)加权得到。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114212038364.png" /></p>
<p>​ 那么，关键的问题来了：这个offset怎么得到呢？<strong>这个offset是通过另一个在相同的输入图像上的卷积得到的。这个卷积的卷积核与当前的可变形卷积的卷积核有相同的空间分辨率。同时，经过这个卷积后得到的offest的输出域，和输入也有同样的空间分辨率。输出维度为2N，分别对应N个2维的offsets。</strong></p>
<p>​ 在训练过程中，用来生成输出特征的卷积核和用来计算offsets的卷积核是同时进行学习的。下图是一个3*3的可变形卷积的示意图。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114212046759.png" /></p>
<p>​ 至于更为详细的可变形卷积思想以及实验，可以更深入的精读《Deformable Convolutional Networks》这篇论文。</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Convolution</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记4——Depth-wise卷积 &amp; Point-wise卷积</title>
    <url>/2022/01/05/d37a1913ba03/</url>
    <content><![CDATA[<p><strong>提示：阅读本文前需要你掌握卷积相关操作概念</strong></p>
<h3 id="normal-convolution">1、Normal Convolution</h3>
<p>​ 输入一张3通道的图像，我们有4个3<strong>3</strong>3的卷积核，卷完以后，会生成4个特征图。特征图的数量等于卷积核的数量。每个卷积核的通道数与图像的通道数一致，一一对应相乘。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114211015420.png" /></p>
<h3 id="depth-wise-convolution">2、Depth-Wise Convolution</h3>
<p>​ Depthwise Convolution的一个卷积核负责一个通道，一个通道只被一个卷积核卷积。上面所提到的常规卷积每个卷积核是同时操作输入图片的每个通道。</p>
<p>​ 同样是对于一张三通道输入图像，Depthwise Convolution不同于上面的常规卷积，其完全是在二维平面内进行。卷积核的数量应当与输入的图像的通道数相同（因为通道和卷积核是一一对应的）。所以一个三通道的图像经过运算后生成了3个Feature Map。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114211022892.png" /></p>
<p>​ 总结而言：Depthwise Convolution完成后的Feature map数量与输入的通道数相同，无法扩展。且这种运算对输入层的每个通道独立进行卷积运算，没有有效的利用不同通道在相同空间位置上的特征信息。</p>
<p>​ 但是，Depthwise通过深度以及广度的操作能很好的保留各个通道信息的同时，降低了计算开销。而这一思想也逐渐应用到了移动端神经网络。</p>
<h3 id="point-wise-convolution1x1卷积">3、Point-Wise Convolution(1x1卷积)</h3>
<p>​ Pointwise Convolution的运算的卷积核的尺寸为 1×1×M，M为输入的图像的通道数。如下图所示：输入图像为3通道，经过4个1x1x3的卷积核以后，生成4个特征图，特征图大小并不会变化，故而这里的卷积运算其实就是将输入的图像在深度方向上进行加权组合，生成新的Feature map。</p>
<p>​ 详见：<a href="https://blog.slks.xyz/2022/01/07/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97%E7%AC%94%E8%AE%B05%E2%80%941x1%E5%8D%B7%E7%A7%AF&amp;%E9%83%A8%E5%88%86%E5%8D%B7%E7%A7%AF&amp;%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF&amp;%E5%8F%AF%E5%8F%98%E6%80%A7%E5%8D%B7%E7%A7%AF/">机器学习基础系列笔记5——1x1卷积 &amp; 部分卷积 &amp; 空洞卷积 &amp; 可变形卷积</a></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114211035827.png" /></p>
<h3 id="depth-wise-separable-convolution">4、Depth-Wise Separable Convolution</h3>
<p>​ Depthwise Separable Convolution是将一个完整的卷积运算分解为两步进行，即上面所述的Depthwise Convolution与Pointwise Convolution。</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Convolution</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记3——反卷积Deconvolution</title>
    <url>/2022/01/04/16c9f87609b5/</url>
    <content><![CDATA[<p><strong>提示：在观看此篇文章前，需要你掌握卷积操作。</strong></p>
<p>​ Deconvolution反卷积通常用于进行图像的上采样，恢复分辨率。又称transposed convolution或是Fractionally-strided convolution。首先，我们先聊一聊为什么需要反卷积来进行上采样？</p>
<p>​ 在反卷积前，人们上采样通常采用插值的方法去进行，但是插值的方法完全是由人工定义规则，并不能够对于不同图像的插值有特定的优化，也没有可调整参数的空间。此时，我们想要让网络能够学出一种最优化的上采样方案，就是我们的反卷积操作。</p>
<p>​ 众所周知如下所示是一个普通的卷积操作，我们拿一个3*3的卷积核去卷一个4*4的矩阵，padding=0，stride=1，得到了一个2*2的矩阵。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210644864.png" /></p>
<p>​ 从实质的角度去理解卷积这一件事情，其实它就是建立了输入与输出图像的像素对应关系，比如说按照上图所示的内容，输入图像中每9个像素，通过卷积核，建立起了和输出图像中1个像素的映射关系。所以Convolution建立的是一个“多对一”的像素映射关系。那么，顾名思义，Deconvolution本身应该要做的就是从output到input之间，建立“一对多”的像素映射关系。也就是说从output的一个值中计算出input的9个值。看到这里也许会有些懵，实际上来说，卷积这个操作是没法逆向进行的，我们这边说的反卷积只是一种形式，因为其比较像而已。</p>
<p>​ 那么反卷积是如何进行的呢？我们先再来看一看卷积的另一种计算形式（除了移动卷积核遍历以外）—— 使用矩阵相乘的形式进行计算，然后能够很好的推出得到反卷积的计算形式。</p>
<p>仍然以上面的例子为例，我们如果想要一次性计算整个ouput中的值，可以如下操作：</p>
<p>​ 1、将input展平，成为一个16 * 1的矩阵A。</p>
<p>​ 2、将kernel按照一定规则扩充，扩充成为一个4 * 16的矩阵B</p>
<p>​ 3、将矩阵A和矩阵B计算矩阵乘法，得到一个1 * 4的向量C，将其reshape成2 * 2即output。</p>
<p>那么在步骤2中的“按照一定规则填充”是指什么呢？</p>
<p>​ 其实就是重新排列一下kernel矩阵, 使得我们通过一次矩阵乘法就能计算出卷积操作后的矩阵。以上述的卷积核为例，应当如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210739770.png" /></p>
<p>然后我们发现，原来卷积操作，可以写成两个矩阵相乘的形式，在上述例子中就是：</p>
<p>B（4 * 16）· A（16 * 1） = C（4 * 1）--》reshape --》 output（2 * 2）</p>
<p>​ 那么，现在反卷积要干的事情其实就是让 <span class="math inline">\(B^T\)</span>（16*4）· <span class="math inline">\(C\)</span>（4*1）就可以得到一个16*1的矩阵，然后进行reshape就可以变成一个4*4的图像，其分辨率为最开始输入的2*2的图像的两倍，就可以完成反卷积。</p>
<p>​ 其实，按照上述的做法，我们就建立了一个1对多的映射关系，请注意，在实际操作中，其实并不需要去计算反卷积的矩阵B内部到底是什么信息，B内部的参数是可以让网络进行学习而得到的，网络学习得到的参数往往就是针对于这一组训练集或者针对于特定任务而言，最好的一个上采样的方案。</p>
<p>​ 所以严格来说，反卷积并不算卷积，只是另一种形式罢了。</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Deconvolution</tag>
      </tags>
  </entry>
  <entry>
    <title>ML2021课程系列笔记4——海森矩阵计算（课程作业）</title>
    <url>/2021/12/23/9bb28e693fc9/</url>
    <content><![CDATA[<h3 id="hung-yi-lee-李宏毅-machine-learning-2021-spring课程-hw2.2笔记">Hung-yi Lee (李宏毅) MACHINE LEARNING 2021 SPRING课程 HW2.2笔记</h3>
<p>​ https://link.zhihu.com/?target=https%3A//speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html</p>
<p>​ 先给出课程中助教提供的代码链接：</p>
<p>​ https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW02/HW02-2.ipynb</p>
<p>​ 先前在系列笔记2中——机器学习任务攻略笔记中，已经提及了在数学理论上，当我们训练不下去的时候，如何分辨是达到了一个Local Minimal还是一个Saddle Point。</p>
<p>​ https://zhuanlan.zhihu.com/p/447280599</p>
<p>​ 此篇笔记从实际的角度进行记录，通过一个实例，讲解如何去进行分辨，整理出的这个框架在今后如果遇到了训练不下去的时候，可以采用此计算，分辨到底是碰到了何种情况：</p>
<p>​ 首先，在实际的训练过程中，我们很难找到梯度为0的点，并且也很难找到一个真正的Local Minimal（也就是海森矩阵特征值全大于0），所以我们首先需要做一些近似：</p>
<ul>
<li><p>我们将gradient小于1^-3即视为近似为0</p></li>
<li><p>如果minimum ratio 大于0.5 且 gradient 小于 1^-3 ，我们即认为其为一个Local Minimal。</p></li>
<li><p>附： Minimum ratio = 海森矩阵的所有特征值中正的特征值的数量 / 海森矩阵的所有特征值的数量</p></li>
</ul>
<p>​ 然后就开始通过代码来实现计算过程：首先我们需要有一个用来作为示例的网络和训练点,这个在助教给的代码中已经准备好了，我此处把重要的东西抽出来记录</p>
<h4 id="step1-定义一个简单的模型">Step1: 定义一个简单的模型</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MathRegressor</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_hidden=<span class="number">128</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.regressor = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">1</span>, num_hidden),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(num_hidden, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.regressor(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="step2-加载属于该模型的预先准备好的某训练点以及用于训练的数据和标签">Step2: 加载属于该模型的预先准备好的某训练点以及用于训练的数据和标签</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = MathRegressor()</span><br><span class="line">model.load_state_dict(<span class="string">&#x27;xxxx&#x27;</span>)  <span class="comment"># xxxx为事先准备好的训练到某一个点的模型文件路径</span></span><br><span class="line">train = Tensor([[<span class="number">0.2400</span>],  <span class="comment"># 然后feature和target(label)也加载进来</span></span><br><span class="line">        [<span class="number">0.2500</span>],</span><br><span class="line">        [<span class="number">0.2600</span>],</span><br><span class="line">        [<span class="number">0.2700</span>],</span><br><span class="line">        [<span class="number">0.2800</span>],</span><br><span class="line">        [<span class="number">0.2900</span>]])</span><br><span class="line">target = Tensor([[-<span class="number">0.1559</span>],</span><br><span class="line">        [-<span class="number">0.1801</span>],</span><br><span class="line">        [-<span class="number">0.1981</span>],</span><br><span class="line">        [-<span class="number">0.2101</span>],</span><br><span class="line">        [-<span class="number">0.2162</span>],</span><br><span class="line">        [-<span class="number">0.2168</span>]])</span><br></pre></td></tr></table></figure>
<h4 id="step3-定义计算该训练进度当前所在位置loss函数的梯度">Step3: 定义计算该训练进度当前所在位置Loss函数的梯度</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># function to compute gradient norm</span></span><br><span class="line"><span class="comment"># model 代表模型实例 ，例如为 MathRegressor()</span></span><br><span class="line"><span class="comment"># criterion为损失函数,例如为 nn.MSELoss()</span></span><br><span class="line"><span class="comment"># train 为训练数据feature 见上</span></span><br><span class="line"><span class="comment"># target为训练数据label 见上</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_gradient_norm</span>(<span class="params">model, criterion, train, target</span>):</span></span><br><span class="line">    model.train()</span><br><span class="line">    model.zero_grad()</span><br><span class="line">    output = model(train)</span><br><span class="line">    loss = criterion(output, target)</span><br><span class="line">    loss.backward()  <span class="comment"># 通过反向传播计算该点梯度</span></span><br><span class="line"></span><br><span class="line">    grads = []</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> model.regressor.children():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(p, nn.Linear):</span><br><span class="line">            param_norm = p.weight.grad.norm(<span class="number">2</span>).item()</span><br><span class="line">            grads.append(param_norm)</span><br><span class="line">		</span><br><span class="line">    grad_mean = np.mean(grads) <span class="comment"># compute mean of gradient norms</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> grad_mean</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">对于内容的一些注解：</span></span><br><span class="line"><span class="string">	前半部分比较好理解，就是做了前向计算以后，然后通过反向传播计算梯度</span></span><br><span class="line"><span class="string">	后半部分，其实是对所有的层的参数的梯度做了一个平均的计算：</span></span><br><span class="line"><span class="string">	1、model.regressor 输出的内容如下</span></span><br><span class="line"><span class="string">    Sequential(</span></span><br><span class="line"><span class="string">      (0): Linear(in_features=1, out_features=128, bias=True)</span></span><br><span class="line"><span class="string">      (1): ReLU()</span></span><br><span class="line"><span class="string">      (2): Linear(in_features=128, out_features=1, bias=True)</span></span><br><span class="line"><span class="string">    )</span></span><br><span class="line"><span class="string">	2、代码中的p在三次循环中分别为：</span></span><br><span class="line"><span class="string">    第一遍循环：Linear(in_features=1, out_features=128, bias=True)</span></span><br><span class="line"><span class="string">    第二遍循环：ReLU()</span></span><br><span class="line"><span class="string">    第三遍循环：Linear(in_features=128, out_features=1, bias=True)</span></span><br><span class="line"><span class="string">    故而我们知道 for p 那个循环其实就是在： 如果该层是全连接层，那么我们就要计算所有权重参数的梯度，如果不是（言外之意是如果是ReLU层，因为ReLU层是激活函数，无权重参数，所以我们不需要考虑）。所以需要注意，如果我们需要计算的模型是一个含有除了Linear以外的 带权重参数的网络模型，这个地方就要有所更改了</span></span><br><span class="line"><span class="string">  3、如果p是Linear层，应当如何计算：</span></span><br><span class="line"><span class="string">  	p.weight 是一个Tensor，为所有的权重参数</span></span><br><span class="line"><span class="string">  	p.weight.grad 是一个Tensor，为所有的权重参数对应当前点的导数（梯度）</span></span><br><span class="line"><span class="string">  	p.weight.grad.norm(2) 是一个仅有一个元素的Tensor，计算了先前的Tensor的二阶范式，其实就是平方和开更号。</span></span><br><span class="line"><span class="string">    p.weight.grad.norm(2).item() 是一个数值，即从Tensor中取出数值来。</span></span><br><span class="line"><span class="string">    最后将该层的 梯度的二阶范式 append 至 grads数组中</span></span><br><span class="line"><span class="string">  4、最后返回值是什么？</span></span><br><span class="line"><span class="string">  	最后grads中有 n个元素，n为所有带权重参数的层的个数（示例中的网络为2个），然后在用np.mean计算即得到最后的返回值，即所有层的梯度的平均值。</span></span><br><span class="line"><span class="string">  	</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="step4-计算hession-矩阵">Step4: 计算Hession 矩阵</h4>
<p>https://github.com/cybertronai/autograd-lib</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 我们使用autograd-lib 这个python库计算Hession矩阵</span></span><br><span class="line">pip install autograd-lib</span><br><span class="line"><span class="comment"># 在github的链接中，作者给出了Hessian矩阵的计算示例，其使用的是高斯牛顿法，我们在此不进行赘述，有兴趣的可以看github链接的计算源码。</span></span><br><span class="line"><span class="comment"># 以下是两个依赖函数，下面用得到，也是github源码中给出的</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_activations</span>(<span class="params">layer, A, _</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    A is the input of the layer, we use batch size of 6 here</span></span><br><span class="line"><span class="string">    layer 1: A has size of (6, 1)</span></span><br><span class="line"><span class="string">    layer 2: A has size of (6, 128)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    activations[layer] = A</span><br><span class="line"></span><br><span class="line"><span class="comment"># helper function to compute Hessian matrix</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_hess</span>(<span class="params">layer, _, B</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    B is the backprop value of the layer</span></span><br><span class="line"><span class="string">    layer 1: B has size of (6, 128)</span></span><br><span class="line"><span class="string">    layer 2: B ahs size of (6, 1)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    A = activations[layer]</span><br><span class="line">    BA = torch.einsum(<span class="string">&#x27;nl,ni-&gt;nli&#x27;</span>, B, A) <span class="comment"># do batch-wise outer product</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># full Hessian</span></span><br><span class="line">    hess[layer] += torch.einsum(<span class="string">&#x27;nli,nkj-&gt;likj&#x27;</span>, BA, BA) <span class="comment"># do batch-wise outer product, then sum over the batch</span></span><br></pre></td></tr></table></figure>
<h4 id="step5-计算minimal-ratio">Step5: 计算Minimal Ratio</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># function to compute the minimum ratio</span></span><br><span class="line"><span class="comment"># model 代表模型实例 ，例如为 MathRegressor()</span></span><br><span class="line"><span class="comment"># criterion为损失函数,例如为 nn.MSELoss()</span></span><br><span class="line"><span class="comment"># train 为训练数据feature 见上</span></span><br><span class="line"><span class="comment"># target为训练数据label 见上</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_minimum_ratio</span>(<span class="params">model, criterion, train, target</span>):</span></span><br><span class="line">    model.zero_grad() </span><br><span class="line">    <span class="comment"># 1、计算Hessian矩阵</span></span><br><span class="line">    <span class="keyword">with</span> autograd_lib.module_hook(save_activations):</span><br><span class="line">        output = model(train)</span><br><span class="line">        loss = criterion(output, target)</span><br><span class="line">    <span class="keyword">with</span> autograd_lib.module_hook(compute_hess):</span><br><span class="line">        autograd_lib.backward_hessian(output, loss=<span class="string">&#x27;LeastSquares&#x27;</span>)</span><br><span class="line">		</span><br><span class="line">    layer_hess = <span class="built_in">list</span>(hess.values())</span><br><span class="line">    <span class="comment"># 2、计算minimum_ratio</span></span><br><span class="line">    minimum_ratio = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> h <span class="keyword">in</span> layer_hess:</span><br><span class="line">        size = h.shape[<span class="number">0</span>] * h.shape[<span class="number">1</span>]</span><br><span class="line">        h = h.reshape(size, size)</span><br><span class="line">        h_eig = torch.symeig(h).eigenvalues </span><br><span class="line">        <span class="comment"># torch.symeig() returns eigenvalues and eigenvectors of a real symmetric matrix</span></span><br><span class="line">        num_greater = torch.<span class="built_in">sum</span>(h_eig &gt; <span class="number">0</span>).item()</span><br><span class="line">        minimum_ratio.append(num_greater / <span class="built_in">len</span>(h_eig))</span><br><span class="line"></span><br><span class="line">    ratio_mean = np.mean(minimum_ratio) <span class="comment"># compute mean of minimum ratio</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ratio_mean</span><br><span class="line">  </span><br><span class="line">activations = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">hess = defaultdict(<span class="built_in">float</span>)</span><br><span class="line">gradient_norm = compute_gradient_norm(model, criterion, train, target)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	在上述代码中，有些许部分与理论不同。代码实现中是分层计算海森矩阵的，即针对于神经网络的每个层计算海森矩阵，而后再求解特征值。然后将每层的结果做一个平均。而理论上，应当计算一个所有参数的大的海森矩阵，对其求解特征值。</span></span><br><span class="line"><span class="string">	即在上述的案例中，我们原本应该得到一个256*256的海森矩阵，但实际上得到了2个128*128的海森矩阵，并且应当是理论上256*256海森矩阵的左上角部分与右下角部分。即下述所示的A和B，剩下的两块的？是L对两层参数交叉求微分的部分，没有计算。</span></span><br><span class="line"><span class="string">	                              [ A   ? ]</span></span><br><span class="line"><span class="string">	                              [ ?   B ]</span></span><br><span class="line"><span class="string">	如此做的原因我思索了很久也没有得出一个结论，有两个合理的可能猜测：</span></span><br><span class="line"><span class="string">		可能1:完整的海森矩阵计算难度过大，故而我们单独计算L对每一层参数的海森矩阵，来作为近似。</span></span><br><span class="line"><span class="string">		可能2:由于某些性质，剩下的没有计算的两块的值，不会影响最终判定海森矩阵是否正定的结果，但是我并没有实际进行证实。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>ML2021课程系列笔记</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>ML2021课程系列笔记3——卷积神经网络CNN</title>
    <url>/2021/12/20/cedd3c9597c5/</url>
    <content><![CDATA[<h3 id="hung-yi-lee-李宏毅-machine-learning-2021-spring课程-week3笔记">Hung-yi Lee (李宏毅) MACHINE LEARNING 2021 SPRING课程 Week3笔记</h3>
<p>### 课程链接：https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html</p>
<p>​ 该篇记录了一个用于影像处理的非常经典的网络架构：CNN网络，其中也提及了如何设计网络架构能够更好的为我们的机器学习任务目标进行服务。</p>
<h2 id="一从neuron-version角度来介绍cnn">一、从Neuron Version角度来介绍CNN</h2>
<p>​ 我们如果使用全连接网络来进行影像处理的话，如下图所示，我们先将一张100*100的3通道RGB图像展平，然后将展平后的向量作为全连接层的输入，假设第一个隐藏层有1000个神经å元，那么第一层的参数就需要有<span class="math inline">\(310^7\)</span>个，非常的多。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114729143.png" alt="image-20220114114729143" style="zoom:20%;" /></p>
<p>​ 所以考虑到影像本身的特性，其实我们并不需要让每一个neural和每一个像素之间都有权重的联系关系。所以我们需要基于影像的特点，提出一个适用于影像处理的架构CNN：</p>
<p>​ 首先我们提出如下的观察：</p>
<h3 id="观察1">观察1：</h3>
<p>​ 我们辨识影响往往是通过影响中的一些重要的部分（Pattern）来做出判断的，比如说，我们要判断一张图片中是不是含有鸟，我们往往可能会判断说有没有鸟嘴、有没有鸟眼睛、有没有鸟爪子等等重要的鸟的组成部分。这样的话呢，我们其实会发现，我们只要训练网络去观察这些重要的组成部分就可以了，而这些组成部分往往是图片的一小部分，所以并不需要每一个神经元都去观察整张图片的信息（FC网络由于每个神经元都和所有的输入像素相连接，所以每个神经元中都会有全局的信息），只需要让网络侦测一些重要的Pattern有没有出现即可。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114815294.png" alt="image-20220114114815294" style="zoom:25%;" /></p>
<p>​ 基于上述观察1，我们就可以提出一些机制（简化1）：Receptive Field感知域机制，如下所示：本来的话，在FC中，每一个Neural都会和整张图片的所有像素都有一个weight相连，但是我们现在可以设置一个3<em>3</em>3的感知域，比如图中左上角的这个红色感知域，然后某一个Neural仅和这个感知域内所有的像素相连，也就是这个神经元仅有3<em>3</em>3 = 27 个weight，再加上bias的参数，就可以得到神经元的输出作为下一层的输入。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114832378.png" alt="image-20220114114832378" style="zoom:25%;" /></p>
<p>​ 那么，以此类推，我们可以有很多很多的感知域，对应不同的Neural，每一个不同的Neural负责不同的感知域部分（如图中所示）。这个地方其实会存在比较多的疑问，比如说：同一个感知域可以连接两个不同的神经元吗？感知域之间可以重叠吗？我们一定要3通道的感知域吗？可以有不同尺度的感知域吗？感知域一定要是相邻的吗？感知域可以是非正方形吗？答案都是可以的，感知域的设计是一个非常自由的选项，其归根结底是需要看你对于问题的理解。一般而言，我们说感知域最好是相邻的，是因为我们认为在影响检测中，如果想要检测一个重要的Pattern的话，这个Pattern应该是会在图像任意位置都有可能出现的。如果有一个特殊的任务，其内容都在左上角，那么你可以设计感知域都重叠在左上角。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114850796.png" alt="image-20220114114850796" style="zoom:25%;" /></p>
<p>​ 那么最经典的Receipt Field应该是怎么样的呢？我们一般都会考虑所有的通道，而不是单个通道的考虑，这样的话我们只需要确定图像平面的感知域大小就可以，将之称为kernal size，一般的kernel size就是3<em>3，5</em>5和7*7已经属于较大的核大小了。然后对于一个receipt field来说，往往不会只有一个neural与之对应，而是会有一组neuron( 64或128个)去和这个感知域相连。</p>
<p>​ 各个不同的receipt field一般都是相邻的，有重叠的，相邻距离叫做stride。同时边界的填充大小叫做padding。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220121172659518.png" /></p>
<h3 id="观察2">2、观察2</h3>
<p>​ 我们发现，影像中同一个模式的部分，可能出现在图像的任何一个地方，比如说在不同的图像上，鸟嘴可能出现在蓝色方框处，也可能出现在红色方框处。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114115003492.png" alt="image-20220114115003492" style="zoom:25%;" /></p>
<p>​ 基于上述的观察，虽然我们在简化1中提到了，对于不同的区域，我们都会有对应的神经元去连接这一块区域（感知域），那么由于我们是要检测同一个模式，所以用于检测同一个模式的感知域的神经元应该是可以共享参数的。如下图所示，用于检测左上角的某模式的一个神经元核检测中部的同一模式的神经元应当共享训练参数。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114115020687.png" alt="image-20220114115020687" style="zoom:25%;" /></p>
<p>​ 那么一般而言，我们是如何去共享参数的呢？我们先前说过，一般而言，每一个感知域都会对应连接64个或128个不同的神经元，所有的感知域所对应的相同序号的神经元全都是共享参数的。以下图中两个红色方框框起的感知域为例，每个感知域都对应了64个神经元，即64组参数，它们各自的第1个神经元的参数（filter1）间参数是共享的，后续同理。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114115047789.png" alt="image-20220114115047789" style="zoom:25%;" /></p>
<p>​ 所以我们发现，Convolutional Layer其实就是人们针对于影像的两大特性，提出了感知域和参数共享这两个简化，从而使得FC进化成了CNN，所以CNN一般情况下我们说仅用于影像处理，或者说用于具有上述我们提及的两大特性的问题领域，才会有比较好的效果。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114115102350.png" alt="image-20220114115102350" style="zoom:25%;" /></p>
<h2 id="二从filter-vision角度来介绍cnn">二、从Filter Vision角度来介绍CNN</h2>
<p>​ 上述的那个角度介绍CNN其实是令我耳目一新的，它非常好的阐明了CNN这个架构之所以这样子设计的原因。那么其实在最开始的时候我学习的是接下来要说的这个从Filter的版本进行的介绍。</p>
<p>​ 首先你需要知道卷积的概念，在卷积层中，其实我们就是用许多个不同的卷积核Filter去卷积我们输入的图像。假设我们的图像是3通道的，那么我们一般的卷积核大小就是一个<span class="math inline">\(3 \times 3 \times 3(width*height*channel)\)</span>的三维Tensor。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114115134255.png" alt="image-20220114115134255" style="zoom:25%;" /></p>
<p>​ 每一个Filter卷积过原图像以后，都会生成一张新的图像，被我们称之为特征图，我们通常使用64个或128个卷积核去对图像卷积，在第一层的卷积层过后，就会生成一张64或128通道的图像，每一个通道都是一个Feature Map。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114115246463.png" alt="image-20220114115246463" style="zoom:20%;" /></p>
<p>那么在多层的卷积层网络中，这样子经过第一层卷积层后得到的一个特征图组成的64通道的图像，将会再次被视为一张图片，经过下一个卷积层。下一层的每个卷积核应当是<span class="math inline">\(3 \times 3 \times 64\)</span>的大小。然后又会根据卷积核的数目，决定该层输出的特征图的数量</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114115306217.png" alt="image-20220114115306217" style="zoom:25%;" /></p>
<h2 id="三-两个version的介绍中的相通点">三、 两个Version的介绍中的相通点</h2>
<p>​ 其实第二个版本中的Filter就是第一个版本中的某个感知域所对应的神经元的参数，也就对应着我们的观察1.如下所示：比如说一个对应着<span class="math inline">\(3 \times 3 \times 3\)</span>的感知域的神经元，其拥有27个参数，这27个参数其实就是我们在第二个版本中所说的Filter的大小。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114115437195.png" alt="image-20220114115437195" style="zoom:25%;" /></p>
<p>​ 同时，我们在卷积的过程中，需要拿卷积核遍历一遍图像，还会有stride和padding，在拿卷积核遍历卷积图像的时候，卷积核的参数不会变化，这也就意味着，对于同一个卷积核（神经元）来说，当其对应去计算不同的感知域时，参数是共享的。对应了我们的观察2.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114115455473.png" alt="image-20220114115455473" style="zoom:25%;" /></p>
<p>​ 所以其实来说两个版本的介绍是完全一致的，从两个方向来介绍能够更好的加深我们对于CNN的理解。</p>
<h2 id="四一些问题与pooling层的作用">四、一些问题与Pooling层的作用</h2>
<p>​ 1、我们一般采用<span class="math inline">\(3 \times 3\)</span>的filter，那么需要担心检测不到比较大的Pattern吗？因为有些Pattern肯定不会只在<span class="math inline">\(3 \times 3\)</span>这么小的一个区域内出现。</p>
<p>​ 答案是不需要担心，因为在多层的卷积神经网络中，我们第一层使用<span class="math inline">\(3 \times 3\)</span>的filter，得到的特征图，在第二层卷积的时候，第二层如果采用的是<span class="math inline">\(3 \times 3\)</span>的filter，我们可以知道，第二层卷积的特征图中的一个像素，其实代表的是原图像中一个<span class="math inline">\(3 \times 3\)</span>的范围，所以第二层的<span class="math inline">\(3 \times 3\)</span>的filter所感知到的源图像的范围其实是比<span class="math inline">\(3 \times 3\)</span>要大的，那就是<span class="math inline">\(9 \times 9\)</span>吗？也不一定，因为考虑到感知域之间会有所重叠。如下图所示，比较好理解，上面的矩阵是原图，下面的矩阵是第一层卷完以后的特征图，在特征图上做<span class="math inline">\(3 \times 3\)</span>的蓝色框卷积，其实就相当于感知到了原图的<span class="math inline">\(5 \times 5\)</span>的一个蓝色方框区域。所以卷积神经网络叠的越深，其能侦测到的特征的尺度上限越大。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114115621526.png" alt="image-20220114115621526" style="zoom:25%;" /></p>
<p>​ 2、Pooling层：</p>
<p>​ 池化层基于这样一个观察：我们发现，影像如果做了下采样，并不会影响整体显示的内容。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114115654899.png" alt="image-20220114115654899" style="zoom:25%;" /></p>
<p>​ 所以在传统的CNN中，Pooling最主要的作用是减少运算量，减少参数。人们往往把Pooling层和卷积层交替叠加，形成卷积神经网络。但其实在现阶段而言，我们的GPU运算能力上来了，池化层在有些时候可有可无，尤其是当我们需要执行一些识别细小Pattern的任务的时候，池化层所进行的下采样很可能让我们丢失一些信息，导致侦测不到一些细小的Pattern。</p>
<p>​ 故而我们在使用一个网络架构的时候，一定要想清楚这个网络架构的某些部分到底是干什么用的，针对什么特性来进行设计的，才能获得比较好的效果以及应用。</p>
<p>3、最后CNN无法处理图像的放缩与旋转，所以在做影像辨识的时候我们往往要做Data Augmentation（先前提及过的方法），来让我们的训练集尽量多元化，避免这个问题。当然也有专门做了相应处理的网络层，叫做Spatial Transformer Layer，感兴趣可以学习。 https://youtu.be/SoCywZ1hZak</p>
<h2 id="五cnn应用-playing-go">五、CNN应用： Playing GO</h2>
<h4 id="如何将下围棋变成一个分类问题">1、如何将下围棋变成一个分类问题？</h4>
<p>​ 我们把下围棋去当作一个分类的问题，假设棋盘是19*19的大小，网络的输入就是一个19*19的向量，每一个位置可能用一个值来代表这个位置当前的状态，（Alpha Go原论文中，每个位置是由一个48维的向量进行表示的），经过网络以后，我们要的输出结果是下一步棋会下在哪里？</p>
<p>​ 这就是一个 19*19个类别的分类问题，网络输出在各个地方的落子概率，挑选落子概率最大的那一个位置下子就可以了。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_01_21_17_35_31_200.png" /></p>
<h4 id="为什么cnn可以用在下围棋上呢">2、为什么CNN可以用在下围棋上呢？</h4>
<p>​ 1、一些pattern比整个棋局要小，并且可以识别出来。如下所示，围棋中也有一个个小的pattern，通过一个个小的pattern就可以去进行一些的判断。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_01_21_17_32_54_32.png" /></p>
<p>​ 2、同一个pattern可能出现在棋盘上的任何位置，可能可以出现在左下角，也可以出现在右上角。围棋中也是这个样子。</p>
<h4 id="那么pooling层在围棋中也会适用吗">3、那么Pooling层在围棋中也会适用吗？</h4>
<p>​ ！完全不适用！并且不可以使用！如果我们在棋盘中使用MaxPooling层的话，移除了偶数行和奇数行以后，会导致很多围棋的细节丢失。所以Pooling层虽然适合做影像处理，但在下围棋这个任务中，显然不是很合适。</p>
<p>​ 所以Alpha Go的原论文中，在附件中阐述的网络结构中也提到了，其设计的网络结构中，已经没有Pooling层了，是非常合理的。</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>ML2021课程系列笔记</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>ML2021课程系列笔记2——机器学习训练任务攻略</title>
    <url>/2021/12/19/8dab9ca264e4/</url>
    <content><![CDATA[<h3 id="hung-yi-lee-李宏毅-machine-learning-2021-spring课程-week2笔记">Hung-yi Lee (李宏毅) MACHINE LEARNING 2021 SPRING课程 Week2笔记</h3>
<h3 id="课程链接httpsspeech.ee.ntu.edu.twhyleeml2021-spring.html">课程链接：https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html</h3>
<p>​ 本篇将会介绍一些机器学习深度学习训练过程中，容易发生的一些问题，以及经常使用的一些基础的Tricks。上篇已经阐明了机器学习任务的训练分为以下三个阶段。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114110835052.png" alt="image-20220114110835052" style="zoom:25%;" /></p>
<p>​ 同时也会有对应的测试集数据进行验证的部分。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114110905969.png" alt="image-20220114110905969" style="zoom: 25%;" /></p>
<p>​ 那么在训练与测试的过程中，可能会出现一些问题，下面的图就是一个整体的Guidance，基本阐述了当在训练时我们遇到不同的现象时，大概是何种问题所致。</p>
<p>​ 此篇将会顺着以下这个分支树进行前序遍历，一条条往下进行讲解。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114110925311.png" alt="image-20220114110925311" style="zoom:25%;" /></p>
<h2 id="一model-bias问题">一、Model Bias问题</h2>
<p>​ 当在训练数据上得到的Loss函数值较大的话，其中一种可能就是Model Bias.Model Bias一般指模型不够复杂，无法很好的拟合数据。从形式化的角度来讲就是，能够拟合数据的函数，不在你所寻找的函数空间中。举个例子来说：你在第一步中设定的拟合函数为Y = a + bx，然后使用梯度下降想要寻找使得Loss最低的一组a和b，但是你会发现，即使你找到了使得Loss最低的一组a和b，这组a和b计算得到的Loss还是很高。原因可能是，你需要拟合的数据其实是一个二次函数，或是更复杂的函数，而你却想要使用线性函数去进行拟合。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220129151628264.png" /></p>
<h2 id="二optimization">二、Optimization</h2>
<p>​ 当在训练数据上得到的Loss函数值较大的话，另外一种可能就是Optimization导致的。此种情况与第一种不同，其模型是有能力拟合数据的，但是由于优化方法的限制，我们没法找到能够使得Loss函数值最小的那一组未知参数。我们先前使用的Gradient Descent用于求解优化的方法，还是存在比较多的限制的。如下图为例，假设Loss函数的图像如下图所示，我们设定的θ的起点在左侧，那么经过一段时间的梯度下降后，其会到达图中蓝线所示的Local Minimum，也就是局部最优，但是其永远也无法找到右侧的全局最优。往往优化算法无法很好的执行是由于模型过于复杂，或不同的特征数据的尺度相差过大等原因导致。</p>
<p>​ 此处仅先简单的介绍Optimization是怎样一种问题，后续第八章中会继续探讨这类问题的产生原因以及在第九章中讲如何解决优化这一问题（如何逃出Shaddle Point）。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114111434996.png" alt="image-20220114111434996" style="zoom: 25%;" /></p>
<h2 id="三如何区分是model-bias还是optimization导致的train-loss过大">三、如何区分是Model Bias还是Optimization导致的Train Loss过大？</h2>
<p>​ 我们先前说，当在训练数据上得到的Loss函数值较大的话，这两种问题都有可能，那么一般而言如何区分呢？一般来说，我们需要通过模型与模型的比较来获得一些见解。如下所示，在右侧的Training Data显示的图像中，20层的网络已经能够将Training Error降至比较低的水准了，那么56层的这个网络Training Error还处于一个较高的水准，那么肯定是Optimizaiton问题，而不是Model Bias的问题。为何这么说呢？因为56层的网络肯定比20层的网路复杂，如果20层的网络已经能够很好的拟合训练数据了，那么56层的网络肯定是具有拟合训练数据的能力的，但是现在Training Error还居高不下，说明是优化的时候出现了问题，或者是进入了一个局部最优点中，导致其找不到最好的那一组参数。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114111512628.png" alt="image-20220114111512628" style="zoom:25%;" /></p>
<h2 id="四训练时能够避免上述情况发生的一些tips">四、训练时能够避免上述情况发生的一些Tips？</h2>
<p>​ 一般新执行一个训练任务的时候，从较浅的网络开始训练，因为一般较浅的网络不会出现优化的问题。如果发现较浅的网络复杂度不够拟合数据，再逐渐加深网络。</p>
<p>​ 如果更深的网络没有获得更小的损失训练数据，则存在优化问题。</p>
<h2 id="五overfitting问题">五、OverFitting问题</h2>
<p>​ 当Training Loss已经降至较低水平，但是在Testing集上的Loss值仍然较高，其中一种可能就是出现了Overfitting过拟合的问题。如下图所示，很好的表现了过拟合问题。由于我们的模型非常有弹性，所以可能在训练集上（蓝色点）时非常好的拟合了，但是在测试集（橙色）上的表现就会比较差。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114111606224.png" alt="image-20220114111606224" style="zoom:25%;" /></p>
<p>​ 更为极端的情况就是训练出如下图所示的函数：在训练集上的数据，都是完全拟合的，但是对于不在训练集上的数据就是一个随机值。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114111622606.png" alt="image-20220114111622606" style="zoom: 15%;" /></p>
<h2 id="六如何解决overfitting问题">六、如何解决OverFitting问题</h2>
<p>​ 下述是一个随着模型逐渐变得复杂，Training Loss和Testing Loss 的值变化曲线。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114111700084.png" alt="image-20220114111700084" style="zoom:16%;" /></p>
<p>​ 对于Overfitting我们有如下的几种解决方案：</p>
<ul>
<li><p>1、更多的训练数据</p>
<ul>
<li><p>如果我们能够收集到更多的训练数据，就可以一定程度上减轻过拟合的问题。比较常用的增加训练数据的方法，叫做Data Augmentation. 如下图所示，比如说在一个图像检测的任务中，我们最开始数据集里的图片只有最左侧一张图片，我们可以将其左右翻转、或者进行放缩，就能够形成新的一些训练数据，来扩充我们的数据集。然而，上下翻转形成的新的图像，一般不会被我们放入数据集中，因为它并不是正常形成的图片，如果加入数据集中很可能让机器学到奇怪的内容。因此，Augmentation也不是随意的对数据进行变换，是需要有一定依据的。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114111733247.png" alt="image-20220114111733247" /><figcaption aria-hidden="true">image-20220114111733247</figcaption>
</figure></li>
</ul></li>
<li><p>2、减少未知参数或共享部分参数：</p>
<ul>
<li>减少模型的复杂度，或者使得模型中某些层共享一些参数，能够一定程度上解决Overfitting的问题。</li>
</ul></li>
<li><p>3、使用更少的特征</p>
<ul>
<li>将一些对于结果影响较为不显著的特征进行丢弃，只保留一些关键重要的特征，也可以一定程度上解决Overfitting。例如：我们要训练一个模型预测车的价格，根据车的如下特征：车大小、车颜色、车品牌、车动力等。其实，在这么多特征中，车颜色应该是对价格影响较少的，所以我们在训练时可以将这个特征舍去，不参与训练。</li>
</ul></li>
<li><p>4、Early Stopping机制（在Week1的Hw中已经提及）</p></li>
<li><p>5、Regularization正则化技术（见后）</p></li>
<li><p>6、DropOut技术（见后）</p></li>
</ul>
<h2 id="七如何避免在training-data上表现很好但是testing-data上表现很差的问题cross-validation交叉验证技术">七、如何避免在Training Data上表现很好但是Testing Data上表现很差的问题——Cross Validation交叉验证技术？</h2>
<p>​ 我们将Training Set分割为Training Set和Validation Set两个集合，一般而言比例为9：1。我们使用划分后的Training Set进行训练，在每个Epoch结束后使用训练期间机器没有见到过的Validation进行验证，依据验证集得到的Loss值来进行模型好坏的衡量。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114111856862.png" alt="image-20220114111856862" style="zoom:15%;" /></p>
<p>​ 那么该如何进行划分呢？一般来说随即划分即可。但随即划分也可能带来一些问题，比如说可能训练集中的数据都偏向于某一类，而验证集的数据偏向于另一类，就可能导致Validation出现问题.故而又出现了N-Fold Cross Validation.如下图所示,我们将Training Set分为N个集合(示例中为3个),其中N-1个集合用于训练,1个集合用于验证,然后每轮Epoch中,都执行N遍,每一遍都拿不同的集合用于训练与验证,然后计算一遍Loss值,最终选取平均Loss最小的那一组参数进行模型的更新.</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114111918585.png" alt="image-20220114111918585" style="zoom: 25%;" /></p>
<h2 id="八optimization问题产生的原因small-gradient">八、Optimization问题产生的原因：Small Gradient</h2>
<p>​ 我们先来看一下优化无法进行的根本原因是什么？无论是训练了一段时间以后Loss无法再下降，还是一开始Loss就无法下降，其终极原因就是达到了梯度接近于0的点，我们通常称为critical point。注意，此处千万不能说是碰到了local minimum，因为这样子会非常不严谨。Critical point 不仅仅指Local Minimum，还有可能是 Saddle Point（鞍点）等情况。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112021653.png" alt="image-20220114112021653" style="zoom:15%;" /></p>
<p>​ 所以我们首先要知道，当我们遇到一个Critical Point的时候，需要区分这到底是一个Local Minimum还是一个Saddle Point。因为如果是一个局部最小值，那么其实就已经无路可走了，但是如果是一个Saddle Point的话，周边仍然是有比他低的值的。还是有办法可以解决一番.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112044178.png" alt="image-20220114112044178" style="zoom:25%;" /></p>
<p>​ <span class="math inline">\(L(\theta)\)</span>函数本身会是一个非常复杂的函数,我们没法知道它的全貌,但是我们可以动用如下的数学手段来判断某一个Critical Point到底是Local Minimum还是Saddle Point,如下所示:</p>
<p>​ 利用泰勒展开,我们可以知道<span class="math inline">\(L(\theta)\)</span>在某一个点<span class="math inline">\(\theta^{&#39;}\)</span>周围的函数的近似值: <span class="math inline">\(g\)</span>为梯度,是<span class="math inline">\(L\)</span>对<span class="math inline">\(\theta\)</span>的一阶导数组成的向量.<span class="math inline">\(H\)</span>为海森矩阵,为<span class="math inline">\(L\)</span>对<span class="math inline">\(\theta\)</span>的二阶微分组成的矩阵.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112216322.png" alt="image-20220114112216322" style="zoom:15%;" /></p>
<p>​ 我们知道,在Critical Point上,梯度为0,所以我们可以将上述公式中中间那一项划掉不看,那么L(θ)在θ’周围的函数值就可以近似为L(θ’) 加上后面这一项.</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112238183.png" alt="image-20220114112238183" style="zoom:25%;" /></p>
<p>​ 因此,我们其实可以通过后面红色方框内的这一项的正负,来判断θ’周围的值的分布到底是如下图所示的三种中的哪一种:</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112259806.png" alt="image-20220114112259806" style="zoom: 25%;" /></p>
<p>​ 为了后续的数学表示,我们先将<span class="math inline">\((\theta - \theta^{&#39;})\)</span>表示为符号<span class="math inline">\(v\)</span>,那么如下图所示: 上述近似式子中的红色方框的那项,值有如下三种情况:</p>
<p>​ 如果对于所有的<span class="math inline">\(v\)</span>来说,该项恒大于0,那就代表在<span class="math inline">\(\theta^{&#39;}\)</span>周围,所有的值都比该点大,该点即为局部最小值.但是问题在于我们没法验证所有的<span class="math inline">\(v\)</span>,那应该如何呢?</p>
<p>​ 已经有人为我们证明了, 对于所有<span class="math inline">\(v\)</span>,<span class="math inline">\(v^THv\)</span>恒大于0这件事情,和海森矩阵H是一个正定矩阵 是等价的, 也等价于 H矩阵的所有特征值都是正的这件事情.</p>
<p>​ 所以理论上我们如果想要知道<span class="math inline">\(v^THv\)</span>的情况,知道θ’周围的分布,那么其实只要计算出H矩阵的所有特征值,看一下分布即可.</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112443208.png" alt="image-20220114112443208" style="zoom:25%;" /></p>
<p>​ 那么如果我们发现这个点是一个Saddle Point的话, 应当如何去继续优化呢? 我们可以利用H进行优化, 我们找到一个矩阵H的特征向量u, 其对应的特征值为λ, λ&lt;0 ,那么如下图所示: <span class="math inline">\(u^THu\)</span>这一项就应当为 &lt; 0 的值.</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112505138.png" alt="image-20220114112505138" style="zoom:15%;" /></p>
<p>​ 故而: 我们令<span class="math inline">\((\theta - \theta^{&#39;}) = u\)</span>即可得到一个比<span class="math inline">\(L(\theta^{&#39;})\)</span>小的值,完成了L值的优化.</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112600293.png" alt="image-20220114112600293" style="zoom: 25%;" /></p>
<p>​ 从执行上来讲,其实就是找一个H矩阵的特征值为负的特征向量u,这个向量u就指明了梯度下降的方向,沿着该方向走一小步,就可以完成Loss函数的值的优化.</p>
<p>​ 到此为止,已经记录了Saddle Point和Local Minimum怎么去区分, 并且也发现Saddle Point并不可怕,可以通过计算H矩阵来进行求解.</p>
<p>​ 在实际我们的训练过程中,其实达到Local Minimum的机会是很少的,基本上都会停留在Saddle Point上,那么这是不是就意味着我们如果碰到了Critical Point也就是梯度为0的点,基本上就可以用求解H来继续训练呢? 理论上应该是可以的,但是在实际操作中,其实我们并不会去这样子做,因为计算H矩阵所需要花费的时间代价太过昂贵了.我们会有其他的训练技巧,来帮助绕过这一些Saddle Point. 这些内容在下面的第9章中会讲述。同时最后的话还需要提及一点，其实大部分的训练优化做不下去了，并不是由于到达了Critical Point，而是由于学习率的原因，在一个山谷的两侧来回震荡，这一点会在10章中进行详细的叙述。</p>
<h2 id="九optimize训练tips-batch-and-momentum">九、Optimize训练Tips: Batch and Momentum:</h2>
<h4 id="batch技术">1、Batch技术</h4>
<p>​ 先前我们说过在训练的过程中，每次进行梯度下降并不是参考所有的训练数据来计算Loss函数的，而是会像下图一样通过一个Batch一个Batch的进行计算。我们在每一轮Epoch之前，一般而言都会对数据集重新划分Batch，也就是说在不同的Epoch中，每一个Batch都是不一样的，这件事情叫做Shuffle。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112658511.png" alt="image-20220114112658511" style="zoom:25%;" /></p>
<p>​ 接下去的问题就是我们为什么要使用Batch呢？考虑如下的一个例子，左侧的Full batch就是每一次机器都要看过所有的数据集以后再更新参数，而右侧的Batch Size = 1则是会在看过每个样例以后都更新一遍参数。从直观上来看，BatchSize越大，其就更新一次参数而言所需要花费的时间越大，但是其更新更有效。那么按照这样子说的话，我们为什么还要分Batch呢？实际状况跟我们的直觉有一些不同。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112717272.png" alt="image-20220114112717272" style="zoom:25%;" /></p>
<p>​ 下面这张图显示了单次update以及一轮epoch训练的时间和BatchSize的关系，我们发现单次update的时间，对于batchsize = 1和=1000来说，竟然差别不大。导致这个的原因是我们考虑了并行计算的因素，也就是使用GPU进行运算的原因。当然，如果BatchSize再增长下去，我们的GPU也是有一定的上限的所以后面也会有较大的一个时间增长。那么，右侧的这幅图就比较好理解了，对于一轮Epoch来说，如果我们的Batch Size比较小的话，在一轮Epoch中，更新Update次数就会比较多，相对而言整体的一轮Epoch的耗时就会较长。所以随着Batch Size的增大，反而一轮Epoch的时间会变长。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112747946.png" alt="image-20220114112747946" style="zoom:25%;" /></p>
<p>​ 这样看来，BatchSize越大，反而训练速度越快。这样的话BatchSize越大，速度又快，更新又准确，那为什么还要分Batch呢？下面一张图表示了BatchSize大小对训练出的网络的准确率的影响，我们可以看到，在BatchSize较大的时候，准确率直线下降，这是为什么呢？原因在于：我们先前所说BatchSize较大的话，每次Update较为准确，没有问题。但是对于网络而言，并不是一次Update就能解决问题的。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112807695.png" alt="image-20220114112807695" style="zoom:23%;" /></p>
<p>​ 如果BatchSize过大，会导致优化问题的出现，如左图所示，原因就是因为其每次update都太准确，如果遇到 critical point或者是local minimum，那么其就会深陷其中，无法继续优化了。如过分了Batch的话，由于每次使用的是不同的Batch，所以每次的L函数都会有些许不一样，如果在L1处到达了一个critical point，在一个Batch训练的时候，也许该点又重新可以继续梯度下降训练了。所以，Batch Size较小的时候带来的单次更新的”Noisy”反而对整体的网络训练能够带来好处。那么，如何衡量就是一个需要我们手工调整的问题了。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112827827.png" alt="image-20220114112827827" style="zoom:27%;" /></p>
<p>​ 最后，先辈们还发现了一个有趣的现象，就是如果我们使用BatchSize不一样的训练方法，训练同一个网络，将Training Loss训练到一样好以后，我们将其在测试集上进行测试，往往是BatchSize小的训练出来的网络，准确率较高。大致原因如下图所示：large batch容易让网络的参数进入一些Sharp Minima峡谷中，这样子的话，一旦训练数据集和测试数据集的分布有些许不同，在训练集上处于很低点的参数应用到测试集上可能会有一个比较大的Loss。相比较而言，small batch往往会跳出这种sharp minima的峡谷，找到一些较为平坦的flat minima，对于这些flat minima的参数来说，即使训练集与分布集的数据分布不同，表现出来的loss性能也不会相差太多。有兴趣的可以研读这篇paper.《On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima 》</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112849800.png" alt="image-20220114112849800" style="zoom:25%;" /></p>
<h4 id="momentum技术">2、Momentum技术</h4>
<p>​ 除了使用Batch来帮助我们训练以外，还有一种借鉴了物理世界的Momentum技术，可以帮助我们走出一些Critical point。</p>
<p>​ 如下图所示，在梯度下降中，也许我们训练至一些critical point，参数就不会继续优化了，但是在物理世界中，如果一个小球从高处滚下，其将会靠着动量滚下saddle point，也有可能靠着动量滚出local minimum。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112915300.png" alt="image-20220114112915300" style="zoom:25%;" /></p>
<p>​ 如下图所示是我们普通梯度下降的算法示意图：从<span class="math inline">\(\theta_0\)</span>开始计算梯度，然后沿着梯度反方向移动下降，一步步进行优化。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114112942271.png" alt="image-20220114112942271" style="zoom:25%;" /></p>
<p>​ 那么在Gradient Descent + Momentum的算法如下：最开始第一步和原来的一样，从<span class="math inline">\(\theta^0\)</span>开始计算梯度，然后沿着梯度反方向移动下降，达到<span class="math inline">\(\theta^1\)</span>时，此时和原先就会发生不同了，其现在的移动会结合前一步的movement（即<span class="math inline">\(m^1\)</span>）以及当前点的梯度<span class="math inline">\(g^1\)</span>，计算出一个新的下降方向<span class="math inline">\(m^2\)</span>，然后进行更新。如图所示：<span class="math inline">\(m^2\)</span>是由 <span class="math inline">\(m^1\)</span>和 <span class="math inline">\(-g^1\)</span>两个向量相加所得到的。从公式上来讲就是$m^1 - g^1 $，两者都有自己的参数，来控制影响整个梯度下降方向的比例。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113022761.png" alt="image-20220114113022761" style="zoom:25%;" /></p>
<p>​ 其实从另一个角度来看，mi其实是先前所有的梯度的和，也就是g0 - gi-1的和。所以我们可以说Momentum是考虑了上一步的movement，也可以说Momentum是考虑了先前所有更新点的梯度值。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113348655.png" alt="image-20220114113348655" style="zoom:15%;" /></p>
<h2 id="十optimize训练tips-automatic-learning-rate">十、Optimize训练Tips: Automatic Learning Rate</h2>
<p>​ 其实，当我们训练卡住的时候，并不一定是碰到了梯度较低的地方，很有可能是在某个山谷的两侧由于学习率过大的问题来回震荡。那么这种现象是怎么产生的呢？</p>
<p>​ 在Week1的HW1笔记中，曾经记录数据预处理归一化的重要性，否则很有可能因为不同特征的数据尺度相差太大导致震荡，从而导致训练不出结果，如下图所示：</p>
<p>​ 下图是一个Error Surface,就是Loss函数的平面，我们使用两种不同大小的学习率去进行梯度下降，黄色的叉叉代表训练终点。我们发现整个Error Surface中，上下维度的梯度比较陡，左右维度的梯度比较缓。如果我们采用较大的学习率，就会产生左图这样子的黑色训练线，在竖直方向疯狂震荡。但是如果我们使用如右图所示的较小的学习率，一开始是可以沿着竖直方向的梯度慢慢更新，但是当要开始沿水平方向更新的时候，会发现学习率太小了，以至于更新了10w次，还距离我们的训练重点遥遥无期。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220121170751170.png" /></p>
<p>​ 所以，我们发现，一个固定的学习率在训练中是不太合适的，最好的话是如图所示，要对不同的参数有不同的学习率，学习率要随着梯度的变化以及参数的变化而进行变化。</p>
<p>​ 于是我们首先提出了如下想法，将原来的学习率η修改成 η/(σit), 这个σit既跟参数相关又跟训练步骤（不同点所在的梯度）相关。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220121170754841.png" /></p>
<p>​ 以下就是一种最为简单的σ的计算方式，通过计算每次更新得到的参数空间所在点的梯度的Norm值的平方的平均，即RMS来计算每步中σ。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113547513.png" alt="image-20220114113547513" style="zoom:25%;" /></p>
<p>​ 这种方法被用在Adagrad中，主要思想就是，如果Loss函数在某个方向上比较平坦,梯度比较小，那么我们希望Learning Rate比较大，快速的走过这一片平坦的区域。如果在某个方向上比较陡峭，我们希望Learning Rate比较小.</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113613777.png" alt="image-20220114113613777" style="zoom:25%;" /></p>
<p>​ 接下来一种较为进阶的做法叫做RMSProp，它在计算每一步的σ的时候，结合了上一步的σ以及该步的梯度g，同时还有一个超参数α，可以进行调整。如果我们调整α比较大的话，代表其参考当前的梯度较多，也就是说如果梯度突然产生较大变化，其就能快速的反应过来，对LearningRate进行快速的调整。相较于前RMS所有先前的梯度都平均权值考虑的做法，这一做法能够更快速的对梯度的变化进行响应。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113634056.png" alt="image-20220114113634056" style="zoom:25%;" /></p>
<p>​ 如下所示，是一个较为公式化的写法，以及一个简单的示意图。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113649974.png" alt="image-20220114113649974" style="zoom: 25%;" /></p>
<p>​ 其实按照这种方法，进行训练的话，可能出现如下图所示的训练曲线：为何训练时过一段时间就会突然上下暴走呢？因为其σ是累积平均得到的，在先前的一段时间里，上下方向的更新梯度都近乎为0，累积一段时间以后，上下的梯度就会很小，然后学习率就会变得很大，但是马上又会因为我们的机制更新学习率回来，从而只会出现这样的震荡一下的现象，而不是一直的上下乱窜。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113710215.png" alt="image-20220114113710215" style="zoom:25%;" /></p>
<p>​ 在自动修改学习率的方法中，还有一种形式叫做Learning Rate Scheduling：它在原先的基础上对η也进行了一些调整。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113737186.png" alt="image-20220114113737186" style="zoom:8%;" /></p>
<p>​ 较为常见的就是Learning Rate Decay这种，随着优化的更新深入，我们使得η逐渐变小。这种想法也是比较能够理解的。类似于越往后快要到达终点了，我们就越要慢慢的靠近，精细的调整，而一开始可以以较大的速率进行更新。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113805989.png" alt="image-20220114113805989" style="zoom:25%;" /></p>
<p>​ 也有一些网络会用到类似下面的Warming Up的黑科技：</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113828593.png" alt="image-20220114113828593" style="zoom:25%;" /></p>
<h2 id="十一综合各种训练技巧的优化器adam">十一、综合各种训练技巧的优化器：Adam</h2>
<p>​ Adam是一种综合了RMSProp和Momentum技术的优化器，其大致算法如下图所示，在此处就不多赘述。原论文网址：https://arxiv.org/pdf/1412.6980.pdf</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113903161.png" alt="image-20220114113903161" style="zoom:33%;" /></p>
<h2 id="十二改变loss函数也有可能影响训练">十二、改变Loss函数，也有可能影响训练：</h2>
<p>​ 此部分通过描述分类任务，来顺带阐明改变Loss函数的形式，也有可能影响训练这样一件事情。下图是回归与分类的任务一些差别，在分类任务中，最终的结果往往是一个类别，而不是一个数值，同时，类别往往会由One-hot向量进行表示。所以，我们分类任务所输出的内容往往是一个多个数值的向量y。然后我们需要比较y和 真实类别的标签直接的差别，尽可能的最小化这个差别即可。那么，由于标签往往都是One-hot 向量，所以我们为了比较y和标签的值，往往都会先对y做一个softmax函数进行处理，将y中的所有值归约化至0-1之间，并且所有值的和为1.</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114113948987.png" alt="image-20220114113948987" style="zoom:23%;" /></p>
<p>​ Soft-Max内部对输入进行的处理如下图所示，我们假设输入y1,y2,y3，我们先将三个输入计算exp(y1),exp(y2),exp(y3),然后求和，然后计算输出。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114013901.png" alt="image-20220114114013901" style="zoom: 25%;" /></p>
<p>​ 那么在得到归一化后的y’之后，我们如何去计算y’和label y 的差距呢？按照先前回归的想法是计算两个向量之间的MSE，也就是如下图所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114036461.png" alt="image-20220114114036461" style="zoom:25%;" /></p>
<p>​ 但其实一般而言，我们在分类任务中，都会采用Cross-Entropy作为Loss函数，即如下所示的公式：</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114056586.png" alt="image-20220114114056586" style="zoom:9%;" /></p>
<p>​</p>
<p>​ 一个简单的解释是，最小化Cross-Entropy和最大化似然概率是完全等同的一件事情（至于为什么完全等同，可以找相关资料），分类任务就是要找出计算得到的y属于哪一类的概率最大，所以我们往往采用Cross-Entropy作为Loss函数。而计算Cross-Entropy之前，我们往往就是要对网络的输出进行SoftMax函数的处理。所以往往SoftMax会和Cross-Entropy绑定在一起，有趣的是Pytorch的底部实现中，如果你的Loss函数使用了Cross-Entropy，那么你在网络结构中是不需要实现SoftMax层的，因为它会自动将SoftMax层加到你的网络的最上面。</p>
<p>​ 如下所示是一个比较直观的结果：当我们采用不同的Loss函数的时候，Error Map也会截然不同。左侧采用MSE的Error map在左上角的区域上（也就是Large Loss）的区域上，梯度就很平坦，就很难训练，而采用Cross-Entropy则会好训练很多。这也就是为什么说有的时候改变Loss函数，也可以改变训练的难度。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114125892.png" alt="image-20220114114125892" style="zoom:25%;" /></p>
<h2 id="十三feature-normalization-batch-normalization-技术">十三、Feature Normalization: Batch Normalization 技术</h2>
<p>​ 我们先前提及过，当训练数据不同维度的特征的尺度相差较大时，训练难度会较大，那么Feature Normalization就是为了使得不同特征的尺度类似，从而使得Error Surface较为平滑。如下图所示：左侧的Loss函数平面，不同特征的梯度变化不同，有Smooth和Steep两类不同的内容。右侧就是做了一个Feature Normalization以后的Error Surface，各个维度都较为平滑。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114217069.png" alt="image-20220114114217069" style="zoom:25%;" /></p>
<p>​ 那么最为平常的特征正则化，如下所示：比如说给出一组x向量，我们计算向量中每个维度的平均值与方差，然后通过如下公式进行计算，我们就可以将所有维度的数据归约化至一个mean为0，deviation为1的一个分布中，使得大致的数据尺度差不多。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114244676.png" alt="image-20220114114244676" style="zoom:25%;" /></p>
<p>​ 上述的归约化处理在HW1的代码中也已经有所体现，那么先前我们在说的是数据预处理步骤中，对于所有数据的归约化。那么对于深度学习来说，可能存在如下问题：</p>
<p>​ 如下图所示，输入的特征经过归一化以后，在第一层的训练参数是比较正常的，但是经过第一层的参数以后，输出的不同维度的数据又可能回到了不同尺度这样一种状态。这样的话，对于第二层的网络来讲，参数优化又会变得较为困难。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114310723.png" alt="image-20220114114310723" style="zoom:25%;" /></p>
<p>​ 所以我们需要在层与层之间也进行归一化的操作，如下示例来讲，就是通过z1,z2,z3计算出u和σ。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114331145.png" alt="image-20220114114331145" style="zoom:25%;" /></p>
<p>​ 然后我们再将z1,z2,z3根据公式来进行归一化的操作，得到归约化后的z1,z2,z3。这边的话其实有一个有趣的内容：原本来说，如果参数更新了，z1更新了，那么只会影响a1的改变，但是现在而言，加入了BN以后，z1更新了以后，会影响到u和σ,从而会再影响归约化后的z1,z2,z3，随后a2,a3也会受到影响。所以，当我们加入归约化的时候，就需要将整个考虑成一个大的网络。所以就把BN做成一个Batch Normalization层。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114355882.png" alt="image-20220114114355882" style="zoom:25%;" /></p>
<p>​ 并且，我们在训练过程中，由于输入数据往往是一个Batch一个Batch输入的，所以训练时计算的u和σ我们往往不会去计算所有的训练数据，而是计算该Batch内部的所有数据的u（向量）和σ（向量）。故而，这个技术叫Batch Normalization。</p>
<p>​ 所以，Batch Normalization往往需要在Batch比较大的时候才会可以使用，会比较好一些。不然的话计算得到的u和σ并不能代表训练数据的一些分布，归约化就会出现一些问题。同时，再归约化时也会有一些小的问题如下：</p>
<p>​ 因为我们归约化至了mean = 0, deviation=1的数据分布，会不会影响后续机器学习的性能，所以我们再归约化后又加入了γ和β两个参数，在训练开始时，γ 一般为1，β一般为0，帮助其更好的拟合后续的特征，同时又能较大程度的保持各个维度的数据在统一尺度下。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114421588.png" alt="image-20220114114421588" style="zoom:26%;" /></p>
<p>​ 那么先前所讲的是在训练过程中的BatchNoramlization,那么如果在Testing的过程中，</p>
<p>​ 每次输入一个数据，没有凑齐一个Batch的情况下，BatchNormalization又应当如何执行呢？此时，我们的u和σ就不来源于测试的Batch了，而是来源于训练时候每一个Batches计算得到的u的均值依据一些权重累加得到。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114114447990.png" alt="image-20220114114447990" style="zoom:25%;" /></p>
<p>​ 总而言之，Batch Normalization能让你的error surface 更加平滑，从而降低训练的难度，让网络拥有更好的性能，这样的解释无论是理论还是实验都已经被人所证实。具体可以参见这篇论文《How Does Batch Normalization Help Optimization?》。</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>ML2021课程系列笔记</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Training Tricks</tag>
      </tags>
  </entry>
  <entry>
    <title>ML2021课程系列笔记1——DeepLearning基本介绍</title>
    <url>/2021/12/17/d3d6f910aaf2/</url>
    <content><![CDATA[<h3 id="hung-yi-lee-李宏毅-machine-learning2021spring课程week1笔记">Hung-yi Lee (李宏毅) MACHINE LEARNING2021SPRING课程Week1笔记</h3>
<h3 id="课程网址httpsspeech.ee.ntu.edu.twhyleeml2021-spring.html">课程网址：https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html</h3>
<p>其实Machine Learning的过程就是以下的三个基本步骤：</p>
<p>​ 1、 Function with Unknown Parameters</p>
<p>​ 2、 Define Loss From Training Data</p>
<p>​ 3、 Optimization</p>
<p>本篇就围绕这三个步骤进行简单的讲解：</p>
<h2 id="一最简单的ml模型函数">一、最简单的ML模型函数：</h2>
<p>​ 在最简单的ML的过程中：</p>
<p>​ 我们的第一步就是要找一个有未知参数的函数，那么最简单的就是最为纯粹的线性模型：Y = wx1 + b.</p>
<p>​ 我们将x1称为feature，w，b称为未知待训练参数，在第二步中，我们定义一个损失函数Loss，这个损失函数代表该线性模型拟合数据的好坏程度。它是模型未知参数的函数，即L(w,b)。我们利用训练数据集，来计算这个Loss函数的值，从而判断该模型拟合数据的好坏。</p>
<p>​ 第三步，我们就是要找到一组最好的w和b，使得Loss函数最小，也就是使得我们的模型最能够拟合数据。在这一步中，常常会用到梯度下降的方法去进行优化。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220121170849128.png" /></p>
<p>​ 至此，一个最为简单的机器学习任务就完成了，我们用一个最简单的带两个未知参数的函数，去拟合一组数据，找到了最能够拟合这组数据的两个参数的数值。简单而言，训练的步骤就是由以下这三步组成。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114105405284.png" alt="image-20220114105405284" style="zoom: 25%;" /></p>
<h2 id="二进阶的ml模型函数">二、进阶的ML模型函数</h2>
<p>​ 然后我们在想，刚才那样是最简单的线性模型，如果我们增加features，我们可以得到如下图所示的带7个参数的模型，也可以得到有28个参数的模型……当然在第二步和第三步中过程是一样的。参数越多，我们能够拟合的features就越多。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114105522828.png" alt="image-20220114105522828" style="zoom: 8%;" /> <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114105556231.png" alt="image-20220114105556231" style="zoom:8%;" /></p>
<p>​ 但是，仅仅是线性的模型的组合，还是让我们能够拟合的函数太过有限了，所以我们还想在第一步中找到更flex一点的函数，于是乎，我们就发现了sigmoid函数：它也有b，w，c三个未知参数。。那么进行推广以后，也可以将所有的函数</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114105640184.png" alt="image-20220114105640184" style="zoom:19%;" /></p>
<p>​ 那么进行推广以后，我们可以将如图所示的红色函数，用三个sigmoid函数的叠加来进行拟合，也就是能够列出一个图片左下方的公式，这个公式共有3*3 + 1 = 10个参数。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114105705024.png" alt="image-20220114105705024" style="zoom:25%;" /></p>
<p>​</p>
<p>​ 我们将这个式子提取出来，再仔细的看一看：</p>
<p>​ 其实我们可以讲上述这个式子写成矩阵相乘的形式，我们首先看sigmoid函数内部所干的事情，sigmoid函数内部所干的事情就可以写成如下所示的矩阵表示形式，r = b + W * x</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114105732731.png" alt="image-20220114105732731" style="zoom:25%;" /></p>
<p>​ 然后我们的r向量中的每一项再分别通过sigmoid函数，得到a向量</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114105800543.png" alt="image-20220114105800543" style="zoom:25%;" /></p>
<p>​ 最后a向量[a1,a2,a3]乘上系数c1,c2,c3，再加上偏执b，得到最终的预测值y。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114105825308.png" alt="image-20220114105825308" style="zoom:25%;" /></p>
<p>​ 故而我们最终就可以将这个more flexible的函数写成如下形式，其中的W，b(绿色)，c，b(灰色)，都是未知参数，而x是features，y是tag。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114105847631.png" alt="image-20220114105847631" style="zoom:25%;" /></p>
<p>​ 随后，我们可以把所有的未知参数拼接起来，称为向量θ。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114105904095.png" alt="image-20220114105904095" style="zoom: 15%;" /></p>
<p>​ 然后，再次回到ML框架中，在第二步的寻找Loss函数的时候，与前面基础的其实相差不多。此时Loss函数应当是θ的函数，即L(θ)，最后再使用梯度下降优化的时候，我们就是要找到一个θ*来使得Loss函数值最小。</p>
<p>​ <span class="math inline">\(\theta^{*} = arg min_\theta L\)</span></p>
<p>​ 至于方法，也与前面一致：计算Loss函数对各个未知参数的倒数，然后梯度下降即可。按照下图所示，我们将L对各个未知参数的导数组成了一个向量，称为梯度。然后依据学习率来进行未知参数的更新。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114110015271.png" alt="image-20220114110015271" style="zoom:23%;" /></p>
<p>​ 在这个训练优化参数的过程中，我们需要注意，我们往往不会一次性拿所有的训练数据来计算损失函数，从而更新未知参数，而是会将训练数据分成一个batch一个batch，每次使用一个batch来计算损失函数，进而计算梯度，更新未知参数。</p>
<p>​ 所有我们需要区分以下一些名词：<strong>Update / Epoch / Batch Size / Training Data</strong></p>
<ul>
<li><p>Update: 每做一次梯度下降，更新一次参数，就叫做一次Update</p></li>
<li><p>Batch Size: 每次用来计算梯度下降更新参数用到的训练集中样本的个数，我们在训练时往往会将其分为一个Batch一个Batch，每次使用一个Batch来计算梯度，更新参数。</p></li>
<li><p>Training Data: 所有的训练数据集样本。</p></li>
<li><p>Epoch: 每当使用过一轮所有的训练数据集样本以后，叫做一个Epoch</p></li>
</ul>
<p>​ 整个的Optimization的过程如下所示：</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114110125128.png" alt="image-20220114110125128" style="zoom:23%;" /></p>
<p>​ 下面是一些帮助理解的例子：</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114110144324.png" alt="image-20220114110144324" style="zoom:25%;" /></p>
<h2 id="三ml模型最终进化deeplearning">三、ML模型最终进化——DeepLearning</h2>
<p>​ 在第二部分的function中，我们拟合了许多个sigmoid函数，sigmoid函数内部又是线性的函数。最终，形成了如下图所示的一个数据流。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114110230140.png" alt="image-20220114110230140" style="zoom:20%;" /></p>
<p>​ 其实，我们在得到[a1,a2,a3]之后，还可以将[a1,a2,a3]再次作为输入，输入到另一个类似结构中去，如下所示：这样子所形成的模型够更好的拟合数据。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114110253145.png" alt="image-20220114110253145" style="zoom:25%;" />‘</p>
<p>​ 我们将每一个sigmoid函数组成的单位叫做一个Neuron，每处理一次数据所有的Neuron组成的叫做一个Hidden Layer，由于整个架构会有很多个Hidden Layer组成，这种架构的模型函数就叫做<strong>Deep Neural Network ( DNN )</strong>，深度神经网络，</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114110326577.png" alt="image-20220114110326577" style="zoom:20%;" />‘’</p>
<p>​ 以下便是一些比较经典的DNN架构的网络：ALexNet、VGG、GoogleNet等等</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/imac/image-20220114110348644.png" alt="image-20220114110348644" style="zoom:25%;" /></p>
<h2 id="附录-hw1-回归任务作业笔记">附录： HW1 回归任务作业笔记</h2>
<h4 id="有关数据预处理中的归一化处理">1、有关数据预处理中的归一化处理</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.data[:, <span class="number">40</span>:] = (self.data[:, <span class="number">40</span>:] - self.data[:, <span class="number">40</span>:].mean(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)) / self.data[:, <span class="number">40</span>:].std(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>​ 其可以帮助你将数据的不同维度的特征数值，压到类似的尺度上，不至于出现有些维度的特征数值是km级别，有些可能是mm级别。如果不同维度的特征尺度相差太大，会导致训练时梯度下降算法非常难以执行，Lr过小的话，体现出的结果就是训练了半天Loss降不下去。Lr过大又可能导致Loss乱窜。所以归一化处理还是很重要的。</p>
<h4 id="如果模型太复杂易过拟合我们可以在loss函数中加入l2正则化项">2、如果模型太复杂易过拟合，我们可以在Loss函数中加入L2正则化项</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_loss</span>(<span class="params">self, pred, target</span>):</span></span><br><span class="line">	regularization_loss = <span class="number">0</span></span><br><span class="line">	<span class="comment"># 使用L2正则项</span></span><br><span class="line">	<span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">		regularization_loss += torch.<span class="built_in">sum</span>(param ** <span class="number">2</span>)</span><br><span class="line">	<span class="keyword">return</span> self.criterion(pred, target) + <span class="number">0.00075</span> * regularization_loss</span><br></pre></td></tr></table></figure>
<h4 id="训练模型的基本步骤以及一些tricks">3、训练模型的基本步骤以及一些tricks</h4>
<ul>
<li>1）每一个epoch中需要执行的必备步骤：切换模型至train模式，通过dataLoader迭代遍历每一个Batch，在每一个Batch中，首先将梯度调整至0，然后前向计算，然后计算Loss，然后通过Loss.backward()反向传播，最后通过优化器更新模型参数。</li>
<li>2）在每一轮epoch结束后 ，使用验证集进行验证，计算dev_mse.</li>
<li>3）在每一轮epoch结束后，如果dev_mse没有进步的话early_stop_cnt++,当early_stop_cnt达到设定值时，提早结束训练。（代表已经很多轮没有进步了）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">min_mse = <span class="number">1000.</span></span><br><span class="line">early_stop_cnt = <span class="number">0</span></span><br><span class="line">epoch = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> epoch &lt; n_epochs:</span><br><span class="line">	model.train() <span class="comment"># set model to training mode</span></span><br><span class="line">	<span class="keyword">for</span> x, y <span class="keyword">in</span> tr_set: <span class="comment"># iterate through the dataloader</span></span><br><span class="line">		optimizer.zero_grad() <span class="comment"># set gradient to zero</span></span><br><span class="line">		x, y = x.to(device), y.to(device) <span class="comment"># move data to device (cpu/cuda)</span></span><br><span class="line">		pred = model(x) <span class="comment"># forward pass (compute output)</span></span><br><span class="line">		mse_loss = model.cal_loss(pred, y) <span class="comment"># compute loss</span></span><br><span class="line">		mse_loss.backward() <span class="comment"># compute gradient (backpropagation)</span></span><br><span class="line">		optimizer.step() <span class="comment"># update model with optimizer</span></span><br><span class="line">	<span class="comment"># After each epoch, test your model on the validation (development) set.</span></span><br><span class="line">	dev_mse = dev(dv_set, model, device)</span><br><span class="line">	<span class="keyword">if</span> dev_mse &lt; min_mse:</span><br><span class="line">		<span class="comment"># Save model if your model improved</span></span><br><span class="line">		min_mse = dev_mse</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&#x27;Saving model (epoch = &#123;:4d&#125;, loss = &#123;:.4f&#125;)&#x27;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>, min_mse))</span><br><span class="line">		torch.save(model.state_dict(), config[<span class="string">&#x27;save_path&#x27;</span>]) <span class="comment"># Save model to specified path</span></span><br><span class="line">		early_stop_cnt = <span class="number">0</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		early_stop_cnt += <span class="number">1</span></span><br><span class="line">	epoch += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># Stop training if your model stops improving for &quot;config[&#x27;early_stop&#x27;]&quot; epochs.</span></span><br><span class="line">	<span class="keyword">if</span> early_stop_cnt &gt; config[<span class="string">&#x27;early_stop&#x27;</span>]:</span><br><span class="line">		<span class="keyword">break</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>ML2021课程系列笔记</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch学习笔记9——常用编码技巧（更新中）</title>
    <url>/2021/12/17/17d1273518ee/</url>
    <content><![CDATA[<h3 id="task1">Task1：</h3>
<h4 id="任务描述完成padding填充使得h和w为2的倍数同时实现下图所示的变换">任务描述：完成padding填充，使得H和W为2的倍数同时，实现下图所示的变换：</h4>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/mac/image-20211229101356170.png" /></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输入的x，维度size为[B,L,C] ,其中L = H * W</span></span><br><span class="line">x = x.view(B, H, W, C) <span class="comment"># 首先将其重新展为 [B,H,W,C]</span></span><br><span class="line"><span class="comment"># padding 然后，如果输入feature map的H，W不是2的整数倍，需要进行padding</span></span><br><span class="line">pad_input = (H % <span class="number">2</span> == <span class="number">1</span>) <span class="keyword">or</span> (W % <span class="number">2</span> == <span class="number">1</span>)</span><br><span class="line"><span class="keyword">if</span> pad_input:</span><br><span class="line">   <span class="comment"># (C_front, C_back, W_left, W_right, H_top, H_bottom)</span></span><br><span class="line">   <span class="comment"># 注意这里的Tensor通道是[B, H, W, C]，所以会和官方文档有些不同</span></span><br><span class="line">   x = F.pad(x, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, W % <span class="number">2</span>, <span class="number">0</span>, H % <span class="number">2</span>)) <span class="comment"># 在右侧和底侧进行padding</span></span><br><span class="line">   </span><br><span class="line"><span class="comment"># 此时要开始进行下采样了，如何在H，W这个平面上进行下采样呢？ 非常关键的编码技巧！！</span></span><br><span class="line">x0 = x[:, <span class="number">0</span>::<span class="number">2</span>, <span class="number">0</span>::<span class="number">2</span>, :]  <span class="comment"># [B, H/2, W/2, C]   ::2 代表 步长</span></span><br><span class="line">x1 = x[:, <span class="number">1</span>::<span class="number">2</span>, <span class="number">0</span>::<span class="number">2</span>, :]  <span class="comment"># [B, H/2, W/2, C]</span></span><br><span class="line">x2 = x[:, <span class="number">0</span>::<span class="number">2</span>, <span class="number">1</span>::<span class="number">2</span>, :]  <span class="comment"># [B, H/2, W/2, C]</span></span><br><span class="line">x3 = x[:, <span class="number">1</span>::<span class="number">2</span>, <span class="number">1</span>::<span class="number">2</span>, :]  <span class="comment"># [B, H/2, W/2, C]</span></span><br><span class="line"><span class="comment"># 然后将四个子矩阵在channel维度[也就是最后一个维度]上进行拼接</span></span><br><span class="line">x = torch.cat([x0, x1, x2, x3], -<span class="number">1</span>)  <span class="comment"># [B, H/2, W/2, 4*C]</span></span><br><span class="line"><span class="comment"># 再重新将H/2,W/2平面展成1个维度</span></span><br><span class="line">x = x.view(B, -<span class="number">1</span>, <span class="number">4</span> * C)  <span class="comment"># [B, H/2*W/2, 4*C]</span></span><br></pre></td></tr></table></figure>
<h3 id="task2">Task2:</h3>
<h4 id="任务描述-python中的广播机制">任务描述： Python中的广播机制</h4>
<p>​ 在python中使用numpy进行<strong>按位运算</strong>的时候，有一个小技巧可以帮助减少代码量——那就是broadcasting,广播机制。简单来说，broadcasting可以这样理解：如果你有一个m * n的矩阵，让它加减乘除一个1 * n的矩阵，它会被复制m次，成为一个m * n的矩阵，然后再逐元素地进行加减乘除操作。同样地对m * 1的矩阵成立。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/mac/750.png" /></p>
<p>代码示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">A = numpy.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">result = A + <span class="number">100</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	[101 102 103]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 就不再需要去书写 A + [100,100,100] 了</span></span><br><span class="line"></span><br><span class="line">A = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])  <span class="comment"># [3,2]</span></span><br><span class="line">result = A + [<span class="number">100</span>, <span class="number">200</span>, <span class="number">300</span>]   <span class="comment"># [3,1]</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">[[101 202 303]</span></span><br><span class="line"><span class="string"> [104 205 306]]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>### Task3:</p>
<h4 id="section"></h4>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Pytorch系列笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch学习笔记8——常用函数整理（更新中）</title>
    <url>/2021/12/16/60a9625b780d/</url>
    <content><![CDATA[<h3 id="softmax-dim应当如何填">1、SoftMax — dim应当如何填？</h3>
<p>官方文档：https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html?highlight=softmax#torch.nn.functional.softmax</p>
<p>1）标准用法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.nn.functional.softmax(<span class="built_in">input</span>, dim)</span><br><span class="line">（Applies a softmax function.）</span><br></pre></td></tr></table></figure>
<p>2）依赖库</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure>
<p>3）简单示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=torch.rand(<span class="number">3</span>,<span class="number">16</span>,<span class="number">20</span>) <span class="comment"># 我们看一个三维的tensor</span></span><br><span class="line">b=F.softmax(a,dim=<span class="number">0</span>)  </span><br><span class="line"><span class="comment"># dim = 0代表 输出的是在dim=0维上的概率分布，也就是说 对于任意的i,j (i是dim=1上的某个坐标，j是dim=2上的某个坐标)，通过softmax之后，要求 a[0][i][j] + a[1][i][j] + a[2][i][j] = 1 【此处仅有3项相加，原因是a向量dim=0维度 长度为3，仅有3个元素。】</span></span><br></pre></td></tr></table></figure>
<p>4）一个更为一般的示例</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=torch.rand(x1,x2,x3,x4,……,xn) <span class="comment"># 我们看一个n维的tensor</span></span><br><span class="line">b=F.softmax(a,dim=m)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dim = m代表 输出的是在dim=m维上的概率分布，也就是说 通过softmax之后，对于任意的dim!=m的维度的一个定位：i1,i2,i3,……im-1,im+1,……in，需要满足如下公式 </span></span><br><span class="line"><span class="comment">#  a[i1][i2]……[im-1][0][im+1]……[in] + </span></span><br><span class="line"><span class="comment">#  a[i1][i2]……[im-1][1][im+1]……[in] +</span></span><br><span class="line"><span class="comment">#  a[i1][i2]……[im-1][2][im+1]……[in] +</span></span><br><span class="line"><span class="comment">#  …… +</span></span><br><span class="line"><span class="comment">#  a[i1][i2]……[im-1][xm][im+1]……[in] = 1 即可</span></span><br></pre></td></tr></table></figure>
<h3 id="view函数">2、View函数</h3>
<p>官方文档：https://pytorch.org/docs/stable/generated/torch.Tensor.view.html?highlight=view#torch.Tensor.view</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Tensor.view(*shape) → Tensor</span><br><span class="line">(Returns a new tensor with the same data as the `self` tensor but of a different `shape`.)</span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import torch</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.rand(<span class="number">10</span>)  <span class="comment"># 一个1维的Tensor</span></span><br><span class="line">y = x.view(<span class="number">2</span>, <span class="number">5</span>) <span class="comment"># 将其resize成了一个2*5大小的 二维的Tensor</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">x: tensor([0.6611, 0.3041, 0.8008, 0.1733, 0.0197, 0.3914, 0.0468, 0.2380, 0.4159,</span></span><br><span class="line"><span class="string">        0.8241])</span></span><br><span class="line"><span class="string">y: tensor([[0.6611, 0.3041, 0.8008, 0.1733, 0.0197],</span></span><br><span class="line"><span class="string">        [0.3914, 0.0468, 0.2380, 0.4159, 0.8241]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>4）扩展示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.rand(<span class="number">20</span>)  <span class="comment"># 一个1维的Tensor</span></span><br><span class="line">y = x.view(<span class="number">2</span>,<span class="number">5</span>,-<span class="number">1</span>) <span class="comment"># 将其resize成了一个 2*5*? 大小的 三维的Tensor，？代表第三维度的大小需要推断得到，在此处的话，最后应该会形成一个2*5*2的三维Tensor。</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">x: tensor([0.5704, 0.4154, 0.0700, 0.8145, 0.1743, 0.1049, 0.1678, 0.2554, 0.9557,</span></span><br><span class="line"><span class="string">        0.0484, 0.7714, 0.5377, 0.8711, 0.6069, 0.0996, 0.6384, 0.9334, 0.2851,</span></span><br><span class="line"><span class="string">        0.5883, 0.5882])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">y: tensor([[[0.5704, 0.4154],</span></span><br><span class="line"><span class="string">         [0.0700, 0.8145],</span></span><br><span class="line"><span class="string">         [0.1743, 0.1049],</span></span><br><span class="line"><span class="string">         [0.1678, 0.2554],</span></span><br><span class="line"><span class="string">         [0.9557, 0.0484]],</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        [[0.7714, 0.5377],</span></span><br><span class="line"><span class="string">         [0.8711, 0.6069],</span></span><br><span class="line"><span class="string">         [0.0996, 0.6384],</span></span><br><span class="line"><span class="string">         [0.9334, 0.2851],</span></span><br><span class="line"><span class="string">         [0.5883, 0.5882]]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下为错误示例：</span></span><br><span class="line">x = torch.rand(<span class="number">10</span>)</span><br><span class="line">y = x.view(<span class="number">2</span>,<span class="number">3</span>)  <span class="comment"># 会报错</span></span><br><span class="line">y = x.view(<span class="number">2</span>,)   <span class="comment"># 会报错</span></span><br></pre></td></tr></table></figure>
<h3 id="permute函数">3、Permute函数</h3>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.permute(input, dims) → Tensor</span><br><span class="line">- parameters:</span><br><span class="line">  input (Tensor) – the input tensor.</span><br><span class="line">  dims (tuple of python:ints) – The desired ordering of dimensions</span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(x.size())</span><br><span class="line"><span class="comment"># torch.Size([2, 3, 5])</span></span><br><span class="line"><span class="built_in">print</span>(torch.permute(x, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)).size())</span><br><span class="line"><span class="comment"># torch.Size([5, 2, 3])</span></span><br><span class="line"><span class="comment"># 我们可以看到：  [dim0,dim1,dim2,dim3,dim4]  经过permute(2,0,1,4,3)以后：</span></span><br><span class="line"><span class="comment"># （ permute的含义：	现在的第0维应当为原来的第2维，现在的第1维应当为原来的第0维，…… ）</span></span><br><span class="line"><span class="comment"># 会变成如下形式。[dim2,dim0,dim1,dim4,dim3]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="nn.identity">4、nn.Identity()</h3>
<p>官方文档：https://pytorch.org/docs/stable/generated/torch.nn.Identity.html#torch.nn.Identity</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class torch.nn.Identity(*args, **kwargs)</span><br><span class="line">- A placeholder identity operator that is argument-insensitive.</span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import torch.nn</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; m = nn.Identity(54, unused_argument1=0.1, unused_argument2=False)</span><br><span class="line">&gt;&gt;&gt; input = torch.randn(128, 20)</span><br><span class="line">&gt;&gt;&gt; output = m(input)</span><br><span class="line">&gt;&gt;&gt; print(output.size())</span><br><span class="line">torch.Size([128, 20])</span><br><span class="line"></span><br><span class="line"># 经过m等于 没有发生任何变换 </span><br></pre></td></tr></table></figure>
<h3 id="nn.parameter">5、nn.Parameter</h3>
<p>官方文档：https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html?highlight=parameter#torch.nn.parameter.Parameter</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class torch.nn.Parameter(data=None, requires_grad=True)</span><br><span class="line">- A kind of Tensor that is to be considered a module parameter.</span><br><span class="line">- 创建一个可训练参数</span><br><span class="line">- when they’re assigned as Module attributes they are automatically added to the list of its parameters, and will appear e.g. in parameters() iterator. </span><br><span class="line">- 当它们作为模型的一个属性的时候，会被自动加入到模型的可训练参数中去</span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Layer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">	  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">	  	self.cls_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, <span class="number">762</span>))</span><br></pre></td></tr></table></figure>
<h3 id="nn.functional.pad">6、nn.functional.pad</h3>
<p>官方文档：https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html?highlight=pad#torch.nn.functional.pad</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.nn.functional.pad(input, pad, mode=&#x27;constant&#x27;, value=0.0)</span><br><span class="line">-	input (Tensor) – N-dimensional tensor</span><br><span class="line">- pad (tuple) – m-elements tuple, where m/2 ≤ input dimensions and m is even.</span><br><span class="line">- mode – &#x27;constant&#x27;, &#x27;reflect&#x27;, &#x27;replicate&#x27; or &#x27;circular&#x27;. Default: &#x27;constant&#x27;</span><br><span class="line">- value – fill value for &#x27;constant&#x27; padding. Default: 0</span><br><span class="line"></span><br><span class="line">对于padding-size的说明：</span><br><span class="line">	填充尺寸用来填充输入的某些维度，从最后一个维度开始进行描述。比如说:</span><br><span class="line">	如果想要填充最后一个维度，那就设置为(padding_left,padding_right)</span><br><span class="line">	如果想要填充最后两个维度，那就设置为(padding_left,padding_right,padding_top,padding_bottom)</span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.function <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">t2d = torch.rand(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">p1d = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(t2d)</span><br><span class="line">out = F.pad(t2d, p1d, <span class="string">&quot;constant&quot;</span>, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(out.size())</span><br><span class="line"><span class="built_in">print</span>(out)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[0.6359, 0.0629],</span></span><br><span class="line"><span class="string">        [0.5814, 0.5980]])</span></span><br><span class="line"><span class="string">torch.Size([2, 4])</span></span><br><span class="line"><span class="string">tensor([[0.0000, 0.6359, 0.0629, 0.0000],</span></span><br><span class="line"><span class="string">        [0.0000, 0.5814, 0.5980, 0.0000]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>4）扩展示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>t4d = torch.empty(<span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>p3d = (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>) <span class="comment"># pad by (0, 1), (2, 1), and (3, 3)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>out = F.pad(t4d, p3d, <span class="string">&quot;constant&quot;</span>, <span class="number">0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(out.size())</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<h3 id="flatten">7、flatten</h3>
<p>官方文档：https://pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.flatten(input, start_dim=0, end_dim=- 1) → Tensor</span><br><span class="line">  - input (Tensor) – the input tensor.</span><br><span class="line">  - start_dim (int) – the first dim to flatten</span><br><span class="line">  - end_dim (int) – the last dim to flatten</span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">t2d = torch.rand(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(t2d, t2d.size())</span><br><span class="line">out = torch.flatten(t2d, <span class="number">1</span>)  <span class="comment"># 从第1维开始，展平后续所有维度</span></span><br><span class="line"><span class="built_in">print</span>(out, out.size())</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[[0.4151, 0.8645],</span></span><br><span class="line"><span class="string">         [0.1289, 0.2260]],</span></span><br><span class="line"><span class="string">        [[0.3302, 0.0393],</span></span><br><span class="line"><span class="string">         [0.9822, 0.5305]]]) torch.Size([2, 2, 2])</span></span><br><span class="line"><span class="string">tensor([[0.4151, 0.8645, 0.1289, 0.2260],</span></span><br><span class="line"><span class="string">        [0.3302, 0.0393, 0.9822, 0.5305]]) torch.Size([2, 4])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>4）扩展示例:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Q1、现在有一个向量t，其size为 [A,B,C,D,E,F,G] ,然后我们对其应用flatten: torch.flatten(t,2,4),</span><br><span class="line">那么size会变成？</span><br><span class="line">Answer: [A,B,C*D*E,F,G]</span><br><span class="line"></span><br><span class="line">Q2、现在有一个向量t，其size为 [A,B,C,D,E,F,G] ,然后我们对其应用flatten: torch.flatten(t,-2),</span><br><span class="line">那么size会变成？</span><br><span class="line">Answer: [A,B,C,D,E,F*G] 等效于应用torch.flatten(t,5) 等效于应用torch.flatten(t,5,6)</span><br><span class="line"></span><br><span class="line">Q3、现在有一个向量t，其size为 [A,B,C,D,E,F,G] ,然后我们对其应用flatten: torch.flatten(t),</span><br><span class="line">那么size会变成？</span><br><span class="line">Answer: [A*B*C*D*E*F*G] </span><br><span class="line"></span><br><span class="line">Q3、现在有一个向量t，其size为 [A,B,C,D,E,F,G] ,然后我们对其应用flatten: torch.flatten(t,1),</span><br><span class="line">那么size会变成？</span><br><span class="line">Answer: [A,B*C*D*E*F*G] </span><br></pre></td></tr></table></figure>
<h3 id="transpose">8、Transpose</h3>
<p>官方文档：https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.transpose(input, dim0, dim1) → Tensor</span><br><span class="line"></span><br><span class="line">-	Returns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped.</span><br><span class="line">- input (Tensor) – the input tensor.</span><br><span class="line">- dim0 (int) – the first dimension to be transposed</span><br><span class="line">- dim1 (int) – the second dimension to be transposed</span><br><span class="line"></span><br><span class="line">注：此处的转置通用于高阶矩阵，函数将会对dim0和dim1这两个维度形成的平面进行转置，交换dim0和dim1,而不影响其他维度。</span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t2d = torch.rand(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(t2d, t2d.size())</span><br><span class="line">out = torch.transpose(t2d, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(out, out.size())</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[0.5228, 0.2990, 0.1111],</span></span><br><span class="line"><span class="string">        [0.4857, 0.4479, 0.6637]]) torch.Size([2, 3])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([[0.5228, 0.4857],</span></span><br><span class="line"><span class="string">        [0.2990, 0.4479],</span></span><br><span class="line"><span class="string">        [0.1111, 0.6637]]) torch.Size([3, 2])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>4）扩展示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">在高维的矩阵中，不要太过注重打印数据显示的变化形式，从维度长度的变化入手，即可清晰的搞懂</span><br><span class="line"></span><br><span class="line">Q1、现在有一个向量t，其size为 [A,B,C,D,E,F,G] ,然后我们对其应用transpose: torch.transpose(t,2,4),</span><br><span class="line">那么size会变成？</span><br><span class="line"></span><br><span class="line">Answer: [A,B,E,D,C,F,G]  可以看到，从size上来讲其实就是交换了第2维和第4维的长度。从数据上来讲，你可以想象其找到了第2维和第4维形成的数据平面，然后应用了正常的转置。</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="cat函数">9、Cat函数</h3>
<p>官方文档：https://pytorch.org/docs/stable/generated/torch.cat.html?highlight=cat#torch.cat</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.cat(tensors, dim=0, *, out=None) → Tensor</span><br><span class="line"></span><br><span class="line">- Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty.</span><br><span class="line"></span><br><span class="line">- tensors (sequence of Tensors) – any python sequence of tensors of the same type. Non-empty tensors provided must have the same shape, except in the cat dimension.</span><br><span class="line">- dim (int, optional) – the dimension over which the tensors are concatenated</span><br><span class="line"></span><br><span class="line">注：tensors参数需要输入一个tensor的序列，所有的需要拼接的tensors需要有同样的形状维度（除了拼接的那一维）</span><br><span class="line">dim指定要拼接的维度</span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(x, x.size())</span><br><span class="line">out = torch.cat((x, x, x), <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(out, out.size())</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">tensor([[-1.2926, -0.3155,  0.5966],</span></span><br><span class="line"><span class="string">        [ 0.8921, -2.0986,  0.0748]]) torch.Size([2, 3])</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">tensor([[-1.2926, -0.3155,  0.5966],</span></span><br><span class="line"><span class="string">        [ 0.8921, -2.0986,  0.0748],</span></span><br><span class="line"><span class="string">        [-1.2926, -0.3155,  0.5966],</span></span><br><span class="line"><span class="string">        [ 0.8921, -2.0986,  0.0748],</span></span><br><span class="line"><span class="string">        [-1.2926, -0.3155,  0.5966],</span></span><br><span class="line"><span class="string">        [ 0.8921, -2.0986,  0.0748]]) torch.Size([6, 3])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>4）扩展示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Q1、现在有一个向量t1，其size为 [A,B,C,D] ,向量t2，其size为[A,B,E,D] 然后我们对其应用cat: torch.cat((t1,t2),2),那么size会变成？</span><br><span class="line"></span><br><span class="line">Answer: [A,B,C+E,D]</span><br><span class="line"></span><br><span class="line">Q2、现在有一个向量t1，其size为 [A,B,C,D] ,向量t2，其size为[A,B,E,D] 然后我们对其应用cat: torch.cat((t1,t2),1),那么size会变成？</span><br><span class="line"></span><br><span class="line">Answer: 函数会报错，因为除了维度1以外，t1和t2的维度2的shape不一样</span><br></pre></td></tr></table></figure>
<h3 id="roll">10、Roll</h3>
<p>官方文档：https://pytorch.org/docs/stable/generated/torch.roll.html?highlight=roll#torch.roll</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.roll(input, shifts, dims=None) → Tensor</span><br><span class="line"></span><br><span class="line">	沿着给定的维数滚动张量。移动到最后一个位置以外的元素将在第一个位置重新引入。如果没有指定尺寸，张量在滚动之前将被压平，然后恢复到原来的形状。</span><br><span class="line">	</span><br><span class="line">- input (Tensor) – the input tensor.</span><br><span class="line">- shifts (int or tuple of python:ints) – 张量的元素被移动的位置数。如果shift是一个元组，dim必须是一个相同大小的元组，并且每个维度将被相应的值滚动</span><br><span class="line">- dims (int or tuple of python:ints) – Axis along which to roll</span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]).view(<span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">y1 = torch.roll(x, <span class="number">1</span>, <span class="number">0</span>)  <span class="comment"># 沿着第0维（列），滚动1个元素</span></span><br><span class="line"><span class="built_in">print</span>(y1)</span><br><span class="line">y2 = torch.roll(x, -<span class="number">1</span>, <span class="number">0</span>) <span class="comment"># 沿着第0维（列），滚动-1个元素</span></span><br><span class="line"><span class="built_in">print</span>(y2)</span><br><span class="line">y3 = torch.roll(x, shifts=(<span class="number">2</span>, <span class="number">1</span>), dims=(<span class="number">0</span>, <span class="number">1</span>)) <span class="comment"># 沿着第0维（列），滚动2个元素，沿着第1维（行），滚动1个元素</span></span><br><span class="line"><span class="built_in">print</span>(y3)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">x:tensor([[1, 2],</span></span><br><span class="line"><span class="string">        [3, 4],</span></span><br><span class="line"><span class="string">        [5, 6],</span></span><br><span class="line"><span class="string">        [7, 8]])</span></span><br><span class="line"><span class="string">y1:tensor([[7, 8],</span></span><br><span class="line"><span class="string">        [1, 2],</span></span><br><span class="line"><span class="string">        [3, 4],</span></span><br><span class="line"><span class="string">        [5, 6]])</span></span><br><span class="line"><span class="string">y2:tensor([[3, 4],</span></span><br><span class="line"><span class="string">        [5, 6],</span></span><br><span class="line"><span class="string">        [7, 8],</span></span><br><span class="line"><span class="string">        [1, 2]])</span></span><br><span class="line"><span class="string">y3:tensor([[6, 5],</span></span><br><span class="line"><span class="string">        [8, 7],</span></span><br><span class="line"><span class="string">        [2, 1],</span></span><br><span class="line"><span class="string">        [4, 3]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="contiguous">11、Contiguous</h3>
<p>官方文档：https://pytorch.org/docs/stable/generated/torch.Tensor.contiguous.html?highlight=contiguous#torch.Tensor.contiguous</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Tensor.contiguous(memory_format=torch.contiguous_format) → Tensor</span><br><span class="line"></span><br><span class="line">返回一个连续的内存张量，其中包含与当前张量相同的数据。 如果当前已经是指定的内存格式，则此函数返回当前张量。 </span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>
<p>3）为什么需要Contiguous?</p>
<ul>
<li><strong><code>torch.view</code></strong>等方法操作需要连续的Tensor。详细原因可见：https://zhuanlan.zhihu.com/p/64551412</li>
<li>出于性能考虑，连续的Tensor，语义上相邻的元素，在内存中也是连续的，访问相邻元素是矩阵运算中经常用到的操作，语义和内存顺序的一致性是缓存友好的，在内存中连续的数据可以（但不一定）被高速缓存预取，以提升CPU获取操作数据的速度。</li>
</ul>
<h3 id="section">12、</h3>
<p>官方文档：</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>4）扩展示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="section-1">13、</h3>
<p>官方文档：</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>4）扩展示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="section-2">14、</h3>
<p>官方文档：</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>4）扩展示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="section-3">15、</h3>
<p>官方文档：</p>
<p>1）标准用法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>2）依赖库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>
<p>3）简单示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<p>4）扩展示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Pytorch系列笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch学习笔记7——一个深度学习程序的通用框架</title>
    <url>/2021/12/15/74d5fdd90932/</url>
    <content><![CDATA[<p>以下是一个深度学习程序的通用框架，大部分基础的深度学习任务都可以按照以下这个框架的步骤去进行书写：</p>
<h4 id="step0-一些依赖项函数">Step0: 一些依赖项函数</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_device</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Get device (if GPU is available, use GPU) &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">  </span><br><span class="line"> <span class="comment"># fix random seed</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">same_seeds</span>(<span class="params">seed</span>):</span></span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        torch.cuda.manual_seed(seed)</span><br><span class="line">        torch.cuda.manual_seed_all(seed)  </span><br><span class="line">    np.random.seed(seed)  </span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h4 id="step1-下载数据准备数据这一步将硬盘的数据加载到内存中">Step1: 下载数据、准备数据（这一步将硬盘的数据加载到内存中）</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Loading data ...&#x27;</span>)</span><br><span class="line"><span class="comment"># 加载Train Features、Train Labels、Test Features</span></span><br><span class="line">train = np.load(<span class="string">&#x27;train.npy&#x27;</span>)</span><br><span class="line">train_label = np.load(<span class="string">&#x27;train_label.npy&#x27;</span>)</span><br><span class="line">test = np.load(<span class="string">&#x27;test.npy&#x27;</span>)</span><br><span class="line"><span class="comment"># 一般而言可以打印一下数据集的大小，心中有数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Size of training data: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(train.shape))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Size of testing data: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(test.shape))</span><br></pre></td></tr></table></figure>
<h4 id="step2-创建dataset类">Step2: 创建Dataset类</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, X, y=<span class="literal">None</span></span>):</span>   <span class="comment"># 主要就是在init函数里定义好 self.data 和 self.label</span></span><br><span class="line">        self.data = torch.from_numpy(X).<span class="built_in">float</span>()  <span class="comment"># 进行赋值</span></span><br><span class="line">        <span class="keyword">if</span> y <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:   <span class="comment"># 这儿需要考虑有y的训练集 和 没有y的测试集</span></span><br><span class="line">            self.label = torch.LongTensor(y.astype(np.<span class="built_in">int</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.label = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span>    <span class="comment"># 基本都是如下这个形式，不太需要变化</span></span><br><span class="line">        <span class="keyword">if</span> self.label <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> self.data[idx], self.label[idx]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.data[idx]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span>  <span class="comment"># 返回数据集长度，一般都是如下这个形式，也不太需要变化</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="step3-将训练数据分割为-训练集-和-验证集">Step3: 将训练数据分割为 训练集 和 验证集</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">VAL_RATIO = <span class="number">0.2</span>  <span class="comment"># 利用此参数控制 验证集占 整个训练数据的比例</span></span><br><span class="line"></span><br><span class="line">percent = <span class="built_in">int</span>(train.shape[<span class="number">0</span>] * (<span class="number">1</span> - VAL_RATIO))</span><br><span class="line">train_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Size of training set: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(train_x.shape))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Size of validation set: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(val_x.shape))</span><br></pre></td></tr></table></figure>
<h4 id="step4-实例化dataset对象以及对应的dataloader对象">Step4: 实例化Dataset对象以及对应的DataLoader对象</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">64</span>  <span class="comment"># 设定 Batch_size，此参数DataLoader</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">train_set = MyDataset(train_x, train_y)</span><br><span class="line">val_set = MyDataset(val_x, val_y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#only shuffle the training data</span></span><br><span class="line">train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=<span class="literal">True</span>) </span><br><span class="line">val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h4 id="step5-创建网络模型">Step5: 创建网络模型</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Classifier</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span>   <span class="comment"># 定义网络层级</span></span><br><span class="line">        <span class="built_in">super</span>(Classifier, self).__init__()</span><br><span class="line">        self.layer1 = nn.Linear(<span class="number">429</span>, <span class="number">1024</span>)</span><br><span class="line">        self.layer2 = nn.Linear(<span class="number">1024</span>, <span class="number">512</span>)</span><br><span class="line">        self.layer3 = nn.Linear(<span class="number">512</span>, <span class="number">128</span>)</span><br><span class="line">        self.out = nn.Linear(<span class="number">128</span>, <span class="number">39</span>) </span><br><span class="line">        self.act_fn = nn.Sigmoid()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span> <span class="comment"># 定义数据的流转逻辑过程</span></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.act_fn(x)</span><br><span class="line">        </span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = self.act_fn(x)</span><br><span class="line"></span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        x = self.act_fn(x)</span><br><span class="line"></span><br><span class="line">        x = self.out(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h4 id="step6-设定一些训练参数为训练作准备">Step6: 设定一些训练参数，为训练作准备</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># fix random seed for reproducibility</span></span><br><span class="line">same_seeds(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># get device </span></span><br><span class="line">device = get_device()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;DEVICE: <span class="subst">&#123;device&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># training parameters </span></span><br><span class="line">num_epoch = <span class="number">20</span>               <span class="comment"># number of training epoch</span></span><br><span class="line">learning_rate = <span class="number">0.0001</span>       <span class="comment"># learning rate</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># the path where checkpoint saved</span></span><br><span class="line">model_path = <span class="string">&#x27;./model.ckpt&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create model, define a loss function, and optimizer</span></span><br><span class="line">model = Classifier().to(device)</span><br><span class="line">criterion = nn.CrossEntropyLoss() </span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure>
<h4 id="step7-开启网络训练参数优化">Step7: 开启网络训练，参数优化</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># start training</span></span><br><span class="line"></span><br><span class="line">best_acc = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    train_loss = <span class="number">0.0</span></span><br><span class="line">    val_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># training</span></span><br><span class="line">    model.train() <span class="comment"># set the model to training mode</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        inputs, labels = data  <span class="comment"># 从data中加载inputs和labels</span></span><br><span class="line">        inputs, labels = inputs.to(device), labels.to(device) <span class="comment"># 拷贝至设备</span></span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 清零梯度</span></span><br><span class="line">        outputs = model(inputs)   <span class="comment"># 将输入放到模型中拿到输出</span></span><br><span class="line">        batch_loss = criterion(outputs, labels) <span class="comment"># 通过损失函数，计算本次损失值</span></span><br><span class="line">        batch_loss.backward()  <span class="comment"># 损失反向传播，计算梯度</span></span><br><span class="line">        optimizer.step() <span class="comment"># 使用optimizer更新一步模型</span></span><br><span class="line"></span><br><span class="line">        train_loss += batch_loss.item()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每一个epoch完成后，如果有验证集的话，就进行validation验证</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(val_set) &gt; <span class="number">0</span>:</span><br><span class="line">        model.<span class="built_in">eval</span>() <span class="comment"># set the model to evaluation mode</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad(): <span class="comment"># 验证集不需要计算梯度</span></span><br><span class="line">            <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(val_loader):</span><br><span class="line">                inputs, labels = data </span><br><span class="line">                inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">                outputs = model(inputs)</span><br><span class="line">                batch_loss = criterion(outputs, labels) </span><br><span class="line"></span><br><span class="line">                val_loss += batch_loss.item()</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[&#123;:03d&#125;/&#123;:03d&#125;] Train Loss: &#123;:3.6f&#125; | Val Loss: &#123;:3.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch + <span class="number">1</span>, num_epoch, train_loss/<span class="built_in">len</span>(train_loader), val_loss/<span class="built_in">len</span>(val_loader)</span><br><span class="line">            ))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 必备过程，如果模型比截止当前更优了，那么就保存并记录，然后输出</span></span><br><span class="line">            <span class="keyword">if</span> val_acc &gt; best_acc:</span><br><span class="line">                best_acc = val_acc</span><br><span class="line">                torch.save(model.state_dict(), model_path)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;saving model with acc &#123;:.3f&#125;&#x27;</span>.<span class="built_in">format</span>(best_acc/<span class="built_in">len</span>(val_set)))</span><br><span class="line">    <span class="keyword">else</span>: <span class="comment"># 没有验证集这一步的话，就可以直接打印输出</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[&#123;:03d&#125;/&#123;:03d&#125;] Train Acc: &#123;:3.6f&#125; Loss: &#123;:3.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">            epoch + <span class="number">1</span>, num_epoch, train_acc/<span class="built_in">len</span>(train_set), train_loss/<span class="built_in">len</span>(train_loader)</span><br><span class="line">        ))</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 如果没有验证这一步骤的话，我们需要保存最终训练得到的这个模型</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(val_set) == <span class="number">0</span>:</span><br><span class="line">    torch.save(model.state_dict(), model_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;saving model at last epoch&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="step8-test-测试计算测试集的预测值">Step8: Test 测试,计算测试集的预测值</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 实例化测试用的DataSet和DataLoader</span></span><br><span class="line">test_set = MyDataset(test, <span class="literal">None</span>)</span><br><span class="line">test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#  实例化模型，加载参数</span></span><br><span class="line">model = Classifier().to(device)</span><br><span class="line">model.load_state_dict(torch.load(model_path))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始进行预测， </span></span><br><span class="line">predict = []</span><br><span class="line">model.<span class="built_in">eval</span>() <span class="comment"># 将模型调整至评估状态（必备步骤）</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad(): <span class="comment"># 由于预测不需要跟踪梯度</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader): <span class="comment"># 计算s</span></span><br><span class="line">        inputs = data</span><br><span class="line">        inputs = inputs.to(device)</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> test_pred.cpu().numpy():</span><br><span class="line">            predict.append(y)</span><br><span class="line">           </span><br><span class="line"><span class="comment"># 输出预测的CSV文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;prediction.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> i, y <span class="keyword">in</span> <span class="built_in">enumerate</span>(predict):</span><br><span class="line">        f.write(<span class="string">&#x27;&#123;&#125;,&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(i, y))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Pytorch系列笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch学习笔记6——优化模型参数</title>
    <url>/2021/12/14/81d5ccd11a24/</url>
    <content><![CDATA[<h1 id="六优化模型参数">六、优化模型参数</h1>
<p>现在我们有了模型和数据，接下去需要通过优化数据参数来训练、验证和测试我们的模型了。</p>
<p>训练模型是一个迭代过程； 在每次迭代（称为 epoch）中，模型对输出进行猜测，计算其猜测中的误差（损失），收集误差对其参数的导数，并使用梯度下降优化这些参数。 下面的代码是先预定义了一些之前记录过的内容</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> ToTensor, Lambda</span><br><span class="line"></span><br><span class="line">training_data = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=ToTensor()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_data = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=ToTensor()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_dataloader = DataLoader(training_data, batch_size=<span class="number">64</span>)</span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNetwork</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NeuralNetwork, self).__init__()</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.linear_relu_stack = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">28</span>*<span class="number">28</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        logits = self.linear_relu_stack(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line">model = NeuralNetwork()</span><br></pre></td></tr></table></figure>
<h3 id="超参数">1、超参数：</h3>
<p>超参数是可调节的参数，可控制模型优化过程。不同的超参数值会影响模型训练和收敛速度</p>
<p>我们为训练定义了以下超参数： - Number of Epochs 迭代数据集的次数 - Batch Size 在更新参数之前通过网络传播的数据样本数量(单次传入网络进行训练的样本数量) - Learning Rate 在每个批次/时期更新模型参数的程度。 较小的值会导致学习速度变慢，而较大的值可能会导致训练过程中出现不可预测的行为。</p>
<p>此处注意区分一些概念： - Batch Size：批大小。在深度学习中，一般采用SGD训练，即每次训练在训练集中取batchsize个样本训练； - iteration：1个iteration等于使用batchsize个样本训练一次； - Epoch：1个epoch等于使用训练集中的全部样本训练一次，通俗的讲epoch的值就是整个数据集被轮几次。</p>
<p>举个例子，我们现在有一个5000个数据的数据集，Batch Size = 100, 我们需要迭代训练50次，那么最终Number of Epoches = 10,Interation = 50.</p>
<h3 id="优化循环">2、优化循环：</h3>
<p>每个Epoch由两个主要部分组成： - Train Loop - 迭代训练数据集并尝试收敛到最佳参数。(由很多次Interation组成) - Validation/Test Loop - 迭代测试数据集以检查模型性能是否正在提高。</p>
<h3 id="损失函数">3、损失函数</h3>
<ul>
<li><p>当提供一些训练数据时，我们未经训练的网络可能没法给出正确的答案。</p></li>
<li><p>损失函数衡量得到的结果与目标值的不相似程度，是我们在训练过程中想要最小化的损失函数。</p></li>
<li><p>为了计算损失，我们使用给定数据样本的输入进行预测，并将其与真实数据标签值进行比较。</p></li>
</ul>
<p>常见的损失函数包括用于回归任务的 nn.MSELoss（均方误差）和用于分类的 nn.NLLLoss（负对数似然）。 nn.CrossEntropyLoss 结合了 nn.LogSoftmax 和 nn.NLLLoss。</p>
<h3 id="优化器">4、优化器</h3>
<ul>
<li><p>优化是在每个训练步骤中调整模型参数以减少模型误差的过程。</p></li>
<li><p>优化算法定义了这个过程是如何执行的（在这个例子中我们使用随机梯度下降）。</p></li>
<li><p>所有优化逻辑都封装在优化器对象中。</p></li>
<li><p>在这里，我们使用 SGD 优化器； 此外，PyTorch 中有许多不同的优化器可用，例如 ADAM 和 RMSProp，它们更适用于不同类型的模型和数据。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure></p></li>
<li><p>我们通过注册模型需要训练的参数并传入学习率超参数来初始化优化器。</p></li>
</ul>
<h4 id="训练循环中优化的三个步骤">训练循环中优化的三个步骤：</h4>
<ul>
<li><p>调用 optimizer.zero_grad() 来重置模型参数的梯度。 梯度默认情况下会相加； 为了防止重复计算，我们在每次迭代时明确地将它们归零。</p></li>
<li><p>通过调用 loss.backwards() 来反向传播预测损失。PyTorch 将损失的梯度存入 w.r.t. 每个参数。</p></li>
<li><p>一旦我们有了梯度，我们就调用 optimizer.step() 通过backward()中收集的梯度来调整参数。</p></li>
</ul>
<h3 id="train-loop-和-test-loop的整体实现">5、Train Loop 和 Test Loop的整体实现</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_loop</span>(<span class="params">dataloader, model, loss_fn, optimizer</span>):</span></span><br><span class="line">    size = <span class="built_in">len</span>(dataloader.dataset)</span><br><span class="line">    <span class="keyword">for</span> batch, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="comment"># Compute prediction and loss</span></span><br><span class="line">        pred = model(X)</span><br><span class="line">        loss = loss_fn(pred, y)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backpropagation</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> batch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            loss, current = loss.item(), batch * <span class="built_in">len</span>(X)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;loss: <span class="subst">&#123;loss:&gt;7f&#125;</span>  [<span class="subst">&#123;current:&gt;5d&#125;</span>/<span class="subst">&#123;size:&gt;5d&#125;</span>]&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_loop</span>(<span class="params">dataloader, model, loss_fn</span>):</span></span><br><span class="line">    size = <span class="built_in">len</span>(dataloader.dataset)</span><br><span class="line">    num_batches = <span class="built_in">len</span>(dataloader)</span><br><span class="line">    test_loss, correct = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> dataloader:</span><br><span class="line">            pred = model(X)</span><br><span class="line">            test_loss += loss_fn(pred, y).item()</span><br><span class="line">            correct += (pred.argmax(<span class="number">1</span>) == y).<span class="built_in">type</span>(torch.<span class="built_in">float</span>).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    test_loss /= num_batches</span><br><span class="line">    correct /= size</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Test Error: \n Accuracy: <span class="subst">&#123;(<span class="number">100</span>*correct):&gt;<span class="number">0.1</span>f&#125;</span>%, Avg loss: <span class="subst">&#123;test_loss:&gt;8f&#125;</span> \n&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">learning_rate = <span class="number">1e-3</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;t+<span class="number">1</span>&#125;</span>\n-------------------------------&quot;</span>)</span><br><span class="line">    train_loop(train_dataloader, model, loss_fn, optimizer)</span><br><span class="line">    test_loop(test_dataloader, model, loss_fn)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Done!&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1
-------------------------------
loss: 2.305831  [    0/60000]
loss: 2.286264  [ 6400/60000]
loss: 2.275372  [12800/60000]
loss: 2.270570  [19200/60000]
loss: 2.243541  [25600/60000]
loss: 2.228191  [32000/60000]
loss: 2.224830  [38400/60000]
loss: 2.197911  [44800/60000]
loss: 2.188963  [51200/60000]
loss: 2.156472  [57600/60000]
Test Error: 
 Accuracy: 44.4%, Avg loss: 2.153718 

Epoch 2
-------------------------------
loss: 2.164675  [    0/60000]
loss: 2.149587  [ 6400/60000]
loss: 2.099088  [12800/60000]
loss: 2.116142  [19200/60000]
loss: 2.057026  [25600/60000]
loss: 2.006994  [32000/60000]
loss: 2.027068  [38400/60000]
loss: 1.953798  [44800/60000]
loss: 1.955666  [51200/60000]
loss: 1.876484  [57600/60000]
Test Error: 
 Accuracy: 54.6%, Avg loss: 1.882143 

Epoch 3
-------------------------------
loss: 1.914309  [    0/60000]
loss: 1.881881  [ 6400/60000]
loss: 1.770059  [12800/60000]
loss: 1.812282  [19200/60000]
loss: 1.696313  [25600/60000]
loss: 1.650967  [32000/60000]
loss: 1.665257  [38400/60000]
loss: 1.568552  [44800/60000]
loss: 1.594818  [51200/60000]
loss: 1.484761  [57600/60000]
Test Error: 
 Accuracy: 61.4%, Avg loss: 1.509315 

Epoch 4
-------------------------------
loss: 1.575193  [    0/60000]
loss: 1.537402  [ 6400/60000]
loss: 1.389850  [12800/60000]
loss: 1.466425  [19200/60000]
loss: 1.346153  [25600/60000]
loss: 1.345708  [32000/60000]
loss: 1.351373  [38400/60000]
loss: 1.272530  [44800/60000]
loss: 1.314754  [51200/60000]
loss: 1.217384  [57600/60000]
Test Error: 
 Accuracy: 63.7%, Avg loss: 1.243355 

Epoch 5
-------------------------------
loss: 1.322318  [    0/60000]
loss: 1.297594  [ 6400/60000]
loss: 1.132705  [12800/60000]
loss: 1.242817  [19200/60000]
loss: 1.121882  [25600/60000]
loss: 1.150953  [32000/60000]
loss: 1.163450  [38400/60000]
loss: 1.091253  [44800/60000]
loss: 1.141570  [51200/60000]
loss: 1.064053  [57600/60000]
Test Error: 
 Accuracy: 65.1%, Avg loss: 1.080539 

Epoch 6
-------------------------------
loss: 1.154191  [    0/60000]
loss: 1.148584  [ 6400/60000]
loss: 0.965631  [12800/60000]
loss: 1.104692  [19200/60000]
loss: 0.985084  [25600/60000]
loss: 1.020977  [32000/60000]
loss: 1.047947  [38400/60000]
loss: 0.976197  [44800/60000]
loss: 1.029986  [51200/60000]
loss: 0.968344  [57600/60000]
Test Error: 
 Accuracy: 66.1%, Avg loss: 0.976119 

Epoch 7
-------------------------------
loss: 1.037672  [    0/60000]
loss: 1.052149  [ 6400/60000]
loss: 0.852071  [12800/60000]
loss: 1.013271  [19200/60000]
loss: 0.898881  [25600/60000]
loss: 0.930241  [32000/60000]
loss: 0.972335  [38400/60000]
loss: 0.901890  [44800/60000]
loss: 0.953780  [51200/60000]
loss: 0.904363  [57600/60000]
Test Error: 
 Accuracy: 67.0%, Avg loss: 0.905581 

Epoch 8
-------------------------------
loss: 0.952564  [    0/60000]
loss: 0.985621  [ 6400/60000]
loss: 0.771567  [12800/60000]
loss: 0.949356  [19200/60000]
loss: 0.841446  [25600/60000]
loss: 0.864854  [32000/60000]
loss: 0.919260  [38400/60000]
loss: 0.852853  [44800/60000]
loss: 0.899662  [51200/60000]
loss: 0.858536  [57600/60000]
Test Error: 
 Accuracy: 68.2%, Avg loss: 0.855451 

Epoch 9
-------------------------------
loss: 0.887674  [    0/60000]
loss: 0.936516  [ 6400/60000]
loss: 0.712008  [12800/60000]
loss: 0.902735  [19200/60000]
loss: 0.800700  [25600/60000]
loss: 0.816214  [32000/60000]
loss: 0.879292  [38400/60000]
loss: 0.819085  [44800/60000]
loss: 0.859679  [51200/60000]
loss: 0.823750  [57600/60000]
Test Error: 
 Accuracy: 69.5%, Avg loss: 0.817833 

Epoch 10
-------------------------------
loss: 0.836203  [    0/60000]
loss: 0.897646  [ 6400/60000]
loss: 0.666050  [12800/60000]
loss: 0.867214  [19200/60000]
loss: 0.769769  [25600/60000]
loss: 0.778995  [32000/60000]
loss: 0.846987  [38400/60000]
loss: 0.794176  [44800/60000]
loss: 0.828553  [51200/60000]
loss: 0.795993  [57600/60000]
Test Error: 
 Accuracy: 70.8%, Avg loss: 0.788062 

Done!</code></pre>
<h3 id="七保存与加载模型">七、保存与加载模型</h3>
<p>PyTorch 模型将学习到的参数存储在称为 state_dict 的内部状态字典中。 这些可以通过 torch.save 方法持久化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line">model = models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line">torch.save(model.state_dict(), <span class="string">&#x27;model_weights.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Downloading: &quot;https://download.pytorch.org/models/vgg16-397923af.pth&quot; to C:\Users\14012/.cache\torch\hub\checkpoints\vgg16-397923af.pth
4.4%IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

11.4%IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

18.5%IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

25.5%IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

35.0%IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

45.9%IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

54.3%IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

61.2%IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

69.2%IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

76.2%IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

86.6%IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

98.3%IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)</code></pre>
<p>要加载模型权重，您需要先创建相同模型的实例，然后使用 load_state_dict() 方法加载参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = models.vgg16() <span class="comment"># we do not specify pretrained=True, i.e. do not load default weights</span></span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;model_weights.pth&#x27;</span>))</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>
<pre><code>VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)</code></pre>
<h4 id="注意一定要在预测之前调用-model.eval-方法以将-dropout-和批量归一化层设置为评估模式-不这样做会产生不一致的推理结果">注意：一定要在预测之前调用 model.eval() 方法，以将 dropout 和批量归一化层设置为评估模式。 不这样做会产生不一致的推理结果。</h4>
<p>在加载模型权重时，我们需要先实例化模型类，因为该类定义了网络的结构。 我们可能希望将此类的结构与模型一起保存，在这种情况下，我们可以将模型（而不是 model.state_dict()）传递给保存函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.save(model, <span class="string">&#x27;model.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = torch.load(<span class="string">&#x27;model.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Pytorch系列笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch学习笔记5——使用AutoGrad自动微分</title>
    <url>/2021/12/13/2c757a5017fb/</url>
    <content><![CDATA[<h1 id="五使用autograd计算自动微分">五、使用AutoGrad计算自动微分</h1>
<p>在训练神经网络时，最常用的算法是反向传播。 在该算法中，参数（模型权重）根据损失函数相对于给定参数的梯度进行调整。 为了计算这些梯度，PyTorch 有一个名为 torch.autograd 的内置微分引擎。 它支持任何计算图的梯度自动计算。</p>
<p>考虑最简单的一层神经网络，输入 x，参数 w 和 b，以及一些损失函数。 它可以通过以下方式在 PyTorch 中定义：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">5</span>)  <span class="comment"># input tensor</span></span><br><span class="line">y = torch.zeros(<span class="number">3</span>)  <span class="comment"># expected output</span></span><br><span class="line">w = torch.randn(<span class="number">5</span>, <span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">z = torch.matmul(x, w)+b</span><br><span class="line">loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)</span><br></pre></td></tr></table></figure>
<p>以下是计算图，因为我们需要计算Loss函数对w和b的梯度，所以在上面我们将w和b的requires_grad设置为了True</p>
<figure>
<img src="https://pytorch.org/tutorials/_images/comp-graph.png" alt="avatar" /><figcaption aria-hidden="true">avatar</figcaption>
</figure>
<p>我们应用于张量来构建计算图的函数实际上是类 Function 的对象。 该对象知道如何在前向计算函数，以及如何在反向传播步骤中计算其导数。 对反向传播函数的引用存储在张量的 grad_fn 属性中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Gradient function for z =&#x27;</span>, z.grad_fn)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Gradient function for loss =&#x27;</span>, loss.grad_fn)</span><br></pre></td></tr></table></figure>
<pre><code>Gradient function for z = &lt;AddBackward0 object at 0x00000271D5D03D90&gt;
Gradient function for loss = &lt;BinaryCrossEntropyWithLogitsBackward0 object at 0x00000271D5CF0F40&gt;</code></pre>
<h3 id="通过-backward函数计算梯度">通过 backward()函数计算梯度</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">loss.backward()</span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br><span class="line"><span class="built_in">print</span>(b.grad)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[0.2175, 0.0032, 0.1359],
        [0.2175, 0.0032, 0.1359],
        [0.2175, 0.0032, 0.1359],
        [0.2175, 0.0032, 0.1359],
        [0.2175, 0.0032, 0.1359]])
tensor([0.2175, 0.0032, 0.1359])</code></pre>
<p>注意：我们只能获取计算图的叶子节点的 grad 属性，这些节点的 requires_grad 属性设置为 True。 对于图中的所有其他节点，梯度将不可用。</p>
<p>出于性能原因，我们只能在给定的计算图上使用一次backward()来执行梯度计算。如果我们需要在同一个计算图上进行多次backward()调用，我们需要将 retain_graph=True 传递给反向调用。</p>
<h3 id="如何停止跟踪梯度">如何停止跟踪梯度？</h3>
<p>默认情况下，所有具有 requires_grad=True 的张量都在跟踪它们的计算历史并支持梯度计算。 但是，在某些情况下我们不需要这样做，例如，当我们训练了模型并且只想将其应用于某些输入数据时，即我们只想通过网络进行前向计算。 我们可以通过用 torch.no_grad() 块包围我们的计算代码来停止跟踪计算：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">z = torch.matmul(x, w)+b</span><br><span class="line"><span class="built_in">print</span>(z.requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    z = torch.matmul(x, w)+b</span><br><span class="line"><span class="built_in">print</span>(z.requires_grad)</span><br></pre></td></tr></table></figure>
<pre><code>True
False</code></pre>
<p>或者使用 detach方法也可以完成此项工作</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">z = torch.matmul(x, w)+b</span><br><span class="line">z_det = z.detach()</span><br><span class="line"><span class="built_in">print</span>(z_det.requires_grad)</span><br></pre></td></tr></table></figure>
<pre><code>False</code></pre>
<h3 id="停止跟踪梯度的一些情况">停止跟踪梯度的一些情况</h3>
<ul>
<li><p>1、将神经网络中的某些参数标记为冻结参数。（通常见于迁移学习）</p></li>
<li><p>2、在仅进行前向传递时加快计算速度，因为对不跟踪梯度的张量进行计算会更有效。</p></li>
</ul>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Pytorch系列笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch学习笔记4——Building NeuralNetwork</title>
    <url>/2021/12/13/e052d246f1f0/</url>
    <content><![CDATA[<h1 id="四神经网络建立">四、神经网络建立</h1>
<p>神经网络由对数据执行操作的层/模块组成。 torch.nn 命名空间提供了构建自己的神经网络所需的所有构建块。 PyTorch 中的每个模块都是 nn.Module 的子类。 神经网络是一个模块本身，由其他模块（层）组成。 这种嵌套结构允许轻松构建和管理复杂的架构。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br></pre></td></tr></table></figure>
<h4 id="步骤-1如果有条件的话使用cuda设备">步骤 1、如果有条件的话，使用Cuda设备</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Using <span class="subst">&#123;device&#125;</span> device&#x27;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Using cuda device</code></pre>
<h4 id="步骤-2我们通过继承nn.module来自定义我们的神经网络类在__ini__中完成神经网络层的定义且在forward函数中完成对输入的处理">步骤 2、我们通过继承nn.Module来自定义我们的神经网络类，在__ini__中完成神经网络层的定义，且在Forward函数中，完成对输入的处理</h4>
<p>nn.Sequential() 是一个有序的层的容器，将一系列的层线性组合在一起，按照顺序执行</p>
<p>nn.Flatten() 将每个 2D 28x28 图像转换为 784 个像素值的连续数组（注意：batches的那个维度被保留了（也就是dim=0的维度被保留了），举例来说，一个[3,28,28]的矩阵，被摊平成了[3,784]的矩阵</p>
<p>nn.Linear(in_features=28*28, out_features=20) 全连接层</p>
<p>nn.ReLU() 非线性激活函数层</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNetwork</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NeuralNetwork, self).__init__()</span><br><span class="line">        self.flatten = nn.Flatten()</span><br><span class="line">        self.linear_relu_stack = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">28</span>*<span class="number">28</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        logits = self.linear_relu_stack(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br></pre></td></tr></table></figure>
<h4 id="步骤-3实例化一个对象并将其移至对应设备打印结构">步骤 3、实例化一个对象，并将其移至对应设备，打印结构</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = NeuralNetwork().to(device)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure>
<pre><code>NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
)</code></pre>
<h4 id="步骤-4在输入上调用模型会返回一个-10-维张量其中包含每个类的原始预测值">步骤 4、在输入上调用模型会返回一个 10 维张量，其中包含每个类的原始预测值。</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X = torch.rand(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, device=device)</span><br><span class="line">logits = model(X)</span><br><span class="line">logits</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[ 0.0394, -0.1041,  0.1203,  0.0809,  0.1222,  0.0305,  0.0539, -0.0241,
          0.0910,  0.0014]], device=&#39;cuda:0&#39;, grad_fn=&lt;AddmmBackward0&gt;)</code></pre>
<h3 id="softmax函数logits-被缩放到值-0-1-dim-参数指示该维度上的值的总和必须为-1">Softmax函数：logits 被缩放到值 [0, 1]。 dim 参数指示该维度上的值的总和必须为 1 。</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred_probab = nn.Softmax(dim=<span class="number">1</span>)(logits) </span><br><span class="line"><span class="built_in">print</span>(pred_probab)</span><br><span class="line">y_pred = pred_probab.argmax(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Predicted class: <span class="subst">&#123;y_pred&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[0.0996, 0.0863, 0.1080, 0.1038, 0.1082, 0.0987, 0.1011, 0.0935, 0.1049,
         0.0959]], device=&#39;cuda:0&#39;, grad_fn=&lt;SoftmaxBackward0&gt;)
Predicted class: tensor([4], device=&#39;cuda:0&#39;)</code></pre>
<h3 id="神经网络模型参数">神经网络模型参数：</h3>
<p>神经网络内的许多层都是参数化的，即具有在训练期间优化的相关权重和偏差。 子类 nn.Module 会自动跟踪模型对象中定义的所有字段，并使用模型的 parameters() 或 named_parameters() 方法使所有参数都可以访问。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Model structure: &quot;</span>, model, <span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Layer: <span class="subst">&#123;name&#125;</span> | Size: <span class="subst">&#123;param.size()&#125;</span> | Values : <span class="subst">&#123;param[:<span class="number">2</span>]&#125;</span> \n&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Model structure:  NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
) 


Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0354, -0.0090,  0.0262,  ..., -0.0218, -0.0343,  0.0239],
        [-0.0130,  0.0023, -0.0083,  ..., -0.0314,  0.0088,  0.0303]],
       device=&#39;cuda:0&#39;, grad_fn=&lt;SliceBackward0&gt;) 

Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0199, -0.0234], device=&#39;cuda:0&#39;, grad_fn=&lt;SliceBackward0&gt;) 

Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0136,  0.0326, -0.0428,  ..., -0.0377, -0.0250,  0.0003],
        [-0.0187, -0.0297, -0.0096,  ...,  0.0277, -0.0320,  0.0395]],
       device=&#39;cuda:0&#39;, grad_fn=&lt;SliceBackward0&gt;) 

Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0206, -0.0259], device=&#39;cuda:0&#39;, grad_fn=&lt;SliceBackward0&gt;) 

Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0047, -0.0406, -0.0102,  ..., -0.0346,  0.0284,  0.0111],
        [-0.0308, -0.0165, -0.0334,  ...,  0.0257,  0.0339,  0.0208]],
       device=&#39;cuda:0&#39;, grad_fn=&lt;SliceBackward0&gt;) 

Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0353,  0.0320], device=&#39;cuda:0&#39;, grad_fn=&lt;SliceBackward0&gt;) </code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Pytorch系列笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch学习笔记3——Transform数据变换</title>
    <url>/2021/12/13/af1b6d3a1966/</url>
    <content><![CDATA[<h1 id="三transform">三、Transform</h1>
<p>通常而言，数据不会以处理好的形式出现，所以我们需要在训练前对数据进行预处理，以适应训练</p>
<p>所有 TorchVision 的 Dataset 都会有两个参数—— transform 用于修改特征，target_transform 用于修改标签——它们接受包含转换逻辑的可调用对象（其实就是接受函数对象）。 torchvision.transforms 模块提供了几种常见的转换。</p>
<h3 id="示例">1、示例：</h3>
<p>如下代码为例，我们所拿到的FashionMNIST的特征是一个PIL Image的格式，它的标签是一个Integer整数。但是我们训练的时候，希望特征是一个正则化后的张量，而标签是一个One-Hot向量张量。所以分别采用ToTensor和Lambda函数来进行处理</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> ToTensor, Lambda</span><br><span class="line"></span><br><span class="line">ds = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=ToTensor(),</span><br><span class="line">    target_transform=Lambda(<span class="keyword">lambda</span> y: torch.zeros(<span class="number">10</span>, dtype=torch.<span class="built_in">float</span>).scatter_(<span class="number">0</span>, torch.tensor(y), value=<span class="number">1</span>))</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>ToTensor() 函数可以将一个 PIL image 或者 NumPy ndarray 转换至一个 FloatTensor，同时放缩图像的像素值范围至0-1.</p>
<p>Lambda可以用于定义任何一个用户定义的lambda表达式，使其成为函数，在上述定义的表达式中： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))</span><br></pre></td></tr></table></figure> 先初始化了一个维度为10的零向量，然后利用scatter_函数，将某一个维度的值赋为1</p>
<h4 id="scatter函数">Scatter函数</h4>
<p>scatter(dim, index, src) 的参数有 3 个，通过一个张量或标量 src 来修改另一个张量，哪个元素需要修改、用 src 中的哪个元素来修改由 dim 和 index 决定 - dim：沿着哪个维度进行索引 - index：用来 scatter 的元素索引 - src：用来 scatter 的源元素，可以是一个标量或一个张量</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Pytorch系列笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch学习笔记2——Dataset介绍</title>
    <url>/2021/12/13/9d4aeea992ce/</url>
    <content><![CDATA[<h1 id="二dataset">二、Dataset</h1>
<p>Pytorch 使用 torch.utils.data.DataLoader 和 torch.utils.data.Dataset 来允许我们使用其预先加载好的数据，或是自己准备的数据集。</p>
<p>Dataset存储样本及其相应的标签，DataLoader在数据集周围包装一个iterable，以便于访问样本。</p>
<p>一些常用的Datasets可以在这边进行查询 https://pytorch.org/tutorials/beginner/basics/data_tutorial.html</p>
<h3 id="下载数据集示例">1、下载数据集示例</h3>
<h4 id="有以下四个参数">有以下四个参数</h4>
<h5 id="root-是训练集测试集数据存储的位置">1、root : 是训练集/测试集数据存储的位置</h5>
<h5 id="train-表明是训练集还是测试集">2、train: 表明是训练集还是测试集</h5>
<h5 id="download-表明如果数据集在root不存在是否从网络下载">3、download： 表明如果数据集在root不存在，是否从网络下载</h5>
<h5 id="transform-和-target_transform-指定特征和标签转换">4、transform 和 target_transform 指定特征和标签转换</h5>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> ToTensor</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">training_data = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=<span class="literal">True</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=ToTensor()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<pre><code>Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\FashionMNIST\raw\train-images-idx3-ubyte.gz


100.0%


Extracting data\FashionMNIST\raw\train-images-idx3-ubyte.gz to data\FashionMNIST\raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\FashionMNIST\raw\train-labels-idx1-ubyte.gz


100.6%


Extracting data\FashionMNIST\raw\train-labels-idx1-ubyte.gz to data\FashionMNIST\raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\FashionMNIST\raw\t10k-images-idx3-ubyte.gz


100.0%


Extracting data\FashionMNIST\raw\t10k-images-idx3-ubyte.gz to data\FashionMNIST\raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\FashionMNIST\raw\t10k-labels-idx1-ubyte.gz


119.3%

Extracting data\FashionMNIST\raw\t10k-labels-idx1-ubyte.gz to data\FashionMNIST\raw</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">test_data = datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">&quot;data&quot;</span>,</span><br><span class="line">    train=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">    transform=ToTensor()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>可以使用Index来访问数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img, label = training_data[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h4 id="pytorch中squeeze和unsqueeze函数">pytorch中squeeze()和unsqueeze()函数</h4>
<p>torch.squeeze() 主要对数据的维度进行压缩，去掉维数为1的的维度，比如是一行或者一列，一个一行三列（1,3）的数去掉第一个维数为一的维度之后就变成（3）行</p>
<p>torch.unsqueeze() 给指定位置加上维数为一的维度，比如原本有个三行的数据（3），在0的位置加了一维就变成一行三列（1,3）。a.unsqueeze(N) 就是在a中指定位置N加上一个维数为1的维度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(img.shape)</span><br><span class="line"><span class="built_in">print</span>(img.squeeze().shape)</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([1, 28, 28])
torch.Size([28, 28])</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.imshow(img.squeeze())</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_14_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h3 id="创建自定义的数据集">2、创建自定义的数据集</h3>
<p>一个自定义的数据集类必须要实现以下三个函数： <strong>init</strong>, <strong>len</strong>, and <strong>getitem</strong></p>
<h4 id="首先是init函数当实例化数据集对象的时候初始化目录标签文件等等">1）首先是Init函数，当实例化数据集对象的时候，初始化目录、标签文件、等等</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):</span><br><span class="line">    self.img_labels = pd.read_csv(annotations_file, names=[&#x27;file_name&#x27;, &#x27;label&#x27;])</span><br><span class="line">    self.img_dir = img_dir</span><br><span class="line">    self.transform = transform</span><br><span class="line">    self.target_transform = target_transform</span><br></pre></td></tr></table></figure>
<h4 id="len__函数返回数据集中样例的数量">2) __len__函数返回数据集中样例的数量</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def __len__(self):</span><br><span class="line">    return len(self.img_labels)</span><br></pre></td></tr></table></figure>
<h4 id="getitem__函数根据给定的idx从数据集中加载并且返回一个样例">3）__getitem__函数根据给定的idx从数据集中加载并且返回一个样例</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def __getitem__(self, idx):</span><br><span class="line">    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])</span><br><span class="line">    image = read_image(img_path)</span><br><span class="line">    label = self.img_labels.iloc[idx, 1]</span><br><span class="line">    if self.transform:</span><br><span class="line">        image = self.transform(image)</span><br><span class="line">    if self.target_transform:</span><br><span class="line">        label = self.target_transform(label)</span><br><span class="line">    return image, label</span><br></pre></td></tr></table></figure>
<h3 id="使用dataloaders来为训练准备数据">3、使用DataLoaders来为训练准备数据</h3>
<p>先前定义的Dataset能够一次检索一个样本的数据集功能和标签。但是在训练模型时，我们通常希望以“batches”的方式传递样本，在每个epoch重新排列数据以减少模型过度拟合，并使用Python的多处理来加速数据检索。</p>
<p>DataLoader 就是帮助我们完成上述事情的一个东西，下面就是将数据装载进DataLoader的过程，可以迭代访问数据集中的内容</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">train_dataloader = DataLoader(training_data, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>下面的每次迭代都会返回一批训练实例和训练标签（分别包含batch_size=64个特征和标签）。因为我们指定了shuffle=True，所以在对所有批进行迭代之后，数据将被洗牌。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_dataloader</span><br></pre></td></tr></table></figure>
<pre><code>&lt;torch.utils.data.dataloader.DataLoader at 0x1f88dccf4f0&gt;</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">iter</span>(train_dataloader)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x1f88e0796d0&gt;</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader))</span><br></pre></td></tr></table></figure>
<pre><code>[tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],
 
 
         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0078, 0.0000],
           ...,
           [0.0000, 0.0000, 0.4510,  ..., 0.8157, 0.0549, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.4196, 0.0000, 0.0000],
           [0.0000, 0.0078, 0.0275,  ..., 0.0000, 0.0000, 0.0000]]],
 
 
         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],
 
 
         ...,
 
 
         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],
 
 
         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],
 
 
         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           ...,
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]),
 tensor([3, 9, 0, 2, 7, 4, 4, 5, 1, 5, 3, 0, 6, 9, 7, 7, 6, 4, 1, 7, 7, 7, 3, 7,
         4, 4, 9, 9, 5, 1, 4, 2, 2, 0, 9, 3, 9, 9, 9, 8, 2, 4, 9, 3, 2, 0, 0, 0,
         5, 7, 5, 7, 1, 9, 8, 7, 0, 4, 9, 0, 2, 3, 8, 7])]</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_features, train_labels = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Feature batch shape: <span class="subst">&#123;train_features.size()&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Labels batch shape: <span class="subst">&#123;train_labels.size()&#125;</span>&quot;</span>)</span><br><span class="line">img = train_features[<span class="number">0</span>].squeeze()</span><br><span class="line">label = train_labels[<span class="number">0</span>]</span><br><span class="line">plt.imshow(img, cmap=<span class="string">&quot;gray&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Label: <span class="subst">&#123;label&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Feature batch shape: torch.Size([64, 1, 28, 28])
Labels batch shape: torch.Size([64])</code></pre>
<figure>
<img src="output_31_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<pre><code>Label: 5</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Pytorch系列笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch学习笔记1——Tensor介绍</title>
    <url>/2021/12/13/81937a6b0d26/</url>
    <content><![CDATA[<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h2 id="一tensor-的初始化">一、Tensor 的初始化</h2>
<h3 id="从数据初始化">1、从数据初始化</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = [[<span class="number">1</span>, <span class="number">2</span>],[<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">x_data = torch.tensor(data)</span><br><span class="line">x_data</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1, 2],
        [3, 4]])</code></pre>
<h3 id="从nparray初始化">2、从nparray初始化</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np_array = np.array(data)</span><br><span class="line">x_np = torch.from_numpy(np_array)</span><br><span class="line">x_np</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1, 2],
        [3, 4]], dtype=torch.int32)</code></pre>
<h3 id="从另一个tensor初始化新的tensor会继承作为参数的tensor的-形状和数据类型除非显式声明">3、从另一个Tensor初始化，新的Tensor会继承作为参数的Tensor的 形状和数据类型，除非显式声明</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_ones = torch.ones_like(x_data) <span class="comment"># retains the properties of x_data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Ones Tensor: \n <span class="subst">&#123;x_ones&#125;</span> \n&quot;</span>)</span><br><span class="line"></span><br><span class="line">x_rand = torch.rand_like(x_data, dtype=torch.<span class="built_in">float</span>) <span class="comment"># overrides the datatype of x_data</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Random Tensor: \n <span class="subst">&#123;x_rand&#125;</span> \n&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Ones Tensor: 
 tensor([[1, 1],
        [1, 1]]) 

Random Tensor: 
 tensor([[0.8288, 0.8223],
        [0.4349, 0.4734]]) </code></pre>
<h3 id="使用随机值进行初始化-rand-ones-zeros函数">4、使用随机值进行初始化 rand() ones() zeros()函数</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">shape = (<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">rand_tensor = torch.rand(shape)</span><br><span class="line">ones_tensor = torch.ones(shape)</span><br><span class="line">zeros_tensor = torch.zeros(shape)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Random Tensor: \n <span class="subst">&#123;rand_tensor&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Ones Tensor: \n <span class="subst">&#123;ones_tensor&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Zeros Tensor: \n <span class="subst">&#123;zeros_tensor&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Random Tensor: 
 tensor([[0.5132, 0.3130, 0.5135, 0.7438],
        [0.9011, 0.3348, 0.6246, 0.7321]]) 

Ones Tensor: 
 tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.]]) 

Zeros Tensor: 
 tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.]])</code></pre>
<h2 id="二tensor的三个重要属性shapedtypedevice">二、Tensor的三个重要属性:shape,dtype,device</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor = torch.rand(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape of tensor: <span class="subst">&#123;tensor.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Datatype of tensor: <span class="subst">&#123;tensor.dtype&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Device tensor is stored on: <span class="subst">&#123;tensor.device&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Shape of tensor: torch.Size([3, 4])
Datatype of tensor: torch.float32
Device tensor is stored on: cpu</code></pre>
<h2 id="三tensor的相关操作">三、Tensor的相关操作</h2>
<p>在默认情况下，Tensor将会被创建于CPU上，我们可以使用以下方法将其复制至GPU中，但是大型的Tensor在拷贝的过程中所耗费的代价是比较昂贵的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    tensor = tensor.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line"></span><br><span class="line">tensor.device</span><br></pre></td></tr></table></figure>
<pre><code>device(type=&#39;cuda&#39;, index=0)</code></pre>
<h3 id="一些常规操作">1、一些常规操作：</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor = torch.ones(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;First row: &#x27;</span>, tensor[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;First column: &#x27;</span>, tensor[:, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Last column:&#x27;</span>, tensor[..., -<span class="number">1</span>])  <span class="comment"># 等价于 tensor[:,-1]</span></span><br><span class="line">tensor[:,-<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line"><span class="built_in">print</span>(tensor)</span><br></pre></td></tr></table></figure>
<pre><code>First row:  tensor([1., 1., 1., 1.])
First column:  tensor([1., 1., 1., 1.])
Last column: tensor([1., 1., 1., 1.])
tensor([[1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.]])</code></pre>
<h3 id="torch.cat-和-torch.stack">2、Torch.cat() 和 Torch.stack()</h3>
<h4 id="torch.cat-沿着一个维度进行堆叠不会改变原tensor的维度即原来是2维矩阵堆叠完还是二维矩阵">torch.cat() 沿着一个维度进行堆叠,不会改变原Tensor的维度，即原来是2维矩阵，堆叠完还是二维矩阵</h4>
<p>示例：dim=0的时候，原来的4x4的矩阵 A 会变成 [[A],[A],[A]]纵向叠加，即12x4的矩阵，示例：dim=1的时候，原来的4x4的矩阵 A 会变成 [A,A,A]横向叠加，即4*12的矩阵</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t1 = torch.cat([tensor, tensor, tensor], dim=<span class="number">0</span>)</span><br><span class="line">t1</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.]])</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t1 = torch.cat([tensor, tensor, tensor], dim=<span class="number">1</span>)</span><br><span class="line">t1</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.],
        [1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.],
        [1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.],
        [1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.]])</code></pre>
<h4 id="torch.stack-沿着一个维度进行堆叠但是会在原tensor的维度上增加一个维度即原来是2维矩阵堆叠完会变成3维矩阵">torch.stack() 沿着一个维度进行堆叠,但是会在原Tensor的维度上增加一个维度，即原来是2维矩阵，堆叠完会变成3维矩阵</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t1 = torch.stack([tensor, tensor, tensor], dim=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(t1.shape)</span><br><span class="line"><span class="built_in">print</span>(t1)</span><br><span class="line">t1 = torch.stack([tensor, tensor, tensor], dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(t1.shape)</span><br><span class="line"><span class="built_in">print</span>(t1)</span><br><span class="line">t1 = torch.stack([tensor, tensor, tensor], dim=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(t1.shape)</span><br><span class="line"><span class="built_in">print</span>(t1)</span><br></pre></td></tr></table></figure>
<pre><code>torch.Size([3, 4, 4])
tensor([[[1., 1., 1., 0.],
         [1., 1., 1., 0.],
         [1., 1., 1., 0.],
         [1., 1., 1., 0.]],

        [[1., 1., 1., 0.],
         [1., 1., 1., 0.],
         [1., 1., 1., 0.],
         [1., 1., 1., 0.]],

        [[1., 1., 1., 0.],
         [1., 1., 1., 0.],
         [1., 1., 1., 0.],
         [1., 1., 1., 0.]]])
torch.Size([4, 3, 4])
tensor([[[1., 1., 1., 0.],
         [1., 1., 1., 0.],
         [1., 1., 1., 0.]],

        [[1., 1., 1., 0.],
         [1., 1., 1., 0.],
         [1., 1., 1., 0.]],

        [[1., 1., 1., 0.],
         [1., 1., 1., 0.],
         [1., 1., 1., 0.]],

        [[1., 1., 1., 0.],
         [1., 1., 1., 0.],
         [1., 1., 1., 0.]]])
torch.Size([4, 4, 3])
tensor([[[1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.],
         [0., 0., 0.]],

        [[1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.],
         [0., 0., 0.]],

        [[1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.],
         [0., 0., 0.]],

        [[1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.],
         [0., 0., 0.]]])</code></pre>
<h3 id="算术运算">3、算术运算</h3>
<h4 id="计算矩阵乘法的几种方式">计算矩阵乘法的几种方式</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(tensor)</span><br><span class="line">y1 = tensor @ tensor.T</span><br><span class="line">y2 = tensor.matmul(tensor.T)</span><br><span class="line">y3 = torch.rand_like(tensor)</span><br><span class="line">torch.matmul(tensor, tensor.T, out=y3)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.]])





tensor([[3., 3., 3., 3.],
        [3., 3., 3., 3.],
        [3., 3., 3., 3.],
        [3., 3., 3., 3.]])</code></pre>
<h4 id="element-wise-product-点对点乘积矩阵对应元素相乘得到结果">element-wise product 点对点乘积（矩阵对应元素相乘得到结果）</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">z1 = tensor * tensor</span><br><span class="line">z2 = tensor.mul(tensor)</span><br><span class="line"></span><br><span class="line">z3 = torch.rand_like(tensor)</span><br><span class="line">torch.mul(tensor, tensor, out=z3)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.]])</code></pre>
<h3 id="in-place-操作">4、In-Place 操作</h3>
<p>像一些会将结果存储到操作数里的计算，我们将之称为In-Place操作，它们会在操作符后面加上后缀 "_"</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(tensor, <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">tensor.add_(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(tensor)</span><br></pre></td></tr></table></figure>
<pre><code>tensor([[1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.],
        [1., 1., 1., 0.]]) 

tensor([[6., 6., 6., 5.],
        [6., 6., 6., 5.],
        [6., 6., 6., 5.],
        [6., 6., 6., 5.]])</code></pre>
<h3 id="bridge-with-numpy机制">5、Bridge with NumPy机制</h3>
<p>Tensors和Numpy在计算机底层可能共享同一块内存，改变其中一个变量就会影响另外一个，需要注意</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = torch.ones(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;t: <span class="subst">&#123;t&#125;</span>&quot;</span>)</span><br><span class="line">n = t.numpy()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;n: <span class="subst">&#123;n&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>t: tensor([1., 1., 1., 1., 1.])
n: [1. 1. 1. 1. 1.]</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t.add_(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;t: <span class="subst">&#123;t&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;n: <span class="subst">&#123;n&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>t: tensor([2., 2., 2., 2., 2.])
n: [2. 2. 2. 2. 2.]</code></pre>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Pytorch系列笔记</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer系列笔记4——Swin Transformer思想与架构</title>
    <url>/2021/12/09/aba242d32ac9/</url>
    <content><![CDATA[<h4 id="论文名称swin-transformer-hierarchical-vision-transformer-using-shifted-windows">论文名称：《Swin Transformer: Hierarchical Vision Transformer using Shifted Windows》</h4>
<h4 id="论文地址httpsarxiv.orgabs2103.14030">论文地址：https://arxiv.org/abs/2103.14030</h4>
<h4 id="模型swin-transformer">模型：Swin Transformer</h4>
<h3 id="一论文摘要与swin-transformer背景介绍">一、论文摘要与Swin Transformer背景介绍</h3>
<p>​ 论文摘要部分即指出了Transformer在视觉领域应用与NLP领域的一些较大的差别，首先就是在视觉领域，视觉实体的规模尺度会存在较大的变化，举例而言，想要识别同一张图像中的同一距离的果实和汽车，两者的规模尺度大小可能会存在较大的不同。第二点就是相比于文字而言，图像像素的分辨率更高，信息量更多，计算更为复杂，需要消耗更多的计算资源与训练时间。相比于先前的Vision Transformer的架构，Swin Transformer使用Shifted Windows这样一个技巧，不仅大大加速了计算速度，和图像的尺度呈线性计算复杂度，并且其也仍然能够考虑到不同窗口之间的信息交互，在识别质量上也提高了2-3个百分点。故而成为了应用性非常广泛的一个架构。那么具体而言，如何加速计算，并且仍然能够考虑不同窗口的信息交互，后面会详细讲解。</p>
<h3 id="二swin-transformer整体架构介绍">二、Swin Transformer整体架构介绍</h3>
<p>​ 在上一篇笔记中，讲过了ViT网络架构，相比于ViT网络架构，Swin Transformer考虑了<strong>多尺度下的图像</strong>，可以看到如下图所示：其通过不断的下采样，在多个图像的尺度维度进行检测，这样的话直观上可以很好的解决我们先前说的视觉实体的规模尺度的大小不同的问题。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120312596.png" /></p>
<p>​ 同样，我们先来看一下Swin Transformer整体的一个架构流程，如下所示：可以看到，我们假设输入的图像是高为H，宽为W，RGB三通道24位真彩图，首先其会有一个Patch Partition层，图像宽高减少为原来的1/4，维度由3变至48. 然后后面跟着四个阶段的运算，除了第一个阶段中经过的是Linear Embedding层，后续每个阶段开始都会经过Patch Merging也就是对图像进行下采样，然后经过堆叠的Swin Transformer Block。此处值得注意的是：我们观察到，Swin Transformer Block的堆叠次数都是偶数，原因在于在该架构中，Block是成对出现的，看到下图的右侧部分，有两个不同的Block，我们暂且将之称为Block1和Block2，如果Swin Transformer Block堆叠2次那么就是Block1+Block2,如果Swin Transformer Block堆叠6次那么就是Block1+Block2+Block1+Block2+Block1+Block2。</p>
<p>​ 在每一个Block中，LN就是Layer Norm层，这个层在先前的Transformer架构中已经出现过多次了，然后MLP是多层感知级，通常由全连接层构成，在Swin Transformer的Block中，比较新的就是W-MSA模块和SW-MSA模块，也就是论文标题中所提到的Shift-Window-Multihead-Self-Attention机制。此机制我们在后续一个个模块时会进行详细讲解。</p>
<p>​ 在整体的流程中，还有一个内容值得我们注意，也就是上面显示的每经过一个阶段，矩阵的维度变化。我们发现，每过一个阶段特征图的宽和高都会减半，而随之特征图数量就会翻倍。其实每一个不同的阶段就是在不同的图像尺度下去进行内容模式的识别观察。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/cvbvbng.png" /></p>
<h3 id="三swin-transformer细节介绍">三、Swin Transformer细节介绍</h3>
<h4 id="patch-partition-linear-embedding介绍">1、Patch Partition &amp; Linear Embedding介绍</h4>
<p>​ 如下图所示，对于输入的Images来说，我们假设输入的图像为H*W*3，那么在Patch Partition的过程中会将其分割成4*4大小的块，然后将每一个块在维度方向进行展平，也就是说先前的H*W*3的矩阵经过此步骤后，长宽会变成H/4 * W/4，至于最后一个维度，将会变为3*16 = 48维，因为我们将其分割成4*4大小的块后，是在维度方向对其进行展平的。展平后，再通过Stage1的一个Linear Embedding层，该层就是对原来的第三维度为48维的三维矩阵进行一个编码（其实就是再进行一个映射），然后三维矩阵的最后一个维度的大小就会变为C。具体C为多少，是不同类型的Swin Transformer的一个参数，后文中会详细提及。在这两层的实际实现中，其实都是通过卷积来实现维度的变化以及编码的，比如在Patch Partition中就可以使用大小为4*4,步长为4的16个卷积核来对原图进行卷积得到结果。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120418491.png" /></p>
<h4 id="patch-merging">2、Patch Merging</h4>
<p>​ Patch Merging层所起到的作用就是将图片下采样，然后在深度方向进行拼接。主要由如下图所示的几步组成：</p>
<p>首先是以2 * 2的格子为一组，将每组中相同位置的像素抽出，形成一个新的矩阵。以下图为例，原特征矩阵为4 * 4，那么以2 * 2格子为1组，会形成4组新的矩阵，每组的矩阵大小为2 * 2，也就是原来的一半。然后将这4组新形成的矩阵，在深度方向做连接，然后完成LayerNorm，最后再在深度维度进行一个线性映射，将深度维度减半。此时就完成了最终的Patch Merging层的输出。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120447510.png" /></p>
<p>​ 对比该模块的输入与输出，可以发现，输出的H和W是输入的一半，深度维度是输入的2倍。符合先前全流程示意图中的H/4 * W/4 * C 变成了H/8 * W/8 * 2C，成功的将图像空间上的尺寸缩小，由较好的保留了信息。</p>
<h4 id="w-msa模块">3、W-MSA模块</h4>
<p>​ W-MSA 全称为Windows Multi-head Self-Attention也就是窗口化的Self-Attention机制，此处以在一个4*4的特征图上做为例子，在上一篇Vision Transformer中的MSA模块，4*4中的每个像素都要去和其他像素进行关联度的计算，那么在W-MSA中，其将原4*4的特征图首先分割成了4个2*2的Window窗口，然后再在每个窗口内部进行单独的Self-Attention的计算。也就是说，每个像素只需要和自己所属Window内部的像素进行关联度的计算即可。这样一来，确实大大减少了计算量，但是你会发现窗口之间的像素也无法进行通信了，导致我们的感受野变小，对于最终的结果产生影响。优劣势还是非常的明确的。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120506850.png" /></p>
<p>​ 在原论文中，给出了MSA和W-MSA的计算复杂度的推导结果公式，我们假设每个窗口含有M * M个像素，计算图像的宽高为h和w，C即为矩阵的第三维度的大小（也就是深度）。详细的推导此处省略。我们从公式中应该可以看出，相比于MSA平方的复杂度（对于hw），W-MSA相对于hw的复杂度是线性的。能够大大的提高计算效率。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120516476.png" /></p>
<h4 id="sw-msa模块">4、SW-MSA模块</h4>
<p>​ 相比于W-MSA而言，SW-MSA才是本篇论文中的重点模块，该模块弥补了W-MSA窗口与窗口间无法进行信息交互的缺陷，同时也保证了和W-MSA一样的计算复杂度。</p>
<p>​ 如下图所示，我们先前说过，在Swin-Transformer中，堆叠的Block都是偶数次，是两个不同的Block的组合。我们可以看到，下图的Layerl所示是第一次的Block堆叠，使用的是W-MSA，然后在Layerl+1中，我们将window进行了重新的分割，然后在每个window中完成计算，新的window中有些仍然是老的window的一部分，但有些新的window已经含有老的多个window的信息了，也就是完成了window间的信息的交互。</p>
<p>那么现在就让我们来一一解决以下两个问题：</p>
<p>​ 1、这个是如何进行重新的分割的呢？</p>
<p>​ 2、这样子重新分割以后，由于要计算的Window数目变成了9个，如果需要并行计算的话，需要将每个window都填充至4*4，这样子就会加大我们的计算量。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120536278.png" /></p>
<p>​ 首先是如何分割的问题：Shifted Window顾名思义，我们将原来的分割线向右和向下偏移一定的像素，然后对原图形成的分割线，就是新的window的划分线。以上面的示意图为例，就是将原来的分割线向右以及向下移动了2个像素点，就得到了新的划分。这个移动的距离，一般来说是窗口的一半，也就是<span class="math inline">\(Math.floor(M/2)\)</span>。</p>
<p>​ 接下来是第二个问题，原论文中给出了如下的示意图：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120606229.png" /></p>
<p>​ 我们将所有window中的一些window进行一个划分，0所在的部分标志为A，1，2所在的标志为C，3，6所在的标志为B，如图1所示，然后进行一个平移，也就是变成图2的形式，这样子的话我们发现又可以将其组成4个新的4 * 4的window进行self-Attention的计算，计算量和以前一致。到此为止，你可能会问，我们不是要按照原来划分的9个window进行计算吗？如果按照现在这个平移过的4 * 4的window进行计算，原先window和window之间的边缘都是跳跃的，而且我们本来就是要原来每个window内部单独计算的，只是为了减轻计算量才进行的平移，所以计算某一个新的4 * 4的混合window的时候，自然不希望内部的两个原来的window之间信息有交互和混合。（就比如说，我们平移后，变成了4号块自己算自己的，5、3号块合起来算，1、7号块合起来算，2、0、6、8号块合起来算，4号块是没有问题的，内部像素本身就是连续的，但是5、3号块一起算就会出现问题，5号块和3号块边缘处的像素是不连续的，而且理论上而言，我们是要单独计算3、5号块各自的Self-Attention的内部像素关联度的，所以我们在计算区域5的时候不要引入区域3的信息）</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120637174.png" /></p>
<p>​ 所以，平移以后对4个新的4*4的window进行的Self-Attention是我们先前提到过的Masked MSA,也就是让每一个新形成的window中，根据原来的分割规则给它套上一个mask。这样子的话，虽然它们在一起训练，但是通过这个mask，仍然使得原来的9个window划分规则中，不同的window之间的像素是不会计算关联度的，或者说关联度为0.</p>
<p>​ 举例来说，如下图所示：我们计算区域5和区域3的这块的Self-Attention的时候，原先是计算了16个α值，那么我们等它计算完以后，将图中蓝色框圈出来的系数全都减去100，这个减100的含义是什么呢？原先计算出的α系数，一般都是比较小量级的，减去100以后，必定是一个比较大的负数，那么经过SoftMax的计算以后，系数就会变成0，也就实现了区域5和区域3之间的像素如果计算关联度，那么就是0。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120650353.png" /></p>
<p>​ 最后的话，我们要注意，计算完以后将对应的小块移回原位置。</p>
<h4 id="relative-position-bias介绍">5、Relative Position Bias介绍：</h4>
<p>​ 在论文中还简单介绍了这样一种相对位置偏移的计算机制。这种机制应用于计算Self-Attention的时候。如下公式所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120718204.png" /></p>
<p>​ 其给出了一组数据，在不同的学习网络中，是否使用偏移、或者是使用相对/绝对位置偏移来计算Attention会导致的结果误差。我们可以发现相对位置偏差能够将结果提升1个百分点左右。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120725660.png" /></p>
<p>​ 那么相对位置偏差是怎么确定的呢？如下所示，假设我们的特征图是左侧的2*2的格子，下方是我们熟知的绝对位置索引，相对位置索引如右侧上面一排所示，其实就是当前计算格子的绝对位置索引减去其他格子的绝对位置索引。然后将四个像素的相对位置索引展开后拼接在一起形成一个新的矩阵。这个矩阵就是二维的相对位置索引矩阵。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/iiioio.png" /></p>
<p>​ 在作者的源码中，其使用的是1维的的相对位置索引矩阵，我们不能简单的将x,y相加，不然可能导致不同位置的相对位置索引一致，导致出现问题。所以作者在源码中经过了一个简单处理。我们先把所有的行列标加上M-1，然后再将行标乘2M-1，然后再将行列标相加，得到的矩阵。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120758495.png" /></p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120804811.png" alt="image-20220115120804811" /><figcaption aria-hidden="true">image-20220115120804811</figcaption>
</figure>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120807646.png" alt="image-20220115120807646" /><figcaption aria-hidden="true">image-20220115120807646</figcaption>
</figure>
<p>​ 然后我们需要把Relative Position Index通过一张Bias Table映射成relative position bias才是用于计算Self-Attention最终用于计算的Bias值，也就是公式里的矩阵B。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120814669.png" /></p>
<h3 id="四swin-transformer-模型扩展参数">四、Swin Transformer 模型扩展参数</h3>
<p>​ 论文中给出了以下一张表格，里面是四种不同的Swin模型的各个阶段的参数。其中有Swin-T,Swin-S,Swin-B,Swin-L四种不同的Swin Transformer模型，分别代表Tiny。</p>
<p>​ 我们解析某一列的参数，concat 4 * 4 就代表要将高和宽下采样4倍，96-d就代表经过Linear Embedding层以后的C大小。接下来的括号内的东西就代表堆叠的block内的参数，window size = 7*7,通过该Block之后输出维度为96，Multi_Head的Head = 3。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/bvbcf123.png" /></p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Transformer系列笔记</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
        <tag>Computer Vision</tag>
        <tag>Swin Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer系列笔记3——Vision Transformer思想与架构</title>
    <url>/2021/12/08/5899e5598f03/</url>
    <content><![CDATA[<p>论文名称：《An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale》</p>
<h4 id="论文地址httpsarxiv.orgabs2010.11929">论文地址：https://arxiv.org/abs/2010.11929</h4>
<h4 id="模型vision-transformer-vit">模型：Vision Transformer (ViT)</h4>
<h3 id="一论文摘要与vision-transformer背景介绍">一、论文摘要与Vision Transformer背景介绍</h3>
<p>​ 自从Transfomer机制出现以后，已经成为了NLP领域的业界标准流程，但是在CV领域的应用较少。CV领域中往往都是会将其和CNN结合使用，或是代替CNN架构中的一部分。这篇论文就提出了其实在CV领域中，Transformer并不需要依赖于CNN来进行使用，其提出的Vision Transformer架构，在基于一些大体量数据的预训练的网络参数然后再迁移学习到一些训练任务时，能够取得非常好的效果，并且也能节省训练的计算资源。所以Vision Transformer是应用于CV领域的，不简单依托于CNN架构的一类Transformer架构的衍生内容。在此论文中，其应用于了CV领域的图象识别任务。</p>
<h3 id="二vision-transformer网络架构">二、Vision Transformer网络架构</h3>
<p>​ 如下图所示，左侧为ViT网络的概览，可以看到，该网络将图片分为一小块一小块的，将每一个小块视为一个向量(被称为Flattened Patches),然后图中的Linear Projection of 这层可以被视为是一个Embedding层，将每一块图像Embedding成为一个对应的向量，然后再在这一系列向量前面，新增一个用于分类的向量，叫做Class Token,再给每一个向量加上一个表示位置信息的向量。随后将这些向量输入进Transformer Encoder中，我们知道，Encoder对于一个输入序列中的每一个向量，都会输出一个对应的向量，我们仅取Class Token输入对应的输出向量，将其放入MLP Head模块（这是一个最终用于分类的层结构）中，然后再由MLP Head模块输出分类类别。Transformer Encoder内部的块结构与Transformer的结构类似，其中MLP是新的模块，后续会详细再讲。到此为止就是整个ViT网络基本的架构。接下来会按照顺序，一个一个模块的进行详细的介绍。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115115915557.png" /></p>
<h4 id="linear-projection-of-flattened-patchesembedding层">1、Linear Projection of Flattened Patches（Embedding层）</h4>
<p>​ 对于标准的Transformer的Encoder模块，一般要求输入的是向量序列，也就是应该是一个二维矩阵[num_token,token_dim]。在该网络架构的代码实现中，可以直接通过一个卷积层来实现，比如说ViT-B/16，B代表Base，16代表分割以16*16为单位分割源图像。在这个网络中，使用卷积核大小为16*16，步长为16。</p>
<p>​ 如果我们使用的图片是[224,224,3]的大小，那么经过卷积以后就会变成[14,14,768]的大小，然后展平就会最终变成[196,768]的二维矩阵。</p>
<p>​ 在输入到Encoder之前，还需要加上 用于分类的向量class token和position embedding，这两者都是可训练参数。</p>
<p>​ 拼接[class]token:Cat([1,768],[196,768]) -&gt;[197,768]</p>
<p>​ 叠加Position Embedding: [197,768] -&gt; [197,768]</p>
<p>​ Position Embedding在此处是通过直接叠加相加的方法完成的，所以矩阵的维度不会发生变化，同时，原论文中给出了不同维度的Position Embedding的效果，我们发现1维和2维的效果差不多，但是都比没有Position Embedding的结果要好，所以在实现过程中就可以实现一维的Pisition Embedding进行叠加。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115115949427.png" /></p>
<p>​ 那么，具体叠加的一维的Position Embedding应该是什么呢？如下图所示，我们对于每个位置计算其和其他位置的余弦相似度。即可得到叠加的具体数值。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120001864.png" /></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120004895.png" /></p>
<h4 id="transformer-encoder层">2、Transformer Encoder层</h4>
<p>​ 其和Transformer中Encoder类似，由许多个Block组成</p>
<p>​ 我们先看Encoder Block的结构，其中基本结构与原始的Transformer的Encoder Block类似，但是其中有一个不太一样的MLP Block结构。MLP Block的结构显示如右侧，其中是几个Linear层，然后配合一些Dropout和激活函数。MLP Block的第一个Linear层，会将原始的输入扩大4倍，就例如如果Linear层的输入是197 * 768的，那么该层的输出是197 * 3072，然后第二个Linear层又会将输出变回197*768的大小。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120029921.png" /></p>
<h4 id="mlp-head层">3、MLP Head层</h4>
<p>​ 此层在训练不同的数据集时，组成模块不太一样。如果训练ImageNet21K或一些更大的数据集的时候，该层由Linear+tanh激活函数+Linear层组成。但是如果迁移到ImageNet1K或者一些小规模的数据集上，那其实只需要一个Linear层即可。具体的内容可以查看论文的源码部分。</p>
<h3 id="三以vit-b16-为例的vision-transformer架构">三、以ViT-B/16 为例的Vision Transformer架构</h3>
<p>​ 我们可以看到先前所讲的各个模块组合在一起以后，整个网络的一个架构。图中的Pre-Logits部分其实就是一个全连接层+激活函数，视情况可以舍弃。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120118127.png" /></p>
<h3 id="四不同vit模型的参数">四、不同ViT模型的参数</h3>
<p>​ 在论文的Table1中有给出三个模型（Base/ Large/ Huge）的参数</p>
<ul>
<li><p>Layers 是Transformer Encoder中重复堆叠Encoder Block的次数。</p></li>
<li><p>Hidden Size是通过Embedding层后每个向量的长度（token 的 dim）。</p></li>
<li><p>MLP Size 是Transformer Encoder中MLP Block第一个全连接的节点个数，一般来说是Hidden Size的4倍。</p></li>
<li><p>Heads 代表Transformer中Multi-Head Attention的heads数。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120147916.png" /></p></li>
</ul>
<h3 id="五hybrid混合模型">五、Hybrid混合模型</h3>
<p>​ 引用：https://blog.csdn.net/qq_37541097/article/details/118242600</p>
<p>在论文中其也提及了Hybrid混合模型，其就是先前摘要中提到的将传统CNN特征提取和Transformer进行结合的做法。</p>
<p>​ 其首先用传统的CNN提取特征，然后再用Vit模型进一步得到最终的结果。</p>
<p>​ 整体的网络架构如下：以ResNet50作为特征提取器的混合模型，但这里的Resnet有些不同。首先这里的R50的卷积层采用的StdConv2d不是传统的Conv2d，然后将所有的BatchNorm层替换成GroupNorm层。同时在原Resnet50网络中，stage1重复堆叠3次，stage2重复堆叠4次，stage3重复堆叠6次，stage4重复堆叠3次，但在这里的R50中，把stage4中的3个Block移至stage3中，所以stage3中共重复堆叠9次。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115120211640.png" /></p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Transformer系列笔记</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
        <tag>Vision Transformer</tag>
        <tag>Computer Vision</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer系列笔记2——原始Transformer架构与Seq2Seq问题</title>
    <url>/2021/12/07/84769e08d06a/</url>
    <content><![CDATA[<h3 id="一相关背景介绍">一、相关背景介绍</h3>
<p>​ Transformer架构最广泛用在Seq2Seq问题上，也就是Sequence-to-Sequence。区别于GAN所对应的Pix2Pix的问题，Seq2Seq的问题也会有非常多的应用和变式，其应用场景也是非常的广。</p>
<p>​ Seq2Seq问题是指输入一个序列，输出一个序列，同时输出序列的长度由训练好的模型进行决定。比较经典的问题就是语音识别、机器翻译、语音翻译等领域。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112932803.png" /></p>
<p>​ 同时，Seq2Seq也可以用于Chatbot聊天机器人，比如说如下所示：我们可以将Person1和Person2的一组对话视为一个input和一个对应的response，两者都是序列。或者一些其他的Question&amp;Answering问题都可以广泛的应用Seq2Seq的模型解决思想。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112939154.png" /></p>
<p>​ 具体的一些相关论文可以参照下图所示的网址进一步了解。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112946229.png" /></p>
<p>​ 同时，还有更多的可以应用Seq2Seq的例子，比如说对于一个Syntactic Parsing问题，也就是语法解析，我们也可以将其视为Seq2Seq的形式，来对其进行思考。输入是一句话，毫无疑问是一个Seq序列。但是，我们所需要的输出结果看上去像是一个树形结构【deep learning组成名词短语，very powerful 组成形容词短语，is 和 very powerful又组成动词短语，最后deep learning和 is very powerful组成一个句子】，但其实，如下图所示，我们可以将图最上方的这个句子作为输出结果，这样就将一个类似图结构的内容转换成了Seq的形式，同时也包含了所有我们需要的结果信息，然后用Seq2Seq的思想去训练模型即可。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112954818.png" /></p>
<p>​ 再比如，Seq2Seq应用于图像领域的目标检测，感兴趣可以查看以下这篇论文。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113003795.png" /></p>
<h3 id="二seq2seq2结局方案origin-transformer">二、Seq2Seq2结局方案——Origin Transformer</h3>
<p>​ 对于一般的Seq2Seq问题，笼统而言，我们一般就是将输入序列经过一个Encoder然后再通过一个Decoder就得到我们的输出序列。但是这个Encoder和Decoder内部的结构就大有讲究，最经典的架构就是Transformer。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113028194.png" /></p>
<h4 id="encoder">1、Encoder</h4>
<p>​ 首先我们关注Transformer的Encoder部分。下面是从输入输出的结果来看，Encoder的输入是一个序列，输出是一个编码过后的序列。（其实只从输入输出来看，像RNN、CNN都可以做到输入一个序列，输出一个序列，但是此篇讲的是Transformer）</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113035456.png" /></p>
<p>​ Transfomer中的Encoder现在一般都由这样的架构组成，如下图所示，由非常多的Block组成，每一个Block并不是指一层网络，可能是有许多曾网络组成。那么输入经过许多个Block的处理，然后输出。那么在Transformer中，每一个Block内部的架构如右侧所示：输入一排向量，先经过Self-attention的机制，输出一排向量，然后这一排向量再经过全连接层，输出一排向量，这一排带红色框的向量就是Block的输出。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113045808.png" /></p>
<p>​ 但实际上，在原来的Transformer中，Block内的结构稍微更复杂一些，其还增加了一个residual的过程，如下所示：</p>
<p>​ 输入的某个向量b经过Self-attention以后，得到向量a,此向量a还要与向量b相加，得到一个新的向量a+b，然后再做Layer Norm,得到一个深蓝色的向量c。（左上角的那个框框代表的就是，接下去接右侧的过程）</p>
<p>​ 然后这个Norm输出的深蓝色的向量c，经过FC层，得到新的向量d，此处还有一个residual的架构，c和d相加，得到新的向量e，然后e再做一次Layer Norm才会得到最终这个Block输出的结果向量。</p>
<p>（LayerNorm本身的过程如图中央所示，先计算向量数据的均值和标准差，然后依据公式xi’ = (xi-m)/σ即可完成归一化。）</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113058827.png" /></p>
<p>​ 讲完每一个Block内完成的事情，我们就可以看Transfomer中给出的这个完整的带细节的架构示意图，其实两者中有部分过程是重叠的，只是表示形式不一样。</p>
<p>​ 首先将输入经过嵌入层，完成编码。如果对嵌入层没有印象，可以查看如下的文章。然后通过Positional Encoding向输入中增加序列不同地方的位置信息。然后经过多次结构的核心部分Nx。这个Nx其实就是我们刚才提到的一个Block。其中，Multi-Head Attention就是Self-Attention的一种扩展的架构，然后Add&amp;Norm就是上述的Residual + LayerNorm的过程。Feed Forward就是上图中通过FC层的过程。所以这张图中Nx内部的这个框框就是一个Block的过程，然后整个Transformer Encoder就由许多个这样的Block组成。【像先前所讲的】</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113109977.png" /></p>
<p>​ 其实Transformer Encoder的架构也是可以灵活改变的，此处只是讲了最初提出的Transformer时候文章中Encoder的架构。</p>
<h4 id="decoder">2、Decoder</h4>
<p>​ 然后的话我们关注Transformer的Decoder部分。Decoder分为两种，一种是Autoregressive（AT）的Decoder,还有一种是Non-Autoregressive（NAT）的Decoder。首先是Autoregressive的Decoder的介绍：</p>
<p>​ Decoder的输入，有两个内容，一个是Encoder输出的序列，还有一个是START标识符号所对应的One-hot编码，这两样东西经过Decoder后，输出一个各种字的概率分布，其中概率最大的那个字就会被作为最后的输出字符。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113200035.png" /></p>
<p>​ 然后我们将START 和 机 组成的one-hot向量的序列输入，再经过Decoder，得到一个概率分布，然后选出概率分布中最高的那个字“机”。以此类推，直到完成所有的输出。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113209026.png" /></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113211451.png" /></p>
<p>​ 在此处其实存在两个问题 ，一个问题是按照上述的过程，其实Decoder后面每一步的输入都来自于自己前一步的输出，就比如说，中间某一步输入是“机器”，输出了“学”，然后下一步输入是“机器学”，输出是“习”。那么，我们要如何避免一步错步步错的情况发生呢？也就是说，如果其中有一步发生了问题，我们应当怎么让机器在后面的步骤中仍然输出正确的结果。第二个问题是，如果按照上述的步骤生成下去，生成出来的序列是无穷无尽的，它永远不会停止，那么机器怎么去决定输出序列的长度呢？这两个问题，后文会有提及，我们先继续讲述Decoder内部到底经历了什么。</p>
<p>​ 我们先来看一张Encoder和Decoder的对比图：从此图而言，我们发现Decoder除了中间那一块被盖住的，以及最后输出层的一些内容以外，Block内部的内容其实和Encoder是类似的。一个比较重要的差别点就是其使用的是Masked Multi-Head Attention。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113222282.png" alt="image-20220115113222282" /><figcaption aria-hidden="true">image-20220115113222282</figcaption>
</figure>
<p>​ 我们先来看一下，这个Masked Multi-Head Attention是什么意思呢？图1是我们熟悉的Self-Attention，每一个输出的向量都是含有输入的所有向量的咨询的，右图是Masked Self Attention机制，也就是在生成b1的时候，是不能使用a1之后的输入向量的，只能使用a1的资讯，生成b2的时候，不能使用a2之后的输入向量，只能使用a1,a2的资讯，以此类推。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113244478.png" alt="image-20220115113244478" /><figcaption aria-hidden="true">image-20220115113244478</figcaption>
</figure>
<p>下面是一个更为具体的示意图：</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113256453.png" alt="image-20220115113256453" /><figcaption aria-hidden="true">image-20220115113256453</figcaption>
</figure>
<p>​ 那么为什么要使用这样的架构呢？原因其实很简单，因为如果不这样子的话，AT形式的Decoder是没法的运作的。因为先前讲的AT的Decoder运作方式，输出的字是一个一个产生的。第一步只有一个输入的“START”标识符对应的One-Hot向量，生成一个字以后，再将START标识符和第一个字输入，得到第二个字，依次类推。所以在生成的时候，它只能参考它前面的输入的序列的资讯，没法获得它之后的资讯。</p>
<p>​ 然后我们来看一下Encoder间和Decoder间是如何传递资讯的呢？也就是刚才那张图中，暂时被灰色遮住的部分：我们会发现，在这个红色框框框起来的模组中，有两个输入的箭头来自于Encoder，一个输入的箭头来自于Decoder的前一步的输出。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113305054.png" alt="image-20220115113305054" /><figcaption aria-hidden="true">image-20220115113305054</figcaption>
</figure>
<p>​ 那么具体来说，是怎么工作的呢，如下所示：此步中的Multi-Head Attention指的是一个Cross-Attention的过程，具体如下所示：在Decoder解析的第一步时，输入是来自Encoder的一个序列，以及Decoder上一步的输出（因为Decoder上一步无输出，此步为第一步，所以这个应该是一个START标识符，表示句子的开始）。</p>
<p>​ 然后Encoder这边输出的序列，a1,a2,a3向量分别乘以一个权重矩阵，形成k1,v1,k2,v2,k3,v3，Deocder这侧的START标识符对应的One-hot编码经过Masked-Self-Attention得到一个向量，然后该向量乘上一个权重矩阵，得到向量q,计算q和k1,k2,k3的相关性并且归一化，得到系数α1’，α2’，α3’.</p>
<p>​ 得到系数α1’，α2’，α3’后，分别和v1,v2,v3相乘相加，得到向量v，然后再经过FC就是该步骤Cross attention的输出，至于后面就是需要再经过上述网络中描述的Add&amp;Norm，也就是Residual和Layer Norm的过程，才完成Decoder中一个Block的过程。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113324988.png" alt="image-20220115113324988" /><figcaption aria-hidden="true">image-20220115113324988</figcaption>
</figure>
<p>​ 然后第二步以此类推，如下图所示，此处就不再赘述。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113331325.png" alt="image-20220115113331325" /><figcaption aria-hidden="true">image-20220115113331325</figcaption>
</figure>
<p>​ 讲到这里的话，Decoder的基本架构也都已经清晰了，我们来解决一下先前的两个遗留问题之一，也就是机器怎么决定输出的序列的长度的？</p>
<p>​ 在AT的Decoder中，我们其实可以在输出的字符集中增加一个叫做END的字符，它就代表一个句子的结束，如果某次Decoder输出的概率分布中，END字符的概率较高，就说明该句子结束了。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113340249.png" alt="image-20220115113340249" /><figcaption aria-hidden="true">image-20220115113340249</figcaption>
</figure>
<p>​ 那么什么又是NAT的Decoder呢？我们先前看到AT的Decoder是一个个输出字符的，NAT的Decoder则是一次性的输入全是START的序列，然后一次性得到输出的字符序列。那么NAT的Decoder又是如何决定输出序列的长度的呢？有两种办法，一个是专门训练一个分类器或者预测器，去预测输出序列的长度，另一个就是我们先假设这个输出的序列不会超过每个定值，比如说300个字符，那么我们就输入一个300个START组成的序列，然后在输出的字符序列中，忽略END字符后面的字符即可。</p>
<p>​ 相比AT来说，NAT有着并行化，更稳定的优势，但是NAT的效果往往比AT要差一些。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113351438.png" alt="image-20220115113351438" /><figcaption aria-hidden="true">image-20220115113351438</figcaption>
</figure>
<h3 id="三如何训练transformer">三、如何训练Transformer</h3>
<p>​ 首先，当我们丢入第一个START字符的时候，希望Decoder输出的Distribution分布，和我们的Ground Truth的结果，能够越接近越好，也就是要最小化cross entropy的值。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113410387.png" alt="image-20220115113410387" /><figcaption aria-hidden="true">image-20220115113410387</figcaption>
</figure>
<p>​ 由于我们会输出好多次字符，所以我们最终是希望，能够最小化每次输出的Distribution和Ground Truth的cross entropy。不要忘记，最后一步输出段落的结尾符号，也要考虑在内。【此处有一个题外话，在实现的时候，其实有些时候可以将START的标识符和END标识符表示为同一个One-Hot编码，因为反正START标识符只会出现在句子的头部，仍然是可以分辨的，不需要区分START和END这两个字符】</p>
<p>​ 同时，此处我们在训练的时候，Decoder的Input不是上一步输出的内容，而是给它正确的答案。这件事情就被我们叫做Teacher Focing。但是这样子和在实际生产使用的时候存在一个不匹配的问题，这个问题我们之后会有所讨论。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113420273.png" alt="image-20220115113420273" /><figcaption aria-hidden="true">image-20220115113420273</figcaption>
</figure>
<h3 id="四关于训练seq2seq类似模型的tips">四、关于训练Seq2Seq类似模型的Tips：</h3>
<h4 id="copy-mechanism">1、Copy Mechanism</h4>
<p>​ 这一个机制在聊天机器人或文档摘要等领域应用的比较广泛，举例来说，有的时候输出的某些内容可以从输入中Copy进行完成，这样就避免机器去学习一些奇怪的词汇，比如说在聊天机器人中库洛洛这样一个人名信息。感兴趣可以继续查看相关的论文</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113453661.png" alt="image-20220115113453661" /><figcaption aria-hidden="true">image-20220115113453661</figcaption>
</figure>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113456022.png" alt="image-20220115113456022" /><figcaption aria-hidden="true">image-20220115113456022</figcaption>
</figure>
<h4 id="guided-attention">2、Guided Attention</h4>
<p>​ 由于有的时候机器可能会忽略输入的某一些部分，此时就可以使用该种手段，该手段通常应用于语音合成、语音辨识领域。</p>
<p>其就是要求机器在做Attention的时候以一个固定的方式，也就是说如果你对于某一个任务已经有了一些既定的发现，就可以将这种限制加入到训练的过程中，引导机器完成Attention的计算过程。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113509972.png" alt="image-20220115113509972" /><figcaption aria-hidden="true">image-20220115113509972</figcaption>
</figure>
<h4 id="beam-search">3、Beam Search</h4>
<p>​ BeamSearch是为了解决如下的一个问题：如下图所示，举例而言，比如说我们输出的字符只有A和B两种，那么Decoder的输出序列，就可以表示为如下图所示的一颗数状结构。红色的路径是Decoder按照先前的贪婪规则得到的输出。但其实，有一条比红色路径更好的输出，就是绿色的路径。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113522389.png" alt="image-20220115113522389" /><figcaption aria-hidden="true">image-20220115113522389</figcaption>
</figure>
<p>​ 可是，我们如果想要找到一个训练过程中这样一条绿色的最优路径是比较难的，因为我们不可能去穷举搜索每一条路径，因为在字符集比较大的情况下，几层叠加的可能就已经非常之多。这个时候就可以使用Beam Search这样一种技术。具体如何进行可以Google搜索详情</p>
<h4 id="optimizing-evaluation-metric">4、Optimizing Evaluation Metric</h4>
<p>​ 我们在训练的时候，目标是最小化每个一一对应的中文字的输出的分布和Ground Truth，而在评估一个模型好坏的时候，我们往往会使用输出的整句和GroundTruth之间的BLEU score来进行评估，所以我们的验证集应当使用BLEU score。那么我们的训练过程中为什么不使用BLEU score呢？简单来说就是如果在训练过程中我们要做两个句子之间的BLEU score，是根本没有办法做微分的也就没有办法做梯度下降去最优化求解。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113543303.png" alt="image-20220115113543303" /><figcaption aria-hidden="true">image-20220115113543303</figcaption>
</figure>
<h4 id="scheduled-sampling">5、Scheduled Sampling</h4>
<p>​ 这个方法是为了解决我们先前提出的两个问题中的第一个问题，以及在那之后提出的一个训练与实际应用过程中的那个Mismatch(也就是训练的时候Decoder的输入使用的是Ground Truth,可是输出的时候不行)。简单直接的想法，就是训练的时候，我们往输入中加入一些噪声，就可以了。具体而言的话，也有许多论文是做这个方向的，如果有兴趣的话可以自行查阅。</p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115113600427.png" alt="image-20220115113600427" /><figcaption aria-hidden="true">image-20220115113600427</figcaption>
</figure>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Transformer系列笔记</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
        <tag>Self Attention</tag>
        <tag>Seq2Seq</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer系列笔记1——Self Attention机制</title>
    <url>/2021/12/06/59e48d4d462f/</url>
    <content><![CDATA[<h3 id="一背景介绍问题引入">一、背景介绍问题引入</h3>
<p>​ 在先前的网络架构中，我们一般输入的都是一个向量，但是有的时候我们需要考虑更为复杂的输入，如下图所示，比如说一个向量的集合，并且向量集合的长度还会发生变化。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115111555364.png" /></p>
<p>​ 一般按来说对于输入是向量集合的话，我们先要对其进行编码处理，一种编码方案为One-hot Encoding,称为独热向量编码，另一种编码方案为Word Embedding方法，称为词嵌入方式。</p>
<p>为了更好的理解，输入为一个向量的集合，下面有一些相关的例子：</p>
<p>​ <strong>示例1：</strong>比如说，输入是一段语音，我们可以将一段1s中的语音视为一个向量的集合输入，每25ms视为一个window窗口，称为1帧，将里面的信息提取出来以后，就成为一个向量。我们将这个窗口每次向后移动10ms，每移动10ms就重新取一次样，也就是多输出一个向量。这样预处理的话，其实就是一段1s的语音我们可以把它视作为100个向量的一个集合输入。 （在上述处理的过程中，至于为什么25ms视为一个window，每次要向后移动10ms，这些都需要视具体的语音任务而定，有兴趣可以进一步看语音处理方面相关的文章）</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115111649129.png" /></p>
<p>​ <strong>示例2</strong>：比如说一个图，也可以被视作一个向量的集合，每个节点都被当作一个向量，这个向量中编码了关于这个节点所有的相关信息。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112432503.png" /></p>
<p>​ 那么对于这样复杂的输入而言，输出可能是什么呢？如下图所示，有三种可能，第一个是对于每个输入的向量，都输出一个label结果，比如说POS tagging任务。第二个是整体就输出一个label结果，比如说Sentiment analysis任务。又或者是第三个所示的seq2seq的任务，比如说语句翻译，或者是语音识别的任务。此篇文章聚焦于第一种情况探讨Self-Attention机制与整体的架构。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112440152.png" /></p>
<h3 id="二self-attention解决方案引入">二、Self-Attention解决方案引入：</h3>
<p>​ 为了解决上面我们说的对于每个输入的vector都输出一个label结果的事情，最简单也最为直观的方法就是如下图所示，假设输入的向量集合长度为4，那么我们将每个输入的向量单独考虑，然后进行结果的输出。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112458834.png" /></p>
<p>​ 但是这样一来，我们相当于没有考虑向量与向量之间的关系，那么这种架构下我们可能考虑上下文吗？答案是可以的，如下图所示：我们可以将前后的向量也输入到当前的全连接层中，这就考虑到了上下文信息。但是这样一来问题又发生了，如果我们想要考虑整个序列的上下文呢？那么这个窗口的长度到底应该选多少呢？要知道我们输入的向量的个数是会变化的。同时，如果将每个向量都要连接到每个FC中的话，需要训练的参数就会大大增加，随之而来的就是非常容易过拟合。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112507468.png" /></p>
<p>​ 在这样一个问题背景下，Self-Attention机制应运而生。如下面两张图片所示，我们可以理解为，每一个单独的向量经过Self-Attention机制计算后，得到一个新的向量，这个新的向量中是含有所有的上下文信息的。同时Self-Attention也可以做好多层，也就是说我们可以像第二张图一样，先走一次Self-Attention然后过FC层，然后再走一次Self-Attention层，然后再过全连接层，然后输出。使得Self-Attention发扬光大的是一篇叫做《Attention is All you Need》的论文，那么Self-Attention内部，到底是如何考虑进上下文之间的关系的呢？</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112528529.png" /></p>
<h3 id="三self-attention架构介绍">三、Self-Attention架构介绍</h3>
<p>​ 我们首先从结果来看Self-Attention做了一件什么事情，它的输入可以是原始input，也可以是隐藏层。然后经过该结构后，就可以将向量a1变成一个带着上下文信息的向量b1。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112544934.png" /></p>
<p>​ 首先，我们以生成向量b1为例，记录整一个过程。如下图所示，首先我们需要考虑a1和另外三个向量的相关性，然后用一个变量α去进行衡量。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112553361.png" /></p>
<p>​ 那么如何计算得到这个α的值呢，我们就需要一个如下所示的模块，这个模块输入两个向量，一个向量乘以矩阵Wq得到向量q，一个乘以矩阵Wk得到向量k，然后我们再把q和k做点积，就得到了α，这个α就代表输入的两个向量之间的相关性。至于Wq和Wk内部是什么我们先不用管，因为其内部的参数是我们需要用训练集训练网络得到的。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112601252.png" /></p>
<p>​ 所以，我们就能够依据上述这个框架计算出a1分别和a1,a2,a3,a4的相关性α(1,1),α(1,2),α(1,3),α(1,4)，我们将之称为Attention Score。具体写成公式的形式就是下图下面的半部分。然后的话呢我们需要将之通过Soft-max函数，做一个归约化，使得他们的和为1，得到α’(1,1),α’(1,2),α’(1,3),α’(1,4)。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112614866.png" /></p>
<p>​ 有了α’(1,1),α’(1,2),α’(1,3),α’(1,4)之后，我们先将a1,a2,a3,a4乘上矩阵Wv得到v1,v2,v3,v4，然后用对应的α’和v做叉积，从v中提取信息，最终将所有对应的叉积相加，就得到了最终的结果b1。形式化的公式写在下图的右上方。然后b2,b3,b4也是同样的过程去进行计算。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112623695.png" /></p>
<p>​ 按照我们介绍的顺序b1,b2,b3,b4我们需要一一算出，其实这一计算过程是可以通过矩阵乘法并行执行的。首先，我们将a1,a2,a3,a4拼接组合成一个大的矩阵，称为I。将I分别乘上矩阵Wq，Wk，Wv之后，就会得到大的矩阵Q,K,V。从结果上而言，大的矩阵Q,K,V就是先前一个个向量计算时候得到的结果向量q1,q2,q3,q4拼接组合而成。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112631291.png" /></p>
<p>​ 我们现在拥有Q,K,V三个矩阵，我们可以用矩阵K的转置乘上矩阵Q就会得到一个α的矩阵，其从结果上而言等价于一个个α计算得到的结果组成的矩阵。具体的推导过程见下图，还是比较好理解的，只是把一些重复的矩阵运算进行了合并而已。得到对应的矩阵A以后，我们对每一列做SoftMax归一化操作，得到矩阵A’。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112638932.png" /></p>
<p>​ 最后我们将矩阵A’和矩阵V相乘，就能生成结果矩阵O。O就是b1,b2,b3,b4向量的拼接。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112647706.png" /></p>
<p>​ 最后，我们可以将整个过程表示如下图：Wq,Wk,Wv三个矩阵内部的参数就是我们需要训练的参数，A’就是我们常说的Attention Matrix.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112657080.png" /></p>
<h3 id="四self-attention架构扩展改进">四、Self-Attention架构扩展改进</h3>
<h4 id="multi-head-self-attention-多头注意力机制">1、Multi-head Self-Attention 多头注意力机制</h4>
<p>​ 在上述的计算过程中，我们就是用qi去找相关的ki，但是相关可能会存在很多种，所以我们应该需要有不同的q，然后不同的q去负责不同的相关性，于是乎出现了Multi-head Self-Attention架构。如下所示，相比于Self-Attention，其只是将计算得到的qi和ki进行拆分。我们先从a乘上矩阵Wq变成q，然后再将q乘上两个不同的矩阵W(q,1)，W(q,2)，分别变成两个不同的向量q1和q2。k和v也是同样的进行操作。然后的话用q1,k1,v1去按照之前的方法计算出一个b1出来，再用q2,k2,v2去计算出一个b2出来</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112728011.png" /></p>
<p>最后再将b1和b2组合起来，乘上一个权重矩阵，得到最终的结果向量b.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112737330.png" /></p>
<h4 id="positional-encoding">2、Positional Encoding</h4>
<p>​ 我们会发现，在先前的Self-Attention架构中，其并没有考虑输入向量组之间向量的远近对于其相关性的影响。就比如a1如果和a2换了位置，也不会影响a1和a4的相关性度量。所以我们会想要有如下的想法：对于输入向量集合中的每个向量来说，都先加上一个不同的向量e，然后再去进行先前的操作。这个e可以是人工指定的，也可以是机器学到的规律。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112754051.png" /></p>
<p>​ 关于e究竟需要是怎么样的东西效果才会好，有许许多多的文章研究。此处只是讲解一个基本的做法，具体感兴趣可以查看下面的论文。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112802708.png" /></p>
<h3 id="五self-attention应用">五、Self-Attention应用</h3>
<p>​ Self-Attention机制应用广泛，最多的就是应用在Transformer架构和BERT架构中，广泛的用于NLP领域。但除了NLP领域，其实其在很多领域也适用。</p>
<p>​ 比如说下图所示的语音处理领域，我们最开始就说过如何将一段语音看作是一个向量集合作为输入，然后就可以采用Self-Attention的机制，进行相关的任务。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112819190.png" /></p>
<p>​ 或者在图像处理的领域，我们可以将一张RGB图的每一个像素点的RGB三个值，视为一个向量输入，然后一张Image就可以被视为一个ImageWidth*ImageHeight长度的向量的集合。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112827842.png" /></p>
<p>​ 以下两篇是使用了Self-Attention架构的有关与图像生成和图像检测的论文，后续可能会出相关的论文阅读笔记。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112836400.png" /></p>
<p>​ 那么Self-Attention和CNN到底有啥区别呢？其实按照我们上面对图像的理解，CNN可以看作是一个只有一小部分感知域的Self-Attention。因为CNN的其中一个特征，就是它有独特的感知域，只感知某像素周围一部分和该像素的关联，而Self-Attetion则是会考虑整个序列，也就是该像素和所有像素之间的关联。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112848232.png" /></p>
<p>​ 有人做过研究，在《On the Relationship between Self-Attention and Convolutional Layers》这篇论文中，以严格的数学证明了CNN是Self-Attention的子集。也就是说在一定条件下，Self-Attention可以和CNN实现完全相同的效果。</p>
<p>​ 同时，在《An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale》这篇文章中，作者也比较了两者的差别。训练数据越多，Self-Attention最后拟合的效果越好，而CNN在训练数据较少时，效果较好。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115112858420.png" /></p>
<p>​ 此处还有一些Self-Attention用于RNN和Graph领域的内容，由于与我所学习的领域相关性不大，所以就暂且忽略了，感兴趣可以去李宏毅老师的Attention的课程最后找到对应的论文内容。</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Transformer系列笔记</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
        <tag>Self Attention</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN系列笔记6——评估GAN的相关方法指标</title>
    <url>/2021/12/05/59cf77767a4c/</url>
    <content><![CDATA[<h3 id="前言">前言：</h3>
<p>​ 本篇笔记为观看李宏毅老师的GAN相关课程后所记录，文中所有图片及内容均来源于李宏毅老师的课程，此处只是搬运+以自己的理解进行记录。全文讲述了如何对GAN生成的图像结果进行一个更为客观的评估的相关方法。</p>
<h3 id="一传统方法如何评估结果好坏">一、传统方法如何评估结果好坏？</h3>
<p>​ 在传统方法中，我们一般会采用计算<strong>Likelihood</strong>的方法来进行衡量。我们训练出了一个Generator，然后我们就会用生成器的生成分布概率去进行计算其生成真实数据的可能性。具体的执行步骤就是，先采样部分真实数据点，然后计算G想要生成每个真实图像数据点的概率，然后求和平均即可得到Likelihood。但是在GAN中，这种方法是行不通的，因为GAN训练好以后是一个网络，是没法算出其产生出某一张图像的概率的。（像传统，如果这个Generator是一个高斯生成模型，是可以进行计算的）</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105752191.png" /></p>
<h3 id="二kernel-density-estimation">二、Kernel Density Estimation</h3>
<p>​ 有一种解决方案如下：输入一堆数据Data，经过生成器后，会产生对应的一堆高维向量（其实就是图像），我们将每一个高维向量视为一个高斯分布的均值，这样一来每一个sample就被近似为了一个高斯分布。然后我们再将这些高斯分布进行融合，就能够得到一个高斯混合模型。这一高斯混合模型是可以计算形成某个图像的概率的。但是使用这次步骤做出来的也会有许多难点和问题，比如不知道需要用多少高斯分布去拟合，不知道需要采样多少点。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105815158.png" /></p>
<p>​ 同时，退一万步讲，其实使用Likelihood来进行估计就不是一个很严谨的事情，Likelihood低，对应的图像质量也可能高。Likelihood高，对应的图像质量也可能低。如下图所示，就是两种可能的情况。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105822595.png" /></p>
<h3 id="三常用评估方法">三、常用评估方法：</h3>
<p>​ 现在的文献，大部分常常看到的用于评估GAN的方法是，使用一个已经训练好的Classifier（可以是一个VGG，也可以是Inception Net），来判断这个生成器生成的图像质量好坏。</p>
<p>我们往往有以下两个评估原则，如下图所示：</p>
<p>​ <strong>原则1</strong>:将一个generated image输入分类器，查看分类器输出的属于各个类的概率，如果概率比较集中，说明生成器生成的图片效果比较好，因为分类器可以很明确的分出来。</p>
<p>​ <strong>原则2</strong>:将一系列generated image输入分类器，查看分类器输出的各个类各存在几张图像，如果分完类以后每个类别的实例差不多的话，说明生成器效果较好，如果数量偏向于某种类别，说明生成器会生成偏向于某一个类别的图像。所以我们希望分出来的分布能够尽量的平滑。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105839124.png" /></p>
<p>​ 有了上述原则以后，我们就可以使用下图所示的Inception Score来进行指标的量化。其中的第一项代表原则1，第二项代表原则2.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105847271.png" /></p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>GAN系列笔记</category>
      </categories>
      <tags>
        <tag>GAN</tag>
        <tag>GAN Evaluation</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN系列笔记5——GAN应用于特征提取（InfoGAN，VAEGAN，BiGAN）</title>
    <url>/2021/12/04/554e29d255b4/</url>
    <content><![CDATA[<h3 id="前言">前言：</h3>
<p>​ 本篇笔记为观看李宏毅老师的GAN相关课程后所记录，文中所有图片及内容均来源于李宏毅老师的课程，此处只是搬运+以自己的理解进行记录。全文讲述了InfoGAN、VAEGAN、BiGAN，以及GAN在特征提取领域相关的应用。</p>
<h3 id="一infogan">一、InfoGAN</h3>
<p>​ 我们在先前的GAN的介绍中说到过，对于一个训练好的GAN，我们是希望输入一个向量，然后GAN会给我们生成一个Object（图像或者是序列等）。然后我们期望，我们输入的向量，每一个维度可能就会代表输出的图像的某一个特征。这其实是非常理想的情况，但实际上，可能当你改变输入向量某一个维度的值的时候，输出的内容并没有按照某个特征进行变化。如果用图示意的话，如下图所示：两幅图是在低维空间中高维特征的分布示意图，我们本身期望其应该是左图的分布，这样当某个纵轴不变，横轴的数值变化时，高维某个相对应特征也会随之变化，但实际上分布可能像右图一样。InfoGAN就是想要解决这样一个问题。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105527683.png" /></p>
<p>​ InfoGAN的框架如下图所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105540261.png" /></p>
<p>​ 首先会将输入向量z，拆成两部分，一部分是向量c，一部分是向量z’，然后输入G后产生图像x，同时，我们需要训练一个分类器，这个分类器要能从x中识别出，产生这个x所使用的向量c的部分的编码，原本需要训练的判别器也是需要训练的缺一不可。然后我们宏观的看一下这一个架构，Generator和Classifier这一套就像是一个类AutoEncoder的东西，只不过其和正常的AutoEncoder刚好相反。正常的AutoEncoder的编码器是输入图片，输出特征编码向量，然后解码器是再反解回图片。而此处的编码器部分是GAN的Generator部分，输入向量，生成图片，然后decoder部分需要从图片中识别出code。在这个架构中，Discriminator是必须的，不然的话训练Generator的结果很有可能就是会把向量c直接附在图片x的信息中间，这样的话Classifier必定能够反解出c，但是这样的话生成的x是不是一张真实的图片就尚未可知了。有了Discriminator就可以保证生成的x是真实。</p>
<p>​ 同时，Discriminator和Classifier在实际训练时往往共享参数，因为它们的输入都是x，只是最后一层输出层不一样而已。</p>
<p>​ 那么，加上这样一个Classifier以后，为什么先前的原先GAN的输入对输出的影响不明确这个问题就能解决了呢？如下图所示：</p>
<p>​ 因为我们需要分类器能从x中恢复出编码c，所以向量c这一部分必定需要对x的图像的某些维度有明确的影响。也就是说，完成GAN训练以后，c部分的每一个维度，都会对x的图像的某一个特征有明确的影响对应，那么z'部分相对应的可能就是那些较为随机的维度。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105550729.png" /></p>
<p>​ 在这里可能会存在一个疑问，我们怎么划分向量z到c和z’呢？哪些维度应该被划分为c？哪些应该被划分为z’？此处要注意：我们并不是先对z进行手动划分的，是在训练完成之后，那部分能被恢复的向量编码维度，才会被称为c。</p>
<h3 id="二vae-gan">二、VAE GAN</h3>
<p>​ VAE GAN可以看作用GAN强化VAE AutoEncoder。网络架构如下图所示：这样的网络架构完成了两件事，一个是原本的希望重构损失越小越好，另一个是Discriminator会保证Generator生成的图片越真实越好。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105607065.png" /></p>
<p>​ 从VAE角度，因为我们如果只考虑VAE的重建损失，往往产生的图片是不真实的，是会很模糊的。新增了Discriminator可以让输出图像更加真实。</p>
<p>​ 从GAN角度，其不只考虑判别器的反馈，因为其知道真实图片长什么样，需要最小化生成图像和原图的误差，所以VAE GAN训练起来会更加稳定。</p>
<p>​ 如下所示是VAE GAN训练的算法：整体的算法如下所示，在每一轮迭代中，首先是图像的生成：有三类x需要生成：1、第一类x是从数据库中直接采样出来的图片。2、第二类是由数据库中采样出的图片经过Encoder再经过Decoder后重建的图片3、第三类图片是，由随机的概率分布生成的编码z通过Encoder以后产生的图像。（注意图中第10行公式En应为De，图片有误）</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105620194.png" /></p>
<p>​ 然后我们先更新训练EN的参数，希望重建误差越小越好，同时也希望x经过Encoder产生出来的z跟P(z)产生出来的z越接近越好，也就是两者KL散度越小越好。</p>
<p>​ 然后更新训练De的参数，希望重建误差越小越好，同时也希望将第2类和第3类图片，丢入判别器以后，得到的值越大越好。</p>
<p>​ 最后更新训练Discriminator的参数，希望第1类图像进入判别器以后值越大越好，同时也希望将第2类和第3类图片，丢入判别器以后，得到的值越小越好。</p>
<h3 id="三bigan">三、BiGAN</h3>
<p>​ BiGAN的架构如下所示：它修改了传统AutoEncoder的部分，然后新增了判别器。在这个网络中有一个Encoder，输入一张图片x，输出code z。有一个Decoder，输入一个code z，输出一张图片。但是这个输入的code z并不是先前Encoder输出的z，而是从一个事先准备好的分布中取样得到的z。然后我们有一个判别器，输入 向量z和 图像x，要让判别器判断，这一对 （向量z，图像x）是来自于编码器的输入输出，还是来自于解码器的输入输出。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105637394.png" /></p>
<p>​ 训练算法如下所示，整体而言描述和其他的描述语言比较一致，比较好理解，此处就不多赘述，</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105645100.png" /></p>
<p>​ 那么为什么BiGAN能够这样子去进行训练呢？其实BiGAN就是干了一件这样的事情：如果我们把Encoder的输入输出看作是一个Join起来的分布，Decoder的输入输出看作是一个Join起来的分布，那么判别器所干的事情就是区分P和Q之间的分布的差距。想要尽可能的去优化Encoder和Decoder，使得P和Q逐渐变得接近。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105653272.png" /></p>
<p>​ 如果这个模型训练到最优，就应当是Encoder和Decoder可以互相解。那其实你会发现就是做了如下这么一件事情：训练一个AutoEncoder和一个Inverse的AutoEncoder。确实没错，如果如下所示的这样一个网络训练到最优，其和使用BiGAN训练到最优的结果是一样的，但是实际上BiGAN和AutoEncoder都没法训练到最优。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105700505.png" /></p>
<p>​ 所以在不是收敛到最优的情况下，BiGAN会比下面这个架构训练好很多。生成的图片会真实很多，会比AutoEncoder架构生成的图像清晰很多。两者的特性不太一样。举个例子，比如可能用BiGAN，你输入一个鸟的图片，经过Encoder，Decoder后生成的图像也会是一只清晰的真实的鸟，但可能跟输入的鸟不一样，而如果用AutoEncoder架构，输入一个鸟的图片，经过Encoder，Decoder后生成的图像会和原图像比较像，但是会比较模糊，是一个不是很清晰真实的图像。</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>GAN系列笔记</category>
      </categories>
      <tags>
        <tag>GAN</tag>
        <tag>InfoGAN</tag>
        <tag>VAEGAN</tag>
        <tag>BiGAN</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN系列笔记4——GAN训练过程中的一些Tips与改进的GAN网络（含LSGAN、WGAN、EBGAN）</title>
    <url>/2021/12/03/ce02100bd0a0/</url>
    <content><![CDATA[<h3 id="一tips1-有关如何更有效的训练判别器">一、Tips1 有关如何更有效的训练判别器</h3>
<p>​ 在第三份笔记中，我们讲到其实在训练GAN的过程中，我们就是在计算最小化JS divergence的这样一个过程。但是其实JS divergence其实存在一个非常严重的问题，根源在于generation data的分布和real data的分布往往是没有任何重叠的，这个没有任何重叠的问题是由以下两个因素导致的：</p>
<p>1、data本质导致。Data本身，我们认为是一个图像是一个高维空间中的一个点，<span class="math inline">\(P_G\)</span>和<span class="math inline">\(P_{data}\)</span>在这个高维空间中都是属于low-dim manifold。所以基本是不存在重叠的部分的。</p>
<p>2、实际操作的时候，我们是先进行的采样，然后再用discriminator去量他们之间的divergence，而且采样的样例也不会太多。所以离散的采样也会导致，两堆采样的点基本上是不可能重叠的，应该是没有交集的。</p>
<p>​ 那么，为什么当<span class="math inline">\(P_G\)</span>和<span class="math inline">\(P_{data}\)</span>没有重合部分的时候，用JS divergence衡量会出问题呢？精确一点来说，应该是会对你训练时候，造成比较大的障碍。首先我们你需要知道一个事实，有关JS divergence，就是如果两个分布没有任何重合，那么计算出来的JS divergence值就是log2，无论其相距多远。如下图所示，更直观一些：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104959639.png" /></p>
<p>​ 对于这三组数据而言，因为算出来的目标函数都是一样的，所以判别器会认为G0跟G1是一样差的，也就没法把G0更新到G1.这样子的话就会给判别器的训练带来一定的困难</p>
<p>​ 这个问题，其实以一个直观的方法来讲就如下图所示：假设蓝点是generated data，绿色是real data，两组点没有交集，我们现在训练一个判别器（其实就是一个binary classifier）,如果这个判别器训练的太好的话呢，就会导致如下图所示的红色实线的情况，蓝色点上方的区域导数都是零，这就会使的Generator在梯度下降的时候，没法继续下去，generated data也就没法像real data靠近。如果这个判别器训练的不行的话，又很容易导致分辨不出两组data。所以，在原始GAN早期，训练是比较不容易的一件事情。因为你没有办法去分辨，到底什么是训练的太好，什么是训练的不行。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105009691.png" /></p>
<h3 id="二least-square-gan-lsgan">二、Least Square GAN ( LSGAN )</h3>
<p>​ 承接上一段落的内容，为了使得上述描述的梯度为0，最后导致蓝色点不会像绿色点靠近情况出现，所以就出现了LSGAN。它就是将之前Discriminator所作的classifier分类问题，改变成了regression回归问题。从操作上来讲，就是将输出的sigmoid激活函数，变成了linear函数。这样的话，就会使得我们的判别器的得分曲线如下图所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105022595.png" /></p>
<h3 id="三wasserstein-gan-wgan">三、Wasserstein GAN ( WGAN )</h3>
<p>​ 相比于原始的GAN，就是把原来用来衡量的JS divergence换成了Earth Mover’s Distance.</p>
<p>​ 首先我们来介绍一下Earth Mover’s Distance是什么东西，如下所示：下图是一个最简单的示例，我们有两个概率分布P和Q，然后你要想办法把概率分布P移到Q的地方去。如果P和Q如下图所示，都是一个一维空间上的分布，那非常简单，Earth Mover’s Distance就是它们之间的距离d。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105043352.png" /></p>
<p>​ 然后让我们再来考虑一个更为复杂的情形：现在P和Q的概率分布如图所示，那么你会发现我要想把P变成Q，我会有许多种挪动的方式。左边是一种挪动方式，右边是一种挪动方式，每一种挪动方式都会算出一个不同的距离，每一种挪动方式，我们就称之为一种“moving plan”。那么，我们会使用所有的moving plan中计算出最小的那个距离，来将其定义为Earth Mover’s Distance。（通俗一点就是，所有方案算一遍，要最小的那个方案）</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105052710.png" /></p>
<p>​ 比如说，同一堆东西我们用同样的颜色来表示，下图所示的P到Q的挪动方式，就是该示例最佳的一个moving plan。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105101411.png" /></p>
<p>​ 下面这张图是一个更为官方与公式化的定义，我们可以把一个moving plan表示成像左图一样的一个矩阵，对应的交叉的区域就表示该块挪动的量。那么你会发现，左边矩阵中每一行值相加应该都会等于其对应的P的那一条区域的值，每一列值相加起来都会等于其对应的Q的那一条区域的值。所以，给定这样一个moving plan，应该怎么去计算这个方案对应的移动距离呢？就用到下图中B(γ)的公式，遍历所有的xp和xq，其实就是遍历矩阵的每一个值，然后做乘积、求和。</p>
<p>​ 最终，如果我们想要求解P和Q的Earth Mover’s Distance，那么就需要穷举所有的moving plan，然后找到所有B(γ)最小的那一个值,就是P和Q的Earth Mover’s Distance.所以你会发现求解这样一个距离还需要解一个最优化问题.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105115495.png" /></p>
<p>​ OK,到此为止,我们已经知道了Earth Mover’s Distance是怎么样一个东西,那么就先来讨论一下,为什么我们用这个距离来进行衡量?有什么样的好处? 如下图所示,原来的JS Divergence计算出来的,对于G0, G50来说,两个差距一致,生成器就没法从G0 Update到G50,但是如果我们使用W Distance,d50是会比d0好的,那也就是说对于Generator来说,会慢慢的从G0 Update 到G50,也就是之前导致训练不起来的因素会被规避掉.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105125389.png" /></p>
<p>​ 那么在训练过程中,WGAN到底应该如何使用Earth Mover’s Distance呢? 我们将原来的V(G,D)函数替换成如下公式即可:</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105135075.png" /></p>
<p>​ 这个公式其实比较好理解,推导过程非常复杂我们再次略过.就是我们需要让从real data中产生出来的值越大越好,generate 中产生的值越小越好.同时,会有一个额外的constrain,就是D这个函数必须是一个 1-Lipschitz函数,我们暂时先不管这个 名词是什么,只需要先知道,这个代表的就是说D需要是一个非常平滑的函数.从直观的角度,为什么需要增加这个限制呢?如下图所示,如果不增加这个限制,就会像下图所示的红色曲线一样,Discriminator永远都不会收敛,两边分化会越来越大.generated data部分会变成无穷小,real data 就会变得无穷大.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105142990.png" /></p>
<p>​ 那么实际上1-Lipschitz函数是什么呢?定义如下: 右边蓝色函数就不是,而绿色函数就是.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105150180.png" /></p>
<p>​ 那我们应该怎么去进行训练呢? 原始的方法就是使用Weight Clipping 方法,但是其实这个方法并没有完全能够限制住D是一个1-Lipschitz函数,但可以相对来说让你的D变得平滑一些.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105158514.png" /></p>
<p>​ 所以后面就出现了 Improved WGAN ( WGAN-GP )来解决这个问题: 它的作者提出了这样一个观察: 就是说D是一个1-Lipschitz函数是和右侧的不等式等价的，也就是说要对于所有网络可能的输入x来说，如果将它给判别起求它的梯度的Norm范式是小于等于1的话，就可以。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105204998.png" /></p>
<p>​ 那么我们现在的方法，就是在整个的式子后面近似补上一项，</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105211649.png" /></p>
<p>​ 在我们的目标函数中加上这样一项以后，在网络训练的过程中，网络就会希望尽可能的满足下面这个式子，但是问题又来了，我们没办法对所有的x做积分，但是如果想要D是一个1-Lipschitz函数，是需要对所有的x来说的。所以我们又进行了部分的近似：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105219880.png" /></p>
<p>​ 如下所示，将最后补充的那一项变更成如下的一项，意思是我们只从一个叫做<span class="math inline">\(P_{penalty}\)</span>的分布中进行取样，我们只保证从这个分布中取出来的x能够满足，其他的就先不保证了。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105229709.png" /></p>
<p>​ 那么<span class="math inline">\(P_{penalty}\)</span>长什么样子呢？如下图所示，我们从<span class="math inline">\(P_{data}\)</span>中取一个点，从<span class="math inline">\(P_{G}\)</span>中随机取一个点，然后在两点的直线上随机采样一个点。这样子采出得到的点所形成的一个分布我们就认为是<span class="math inline">\(P_{penalty}\)</span>。如图所示，其实就是大概是图中蓝色部分区域。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105307969.png" /></p>
<p>​ 那为什么我们不用考虑整个Image Space空间中的x，只需要考虑<span class="math inline">\(P_{penalty}\)</span>分布上的x了呢？原因其实只是通过实验做出来，这样子效果是好的。其实从直观的角度上也可以有理解，因为我们之前说过其实训练过程就是<span class="math inline">\(P_{G}\)</span>向<span class="math inline">\(P_{data}\)</span>慢慢靠近的这么一个过程，那么也就是说其实只有<span class="math inline">\(P_{penalty}\)</span>这块部分区域的点的梯度才会影响。</p>
<p>​ 同时，我们还要再做一个改进。我们刚才目标函数补充的那一项，将其进一步修改。我们希望训练过程中，梯度越接近1越好。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105332353.png" /></p>
<p>​ 其实在刚才的WGAN-GP的过程中，做了很多的近似，很多结果也是由实验得出的，那么Spectrum Norm提出了一种方法，真的可以限制判别器学习完以后，在每一个位置的Gradient Norm都是可以小于1的。</p>
<p>​ 在最后，我们回到WGAN的算法，看看在实际的过程中，怎么从GAN变成WGAN：整体而言就是修改下图中黑框框的四个部分，1个是在LearningD的过程中，将目标函数部分的sigmoid输出移除掉，同时要记得使用weight cliipping 获得gradient penalty来进行限制。再就是在Learning G的过程中，将目标函数进行部分的修改，就可以了。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105348387.png" /></p>
<h3 id="四energy-based-gan-ebgan">四、Energy-Based GAN ( EBGAN )</h3>
<p>​ 其与原始GAN唯一的不同在于其修改了DIscriminator的架构，Discriminator原本来说是一个Binary Classifier，但是在EBGAN中，将其变成了一个Auto Encoder自动编码器，Generator是跟原来一样的。架构如下图所示：</p>
<p>​ 整一个Discriminator仍旧会输出一个Scalar分数，但现在这个分数是从何而来的呢？他是基于Auto Encoder的重建误差得到的。之所以这样做，EBGAN是基于以下一个假设的：越真实的Image它经过AutoEncoder以后，重建误差越小，越虚假的Image重建误差越大。那么EBGAN的好处在于这个Discriminator是可以预训练的，因为AutoEncoder的训练并不需要用到negative的样例。只需要给positive的样例，然后最小化重建误差就可以了。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105401559.png" /></p>
<p>​ 相比于原来的GAN来说，因为Origin GAN它不能预训练Discriminator，所以一开始DIscriminator就会很弱，训练起来就会很慢。而EBGAN的Discriminator一开始就相对比较强。</p>
<p>​ 在训练EBGAN的时候，需要注意以下一点：以下图为示例，我们会想要让real data最后得到的值比较大，generate data得到的值比较小，但是我们不能让generate data得到的值无限小，不加限制。因为这样的话就会让Discriminator对于generate data的输入而言，其全部输出noise，这样的话既可以把输出分数压的很低。所以我们需要一个margin，让genrate data对应的分数，只要小于margin以下的值就可以，不需要再变得更小。而至于margin的值就是一个我们需要调整的超参数。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115105412942.png" /></p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>GAN系列笔记</category>
      </categories>
      <tags>
        <tag>GAN</tag>
        <tag>LSGAN</tag>
        <tag>WGAN</tag>
        <tag>EBGAN</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN系列笔记3——GAN的数学理论支撑</title>
    <url>/2021/12/02/147dd3a9b3ed/</url>
    <content><![CDATA[<h3 id="前言">前言：</h3>
<p>​ 本篇笔记为观看李宏毅老师的GAN相关课程后所记录，文中所有图片及内容均来源于李宏毅老师的课程，此处只是搬运+以自己的理解进行记录。全文讲述了GAN的理论数学部分的支撑，将直观的GAN训练过程背后的原理，为什么能这么做，训练的时候又需要注意的点是为什么这些内容进行了讲解。</p>
<h3 id="一我们通常说的生成问题从本质上来看是什么呢">一、我们通常说的生成问题，从本质上来看是什么呢？</h3>
<p>​ 从生成一张图片x来说，图片x其实就是在图片高维空间中的一个点。比如说64 * 64的图像，其实质就是64*64维空间中的某一个点。</p>
<h3 id="二gan训练的过程到底是在干什么呢">二、GAN训练的过程到底是在干什么呢？</h3>
<p>​ 在1中，我们发现其实在图像的高维空间中，存在意义的图像的点其实是很稀疏的，那么训练的时候，其实是提供了一堆有意义的图像的高维点，然后想要通过GAN来找到这些点的分布情况，也就是说，找到在图像高维空间中，有意义的图像的点所遵循的分布是怎么样的。这种分布情况，我们人是无法直接找到的。</p>
<p>​ 找到这种分布情况以后，其实生成的过程就是在概率分布中较高概率的位置进行取样，得到的可能就是能够令我们满意的图像。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104004253.png" /></p>
<h3 id="三在gan之前我们的训练所依据的理论是什么">三、在GAN之前，我们的训练所依据的理论是什么？</h3>
<p>​ 使用Maximum Likelihood Estimation 最大似然估计。整体的思想与过程如下图所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104025964.png" /></p>
<p>​ 首先我们有一个数据集分布，也就是我们通常使用的训练集<span class="math inline">\(P_{data}\)</span>。</p>
<p>​ 我们还有一个分布<span class="math inline">\(P_G\)</span>，其是θ的函数，就是我们要训练的用于生成的概率分布。我们的目标其实就是说想要找到一个θ值让<span class="math inline">\(P_G\)</span>去接近<span class="math inline">\(P_{data}\)</span>就可以了。但是怎样量化计算这个概率分布的接近呢？</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104038477.png" /></p>
<p>​ 我们可以先从<span class="math inline">\(P_{data}\)</span>中采集m个样本，然后带入到<span class="math inline">\(P_{G}\)</span>这个概率分布里面，希望得到的对应的概率越大越好。然后我们可以将所有的几率相乘，就会得到L。最终目标就是要找最好的θ使得能够让这个L最大。</p>
<p>​ 其实所谓的Maximum Likelihood 等同于机器学习中的 Minimize KL Divergence.下图的话是数学公式相关的推导过程，</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104119273.png" /></p>
<p>​ 那么现在问题来了，我们怎么去定义一个general 的<span class="math inline">\(P_G\)</span>。如果这个<span class="math inline">\(P_G\)</span>是符合高斯分布或者其他简单分布的话，是没有问题的。但是如果<span class="math inline">\(P_G\)</span>要符合这些分布然后再去拟合<span class="math inline">\(P_{data}\)</span>的话，显然就会受到很多的限制。所以我们需要一个更general的分布来去拟合<span class="math inline">\(P_{data}\)</span>。但是如果<span class="math inline">\(P_{G}\)</span>不受限制，是一个很复杂的很general的分布的话，上述计算式子中<span class="math inline">\(P_{G}(X;\theta)\)</span>这一项就很难计算出来，所以我们才有了下述的想法。</p>
<h3 id="四在gan中我们所依据的理论是什么">四、在GAN中，我们所依据的理论是什么？</h3>
<p>​ GAN中的Generator是一个网络，我们假设输入的是一个符合正态分布的各种采样点，这些点通过G以后，会产生一个新的分布，这个新的分布其实就是<span class="math inline">\(P_G(x)\)</span>。随后我们的目标也是让这个<span class="math inline">\(P_G(x)\)</span>和<span class="math inline">\(P_{data}(x)\)</span>这两个分布越接近越好。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104254669.png" /></p>
<p>​ 从公式来看，就是最小化<span class="math inline">\(P_G\)</span>和<span class="math inline">\(P_{data}\)</span>之间的某一种差异。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104316362.png" /></p>
<p>​ 看到这里，如果我们知道<span class="math inline">\(P_G\)</span>和<span class="math inline">\(P_{data}\)</span>的公式，那么我们是能够很方便的代入Divergence的公式中，然后用类似于梯度下降的方法，去最小化它。但是问题是，我们现在并不知道<span class="math inline">\(P_G\)</span>和<span class="math inline">\(P_{data}\)</span>的公式，也就是根本无法计算这个Div。这就是GAN神奇之处：</p>
<p>虽然我们没法知道<span class="math inline">\(P_G\)</span>和<span class="math inline">\(P_{data}\)</span>的公式，但是我们是可以从中进行采样的。从<span class="math inline">\(P_{data}\)</span>中进行采样无非就是从我们的训练集中取数据出来，从<span class="math inline">\(P_G\)</span>中进行采样，无非就是从正态分布中采样然后丢到Generator中，得到的数据。如下所示</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104340643.png" /></p>
<p>​ 那么其实GAN训练Discriminator的目的，就是为了能够通过Discriminator来计算出<span class="math inline">\(P_G\)</span>和<span class="math inline">\(P_{data}\)</span>的Divergence。从宏观上来看，是怎么完成这样一件事情的呢？</p>
<p>​ 我们前面说过训练的Discriminator在训练过程中，就是要学会给从<span class="math inline">\(P_{data}\)</span>的中采样出的数据高分，给从<span class="math inline">\(P_{G}\)</span>中采样出的数据低分。所以我们当时在训练Discriminator的时候，就写了一个目标函数，V(G,D)来完成上述的目标,然后要训练D的参数，找到一组D的参数使得V(D,G)最大。神奇的事情就是，这个V其实就是J-S Divergence有非常密切的关系。</p>
<p>​ 从直观上讲，如果<span class="math inline">\(P_{data}\)</span>和<span class="math inline">\(P_G\)</span>采样出来的数据靠的很近，那Discriminator自然无法区分，也就是没有办法找到一个D使得V变得很大，这个时候其实意味着就是<span class="math inline">\(P_{data}\)</span>和<span class="math inline">\(P_G\)</span>很接近，也就是说这两个概率分布数据的Divergence其实是很小的。所以如何达到一个最大的V值，会跟这两堆数据的Divergence是肯定存在关系的。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104420420.png" /></p>
<p>以下是详细的推导，证明为什么V会跟Divergence有关系？</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104429437.png" /></p>
<p>​ 我们把积分里的每一项都分开来算，为每一项都找一个最好的D(x)。</p>
<p>【因为D(X)假设可以是任何函数，也就是D(x)的输出可以是任意值】</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104440904.png" /></p>
<p>​ 将这个公式回代到V中，将原来V中的D(x) 用我们得到的结果进行替代：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104448302.png" /></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104454398.png" /></p>
<p>​ 所以推导到此，我们就得出了一个结论，当我们train一个Discriminator的时候，我们让目标函数最大化，让目标函数最大化其实就是让<span class="math inline">\(P_{data}\)</span>和<span class="math inline">\(P_G\)</span>这两个概率分布sample出来的数据之间的J-S Divergence最小。</p>
<p>​ 所以整个问题的逻辑变成了现在这样子：我们本来是要使得<span class="math inline">\(P_G\)</span>和<span class="math inline">\(P_{data}\)</span>的Div最小，现在的话呢，由于我们max V(D,G)和J-S Divergence相关，所以可以用max V(D,G)这一项把原来的Div 这一项替换掉。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104505340.png" /></p>
<p>​ 于是乎就变成了我们要解的问题就是如下图所示的一个式子：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104513342.png" /></p>
<p>​ 从直观上理解，我们可以从下面这个示例上来理解：我们假设现在只有G1，G2，G3这三个生成器可以选，D的横坐标变化我们假设就是选择了不同的Discriminator, V(G1,D)的函数如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104521610.png" /></p>
<p>​ 我们先来以一个实例，来理解一下我们要实现的目标。首先就是当G固定的时候，要找到一个D，使得V(G,D)最大，所以按照我们的示例，可以在选择不同的G的时候，找到三个对应的点，这三个对应的点所对应的横坐标D，就是能够使得，在当前的G下，让V（G,D）最大的那个D。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104529086.png" /></p>
<p>​ 然后我们要找一个G，最小化各种不同的G的最大V(G,D)，按照上图的示例，那么我们就应该选择G3，因为在三个V(G,D)的红点中，V(G3,D)对应的值最低，所以G3才是能够使得各种不同的G的最大V(G,D)最小。</p>
<p>​ 从意义的角度来看，其实如下图所示，V(G,D)中的这个最大值的函数值，其实就是用这个<span class="math inline">\(P_G\)</span>和<span class="math inline">\(P_{data}\)</span>之间的Divergence。这也就很好理解，在这么多的G中，我们要选择那个最小的，来最小化Divergence.</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104536101.png" /></p>
<p>​ 现在的话，就是要找到一个解决方案，怎么样去数学上或者是程序上，求解这个目标。其实这就是我们最开始讲过的迭代的训练GAN的这样一个过程。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104548084.png" /></p>
<p>​ 接下去我们进一步的解释，为什么这样一个迭代训练的过程，就是在解上面提到的一个min max的问题。</p>
<p>​ 为了简化min,max的求解，使得更好理解，我们先不想max V(G,D)里面的事情，我们直接设maxV(G,D) 为 L(G),因为外面那层min是跟D没关系的。</p>
<p>​ 那问题就变成了如下图所示，那其实就很简单，就是用梯度下降去进行优化。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104602866.png" /></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104605809.png" /></p>
<p>​ 所以整体的求解最优化问题的算法应该是像下图一样：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104613127.png" /></p>
<p>​ 其实在这个迭代的过程中，并不是非常准确的在减少JS divergence,因为在求解的过程中，其实G是在一代一代变化的，也就是我们看到的从G0到G1到G2这样子，那么每次G变化以后呢，其实V(G,D)应该都会发生变化。我们说其完成了Decrease js divergence这件事呢，是基于一个默认近似的，就是我们默认D0* 和 D1* 近似相等，也就是说G0和G1之间不会有太大的变化，也就是说G的每一代的更新不会太大。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104624268.png" /></p>
<p>​ <strong>也就是因为有这样一个假设，所以你每一轮迭代训练生成器的时候，不能够update太多次，而在train判别器的时候，理论上应该训练到底，使得判别器达到最优。</strong></p>
<p>​ <strong>然后我们在实际做的时候，如下图所示，我们的目标函数其实和理论的V还有一定的区别，理论的V是期望值，但是实际上不太可能做的到这一点，所以我们其实是用离散的采样来进行代替的。</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104649400.png" /></p>
<p>​ 所以最后回顾一下训练GAN的算法，对于有一些步骤其实可以理解的更为深入。比较重要的其实就是之前提过的，在每一轮迭代中，你其实可以使用梯度下降去更新很多遍的判别器的参数，但是在更新生成器参数的时候，只能更新一次，如果更新的太大了，G0 不约等于G1了，那么你在做的事情也就是不会在minimize js divergence了，就和理论不符合了。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104659145.png" /></p>
<p>​ 最后还有一个需要提及的内容，在原论文中，其实训练Generator的参数的目标函数并不是我们上面所写的，而是会把某一项进行部分的改变如下所示。但其实两种参数都可以进行训练。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115104707603.png" /></p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>GAN系列笔记</category>
      </categories>
      <tags>
        <tag>GAN</tag>
        <tag>Theoretical Basis</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN系列笔记2——常见GAN变种（ConditionalGAN，PatchGAN，CycleGAN等）</title>
    <url>/2021/12/01/85bccde5409d/</url>
    <content><![CDATA[<h3 id="前言">前言：</h3>
<p>​ 本篇笔记为观看李宏毅老师的GAN相关课程后所记录，文中所有图片及内容均来源于李宏毅老师的课程，此处只是搬运+以自己的理解进行记录。全文讲述了一些常见的GAN的变种，以及它们的一些核心的思想，包括Conditional GAN用于Text-To-Image和Image-To-Image的任务，期间有提及一些改进诸如Patch GAN。然后简单讲述了StackGAN的思想以及应用场景。之后，是对非监督学习条件生成领域的一些探讨，这一部分最常见的就是风格迁移的应用。讲述了两大类实现非监督学习条件生成的方法思想，第一类是直接生成，其中介绍了CycleGAN和变体StarGAN。第二类是投射至相同公共空间的方法，其中包含了解决此方法中一个关键问题的各种思想方案。看完本篇笔记，你应当会对Conditinal GAN和Unsupervised Conditional Generation领域及该领域下的CycleGAN思想有一个大概的了解，随后你可以选择感兴趣的GAN网络，再去详细的阅读原论文，研究细节部分。</p>
<h3 id="一conditional-gan">一、Conditional GAN</h3>
<p>​ 条件GAN所要完成的目标就是你可以通过一些限制条件，来让GAN网络生成的图像符合你的要求。比较经典的就是Text-To-Image和Image-To-Image两种任务。</p>
<h4 id="text-to-image任务">1、Text-To-Image任务</h4>
<p>​ 该任务目标是，你输入一段话，然后根据输入的语义来生成一张图片。这样一个任务其实我们可以用传统的监督学习方法来完成它，如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114223140981.png" /></p>
<p>​ 但是使用这种传统的方法，会出现一些问题，比如说，训练网络完成以后你输入文字"train"，而在我们的训练集里面，关于"train"的图片有很多种，比如说一些正面的火车照片，或者是一些侧面的火车照片。最后会导致的结果就是，这个监督学习生成的结果又要像正面的火车，又要像侧面的火车，最后就会变成一个很多图片的平均，也就是会生成一个非常模糊的图像。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114223153376.png" /></p>
<p>​ 所以我们需要用到Conditional GAN的技术。在前一篇文章中讲过，GAN本身最后实现的一个效果是，输入一个随机的分布向量，或者说Noise，然后其会生成一个对象（图片或其他）。那么在Conditional GAN中呢，从最终实现的效果而言，其实就是多吃了一个内容c，这个内容c也就是我们所指定的条件。在Text-To-Image的任务中，内容c也就是我们所指定的文本信息。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114223205025.png" /></p>
<p>​ 那么Discriminator方面，跟普通的GAN又需要有啥区别呢？如下图所示，对于判别器而言，其输入也需要新增一个内容，也就是我们指定的条件c。</p>
<p>​ 我们为什么需要这么干呢？如果判别器仍然和原来一样，那么其实你会发现，因为判别器只会看生成的图片x是否够真实，而不会看x和内容c匹不匹配。也就是说，如果你输入”cat“作为内容c，但是生成器画了一个很好很真实的火车图片，判别器仍然会给高分。这样到最后的结果其实就是，你会发现你指定的条件c和生成出来的图片完全不匹配，虽然这些生成的图片都很真实。</p>
<p>​ Ok，所以我们回到Conditional GAN判别器的架构，最后输出的值里面，其实含有两部分信息的含义。一个是图像x是不是够真实，一个是内容条件c和图像x是否匹配。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114223223659.png" /></p>
<p>​ 所以在这种判定条件下，什么样的情况要给高分呢？什么样的情况要给低分呢？</p>
<p>​ Case1 : x真实 + c 和 x 匹配 【高分】</p>
<p>​ Case2 : x虚假 【低分】</p>
<p>​ Case3 : x真实 + c 和 x 不匹配 【低分】</p>
<p>​ 所以你会发现，相比普通GAN中的判别器，它多了一种要给低分的情况，这个在之后整个的伪代码中会有所体会。伪代码如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114223235243.png" /></p>
<p>​ 整体而言整个过程还是比较好理解的，首先也是从数据库里拿m个正面的样例，然后采样m个noise信号，将这m个信号和生成器生成的数据组合成一组数据。然后再随机的从数据库中取m个图片。注意，这一步目的是取一组真实的图片，但是给这些图片贴上不正确的标签c，后面在目标函数中会有所体现。</p>
<p>​ 整个目标函数有3项，第一项和第二项与GAN类似，也就是刚才上面提到的Case1和Case2。第三项其实就是对应上面提到的Case3，如果向Discriminator中投入ci和随机取的与ci并不匹配的图像，那么判别器也应当给其低分。然后用梯度上升，最大化目标函数即可，这就完成了训练判别器的部分。</p>
<p>​ 在训练生成器的部分，就和GAN几乎一样了，我们就此省略不再细谈。</p>
<p>​ 说完Conditional GAN的整体的训练算法伪代码，再来讨论一下Conditinal GAN 的判别器部分的网络架构应该如何搭建，Conditinal GAN的判别器部分有以下两种常见的网络架构：</p>
<h5 id="架构1最为常见">1、架构1：最为常见</h5>
<p>​ 如下图所示的架构是最为常见的一种架构，先有两个网络，分别将x和c做embedding编码，然后将两个编码输入判别器网络中，其会输出一个分数，就代表我们先前说的x是否真实，或者c和x是否匹配。但是这种架构其实并不能分清楚，到底是因为哪种问题，所以才导致了低分。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115002938439.png" /></p>
<h5 id="架构2有部分论文采用但是也是蛮有道理的一个架构">2、架构2：有部分论文采用，但是也是蛮有道理的一个架构</h5>
<p>​ 此种架构，先把对象x输入一个判别器网络中，然后直接输出一个分数，这个分数代表x是否真实。然后再将条件c和对象x输入另一个判别器网络中，输出一个分数，代表c和x是否匹配。最后再将两个分数综合起来，得到最终判别器的分数。这样子的话，我们就可以知道，到底导致低分是什么原因。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115002950662.png" /></p>
<h4 id="image-to-image-任务">2、Image-To-Image 任务</h4>
<p>​ 和这个任务相关的一篇论文其实是非常经典的一篇论文，CVPR 2017的《Image-to-Image Translation with Conditional Adversarial NetWorks》，有兴趣也可以去阅读原论文。下图是原论文中的一些应用的截图：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003023803.png" /></p>
<p>​ 和先前的Text-To-Image的任务一样，如果采用传统的监督学习的方法，很有可能产生的图像会非常模糊，所以就需要Conditional GAN来完成。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003031956.png" /></p>
<p>​ 如下所示就是使用Conditional GAN的生成器和判别器的一个示意结果图，其实跟Text-To-Image是一样的，此处就不多赘述了。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003040918.png" /></p>
<p>​ 但是其实以这种方法生成出来的图片，也会存在一些小的问题，参见之后的第二幅图。就是比如说它可能会在图像的某些地方产生奇奇怪怪的内容。你可以仔细观察GAN生成图像的左上角，出现了奇怪的内容。这是由于什么产生的呢？就是Generator其实只关心一个是我产生出来的图像好不好，另一个是和输入图像是不是匹配，但不太会关心一个点：就是说和产生的图片和原来的有监督学习中的目标图像是不是相似。</p>
<p>​ 所以，我们往往会加上一个额外的限制，就是我们希望Generator生成的图片和原来的图像越接近越好，也就是说既考虑了原来监督学习中的as close as possible，也考虑了GAN的评分机制。如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003054587.png" /></p>
<p>​ 下面这个就是上面所讲的三种方法不同的生成效果示意图</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003103515.png" /></p>
<p>​ 同时，在《Image-to-Image Translation with Conditional Adversarial NetWorks》这篇论文中，它的Discriminator经过了一些额外的设计。这就是其引入的Patch GAN。Patch GAN解决了一件什么事情呢？</p>
<p>​ 如果你要用Conditional GAN产生的图片非常的大，很有可能产生的结果会很差。原因是什么呢？如果图片很大，代表其展开后维度非常的高，那就需要有非常多的参数去训练它，参数一旦非常多，训练以后很容易导致过拟合的情况发生。所以，作者提出了PatchGAN的想法，如下图所示，左边是传统的Discriminator，右边是PatchGAN的。</p>
<p>​ PatchGAN的Discriminator并不是直接检查整张图像，而是只检查一个小窗口内的图像。得出一个分数。然后再综合所有窗口得出的分数。至于检查的小窗口的尺寸为多大，是一个需要调整的超参数，原论文中也对其有一定的分析，此处不多赘述。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003123825.png" /></p>
<h3 id="二stack-gan">二、Stack GAN</h3>
<p>​ StackGAN来源于这篇论文：ICCV2017《StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks》。简单而言，其只是将Conditional GAN的生成分成了好几个阶段，用于能够生成分辨率更高的图片。这是原论文中所显示的流程图</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003145750.png" /></p>
<p>​ 简单而言，步骤如下，首先输入一段文本描述，通过Embedding嵌入层后，经过一系列的Conditioning Augmentation的处理，将各种信息连接在一起，然后在生成器部分，首先生成第一阶段的结果图片。然后在输入到第一阶段的判别器中。当第一阶段的生成器和判别器完成训练以后，我们再将第一阶段的生成结果，与描述文本作为输入，开始训练第二阶段的GAN网络。步骤与第一阶段的GAN网络类似，最终可以得到更高分辨率的第二阶段的结果图像。具体细节部分，我暂时也没有完整的阅读过原论文，暂且只是领会一下这种方法的大致思路。</p>
<h3 id="三unsupervised-conditional-generation">三、Unsupervised Conditional Generation</h3>
<p>​ 非监督的条件生成，通常用于风格迁移。在风格迁移的应用场景中，我们往往能够收集到许多Domain X的信息，也能收集到许多Domain Y的信息，但是不一定能够拥有Domian X和Domain Y的一一对应的pair 数据。像类似这样子的场景中，非监督的条件生成就是一个非常好的解决方案。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003209328.png" /></p>
<p>​ 非监督的条件生成，我们往往会有两种方法思路去完成，如下所示：</p>
<p>​ 方法1是Direct Transformation 直接转换，此种直接通过一个生成器进行转换的方法，往往两个域内的图像不能够有太过巨大的差距，通常用于做纹理或者颜色上的一些改变，以达到风格的变化。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003225024.png" /></p>
<p>​ 方法2是Projection to Common Space 投射到公共空间，此种方法通过将两个Domain投射到一个公共空间中，完成转换。具体而言，对于下述的任务来说，先将DomainX真实人脸的信息通过一个Domain X的编码器转换到公共空间，也就是我们的脸部属性空间，然后再将脸部属性空间，通过一个Domain Y的解码器，解码出我们的DomainY动漫人脸的信息。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003237748.png" /></p>
<p>接下去我们会对两种方法进行详细的讨论：</p>
<h4 id="direct-transformation内含cyclegan网络讲解"><strong>1、Direct Transformation（内含CycleGAN网络讲解）</strong></h4>
<p>​ 我们要训练一个生成器，能够完成将图片从DomainX直接转换至DomainY的任务，但是该生成器产生的图片我们怎么去评价呢？在有监督学习中，我们有一对一的数据，但是在无监督学习中，对于这个输入而言，我们并没有pair可以提供给它。所以此时，我们需要一个Discriminator，这个判别器用于判断一个图片，是否属于DomainY，然后输出一个分数。</p>
<p>​ 那么这样一来，Generator的目标就是如何将DomainX的图片转换成一个新的图片，能够骗过Discriminator，而Discriminator也要努力鉴别这个图像到底是不是属于DomainY。下图，就是整个过程的一个直观的示意图。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003304210.png" /></p>
<p>​ 在这样一个过程中，好像问题已经解决了，实则不然。你会发现，生成器只学会了怎么生成一个DomainY的图片去骗过判别器，但是我们并没有给它限制，说要让这个生成器生成的DomainY的图片和原来的DomainX的图片要相似啊。那万一，输入是一张DomainX的风景图，生成器输出了一张DomainY的人像图，不照样能够获得很高的分数，这当然就不对啦。</p>
<p>​ 所以，我们就希望生成器生成的DomainY的输出，应该和DomainX的输入应当会存在一定的关系才对，而不是毫无关系可言。针对于这个问题而言，有许多解决方案，叙述如下，其中最著名的就是熟知的cycleGAN。</p>
<h5 id="解决方案1不管这个问题">1）解决方案1：不管这个问题</h5>
<p>​ 听上去这个解决方案非常的扯淡，但其实在某种条件下它确实work。具体而言是什么意思呢？当我们的网络层数不是很深的时候，其实网络本身也倾向于不对input做太大的改变，有人也做过实验，不去管这个问题，在某些情况下也不会得到太差的结果，得到的结果和input其实也类似。</p>
<p>​ 但是，如果我们的网络比较深的话，经过非常多的非线性变换与线性变换，其实就并不好说，最后输出的output，会和input相差不大了。这个时候的话，我们可能就需要其他的解决方案。</p>
<h5 id="解决方案2利用预训练的编码器网络如下图所示">2）解决方案2：利用预训练的编码器网络，如下图所示：</h5>
<p>​ 我们利用两个预训练好的DomainX和DomainY的编码器网络，在GAN训练的时候呢，生成器训练的目标任务又多了一项。之前生成器只需要生成图片，努力的去骗过Discriminator就可以，也就是说只要生成的图片越来越像DomainY的图片就可以，但是我现在希望生成器生成的图片，经过DomainY预训练的编码器网络后，生成的特征向量A，和原图经过DomainX预训练的编码器网络后生成的特征向量B，也尽可能地相似。这样一来，你会发现，如果两个编码后的内容越接近越好的话，DomainX在转换至DomainY的时候，产生的图片，应该是保留了原来DomainX图片的某些特征的。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003341802.png" /></p>
<h5 id="解决方案3cyclegan">3）解决方案3：CycleGAN</h5>
<p>​ 原论文题目为《Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks》，有兴趣的同学可以看原论文，其主要大致思想如下图所示：</p>
<p>​ 我们不仅训练一个DomainX到DomainY的生成器，同时也训练一个DomainY到DomainX的生成器，生成器X-&gt;Y在原有的需要骗过Dy的基础上，还需要使得原始输入图像和经过两个生成器后产生的图像越接近越好，这也就是我们常说的Cycle consistency，循环一致性。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003358128.png" /></p>
<p>​ 对于CycleGAN来说，我们可以训练双向的一个网络，两个一起去做训练。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003406257.png" /></p>
<p>​ 其实CycleGAN也存在一些问题，在论文《CycleGAN, a Master of Steganography》中，其作者提到，在DomianX的输入图像经过两个生成器的过程中，出现问题。具体而言，输入的图像的有些信息会在经过第一个生成器的时候被隐藏起来，此处的被隐藏起来也就是指人肉眼观察不到，而当其经过第二个生成器的时候，又会被还原出来。如下图红色方框中所示。这就意味着，生成器网络有隐藏信息的能力，我们如果只控制input和经过两个生成器的output的一致性，中间产生的我们真正要的图像还是有可能丢失原图的部分信息。这是一个尚待研究的问题。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003414078.png" /></p>
<p>​ 此处的话补充一下另外一个网络，是在CycleGAN的基础上进行的一个升级，叫做StarGAN。其应用领域在于，当你需要多个Domain的信息风格互相转换的时候，怎么进行网络的学习与处理。</p>
<p>​ 按照之前CycleGAN的思路，如果我们想要在4个Domain内做互相转换，需要在两两之间训练一组生成器。StarGAN就是可以之训练一个生成器，就完成在多个Domain之间的信息互相转换。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003422218.png" /></p>
<p>​ 原论文为《StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation》，其主要思想及训练过程如下：</p>
<ul>
<li><p>A)步骤，首先训练判别器，判别器会完成两件事，一是要判别这个图像他是真实的还是虚假的，二是要做一个分类的问题，它是属于哪一个Domain，给出两个结果。</p></li>
<li><p>B)C)步骤, 在训练生成器时，要完成这样一个任务。首先输入我们的输入图片，以及目标Domain，然后生成器会生成一个Fake Image，我们将这个Fake Image和原来的Domain作为输入，再次送入生成器中，会得到一张Reconstructed Image，我们希望这张重建的图像和输入的图像之间的差距越小越好，其实这就是Cycle Consistency类似的思想。</p></li>
</ul>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003432585.png" /></p>
<ul>
<li><ol start="4" type="A">
<li>步骤，同时在训练生成器的时候，还有一个目标，就是要让这个Fake Image骗过我们之前训练好的Discriminator，使得Discriminator的输出越大越好。</li>
</ol></li>
</ul>
<p>​ 下图是一个训练应用实例的示意图，在StarGAN的实际训练过程中，其实域可以是由一组编码决定的。就比如说00101代表一个域，10011也代表一个域。然后00101有一个参照表，也就是label，代表相对的含义。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003446510.png" /></p>
<h4 id="projection-to-common-space">2、Projection to Common Space</h4>
<p>​ 在此类方法，如果我们想要完成DomainX和DomainY两种风格的互相转换，我们其实需要的就是如下图所示的2个Encoder和2个Decoder。例如，如果要从X转换至Y，那么图像应当先通过EncoderX，得到一个Face Attribute，应该是一个Latent Vector，然后再经过DecoderY，最终得到DomainY的图像。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003534380.png" /></p>
<p>​ 这样来看，如果我们拥有一对一的pair数据，那么其实完成这个任务非常的容易，只需要正常的监督学习训练即可。但是我们现在是无监督场景下的训练，应当如何完成训练呢？</p>
<p>​ 我们可以像下图所示这样进行训练，其实就是训练了两个自动编码器，通过最小化重建误差来进行优化。然后在此基础上我们可以加两个判别器。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003544456.png" /></p>
<p>​ 如此而言，我们确实可以得到2个Encoder和2个Decoder。但是这两组AutoEncoder（VAEGAN）是完全没有关系的。这意味着什么呢？你看上图中，中间的这个Latent vector，两边共用一个，其实来说，两边训练出来以后，得到的中间的这个特征向量，每一个维度所代表的含义会是完全不同的。其实就变成了如下图所示的这样子一个效果。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003552083.png" /></p>
<p>​ 所以最终导致的结果就是：你将一个DomainX的图片丢入X编码器，得到一个向量，然后将向量丢入Y解码器，可能生成的是一个完全不相关的DomainY的图片。</p>
<p>​ 接下来我们就是要解决这个问题，也会有比较多的文献解决方案：</p>
<h5 id="解决方案1共用部分隐藏层参数">1）解决方案1：共用部分隐藏层参数</h5>
<p>​ 共用EncoderX和EncoderY的后面几层，同时也共用DecoderX和DecoderY的前面几层。这样子做其实就是希望，接近中间这个特征向量的层共用参数以后，两边的编码能够在中间的特征向量的维度上达成一致。</p>
<p>​ 这种解决方案比较极端的情况时，可以让EncoderX和EncoderY共用所有参数，DecoderX和DecoderY共用所有参数，只是在训练和使用的时候，我输入一个标签，代表这个是X Domain还是Y Domain。这个方法用于CoupleGAN和UNIT</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003616483.png" /></p>
<h5 id="解决方案2domain-discriminator">2）解决方案2：Domain Discriminator</h5>
<p>​ 我们在网络架构中，新增一个Domain Discriminator。在训练的过程中，EncoderX和EncoderY还有一个任务，就是说他们所生成的中间的特征向量，还要能骗过Domain Discriminator，让这个判别器无法鉴别，这个特征向量到底是从EncoderX来的，还是从EncoderY来的。如此一来，完成训练后，相当于说是两个编码器产生的中间的特征向量应该遵循着类似的分布，能够在中间的特征向量的维度表示上达成一致。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003651260.png" /></p>
<h5 id="解决方案3利用cycle-consistency的类似思想">3）解决方案3：利用Cycle Consistency的类似思想</h5>
<p>​ 如图红线路径所示，图像经过EncoderX，产生特征向量，经过DecoderY产生Image，再将这个Image作为输入进入EncoderY，产生特征向量，经过DecoderX产生output，然后最小化input和output的重建误差即可。该方法被用于ComboGAN。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003717264.png" /></p>
<h5 id="解决方案4利用semantic-consistency的类似思想">4）解决方案4：利用Semantic Consistency的类似思想</h5>
<p>​ 按照图中红线路径，input输入经过EncoderX，产生特征向量A，经过DecoderY产生Image，再将这个Image作为输入进入EncoderY，产生特征向量B。然后最小化A和B的差别即可。相比于CycleConsistency，此种思想直接在特征向量的空间中去考虑相似度，避免了比如说可能input和output表象上很像，但其实中间特征向量代表维度仍然不同这种问题。该种思想在DTN和XGAN网络中使用。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220115003743216.png" /></p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>GAN系列笔记</category>
      </categories>
      <tags>
        <tag>GAN</tag>
        <tag>ConditionalGAN</tag>
        <tag>PatchGAN</tag>
        <tag>CycleGAN</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN系列笔记1——GAN的基本理念与思想</title>
    <url>/2021/11/30/9fbfb5044884/</url>
    <content><![CDATA[<h3 id="前言">前言：</h3>
<p>​ 本篇笔记为观看李宏毅老师的GAN相关课程后所记录，文中所有图片及内容均来源于李宏毅老师的课程，此处只是搬运+以自己的理解进行记录。全文按照李宏毅老师讲课的逻辑进行记录，先从GAN的基本理论概念讲起，中间提及了Structure Learning的问题，然后回答了GAN中的两个经典的问题，然后对VAE和GAN的结果做了简单的比较，最后做了总结，看完以后应该会对GAN有一个完整的概念与理解。全文共4800字左右。</p>
<h3 id="一basic-idea-基本概念">一、Basic Idea 基本概念</h3>
<p>​ GAN是完成了一个Generation的任务，从目标上而言，其实就是我们要训练一个NN的generator，这个generator可以完成下述任务：你给机器一个随机的向量，机器就可以给你输出你想要的物体（可以是图像也可以是其他）。（当然，这种类型的generator看上去是没什么用的，因为你不知道随机向量到底会生成什么样子的东西，但通常向量的每个维度可能就是用于控制输出图像的一个特征部分，现在暂时我们只专注于完成这样一个随机的任务部分）。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114214941737.png" /></p>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114214945273.png" alt="image-20220114214945273" /><figcaption aria-hidden="true">image-20220114214945273</figcaption>
</figure>
<figure>
<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114214948402.png" alt="image-20220114214948402" /><figcaption aria-hidden="true">image-20220114214948402</figcaption>
</figure>
<p>​ GAN比较神奇的点在于其还会同时训练一个Discriminator，即判别器。从目标上而言，其要完成如下任务:输入一个图像，输出一个值，这个值越大，代表图像越真实。值越小，代表图像越虚假。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114214959500.png" /></p>
<p>​ 那么在GAN中，Generator和Discriminator的关系其实就是对抗竞争，或者说互相帮助互相进步的关系。如下图所示：第一代的生成器生成的东西，交给第一代判别器。第一代生成器在第一代判别器的反馈下，进化为第二代的生成器，然后判别器也随之进化为第二代，循环往复下去（有一种道高一尺，魔高一丈的感觉）</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215010569.png" /></p>
<p>​ 一个更好的比方，下图中，Generator和Discriminator就像是学生和老师在对话一样，在这个过程中，学生逐渐进步。老师的要求标准也越来越高。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215031820.png" /></p>
<p>​ 在这样一个过程中，留下两个疑问：Generator做生成为什么不自己学提高水平呢？Discriminator这么会批评，为什么不自己做生成呢？【解释与回答见第四章】</p>
<p>​ 现在我们先来讨论一下整个训练的算法伪代码过程，如下所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215049291.png" /></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215052840.png" /></p>
<p>​ 首先我们初始化生成器和判别器，然后在每一个训练迭代阶段，进行两件事：</p>
<p>​ 1、我们将Generator固定住，训练Discriminator的参数。具体而言，我们首先随机的输入一些向量，通过G生成一些随机的generated objects，然后再从真实数据库中取出一些objects，将这两部分图片作为D的输入，来训练D。目的是要让D看到generated objects 就给出尽可能接近0的分数，让D看到真实的objects就给出尽可能接近1的分数。(其实就是给两部分图片打个标，然后训练一个分类器，如上图所示)</p>
<p>​ 2、固定住Discriminator的参数，调整生成器的参数。具体而言就是：将一个随机的vector丢入生成器里，生成一张图片，将图片放入判别器中，得到一个分数，我们训练此步的目标是要使最后输出的那个分数越接近1越好。从代码上，这个要怎么进行操作呢？我们往往会将生成器的NN和判别器的NN合并成一个大的网络，锁住判别器部分层的参数，这相当于这个大的网络中间有一层很宽的隐藏层（就是输出图片那一层），然后我们要使得最后生成的结果越大越好，就是Gradient Ascent，其实就是在Objective Function上加一个负号，就可以完成这个任务。</p>
<p>​ 下述是更为正式的算法伪代码：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215114053.png" /></p>
<p>要注意，在这个算法中，有一些超参数是需要手工去调整以找到最佳效果的：</p>
<p>​ 1、输入的向量的维度，5维、10维、……</p>
<p>​ 2、在每一个迭代过程中：更新判别器的次数，可以是1~n次。</p>
<p><strong>算法中的一些解释：</strong></p>
<p>​ 1、更新判别器参数的时候的Objective Function：</p>
<p>​ 第一项：<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215147446.png" />代表真实数据集的图像进到判别器中的分数均值。</p>
<p>​ 第二项：<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215201515.png" />代表生成的图像进到判别器中的分数被1减去后的均值。</p>
<p>​ 我们要让这个目标函数最大，其实就是完成了最开始说的，真实数据集图像进到判别器中，分数越接近1越好，生成图像进入，分数越接近0越好。</p>
<p>​ 2、更新生成器参数的时候的Objective Function：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215238651.png" /></p>
<p>​ 其实就是随机向量通过生成器，再通过判别器后，得到的均值越大越好。然后用梯度上升方法，去最大化这个目标函数。</p>
<h3 id="二structure-learning">二、Structure Learning</h3>
<p>​ 首先，什么是Structure Learning？机器学习本身其实就是找到一个函数f，去完成X-&gt;Y这样一件事情。回归问题，其实就是输出一个分数。分类问题就是输出一个类别，结构化学习其实就是输出一个更复杂的比如说一个序列，一个矩阵，一个图，一个树等等这样的问题。往往这种复杂的结构是由很多个组件组成，并且这些组件之间是有关联关系的。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215309664.png" /></p>
<p>​ 为什么Structure Learning是很Challenging的呢？其实就是如下图所说的，一个的话是它可以被视为One-shot Learning或者是Zero-shot Learning。那什么是One-Shot Learning 或者说Zero-shot Learning呢？例如，在分类作业中，我们如果需要训练，每个类别都需要给出一系列的数据范例。而One-Shot Learning 或者Zero-shot Learning就是指，可能有些类别完全没有范例，或者说只有很少的范例。</p>
<p>​ Structure Learning里面，输出的是一个结构体，也就是说很有可能训练的句子里面是完全不会有重复的东西的。如果我们把所有的可能输出都视为一个类的话，输出的空间是很巨大的。并且大多数的类都是没有任何训练数据的。所以机器需要一定的创造性。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215320786.png" /></p>
<p>​ 第二点的话，在Structure Learning中，机器必须学会规划。机器可以一个个组件的去产生，但是它一定要学会组件和组件之间的关系与限制。需要全局的去进行考虑。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215331213.png" /></p>
<h3 id="三structure-learning的一些解决方案">三、Structure Learning的一些解决方案</h3>
<p>​ 在传统的方法分类中，其实有两类：一类是Bottom Up的方法，一类是Top Down的方法。自底而上的方法主要是学习怎么去生成Component，然后再进行合并，这个很像Generator做的事情，但是这样很容易失去大局观。自上而下的方法是学会评估一个物体，然后找到最好的那个，这个很像Discriminator做的事情，但是这样做的问题是很难做生成。【为什么这么说见第四章】其实GAN就是解决Structure Learning的一个解决方案，他就像是把两种方法做了结合。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215356504.png" /></p>
<h3 id="四为什么generator不能自己学为什么discriminator不能自己生成">四、为什么Generator不能自己学？为什么Discriminator不能自己生成？</h3>
<h4 id="generator为什么不能自己学">1、Generator为什么不能自己学？</h4>
<p>​ 在传统的有监督学习中，我们只要有大量的真实图片数据，以及他们对应的标签，我就可以完成生成图片这样一个任务。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215423815.png" /></p>
<p>​ 但是问题就来了，我们怎么给这些真实图片数据打标签呢？如果是随机赋给他们一些向量标签，那最后的训练是会很困难的。因为比如说我们看两个1的图片比较相似，当然希望向量中有一部分的标签内容是类似的，而不是说这两个1的图片对应的向量标签完全不一致。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215433669.png" /></p>
<p>​ 也就是说，我们总是希望这个input和output的内容是存在一些联系的，而不是毫无联系。说到这里，其实问题还是可以解决的，怎么去解决这个编码问题呢？</p>
<p>​ 正巧，我的上一篇文章中讲了各种自动编码器的相关知识，这个编码问题，我们可以训练一个NN编码器来进行解决。这个编码器完成一件什么事呢？给它一个图片，它输出一个向量，来表示这个图片的相关特征。具体而言，自动编码器怎么进行训练，详见自动编码器的文章，如下：这里的话也给一张李宏毅老师课程的截图示意：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215447872.png" /></p>
<p>​ 仔细想来，其实这个Decoder干的是不是就是Generator的事情？是的！因为它也是接收一个Vector向量，输出一张图片，如下图所示：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215456226.png" /></p>
<p>​ 这样看来，其实理论上来讲，只要我们训练好了一个自动编码器，把Decoder部分拿出来，就是一个生成器。然后我们随便给一个向量，他就会输出一个对应的图像。</p>
<p>​ 但是Auto-Encoder存在什么样的问题呢？如下图所示：比如说，我们已知a向量可以产生一个图片，b向量可以产生一个图片，那么0.5<em>a+0.5</em>b会产生什么呢？很有可能会产生Noise，因为这样的生成器本身是一个神经网络，不是线性的。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215508501.png" /></p>
<p>​ 说到这里，其实还没有正面回答Generator为什么不能自己学这个问题，但大家不要着急。我们继续说，这个问题其实我们可以用VAE来解决，也就是上篇文章末尾重点讲过的变分自动编码器。</p>
<p>​ 如下图所示：有了变分编码器，因为变分自动编码器是对一个概率分布进行了编码，而不是固定的。所以我们能够将这个decoder训练的更为稳定。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215517660.png" /></p>
<p>​ 那么，现在看来，好像Auto-Encoder就能解决Structure Learning这样一个任务了，那为什么我们还需要GAN这个技术呢？接下去要说的就是Auto-Encoder这套技术所缺少的内容。</p>
<p>​ 在Auto-Encoder的技术中，我们实现的目标是：让生成的图片和目标图像越像越好。那么问题来了，什么叫越像越好？正常来说，我们就是把这个图像展开成一个vector，然后逐像素的计算距离差。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215528542.png" /></p>
<p>​ 我们先前说过，自动编码器是不能让它完整的保留所有的信息的，不然就失去了编码的意义，机器只要学习复制就可以了。所以自动编码器的生成器部分，生成的目标总是和源图像会有一些差距，会有一些取舍。这个时候，取舍在哪里就很重要！如下图所示：右上角是目标图像，下面四个是生成的图像。生成图像第一排，只偏差了1个像素，第二排，偏差了6个像素。从计算相似度而言，第一排优于第二排，但是从人的感知而言，第二排优于第一排。所以我们如果只是单纯的计算距离差，让两者越像越好，就有可能会产生第一排的结果。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215538491.png" /></p>
<p>​ 在做Structure Learning的过程中，我们说过组件和组件之间的关系是很重要的，需要考虑全局观念。这个偏差出来的多的像素本身没有错误，有错的是它如果是有像素值的，那么它周边的组件，也应当是有填充的，而不是空白的。这个像素要和周围的像素一致，这个其实就是组件和组件的一种关联。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215546546.png" /></p>
<p>​ 但是我们训练一个生成器的时候，当我们训练一个网络的时候，是很难把组件和组件的关系放进去的。因为在NN网络这个架构里面，如果前一层的权重都已经确定了，最后的输出之间是独立的。每个输出神经元之间没法互相进行配合。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215603961.png" /></p>
<p>​ 其实像这种也可以解决，只不过需要更深的网络结构。更深的网络结构能够帮助你把这种组件与组件之间的相关性考虑进去。所以，如果有一个GAN网络，一个Auto-Encoder网络，要完成一个目标，往往Auto-Encoder的网络需要更深，才能达到和GAN类似的效果。</p>
<p>​ 其实讲到这里，都没有明确的回答Generator为什么不能自己学这个问题，但是其实已经回答掉了。因为我们刚才讲的，Auto-Encoder就是训练了一个单的Generator，是抛弃了Discriminator的一个架构。如果这样子让Generator自己学，当然可以，只不过会存在上述所说的种种问题和难处。</p>
<h4 id="discriminator为什么不能自己产生image">2、Discriminator为什么不能自己产生Image？</h4>
<p>​ Discriminator总的来说干了一件什么事呢？它其实就是输入一个对象，输出一个分数，这个分数表示这个对象多好或多差，进行评估。对于Discriminator来说，它要考虑组件和组件之间的关系就很容易了，因为他是看到整个图片的。</p>
<p>​ 那么我们其实是可以用Discriminator来产生Image的，只不过会非常的卡，非常的慢，为什么这么说呢，我们先看，如果硬要用Discriminator来产生Image，步骤应该是怎样的：</p>
<p>​ 假设我们已经训练好了一个好的判别器，那么我们只需要执行如下公式即可：</p>
<p>​ 穷举所有的x，然后一个个丢到判别器里，让它看是不是高分。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215739478.png" /></p>
<p>​ 虽然这看上去不是很合理，对于穷举而言。但是这其实并不是关键所在。我们现在先假设这个方法确实可行，那难道就可以了吗？别忘了，我们先前的假设：“假设我们已经训练好了一个好的判别器”，那么我们怎么训练这个判别器呢？这才是问题的关键！</p>
<p>​ 理论上讲很简单，我给他好的样例，让他输出高分，烂的样例，让他输出低分。但是实际上呢，我们手上只有好的样例。如果只有这样的训练实例，会导致网络看到啥都给高分。所以，怎么去产生不好的样例，产生怎样不好的样例，就是一个很关键的问题：</p>
<p>​ 如果不好的样例就只是一些噪音，那其实机器很容易会给一些尚可的模糊的图片打高分，这并不是我们希望看到的。如下图所示。所以<strong>只有差的样例足够的好，才能让机器真正的学会评判好的图片和坏的图片</strong>，</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215749015.png" /></p>
<p>​ 所以现在如何生成足够好的 差的样例就很重要，那么我们就需要一个生成差的样例的过程，在没有Generator的前提下，这就是一个鸡生蛋蛋生鸡的循环问题了。所以如果真的想要完成这件事情，只能通过一个迭代的形式去完成：</p>
<p>​ 我先学一个最差的Discriminator出来，然后用这个去做生成，生成出来的样例用来训练更好的Discriminator，循环往复。你会发现这个过程好像跟GAN差不多，但是如果没有generator，要比GAN累好多，慢很多。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215808954.png" /></p>
<p>​ 这时候再来看如果我们把Generator加上，GAN就是利用Generator来求解这个argmax的问题，用于生成一些负面的样例。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215815222.png" /></p>
<h3 id="五比较vae和gan的结果">五、比较VAE和GAN的结果：</h3>
<p>​ 下图是各个GAN和VAE在不同参数下，所表现出来的性能分数的值的区间。还附带了一个VAE和GAN生成人物头像的直观结果。</p>
<p>1、VAE比较稳定，给它不同的参数，所表现出来的性能相差不大。</p>
<p>2、GAN相对而言比较吃参数，但是只要参数正确，所生成的最好结果也是远远优于VAE产生的结果的。<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/2222sdsa.png" /></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114215842339.png" /></p>
<h3 id="六总结">六、总结</h3>
<p>1）生成器：</p>
<p>​ 优势：很快就能生成一个东西</p>
<p>​ 劣势：很难察觉组件和组件之间的关系，只是模仿一个表象</p>
<p>2）判别器：</p>
<p>​ 优势：可以考虑大局观</p>
<p>​ 劣势：生成一个东西非常的困难</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114222543440.png" /></p>
<p>3）GAN的优势：</p>
<p>1、从判别器的角度而言，使用Generator来进行negative example的生成，更为高效。</p>
<p>2、从生成器的角度而言，它虽然仍然是一个组件一个组件的生成对象，但是相比传统的计算L1,L2的损失而言，它会从Discriminator那边得到全局视野的反馈，更能理解组件与组件之间的关系。</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>GAN系列笔记</category>
      </categories>
      <tags>
        <tag>GAN</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记2——数据表征与自动编码器</title>
    <url>/2021/11/24/379e9f408368/</url>
    <content><![CDATA[<h2 id="数据表征与自动编码器">数据表征与自动编码器</h2>
<h3 id="前言">前言：</h3>
<p>​ 本文简单讲解了数据表征与自动编码器的相关知识，主要来说涵盖数据表征的概念与理解，简单自动编码器的组成，堆叠式自动编码器的组成与训练方法，卷积、循环、去噪、稀疏自动编码器的简单介绍，以及变分自动编码器较为详细的概念与一个有趣的应用。</p>
<h3 id="什么是数据表征">1、什么是数据表征？</h3>
<p>以下是两组数字顺序：</p>
<p>​ 40，27，25，36，81，57，10，73</p>
<p>​ 1，2，3，4，5，6，7，8，9，10，11，12，13，14，15，16，17</p>
<p>​ 简单来看，第一行的数据更少，信息量更小，但是其实第二行的数据具有很好的递增特征，反而更容易进行记忆。数据中的类似于这种的模式被我们称为数据表征。模式可以更好的帮助我们有效的存储信息。</p>
<h3 id="一个简单自动编码器的组成">2、一个简单自动编码器的组成</h3>
<p>​ 自动编码器由两部分组成：将输入转换为潜在表征的编码器（识别网络），以及将内部表征转换为输出的解码器（生成网络）。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114205901462.png" alt="image-20220114205901462" style="zoom:150%;" /></p>
<p>​ 上述示例就是一个由3个神经元组成的隐藏层（编码器），以及由6个神经元组成的输出层（解码器）。输出又通常称为重构，自动编码器会试图重构输入，且成本函数包含一个重构损失，重构和输入不一致的时候会进行惩罚。</p>
<p>​ 注意：自动编码器的输出数量应等于输入数量。同时，自动编码器本身其实是一个在学习数据潜在表征，然后再由表征还原数据的一个过程。它通常用于降维或者无监督的预训练。</p>
<h3 id="堆叠式自动编码器">3、堆叠式自动编码器</h3>
<p>​ 自动编码器可以有许多个隐藏层，就成为了堆叠式自动编码器（深度自动编码器）。但是我们需要注意不能使编码器太过于强大了。为什么呢？仍然以下述为例：</p>
<p>​ 40，27，25，36，81，57，10，73</p>
<p>​ 1，2，3，4，5，6，7，8，9，10，11，12，13，14，15，16，17</p>
<p>​ 如果编码器太过于强大了，可能他就会准确的记住每一个数字（也就是做了一个简单的一一映射，而没有去学习潜在的模式）。就好比一个记忆力非常好的人看到这两串数字，说我不需要去看这个数字里面到底存在什么样的模式，只要直接背就完了，没有区别。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114205946184.png" alt="image-20220114205946184" style="zoom: 150%;" /></p>
<p>​ 上图是一个常见的堆叠式自动编码器的示意图，往往会是这样一个类三明治结构。下图是一组输入与重构的可视化结果：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210006336.png" /></p>
<p>​ 为了更好的帮助理解自动编码器降维的用处，我们举一个简单的例子：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210017508.png" /></p>
<p>​ 在上图中这样一个简单的自动编码器网络中，其实质就是将一组3维数据通过编码器降到了2维。然后在通过解码器将2维数据重构至3维。实际操作过程中，构建好这样一组自动编码器网络后，你可以先使用解码器将数据降维，然后做一些学习，然后再将数据进行重构，能够帮助进行更好的实例泛化。</p>
<p>​ 同样，为了更好的帮助理解自动编码器用于无监督预训练的用处，我们也举一个简单的例子：</p>
<p>​ 先我们学过如果要处理一个复杂的有监督任务，但是没有很多标记好的数据，那么可以在网上寻找已知的类似任务的神经网络，并且重用其较低层的网络，然后用少量数据对高层网络进行训练即可。这样其就不必从底层特征开始学起，只会重用原有网络的底层特征检测。</p>
<p>​ 讲到这里，应该明白了，自动编码器其实也是同一个原理。刚才说了，自动编码器的第一步是编码器，编码器的本质是寻找数据的潜在表征，那不也就相当于做了底层的特征检测嘛，而且训练数据还是可以不需要标签的。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210030274.png" /></p>
<p>​</p>
<p>​ 所以，如上图所示，如果我们手上有一个大型数据集，但是难受的是大部分的数据都是未标记状态的，只有少数打上了标签。那么我们可以先使用所有的数据来训练一个自动编码器，训练完以后，将编码器部分的网络复制到我们新的神经网络中，然后在此基础上构建高层的神经网络，这样的话只要再用少部分带标记的数据训练一下该神经网络的高层部分就可以得到一个较好的效果了。</p>
<p>### 4、如何训练堆叠式自动编码器：</p>
<p>一般情况下，我们有两种方式可以用于训练自动编码器。</p>
<p>​ 1. 将解码器层的权重与编码器层的权重绑定起来。这样的话可以将模型中整体的训练参数减半，并且加快训练速度并且降低了过拟合的风险。</p>
<ol start="2" type="1">
<li><p>一次训练一个浅层自动编码器然后将他们进行堆叠。（这种技术现在用的较少），示意图如下：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210104140.png" /></p>
<p>​ 示意图本身已经较清楚的讲解了整个过程，我再做一遍简略的讲述。比如说，我们现在要训练最右侧这样一个堆叠式自动编码器，他的编码器部分有两层，我们将其分为两阶段来看这个问题。首先按训练第一个自动编码器，将隐藏层1的参数训练好。然后再训练第二个自动编码器，将隐藏层2的参数训练好。注意，在训练第二个自动编码器的时候，用到的输入其实是训练好的第一个自动编码器将输入编码后的结果。以公式的形式表达的话就是：</p>
<p>​ 我们假设输入为i，第一个自动编码器的编码函数为 <strong>f_encoder1() </strong>,解码函数为<strong>f_decoder1()</strong>,第二个自动编码器的编码函数为<strong>f_encoder2()</strong>,解码函数为<strong>f_decoder2()</strong>。</p>
<p>​ 那么在训练第一个自动编码器的时候，输入为i，重构输出为 <strong>f_decoder1(f_encoder1(i))</strong>。在训练第二个自动编码器的时候，输入为<strong>f_encoder1(i)</strong>，重构输出为<strong>f_decoder2( f_encoder2( f_encoder1(i) ))</strong></p></li>
</ol>
<h3 id="其他类型的自动编码器">5、其他类型的自动编码器</h3>
<p>​ <strong>(1) 卷积自动编码器</strong></p>
<p>​ 用于为图像构建自动编码器。一般编码器层是由卷积层和池化层组成的常规CNN。会减少输入的空间尺寸，增加深度即特征图的数量。解码器则进行相反的操作。</p>
<p>​ <strong>(2)循环自动编码器</strong></p>
<p>​ 用于为序列构建自动编码器，例如时间序列或文本。编码器通常为序列到向量的RNN，能够将输入序列压缩为单个向量。其可以处理任何长度的序列。</p>
<p>​ <strong>(3)去噪自动编码器</strong></p>
<p>​ 到目前为止，为了让自动编码器不过于强大，也就是为了让他学习一些数据的浅层特征，我们通过限制编码曾大小让它成为不完整的自动编码器。其实，我们还可以通过向其输入中添加噪声，训练它来恢复无噪声输入，也可以让其学习数据的有用特征。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210254970.png" /></p>
<p>​ 可以在编码器的输入中叠加高斯噪声，也可以加一层dropout层。去噪编码器不仅可以用于降维数据可视化或者无监督预训练，也可以用于图像去噪。</p>
<p>​ <strong>(4)稀疏自动编码器</strong></p>
<p>​ 使用稀疏性来对编码器进行约束，使其对良好的特征进行提取学习。通过在成本函数中添加适当的函数项，来强迫自动编码器减少编码层中活动神经元的数量。</p>
<p>​ 另一种方法是在每次训练迭代时测量编码层的实际稀疏度，并在测量稀疏度预目标稀疏度不同时对模型进行惩罚。</p>
<p>​ <strong>(5)变分自动编码器</strong></p>
<p>​ 变分自动编码器较为特殊，具体而言有两大特点：</p>
<p>​ <strong>特点1</strong>:概率自动编码器：意思是即使在训练好以后，它们的输出部分也会由概率决定。</p>
<p>​ <strong>特点2</strong>:生成式自动编码器：指它们可以生成看上去像是从训练集中采样的新实例。</p>
<p>​ 在先前讲到的自动编码器中，我们往往以一个数值来表示一个特征维度的值，如下 所示，将人脸图像编码成了一个六维向量，每个维度一个值。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210408918.png" /></p>
<p>​ 在上面的示例中，我们使用单个值来描述输入图像在潜在特征上的表现。但在实际情况中，我们可能更多时候倾向于将每个潜在特征表示为可能值的范围。</p>
<p>​ 而变分自编码器便是用“取值的概率分布”代替原先的单值来描述对特征的观察的模型，如下图的右边部分所示，经过变分自编码器的编码，每张图片的微笑特征不再是自编码器中的单值而是一个概率分布。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210429150.png" /></p>
<p>​ 所以在变分自动编码器中，我们现在将给定输入的每个潜在特征表示为概率分布。当从潜在状态解码时，我们将从每个潜在状态分布中随机采样，生成一个向量作为解码器模型的输入。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210436379.png" /></p>
<p>​ 那么如何训练变分自动编码器呢？其成本函数由应当如何设计？</p>
<p>​ 变分自动编码器学习的是隐变量（特征）Z的概率分布，因此在给定输入数据X的情况下，变分自动编码器的推断网络输出的应该是Z的后验分布p（z|x）。 但是这个p（z|x）后验分布本身是不好求的。所以有学者就想出了使用另一个可伸缩的分布q（z|x）来近似p（z|x）。通过深度网络来学习q（z|x）的参数，一步步优化q使其与p(z|x)十分相似，就可以用它来对复杂的分布进行近似的推理。</p>
<p>​ 这个时候就出现了成本函数的设计理念，成本函数由两部分组成，第一部分是通常的重构损失，我们可以使用交叉熵来衡量。第二部分是潜在损失。它就是上述提到的目标分布q和编码的实际分布p之间的KL散度。通过简化后，就可以得到以下公式：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210448726.png" /></p>
<p>​ L1是潜在损失，n是编码的维度，u(j)和sigma(j) 是第j个分量的均值和标准差。向量u和sigma由编码器进行输出。KL散度及如何通过KL散度推导出简化的公式部分本文进行了省略，详细可以看引用（2）。</p>
<p>​ 最后提一下整个变分自动编码器的网络结构如下：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210503507.png" /></p>
<p>​ 编码器产生平均编码u和标准差sigma，然后实际编码是从u和sigma的高斯分布中进行随机采样之后得到的。解码器正常解码采样得到的编码即可。</p>
<h4 id="一些有趣的应用">一些有趣的应用：</h4>
<p>​ 变分自动编码器使得语义插值成为了可能，可以在编码级别进行插值，而非在数据级别进行插值。总体而言就是如下图所示的一个过程：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114210518169.png" /></p>
<p><strong>文中引用与部分图片来源：</strong></p>
<p>1）《机器学习实战 基于Scikit-learn、keras、tensorflow》机械工业出版社</p>
<p>2） 一文理解变分自编码器（VAE）https://zhuanlan.zhihu.com/p/64485020</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Basic Concepts</tag>
        <tag>Auto Encoder</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记1——One-Hot编码与Word Embedding</title>
    <url>/2021/11/23/3ad8cb19bc7a/</url>
    <content><![CDATA[<h3 id="一one-hot-encoding独热向量">一、One-Hot Encoding独热向量</h3>
<p>​ 独热向量是指使用N位0或1来对N个状态进行编码，每个状态都有它独立的表示形式，并且其中只有一位为1，其他位都为0。</p>
<p>​ 比如我们现在要编码apple，我们用5位向量来进行编码，如下所示：</p>
<ul>
<li><p>apple [1 0 0 0 0]</p></li>
<li><p>bag [0 1 0 0 0]</p></li>
<li><p>cat [0 0 1 0 0]</p></li>
<li><p>dog [0 0 0 1 0]</p></li>
<li><p>elephant [0 0 0 0 1]</p></li>
</ul>
<p>​ 如果我们现在想要编码其他另外的单词，那就需要更多位参与编码，但是这五个单词的编码前5位仍然能够是这样，只不过后面省略号省略的部分都为0罢了。</p>
<p>​ 使用这种独热向量的表示形式能够很好的对各种内容进行编码，但是它并没有考虑编码内容与内容之间的关联。就比如说，在上述例子中，cat，都属于动物，他们之间应当存在联系，apple 和 其它四个内容没有联系。但是，从上述的编码中我们没法看出cat。</p>
<p>​ 同时使用独热向量形成的特征矩阵会非常的稀疏，占用的空间非常的大。</p>
<h3 id="二word-embedding-词嵌入">二、Word Embedding 词嵌入</h3>
<p>​ Word Embedding就是为了解决One-hot编码的缺陷，其用一个向量来对一个词进行表示。其具有很强的表达关联特征的能力。</p>
<p>​ 比如说，我们以如下为例，我们现在要使用两种编码表示公主、王妃</p>
<ol type="1">
<li>使用One-Hot:</li>
</ol>
<p>​ 公主 [1 0]</p>
<p>​ 王妃 [0 1]</p>
<ol start="2" type="1">
<li><p>使用 Word Embedding:</p>
<p>公主 = 0.5 * 皇帝 + 0.125 * 宫里 + 0.5 * 女</p>
<p>王妃 = 0.3 * 皇帝 + 0.375 * 宫里 + 0.5 * 女</p>
<p>​ 因为我们就以三个额外的维度来进行编码，所以两者应当表示为三维的向量。于是，公主表示为 [0.5 0.125 0.5]，王妃表示为 [0.3,0.375,0.5]。这样一来，我们就可以知道公主和王妃在内在中，存在着某种意义上的关联。</p>
<p>​ 当然在上述例子中，系数都是举个例子随便写的，我们想要表达的意思就是，比如我们将要词映射到一个二维的特征空间中，每个词就可以表示成一个二维的点，那么我们就能知道词和词之间存在的某些关系。同理，如果词映射到一个三维的特征空间，那就是表示成三维空间中的一个点。</p>
<p>​ 如下图所示，就是一个直观的例子，我们将这么多词映射到二维空间中，就可以找到它们在二维空间的分布，找到其内在的词与词之间的关系，比如说，在图中我们就看到了三个明显的聚类。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114205646350.png" /></p>
<p>​ 那么Word Embedding一般是怎么做的呢？其就是一个全连接的神经网络层。如下所示：左边是一个以2×6的one-hot矩阵为输入，中间层节点数为3的全连接的神经网络层。从右边可以看出，这个计算过程就相当于从 w i,j 矩阵中取出第1,2行，跟字向量的查表操作是一样的（从表中找出对应的向量）。这样子编码得到的对应向量就是3维的。如果你想要编码得到n维的向量，那么中间层就应该为节点数为n的全连接神经网络层。一般我们在神经网络中看到的Embedding层就是这样子设计的。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114205700989.png" /></p>
<p>因此，Embedding层其实就是以one hot为输入、中间层节点为字向量维数的全连接层！而这个全连接层的参数，就是一个“字向量表”！这其实就是将读热编码后的稀疏矩阵经过一个线性变化（其实就是查表）将其转换成一个密集矩阵的过程。</p>
<p>最后总结一下，Embedding层最终完成的工作：</p>
<ul>
<li>将稀疏矩阵经过线性变换（查表）变成一个密集矩阵</li>
<li>这个密集矩阵用了N个特征来表示所有的词。密集矩阵中表象上是一个词和特征的关系系数，实际上蕴含了大量的词与词之间的内在关系。</li>
<li>它们之间的权重参数，用的是嵌入层学习来的参数进行表征的编码。在神经网络反向传播优化的过程中，这个参数也会不断的更新优化。</li>
</ul></li>
</ol>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Basic Concepts</tag>
        <tag>Info Encoding</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础系列笔记0——常见概念与函数（更新中）</title>
    <url>/2021/11/22/6afd3e085246/</url>
    <content><![CDATA[<h3 id="softmax和cross-entropy交叉熵函数">1、SoftMax和Cross-Entropy交叉熵函数</h3>
<p>​ 我们常常使用交叉熵（cross entropy）来进行判别分布的相似性，交叉熵公式如下图所示：公式中pi和qi<img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/wpsCF9D.tmp.jpg" alt="img" />为真实的样本分布和生成器的生成分布。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114201037115.png" /></p>
<p>​ <strong><em>*Soft-Max*</em></strong>内部对输入进行的处理如下图所示，我们假设输入y1,y2,y3，我们先将三个输入计算exp(y1),exp(y2),exp(y3),然后求和，然后计算输出。</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114201047994.png" /></p>
<h3 id="kl散度">2、KL散度</h3>
<h3 id="sigmoid-function-s型激活函数">3、Sigmoid Function ( S型激活函数 )</h3>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114201125789.png" /></p>
<h3 id="rectified-linear-unit-relu激活函数">4、Rectified Linear Unit ( ReLu激活函数 )</h3>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114201156330.png" alt="image-20220114201156330" /><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114201159496.png" /></p>
<h3 id="update-epoch-batch-size-training-data">5、Update / Epoch / Batch Size / Training Data<br />
</h3>
<ul>
<li><p><strong>Update</strong>: 每做一次梯度下降，更新一次参数，就叫做一次Update</p></li>
<li><p><strong>Batch Size</strong>: 每次用来计算梯度下降更新参数用到的训练集中样本的个数</p></li>
<li><p><strong>Training Data</strong>: 所有的训练数据集样本，我们在训练时往往会将其分为一个Batch一个Batch，每次使用一个Batch来计算梯度，更新参数。</p></li>
<li><p><strong>Epoch</strong>: 每当使用过一轮所有的训练数据集样本以后，叫做一个Epoch</p></li>
</ul>
<p>整个的Optimization的过程如下所示：</p>
<p>​ <img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114201333605.png" /></p>
<p>下面是一些帮助理解的例子：</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220114201341888.png" /></p>
<h3 id="backbone-head-neck-bottleneck">6、BackBone / Head / Neck / BottleNeck</h3>
<ul>
<li>BackBone：翻译为主干网络，其是神经网络的主干部分。这个主干网络大多时候指的是提取特征的网络，其作用就是提取图片中的信息，以供后面的网络使用。这些网络经常使用的是ResNet、VGG等，而不是由我们自己设计的网络，因为这些主干网络已经证明了它们在分类等问题上的特征提取能力是很强的。在用这些网络作为backbone的时候，都是直接加载官方已经训练好的模型参数，后面接着我们自己的网络。让网络的这两个部分同时进行训练，因为加载的backbone模型已经具有提取特征的能力了，在我们的训练过程中，会对参数进行微调，使得其更适合于我们自己的任务。</li>
<li>Head：是获取网络输出内容的网络，head利用之前网络提取的这些特征，做出预测。</li>
<li>Neck: 是放在Backbone和Head之间的，是为了更好的利用Backbone提取的特征</li>
<li>Bottleneck: 瓶颈，通常指的是网络输入的数据维度和输出的维度不同，输出的维度比输入的小了许多.</li>
</ul>
<h3 id="ablation-study">7、Ablation Study</h3>
<p>​ 消融研究，消融研究通常是指删除模型或算法的某些“功能”，并查看其如何影响性能。</p>
<p>​ 在论文中一般来说会提出多个创新方法，或者新型结构模块，或注意力模块等。这些东西在一起为模型的性能作出了贡献。然而为了了解每个部分单独能发挥的作用，常常会在论文中提出消融研究。</p>
<p>​ 例如某论文提出了方法A,B,C。而该论文是基于某个baseline的改进。因此，在消融研究部分，会进行以下实验，baseline ，baseline+A，baseline+B, baseline+C, baseline+A+B+C等实验的各个评价指标有多少，从而得出每个部分所能发挥的作用有多大。</p>
<p>​ 比较简单来说，就是控制变量法，来判断某一个模块是否真的有作用。</p>
]]></content>
      <categories>
        <category>⓵ 深度学习笔记</category>
        <category>Basic系列笔记</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Basic Concepts</tag>
      </tags>
  </entry>
</search>
